{"parentUuid":null,"isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","type":"progress","data":{"type":"hook_progress","hookEvent":"SessionStart","hookName":"SessionStart:startup","command":"entire hooks claude-code session-start"},"parentToolUseID":"daf366be-adb9-4703-aa56-30d0107ce06c","toolUseID":"daf366be-adb9-4703-aa56-30d0107ce06c","timestamp":"2026-02-21T08:02:47.896Z","uuid":"dc450745-0984-4222-bb21-ed7f2a3d4c43"}
{"type":"file-history-snapshot","messageId":"56849ec2-c01a-4b8e-8ae1-544094623784","snapshot":{"messageId":"56849ec2-c01a-4b8e-8ae1-544094623784","trackedFileBackups":{},"timestamp":"2026-02-21T08:02:58.343Z"},"isSnapshotUpdate":false}
{"parentUuid":"dc450745-0984-4222-bb21-ed7f2a3d4c43","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","type":"user","message":{"role":"user","content":"did you read the claude.md"},"uuid":"56849ec2-c01a-4b8e-8ae1-544094623784","timestamp":"2026-02-21T08:02:54.766Z","todos":[],"permissionMode":"default"}
{"parentUuid":"56849ec2-c01a-4b8e-8ae1-544094623784","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","message":{"model":"claude-sonnet-4-6","id":"msg_01KLqHo9HUW8xv2oJtuUHhsk","type":"message","role":"assistant","content":[{"type":"text","text":"Yes, I've read the CLAUDE.md. It's loaded automatically into my context at the start of every conversation via the system reminder.\n\nIt covers:\n- **Project overview**: AI-powered code review platform (BugViper)\n- **Tech stack**: FastAPI + Neo4j + Tree-sitter backend, Next.js 16 frontend\n- **Project structure**: All major directories and their roles\n- **Commands**: How to run backend, frontend, tests, linting\n- **Conventions**: Python (Black/Ruff/100 chars) and TypeScript (strict mode)\n- **Architecture**: Graph schema, search tiers, API endpoints, cost pitfalls\n\nAnything specific you want to work on?"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":8873,"cache_read_input_tokens":16433,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":8873},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLs91bRCqyiV3xYEcgG4","type":"assistant","uuid":"c2ef5ade-2e8a-40e6-9336-bb3467213f65","timestamp":"2026-02-21T08:03:03.261Z"}
{"parentUuid":"c2ef5ade-2e8a-40e6-9336-bb3467213f65","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"6f38e5c6-4e14-411c-a515-be5638724a1f","toolUseID":"6f38e5c6-4e14-411c-a515-be5638724a1f","timestamp":"2026-02-21T08:03:03.310Z","uuid":"01321bd6-b07c-40fb-a072-64584a79b734"}
{"parentUuid":"01321bd6-b07c-40fb-a072-64584a79b734","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":1514}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-21T08:03:04.825Z","uuid":"a19273c6-3abf-4e1d-8f66-88878347da66","toolUseID":"6f38e5c6-4e14-411c-a515-be5638724a1f"}
{"type":"file-history-snapshot","messageId":"c24e474a-29dd-4bc8-afe3-07caafdf094e","snapshot":{"messageId":"c24e474a-29dd-4bc8-afe3-07caafdf094e","trackedFileBackups":{},"timestamp":"2026-02-21T08:05:38.177Z"},"isSnapshotUpdate":false}
{"parentUuid":"a19273c6-3abf-4e1d-8f66-88878347da66","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","type":"user","message":{"role":"user","content":"curl 'http://localhost:8000/api/v1/query/search?query=class%20LoginRequest(BaseModel)%3A' \\\n  -H 'Accept: */*' \\\n  -H 'Accept-Language: en-US,en;q=0.9' \\\n  -H 'Authorization: Bearer REDACTED.REDACTED.REDACTED' \\\n  -H 'Connection: keep-alive' \\\n  -H 'Content-Type: application/json' \\\n  -H 'Origin: http://localhost:3000' \\\n  -H 'Referer: http://localhost:3000/' \\\n  -H 'Sec-Fetch-Dest: empty' \\\n  -H 'Sec-Fetch-Mode: cors' \\\n  -H 'Sec-Fetch-Site: same-site' \\\n  -H 'User-Agent: Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/145.0.0.0 Mobile Safari/537.36' \\\n  -H 'sec-ch-ua: \"Chromium\";v=\"145\", \"Not:A-Brand\";v=\"99\"' \\\n  -H 'sec-ch-ua-mobile: ?1' \\\n  -H 'sec-ch-ua-platform: \"Android\"' the Full text Search is not working , it should point out the lines and file and give us way to query 10+ lines up and 10+ lines down and in the ui add it as well . curl 'http://localhost:8000/api/v1/query/search-symbols?query=class%20LoginRequest(BaseModel)%3A' \\\n  -H 'Accept: */*' \\\n  -H 'Accept-Language: en-US,en;q=0.9' \\\n  -H 'Authorization: Bearer REDACTED.REDACTED.REDACTED' \\\n  -H 'Connection: keep-alive' \\\n  -H 'Content-Type: application/json' \\\n  -H 'Origin: http://localhost:3000' \\\n  -H 'Referer: http://localhost:3000/' \\\n  -H 'Sec-Fetch-Dest: empty' \\\n  -H 'Sec-Fetch-Mode: cors' \\\n  -H 'Sec-Fetch-Site: same-site' \\\n  -H 'User-Agent: Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/145.0.0.0 Mobile Safari/537.36' \\\n  -H 'sec-ch-ua: \"Chromium\";v=\"145\", \"Not:A-Brand\";v=\"99\"' \\\n  -H 'sec-ch-ua-mobile: ?1' \\\n  -H 'sec-ch-ua-platform: \"Android\"'{\n    \"detail\": \"Symbol search failed: {neo4j_code: Neo.ClientError.Procedure.ProcedureCallFailed} {message: Failed to invoke procedure `db.index.fulltext.queryNodes`: Caused by: org.apache.lucene.queryparser.classic.ParseException: Encountered \\\" \\\":\\\" \\\": \\\"\\\" at line 1, column 29.\\nWas expecting one of:\\n    <EOF> \\n    <AND> ...\\n    <OR> ...\\n    <NOT> ...\\n    \\\"+\\\" ...\\n    \\\"-\\\" ...\\n    <BAREOPER> ...\\n    \\\"(\\\" ...\\n    \\\"*\\\" ...\\n    \\\"^\\\" ...\\n    <QUOTED> ...\\n    <TERM> ...\\n    <PREFIXTERM> ...\\n    <WILDTERM> ...\\n    <REGEXPTERM> ...\\n    \\\"[\\\" ...\\n    \\\"{\\\" ...\\n    <NUMBER> ...\\n    } {gql_status: 52N37} {gql_status_description: error: procedure exception - procedure execution error. Execution of the procedure db.index.fulltext.queryNodes() failed.}\"\n} symbol search failed as well . "},"uuid":"c24e474a-29dd-4bc8-afe3-07caafdf094e","timestamp":"2026-02-21T08:05:34.932Z","todos":[],"permissionMode":"default"}
{"parentUuid":"c24e474a-29dd-4bc8-afe3-07caafdf094e","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","message":{"model":"claude-sonnet-4-6","id":"msg_01NzHvqLrBjdapHHnL6GVDwB","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The user is reporting two issues:\n1. Full-text search is not working properly - it should point out lines and files, and allow querying 10+ lines up and down\n2. Symbol search is failing with a Lucene parse error when the query contains special characters like `class LoginRequest(BaseModel):`\n\nThe Lucene parse error is because the query `class LoginRequest(BaseModel):` contains special characters like `(`, `)`, `:` which are Lucene syntax characters and need to be escaped.\n\nLet me look at the current search implementation to understand what's happening and what needs to be fixed.\n\nKey files to look at:\n- `db/queries.py` - CodeQueryService (search, stats, CRUD)\n\n\n- `api/routers/query.py` - search endpoints\n- `api/services/code_search.py` - CodeFinder class\n- Frontend: `frontend/app/(protected)/query/page.tsx`\n\nLet me read the relevant files to see how the search is currently implemented.","signature":"EvIHCkYICxgCKkAtNbWJEUr+gxKbRRudYuFokBaocFEaleyhwyFR1kiHfwfWTDokrAaFCltpdHz1gp//s5ub5Q7scwVTcdOaE5qZEgye5zsZLJSZcsX19y4aDBtzzSyPoQadLuAETiIwtxMp6mMnjdQQfK6g8l5+ZfL5xtXxbTg91ahEl2OOEFHhl98DMxkLQsQYzOz9bA0JKtkGmM7AxBdeO6HPIqqN5dGhWIXbVs4VxEU7smYfft+sxFJwezqirMu5HEj/sx3+1druxyvjvcz5VoC8qbNulEqSt+5O5e6gKkNX0TiWUWTMI+zmCvZ9SF6ZZIumvdmBy27z4BNKDZow4Gr16r0zIyT7nLdbKAs2P3xMEjgRon/lSwXiMn9bUbCSkBuc3tR0EoAVP44yOeuj3Mw4HntW7AHYtrek9alCAUGa10mBV6tnKNj/n5/WLNtmToP8jLnd5bONp5b2olLK/M5+EtztvkNa6KOKM+/beNJSOlW4yYJMwzCz9udfU9Bp6eF6oPH+bc8V7LB9y/e3+EFinXFM5SErCbRQMRxu6N3J0L/7VEUcFi435YcyvPO2nQEX2Ey2avTBG3VNqCTZezsm/Z0VrzWWTkmjqSFb6uptPtJ493NuZIK8k5oXBNnfkPRPWga/uU2U9SYHNP5lV4zdybIJOn5OKjvksSRv/evcwT4ii0Img0O3X8YieROi+hBdbzFYFLNUpeP1MUEPfAVI9eEOfk4Iw+Wi4GODRfYNdxP9EQOcLDxgOJwFUHxhJRE2Ui+wpoYjwG74o6Ij5B/7E/ECGBC+vt2JE9ip2xJcrPVRWTaCUM3wLN2G8p7kDNupNLZezpSDjtQ4oMcwsoT5U7u0XkO7he8PigaTjcXcMLjruWfIwjwF+jOPjOayBDMJP8hb9nicn8StCV1laVMY5PBEon3Chg7RDGYPmLXHKnvJGOTBEJ8WZwJwJhNZGNL9e+jPnw2mKsnOuX6QfWQm1/IpK8v2i/ZD41UvkQ5ZCRMfNoFm0wHfWVuygVHnIfmfmz6JAMyLhhbEoU9+LAEBP9RtIxsnf2yV7q32acvpUP+VAoRTNqLnEDaldpvrEi5RmiJeEiKe6RTScR9LN3j6zjXbrE3mAp1jIt3XUFx6A81H6H8ICluk+pHwUmwfjRY3hSGlik5ixphMHrIO336wImlSsY5yiP/Ot6dID7THllAp06LlJdCmsd5AyX/AYkyD7QykASOntRLANJadsB/H32HTwWK99PREWtIFwT6PAWKJ1m2vo9SptOdQIwElR7j+XSmgtz2urNFbjOqg+bLQie+jmdwHr3vrKgRiPzQtIi3JunA/9Ri/agVjI0zRedIYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":3105,"cache_read_input_tokens":25306,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3105},"output_tokens":6,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsLmgqLruEXwQ1jHnVx","type":"assistant","uuid":"69ec4f99-7927-4cdc-9dc8-42c008a8b890","timestamp":"2026-02-21T08:05:45.140Z"}
{"parentUuid":"69ec4f99-7927-4cdc-9dc8-42c008a8b890","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","message":{"model":"claude-sonnet-4-6","id":"msg_01NzHvqLrBjdapHHnL6GVDwB","type":"message","role":"assistant","content":[{"type":"text","text":"Let me read the relevant files to understand the current state."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":3105,"cache_read_input_tokens":25306,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3105},"output_tokens":6,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsLmgqLruEXwQ1jHnVx","type":"assistant","uuid":"e7dab556-38eb-4983-8aa2-451827cec434","timestamp":"2026-02-21T08:05:45.174Z"}
{"parentUuid":"e7dab556-38eb-4983-8aa2-451827cec434","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01NzHvqLrBjdapHHnL6GVDwB","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JZNLPDwceUHeKEb1EZcz7h","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/db/queries.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":3105,"cache_read_input_tokens":25306,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3105},"output_tokens":6,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsLmgqLruEXwQ1jHnVx","type":"assistant","uuid":"42035809-e451-493c-930a-51d9789023a9","timestamp":"2026-02-21T08:05:45.855Z"}
{"parentUuid":"42035809-e451-493c-930a-51d9789023a9","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01NzHvqLrBjdapHHnL6GVDwB","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0122TktPqNpW6a6aUR4Nw5ZW","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":3105,"cache_read_input_tokens":25306,"output_tokens":379,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":3105,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLsLmgqLruEXwQ1jHnVx","type":"assistant","uuid":"f7103b1d-54fe-4495-b2d1-b9d2ab8acc2e","timestamp":"2026-02-21T08:05:46.193Z"}
{"parentUuid":"f7103b1d-54fe-4495-b2d1-b9d2ab8acc2e","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01JZNLPDwceUHeKEb1EZcz7h","toolUseID":"toolu_01JZNLPDwceUHeKEb1EZcz7h","timestamp":"2026-02-21T08:05:46.277Z","uuid":"b7c3614c-d8a6-4dee-a83e-2e5076fb0bac"}
{"parentUuid":"42035809-e451-493c-930a-51d9789023a9","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JZNLPDwceUHeKEb1EZcz7h","type":"tool_result","content":"     1→\n     2→\n     3→from typing import Dict, List, Any, Optional\n     4→import re\n     5→import logging\n     6→\n     7→from .client import Neo4jClient\n     8→from .schema import CYPHER_QUERIES\n     9→\n    10→logger = logging.getLogger(__name__)\n    11→\n    12→class CodeQueryService:\n    13→    \"\"\"\n    14→    Service for querying code elements from the Neo4j graph.\n    15→    \n    16→    Provides methods for:\n    17→    - Finding method/function usages and callers\n    18→    - Analyzing class hierarchies\n    19→    - Searching code by name or content\n    20→    - Reconstructing files from the graph\n    21→    \"\"\"\n    22→    \n    23→    def __init__(self, client: Neo4jClient):\n    24→        self.db = client\n    25→    \n    26→    # =========================================================================\n    27→    # Graph Statistics\n    28→    # =========================================================================\n    29→    \n    30→    def get_graph_stats(self) -> Dict[str, int]:\n    31→        \"\"\"Get statistics about the code graph.\"\"\"\n    32→        query = CYPHER_QUERIES[\"get_graph_stats\"]\n    33→        records, _, _ = self.db.run_query(query)\n    34→        \n    35→        if records:\n    36→            return dict(records[0])\n    37→        return {}\n    38→\n    39→    def list_repositories(self) -> List[Dict[str, Any]]:\n    40→        \"\"\"List all repositories in the database.\"\"\"\n    41→        query = \"\"\"\n    42→        MATCH (r:Repository)\n    43→        OPTIONAL MATCH (r)-[:CONTAINS*]->(f:File)\n    44→        RETURN r.id as id, r.name as name, r.owner as owner,\n    45→               r.url as url, r.path as local_path,\n    46→               r.last_commit_hash as last_commit,\n    47→               r.created_at as created_at,\n    48→               r.updated_at as updated_at,\n    49→               count(DISTINCT f) as file_count\n    50→        ORDER BY r.updated_at DESC, r.name\n    51→        \"\"\"\n    52→        records, _, _ = self.db.run_query(query)\n    53→        \n    54→        def convert_datetime(value):\n    55→            \"\"\"Convert Neo4j DateTime to ISO string format.\"\"\"\n    56→            if value is None:\n    57→                return None\n    58→            # Check if it's a Neo4j DateTime object\n    59→            if hasattr(value, 'iso_format'):\n    60→                return value.iso_format()\n    61→            # If it's already a string or other type, return as is\n    62→            return str(value) if value is not None else None\n    63→        \n    64→        return [\n    65→            {\n    66→                \"id\": record.get(\"id\"),\n    67→                \"name\": record.get(\"name\"),\n    68→                \"owner\": record.get(\"owner\"),\n    69→                \"url\": record.get(\"url\"),\n    70→                \"local_path\": record.get(\"local_path\"),\n    71→                \"last_commit\": record.get(\"last_commit\"),\n    72→                \"created_at\": convert_datetime(record.get(\"created_at\")),\n    73→                \"updated_at\": convert_datetime(record.get(\"updated_at\")),\n    74→                \"file_count\": record.get(\"file_count\") or 0\n    75→            }\n    76→            for record in records\n    77→        ]\n    78→\n    79→    def delete_repository(self, repo_id: str) -> bool:\n    80→        \"\"\"Delete a repository and all its associated data.\"\"\"\n    81→        try:\n    82→            query = \"\"\"\n    83→            MATCH (r:Repository)\n    84→            WHERE r.id = $repo_id OR r.repo = $repo_id\n    85→            OPTIONAL MATCH (r)-[:CONTAINS*]->(n)\n    86→            DETACH DELETE r, n\n    87→            RETURN count(r) as deleted_count\n    88→            \"\"\"\n    89→            records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n    90→            return records and records[0][\"deleted_count\"] > 0\n    91→        except Exception as e:\n    92→            logger.error(\"Error deleting repository %s: %s\", repo_id, e)\n    93→            return False\n    94→    \n    95→    def get_repository_stats(self, repo_id: str) -> Dict[str, Any]:\n    96→        \"\"\"Get statistics for a specific repository.\"\"\"\n    97→        if not self.db.connected:\n    98→            # Return mock stats\n    99→            return {\n   100→                \"files\": 25,\n   101→                \"classes\": 12,\n   102→                \"functions\": 89,\n   103→                \"methods\": 156,\n   104→                \"lines\": 3420,\n   105→                \"imports\": 67,\n   106→                \"languages\": [\"Python\", \"TypeScript\", \"JavaScript\"]\n   107→            }\n   108→            \n   109→        query = CYPHER_QUERIES[\"get_repo_stats\"]\n   110→        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n   111→        \n   112→        if records:\n   113→            record = records[0]\n   114→            return {\n   115→                \"files\": record[\"file_count\"],\n   116→                \"classes\": record[\"class_count\"],\n   117→                \"functions\": record[\"function_count\"],\n   118→                \"methods\": record[\"method_count\"],\n   119→                \"lines\": record[\"line_count\"],\n   120→                \"imports\": record[\"import_count\"],\n   121→                \"languages\": record[\"languages\"]\n   122→            }\n   123→        return {}\n   124→    \n   125→    # =========================================================================\n   126→    # Method and Function Queries\n   127→    # =========================================================================\n   128→    \n   129→    def find_method_usages(self, method_name: str) -> Dict[str, Any]:\n   130→        \"\"\"Find all usages of a method by name.\"\"\"\n   131→        query = CYPHER_QUERIES[\"find_method_usages\"]\n   132→        records, _, _ = self.db.run_query(query, {\"method_name\": method_name})\n   133→\n   134→        results = []\n   135→        for record in records:\n   136→            # Convert Neo4j Node objects to dictionaries for JSON serialization\n   137→            callers = []\n   138→            for caller_dict in record[\"callers\"]:\n   139→                if caller_dict and caller_dict.get(\"caller\"):\n   140→                    callers.append({\n   141→                        \"caller\": dict(caller_dict[\"caller\"]) if hasattr(caller_dict[\"caller\"], \"__iter__\") and not isinstance(caller_dict[\"caller\"], str) else {\"name\": str(caller_dict[\"caller\"])},\n   142→                        \"line\": caller_dict.get(\"line\")\n   143→                    })\n   144→\n   145→            references = []\n   146→            for ref_dict in record[\"references\"]:\n   147→                if ref_dict and ref_dict.get(\"line\"):\n   148→                    references.append({\n   149→                        \"line\": dict(ref_dict[\"line\"]) if hasattr(ref_dict[\"line\"], \"__iter__\") and not isinstance(ref_dict[\"line\"], str) else {\"line\": str(ref_dict[\"line\"])},\n   150→                        \"col_start\": ref_dict.get(\"col_start\")\n   151→                    })\n   152→\n   153→            results.append({\n   154→                \"method\": dict(record[\"m\"]) if record[\"m\"] else None,\n   155→                \"callers\": callers,\n   156→                \"references\": references\n   157→            })\n   158→        return {\"usages\": results}\n   159→    \n   160→    def find_method_context(self, method_id: str) -> Dict[str, Any]:\n   161→        \"\"\"Find the full context of a method (class, file, repo, user).\"\"\"\n   162→        query = CYPHER_QUERIES[\"find_method_context\"]\n   163→        records, _, _ = self.db.run_query(query, {\"method_id\": method_id})\n   164→        \n   165→        if records:\n   166→            record = records[0]\n   167→            return {\n   168→                \"user\": record[\"user\"],\n   169→                \"repo\": record[\"repo\"],\n   170→                \"file\": record[\"file\"],\n   171→                \"class\": record[\"class_name\"],\n   172→                \"method\": record[\"method\"],\n   173→                \"lines\": f\"{record['start_line']}-{record['end_line']}\"\n   174→            }\n   175→        return {}\n   176→    \n   177→    def find_callers(self, symbol_name: str) -> List[Dict[str, Any]]:\n   178→        \"\"\"Find all methods/functions that call a specific symbol.\"\"\"\n   179→        query = CYPHER_QUERIES[\"find_callers\"]\n   180→        records, _, _ = self.db.run_query(query, {\"name\": symbol_name})\n   181→        \n   182→        return [\n   183→            {\n   184→                \"caller\": record[\"caller_name\"],\n   185→                \"type\": record[\"caller_type\"],\n   186→                \"file\": record[\"file_path\"],\n   187→                \"line\": record[\"call_line\"]\n   188→            }\n   189→            for record in records\n   190→        ]\n   191→    \n   192→    # =========================================================================\n   193→    # Class Queries\n   194→    # =========================================================================\n   195→    \n   196→    def get_class_hierarchy(self, class_name: str) -> Dict[str, Any]:\n   197→        \"\"\"Get the inheritance hierarchy of a class.\"\"\"\n   198→        query = CYPHER_QUERIES[\"get_class_hierarchy\"]\n   199→        records, _, _ = self.db.run_query(query, {\"class_name\": class_name})\n   200→        \n   201→        if records:\n   202→            record = records[0]\n   203→            return {\n   204→                \"class\": dict(record[\"c\"]) if record[\"c\"] else None,\n   205→                \"ancestors\": [dict(n) for n in record[\"ancestors\"]] if record[\"ancestors\"] else [],\n   206→                \"descendants\": [dict(n) for n in record[\"descendants\"]] if record[\"descendants\"] else []\n   207→            }\n   208→        return {}\n   209→    \n   210→    # =========================================================================\n   211→    # File Queries\n   212→    # =========================================================================\n   213→    \n   214→    def get_file_structure(self, file_id: str) -> Dict[str, Any]:\n   215→        \"\"\"Get the structure of a file (classes, functions, imports).\"\"\"\n   216→        query = CYPHER_QUERIES[\"get_file_structure\"]\n   217→        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n   218→        \n   219→        if records:\n   220→            record = records[0]\n   221→            return {\n   222→                \"file\": dict(record[\"f\"]) if record[\"f\"] else None,\n   223→                \"classes\": record[\"classes\"],\n   224→                \"functions\": [dict(f) for f in record[\"functions\"]] if record[\"functions\"] else [],\n   225→                \"imports\": [dict(i) for i in record[\"imports\"]] if record[\"imports\"] else []\n   226→            }\n   227→        return {}\n   228→    \n   229→    def get_repo_overview(self, repo_id: str) -> Dict[str, Any]:\n   230→        \"\"\"Get an overview of a repository.\"\"\"\n   231→        if not self.db.connected:\n   232→            # Return mock overview\n   233→            return {\n   234→                \"repo\": {\n   235→                    \"id\": repo_id,\n   236→                    \"name\": repo_id.split(\"/\")[-1] if \"/\" in repo_id else repo_id,\n   237→                    \"owner\": repo_id.split(\"/\")[0] if \"/\" in repo_id else \"unknown\"\n   238→                },\n   239→                \"files\": 25,\n   240→                \"classes\": 12,\n   241→                \"functions\": 89,\n   242→                \"languages\": [\"Python\", \"TypeScript\", \"JavaScript\"]\n   243→            }\n   244→            \n   245→        query = CYPHER_QUERIES[\"get_repo_overview\"]\n   246→        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n   247→        \n   248→        if records:\n   249→            record = records[0]\n   250→            return {\n   251→                \"repo\": record[\"repo\"],\n   252→                \"files\": record[\"file_count\"],\n   253→                \"classes\": record[\"class_count\"],\n   254→                \"functions\": record[\"function_count\"],\n   255→                \"languages\": record[\"languages\"]\n   256→            }\n   257→        return {}\n   258→    \n   259→    def get_repo_files(self, repo_id: str) -> List[Dict[str, Any]]:\n   260→        \"\"\"Get all files in a repository.\"\"\"\n   261→        query = CYPHER_QUERIES[\"get_repo_files\"]\n   262→        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n   263→        \n   264→        return [\n   265→            {\n   266→                \"file\": dict(record[\"f\"]) if record[\"f\"] else None,\n   267→                \"language\": record[\"language\"],\n   268→                \"lines_count\": record[\"lines_count\"]\n   269→                \n   270→            }\n   271→            for record in records\n   272→        ]\n   273→    \n   274→    # =========================================================================\n   275→    # Search Operations\n   276→    # =========================================================================\n   277→    \n   278→    def _escape_lucene_query(self, query: str) -> str:\n   279→        \"\"\"\n   280→        Escape Lucene special characters in search query.\n   281→\n   282→        Strategy: Wrap the entire query in quotes to treat it as a literal phrase search.\n   283→        This prevents Lucene from interpreting special characters.\n   284→\n   285→        For complex queries, users can use wildcards: *\n   286→        \"\"\"\n   287→        query = query.strip()\n   288→\n   289→        # If query is empty, return a wildcard\n   290→        if not query:\n   291→            return '*'\n   292→\n   293→        # If the query already has quotes, escape internal quotes\n   294→        if '\"' in query:\n   295→            # Escape any existing quotes and wrap in quotes\n   296→            query = query.replace('\"', '\\\\\"')\n   297→\n   298→        # Wrap in quotes to make it a literal phrase search\n   299→        # This treats special characters as literals\n   300→        return f'\"{query}\"'\n   301→\n   302→    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n   303→        \"\"\"Search for code by name or docstring.\"\"\"\n   304→        # Escape Lucene special characters to prevent query parsing errors\n   305→        escaped_term = self._escape_lucene_query(search_term)\n   306→\n   307→        query = CYPHER_QUERIES[\"search_code\"]\n   308→        records, _, _ = self.db.run_query(query, {\"search_term\": escaped_term})\n   309→\n   310→        return [\n   311→            {\n   312→                \"node\": dict(record[\"node\"]) if record[\"node\"] else None,\n   313→                \"type\": record[\"type\"],\n   314→                \"file\": record[\"file\"],\n   315→                \"score\": record[\"score\"]\n   316→            }\n   317→            for record in records\n   318→        ]\n   319→\n   320→    def search_symbols(\n   321→        self,\n   322→        search_term: str,\n   323→        limit: int = 20\n   324→    ) -> List[Dict[str, Any]]:\n   325→        \"\"\"\n   326→        Search symbols using fulltext index.\n   327→\n   328→        Args:\n   329→            search_term: Search query (supports fuzzy matching)\n   330→            limit: Maximum results to return\n   331→\n   332→        Returns:\n   333→            List of matching symbols with scores\n   334→        \"\"\"\n   335→        query = CYPHER_QUERIES[\"search_symbols\"]\n   336→        records, _, _ = self.db.run_query(query, {\n   337→            \"search_term\": search_term,\n   338→            \"limit\": limit\n   339→        })\n   340→\n   341→        return [\n   342→            {\n   343→                \"name\": record[\"name\"],\n   344→                \"qualified_name\": record[\"qualified_name\"],\n   345→                \"type\": record[\"type\"],\n   346→                \"file_id\": record[\"file_id\"],\n   347→                \"line\": record[\"line\"],\n   348→                \"visibility\": record[\"visibility\"],\n   349→                \"score\": record[\"score\"]\n   350→            }\n   351→            for record in records\n   352→        ]\n   353→\n   354→    def find_symbol_by_qualified_name(\n   355→        self,\n   356→        qualified_name: str,\n   357→        repo_id: str\n   358→    ) -> Optional[Dict[str, Any]]:\n   359→        \"\"\"\n   360→        Find a symbol by its exact qualified name.\n   361→\n   362→        Args:\n   363→            qualified_name: Full qualified name (e.g., module.Class.method)\n   364→            repo_id: Repository ID to search in\n   365→\n   366→        Returns:\n   367→            Symbol information if found\n   368→        \"\"\"\n   369→        query = CYPHER_QUERIES[\"search_symbols_by_qualified_name\"]\n   370→        records, _, _ = self.db.run_query(query, {\n   371→            \"qualified_name\": qualified_name,\n   372→            \"repo_id\": repo_id\n   373→        })\n   374→\n   375→        if records:\n   376→            record = records[0]\n   377→            return {\n   378→                \"id\": record[\"id\"],\n   379→                \"name\": record[\"name\"],\n   380→                \"qualified_name\": record[\"qualified_name\"],\n   381→                \"type\": record[\"type\"],\n   382→                \"file_id\": record[\"file_id\"],\n   383→                \"line_start\": record[\"line_start\"],\n   384→                \"line_end\": record[\"line_end\"],\n   385→                \"scope\": record[\"scope\"],\n   386→                \"visibility\": record[\"visibility\"],\n   387→                \"docstring\": record[\"docstring\"]\n   388→            }\n   389→        return None\n   390→\n   391→    def autocomplete_symbols(\n   392→        self,\n   393→        prefix: str,\n   394→        repo_id: str,\n   395→        limit: int = 20\n   396→    ) -> List[Dict[str, Any]]:\n   397→        \"\"\"\n   398→        Get symbol autocomplete suggestions.\n   399→\n   400→        Args:\n   401→            prefix: Prefix to match (e.g., \"module.Clas\")\n   402→            repo_id: Repository ID\n   403→            limit: Maximum results\n   404→\n   405→        Returns:\n   406→            List of matching symbol qualified names\n   407→        \"\"\"\n   408→        query = CYPHER_QUERIES[\"autocomplete_symbols\"]\n   409→        records, _, _ = self.db.run_query(query, {\n   410→            \"prefix\": prefix,\n   411→            \"repo_id\": repo_id,\n   412→            \"limit\": limit\n   413→        })\n   414→\n   415→        return [\n   416→            {\n   417→                \"qualified_name\": record[\"qualified_name\"],\n   418→                \"type\": record[\"type\"],\n   419→                \"visibility\": record[\"visibility\"],\n   420→                \"file_id\": record[\"file_id\"]\n   421→            }\n   422→            for record in records\n   423→        ]\n   424→\n   425→    def find_symbols_in_scope(\n   426→        self,\n   427→        file_id: str,\n   428→        scope: str = \"module\"\n   429→    ) -> List[Dict[str, Any]]:\n   430→        \"\"\"\n   431→        Find all symbols in a specific scope.\n   432→\n   433→        Args:\n   434→            file_id: File ID to search in\n   435→            scope: Scope type (module, class, function)\n   436→\n   437→        Returns:\n   438→            List of symbols in the scope\n   439→        \"\"\"\n   440→        query = CYPHER_QUERIES[\"find_symbols_in_scope\"]\n   441→        records, _, _ = self.db.run_query(query, {\n   442→            \"file_id\": file_id,\n   443→            \"scope\": scope\n   444→        })\n   445→\n   446→        return [\n   447→            {\n   448→                \"name\": record[\"name\"],\n   449→                \"qualified_name\": record[\"qualified_name\"],\n   450→                \"type\": record[\"type\"],\n   451→                \"line_start\": record[\"line_start\"],\n   452→                \"visibility\": record[\"visibility\"]\n   453→            }\n   454→            for record in records\n   455→        ]\n   456→    \n   457→    def find_symbol_definition(self, symbol_name: str, repo_id: str) -> List[Dict[str, Any]]:\n   458→        \"\"\"Find where a symbol (class, function, method, variable) is defined.\"\"\"\n   459→        query = \"\"\"\n   460→        MATCH (symbol)\n   461→        WHERE symbol.name = $symbol_name\n   462→          AND (symbol.file_id STARTS WITH $repo_id OR symbol.class_id STARTS WITH $repo_id)\n   463→        MATCH (f:File)-[:DEFINES*1..2]->(symbol)\n   464→        RETURN symbol.name as name, labels(symbol)[0] as type,\n   465→               f.path as file, symbol.line_start as line,\n   466→               symbol.docstring as docstring, symbol.source_code as source_code\n   467→        \"\"\"\n   468→        records, _, _ = self.db.run_query(query, {\n   469→            \"symbol_name\": symbol_name,\n   470→            \"repo_id\": repo_id\n   471→        })\n   472→\n   473→        return [\n   474→            {\n   475→                \"name\": record[\"name\"],\n   476→                \"type\": record[\"type\"],\n   477→                \"file\": record[\"file\"],\n   478→                \"line\": record[\"line\"],\n   479→                \"docstring\": record[\"docstring\"],\n   480→                \"source_code\": record.get(\"source_code\")\n   481→            }\n   482→            for record in records\n   483→        ]\n   484→    \n   485→    # =========================================================================\n   486→    # Impact Analysis\n   487→    # =========================================================================\n   488→    \n   489→    def analyze_change_impact(self, target_id: str) -> List[Dict[str, Any]]:\n   490→        \"\"\"Analyze the impact of changing a specific code element.\"\"\"\n   491→        query = CYPHER_QUERIES[\"analyze_change_impact\"]\n   492→        records, _, _ = self.db.run_query(query, {\"target_id\": target_id})\n   493→\n   494→        return [\n   495→            {\n   496→                \"affected\": record[\"affected\"],\n   497→                \"type\": record[\"type\"],\n   498→                \"file\": record[\"file\"],\n   499→                \"distance\": record[\"distance\"]\n   500→            }\n   501→            for record in records\n   502→        ]\n   503→\n   504→    def analyze_change_impact_enhanced(\n   505→        self,\n   506→        qualified_name: str,\n   507→        repo_id: str\n   508→    ) -> Dict[str, Any]:\n   509→        \"\"\"\n   510→        Enhanced impact analysis with multi-dimensional impact tracking.\n   511→\n   512→        Analyzes:\n   513→        - Direct callers\n   514→        - Transitive callers (up to 3 levels)\n   515→        - Inheritance impact (for classes/methods)\n   516→        - Import impact (files that import changed file)\n   517→\n   518→        Args:\n   519→            qualified_name: Fully qualified name of the symbol\n   520→            repo_id: Repository ID\n   521→\n   522→        Returns:\n   523→            Dict with categorized impact analysis\n   524→        \"\"\"\n   525→        query = CYPHER_QUERIES[\"analyze_change_impact_enhanced\"]\n   526→        records, _, _ = self.db.run_query(query, {\n   527→            \"qualified_name\": qualified_name,\n   528→            \"repo_id\": repo_id\n   529→        })\n   530→\n   531→        if records:\n   532→            record = records[0]\n   533→            return {\n   534→                \"target\": record[\"target\"],\n   535→                \"direct_calls\": [call for call in record[\"direct_calls\"] if call.get(\"name\")],\n   536→                \"transitive_calls\": [call for call in record[\"transitive_calls\"] if call.get(\"name\")],\n   537→                \"inheritance_impact\": [imp for imp in record[\"inheritance_impact\"] if imp.get(\"name\")],\n   538→                \"import_impact\": [imp for imp in record[\"import_impact\"] if imp.get(\"name\")],\n   539→                \"total_impact\": record[\"total_impact\"]\n   540→            }\n   541→        return {\n   542→            \"target\": qualified_name,\n   543→            \"direct_calls\": [],\n   544→            \"transitive_calls\": [],\n   545→            \"inheritance_impact\": [],\n   546→            \"import_impact\": [],\n   547→            \"total_impact\": 0\n   548→        }\n   549→\n   550→    def get_call_graph(\n   551→        self,\n   552→        qualified_name: str,\n   553→        repo_id: str,\n   554→        max_depth: int = 3\n   555→    ) -> List[Dict[str, Any]]:\n   556→        \"\"\"\n   557→        Get the call graph starting from a symbol.\n   558→\n   559→        Args:\n   560→            qualified_name: Starting symbol\n   561→            repo_id: Repository ID\n   562→            max_depth: Maximum depth to traverse\n   563→\n   564→        Returns:\n   565→            List of caller-callee relationships\n   566→        \"\"\"\n   567→        query = CYPHER_QUERIES[\"get_call_graph\"]\n   568→        records, _, _ = self.db.run_query(query, {\n   569→            \"qualified_name\": qualified_name,\n   570→            \"repo_id\": repo_id,\n   571→            \"max_depth\": max_depth\n   572→        })\n   573→\n   574→        return [\n   575→            {\n   576→                \"caller\": record[\"caller\"],\n   577→                \"callee\": record[\"callee\"],\n   578→                \"caller_type\": record[\"caller_type\"],\n   579→                \"callee_type\": record[\"callee_type\"],\n   580→                \"line\": record[\"line\"],\n   581→                \"depth\": record[\"depth\"]\n   582→            }\n   583→            for record in records\n   584→        ]\n   585→    \n   586→    # =========================================================================\n   587→    # Code Retrieval Operations\n   588→    # =========================================================================\n   589→\n   590→    def get_code_at_line(self, file_id: str, line_number: int) -> Optional[str]:\n   591→        \"\"\"\n   592→        Get the code content at a specific line.\n   593→\n   594→        Note: Uses file source_code and extracts the specific line.\n   595→        \"\"\"\n   596→        source_code = self.reconstruct_file(file_id)\n   597→        if not source_code:\n   598→            return None\n   599→\n   600→        lines = source_code.split('\\n')\n   601→        if 0 < line_number <= len(lines):\n   602→            return lines[line_number - 1]\n   603→        return None\n   604→\n   605→    def get_code_range(\n   606→        self,\n   607→        file_id: str,\n   608→        start_line: int,\n   609→        end_line: int\n   610→    ) -> List[Dict[str, Any]]:\n   611→        \"\"\"\n   612→        Get code content for a range of lines.\n   613→\n   614→        Note: Uses file source_code and extracts the range.\n   615→        \"\"\"\n   616→        source_code = self.reconstruct_file(file_id)\n   617→        if not source_code:\n   618→            return []\n   619→\n   620→        lines = source_code.split('\\n')\n   621→        result = []\n   622→\n   623→        for i in range(start_line - 1, min(end_line, len(lines))):\n   624→            if i >= 0:\n   625→                line_content = lines[i]\n   626→                result.append({\n   627→                    \"line\": i + 1,\n   628→                    \"content\": line_content,\n   629→                    \"is_comment\": line_content.strip().startswith(('#', '//', '/*')),\n   630→                    \"is_blank\": len(line_content.strip()) == 0\n   631→                })\n   632→\n   633→        return result\n   634→    \n   635→    # =========================================================================\n   636→    # File Reconstruction\n   637→    # =========================================================================\n   638→    \n   639→    def get_repository_files(self, repo_id: str) -> List[Dict[str, Any]]:\n   640→        \"\"\"Get all files in a repository.\"\"\"\n   641→        query = \"\"\"\n   642→        MATCH (r:Repository)\n   643→        WHERE r.id = $repo_id OR r.repo = $repo_id\n   644→        MATCH (r)-[:CONTAINS*]->(f:File)\n   645→        RETURN f.id as id, f.path as path, f.language as language,\n   646→               f.lines_count as lines_count\n   647→        ORDER BY f.path\n   648→        \"\"\"\n   649→        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n   650→        return [\n   651→            {\n   652→                \"id\": record[\"id\"],\n   653→                \"path\": record[\"path\"],\n   654→                \"language\": record[\"language\"],\n   655→                \"lines_count\": record[\"lines_count\"]\n   656→            }\n   657→            for record in records\n   658→        ]\n   659→    \n   660→    def reconstruct_file(self, file_id: str) -> Optional[str]:\n   661→        \"\"\"\n   662→        Reconstruct a file's complete content from source_code property.\n   663→\n   664→        Returns:\n   665→            Complete file source code or None if not found\n   666→        \"\"\"\n   667→        query = \"\"\"\n   668→        MATCH (f:File {id: $file_id})\n   669→        RETURN f.source_code as source_code, f.path as path\n   670→        \"\"\"\n   671→        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n   672→\n   673→        if not records:\n   674→            return None\n   675→\n   676→        source_code = records[0].get(\"source_code\")\n   677→        if not source_code:\n   678→            # Fallback: try to reconstruct from individual code elements\n   679→            # This shouldn't be needed but provides a safety net\n   680→            print(f\"⚠️  Warning: File {records[0].get('path')} has no source_code stored\")\n   681→            return None\n   682→\n   683→        return source_code\n   684→\n   685→    def verify_reconstruction(self, file_id: str) -> Dict[str, Any]:\n   686→        \"\"\"\n   687→        Verify that file reconstruction is possible and show stats.\n   688→\n   689→        Args:\n   690→            file_id: File ID to verify\n   691→\n   692→        Returns:\n   693→            Dict with verification results\n   694→        \"\"\"\n   695→        query = \"\"\"\n   696→        MATCH (f:File {id: $file_id})\n   697→        OPTIONAL MATCH (f)-[:DEFINES]->(c:Class)\n   698→        OPTIONAL MATCH (f)-[:DEFINES]->(fn:Function)\n   699→        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)\n   700→        RETURN f.path as path,\n   701→               f.language as language,\n   702→               f.lines_count as lines_count,\n   703→               f.source_code IS NOT NULL as has_source_code,\n   704→               size(f.source_code) as source_code_size,\n   705→               count(DISTINCT c) as class_count,\n   706→               count(DISTINCT fn) as function_count,\n   707→               count(DISTINCT m) as method_count\n   708→        \"\"\"\n   709→        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n   710→\n   711→        if not records:\n   712→            return {\"error\": \"File not found\", \"file_id\": file_id}\n   713→\n   714→        record = records[0]\n   715→        can_reconstruct = record[\"has_source_code\"]\n   716→\n   717→        return {\n   718→            \"file_id\": file_id,\n   719→            \"path\": record[\"path\"],\n   720→            \"language\": record[\"language\"],\n   721→            \"lines_count\": record[\"lines_count\"],\n   722→            \"can_reconstruct\": can_reconstruct,\n   723→            \"source_code_size\": record[\"source_code_size\"] or 0,\n   724→            \"classes\": record[\"class_count\"],\n   725→            \"functions\": record[\"function_count\"],\n   726→            \"methods\": record[\"method_count\"],\n   727→            \"status\": \"✅ Ready\" if can_reconstruct else \"❌ No source_code\"\n   728→        }\n   729→    \n   730→    def get_symbol_source(self, qualified_name: str, repo_id: str) -> Optional[str]:\n   731→        \"\"\"\n   732→        Get source code for a specific symbol.\n   733→\n   734→        Args:\n   735→            qualified_name: Fully qualified name of the symbol\n   736→            repo_id: Repository ID\n   737→\n   738→        Returns:\n   739→            Source code of the symbol or None\n   740→        \"\"\"\n   741→        query = \"\"\"\n   742→        MATCH (s:Symbol {qualified_name: $qualified_name})\n   743→        WHERE s.file_id STARTS WITH $repo_id\n   744→        RETURN s.source_code as source_code\n   745→        LIMIT 1\n   746→        \"\"\"\n   747→        records, _, _ = self.db.run_query(query, {\n   748→            \"qualified_name\": qualified_name,\n   749→            \"repo_id\": repo_id\n   750→        })\n   751→\n   752→        if records and records[0][\"source_code\"]:\n   753→            return records[0][\"source_code\"]\n   754→\n   755→        # Fallback: try to get from definition node\n   756→        symbol = self.find_symbol_by_qualified_name(qualified_name, repo_id)\n   757→        if symbol and symbol.get(\"type\"):\n   758→            if symbol[\"type\"] == \"class\":\n   759→                return self.get_class_source(f\"{symbol['file_id']}:class:{symbol['name']}:{symbol['line_start']}\")\n   760→            elif symbol[\"type\"] == \"function\":\n   761→                return self.get_function_source(f\"{symbol['file_id']}:func:{symbol['name']}:{symbol['line_start']}\")\n   762→            elif symbol[\"type\"] == \"method\":\n   763→                # More complex - need to find class first\n   764→                pass\n   765→\n   766→        return None\n   767→\n   768→    def verify_repository_reconstruction(self, repo_id: str) -> Dict[str, Any]:\n   769→        \"\"\"\n   770→        Verify that all files in a repository can be reconstructed.\n   771→\n   772→        Args:\n   773→            repo_id: Repository ID\n   774→\n   775→        Returns:\n   776→            Dict with verification stats\n   777→        \"\"\"\n   778→        query = \"\"\"\n   779→        MATCH (r:Repository)\n   780→        WHERE r.id = $repo_id OR r.repo = $repo_id\n   781→        MATCH (r)-[:CONTAINS*]->(f:File)\n   782→        RETURN count(f) as total_files,\n   783→               sum(CASE WHEN f.source_code IS NOT NULL THEN 1 ELSE 0 END) as files_with_source,\n   784→               sum(f.lines_count) as total_lines,\n   785→               sum(size(f.source_code)) as total_source_size\n   786→        \"\"\"\n   787→        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n   788→\n   789→        if not records:\n   790→            return {\"error\": \"Repository not found\", \"repo_id\": repo_id}\n   791→\n   792→        record = records[0]\n   793→        total_files = record[\"total_files\"] or 0\n   794→        files_with_source = record[\"files_with_source\"] or 0\n   795→        success_rate = (files_with_source / total_files * 100) if total_files > 0 else 0\n   796→\n   797→        # Get list of files without source code\n   798→        problem_files_query = \"\"\"\n   799→        MATCH (r:Repository)\n   800→        WHERE r.id = $repo_id OR r.repo = $repo_id\n   801→        MATCH (r)-[:CONTAINS*]->(f:File)\n   802→        WHERE f.source_code IS NULL\n   803→        RETURN f.path as path, f.id as file_id\n   804→        LIMIT 10\n   805→        \"\"\"\n   806→        problem_records, _, _ = self.db.run_query(problem_files_query, {\"repo_id\": repo_id})\n   807→\n   808→        return {\n   809→            \"repo_id\": repo_id,\n   810→            \"total_files\": total_files,\n   811→            \"files_with_source\": files_with_source,\n   812→            \"files_without_source\": total_files - files_with_source,\n   813→            \"success_rate\": f\"{success_rate:.1f}%\",\n   814→            \"total_lines\": record[\"total_lines\"] or 0,\n   815→            \"total_source_size_mb\": (record[\"total_source_size\"] or 0) / 1024 / 1024,\n   816→            \"status\": \"✅ All files ready\" if success_rate == 100 else f\"⚠️  {total_files - files_with_source} files missing source\",\n   817→            \"problem_files\": [r[\"path\"] for r in problem_records] if problem_records else []\n   818→        }\n   819→\n   820→    def reconstruct_repository(self, repo_id: str) -> Dict[str, str]:\n   821→        \"\"\"\n   822→        Reconstruct all files in a repository.\n   823→        \n   824→        Returns:\n   825→            Dict mapping file paths to their reconstructed content\n   826→        \"\"\"\n   827→        files = self.get_repository_files(repo_id)\n   828→        reconstructed = {}\n   829→        \n   830→        for file_info in files:\n   831→            content = self.reconstruct_file(file_info[\"id\"])\n   832→            if content is not None:\n   833→                reconstructed[file_info[\"path\"]] = content\n   834→        \n   835→        return reconstructed\n   836→    \n   837→    def get_file_metadata(self, file_id: str) -> Dict[str, Any]:\n   838→        \"\"\"Get complete metadata for a file including all code elements.\"\"\"\n   839→        query = \"\"\"\n   840→        MATCH (f:File {id: $file_id})\n   841→        OPTIONAL MATCH (f)-[:DEFINES]->(c:Class)\n   842→        OPTIONAL MATCH (f)-[:DEFINES]->(fn:Function)\n   843→        OPTIONAL MATCH (f)-[:HAS_IMPORT]->(i:Import)\n   844→        RETURN f.path as path,\n   845→               f.language as language,\n   846→               f.lines_count as lines_count,\n   847→               collect(DISTINCT {name: c.name, line: c.line_start, bases: c.base_classes}) as classes,\n   848→               collect(DISTINCT {name: fn.name, line: fn.line_start, params: fn.params}) as functions,\n   849→               collect(DISTINCT {module: i.module, names: i.imported_names}) as imports\n   850→        \"\"\"\n   851→        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n   852→\n   853→        if records:\n   854→            record = records[0]\n   855→            return {\n   856→                \"path\": record[\"path\"],\n   857→                \"language\": record[\"language\"],\n   858→                \"lines_count\": record[\"lines_count\"],\n   859→                \"classes\": [c for c in record[\"classes\"] if c[\"name\"]],\n   860→                \"functions\": [f for f in record[\"functions\"] if f[\"name\"]],\n   861→                \"imports\": [i for i in record[\"imports\"] if i[\"module\"]]\n   862→            }\n   863→        return {}\n   864→\n   865→    def get_method_source(self, method_id: str) -> Optional[str]:\n   866→        \"\"\"Get the source code of a specific method.\"\"\"\n   867→        query = \"\"\"\n   868→        MATCH (m:Method {id: $method_id})\n   869→        RETURN m.source_code as source_code\n   870→        \"\"\"\n   871→        records, _, _ = self.db.run_query(query, {\"method_id\": method_id})\n   872→        return records[0][\"source_code\"] if records and records[0][\"source_code\"] else None\n   873→\n   874→    def get_function_source(self, function_id: str) -> Optional[str]:\n   875→        \"\"\"Get the source code of a specific function.\"\"\"\n   876→        query = \"\"\"\n   877→        MATCH (f:Function {id: $function_id})\n   878→        RETURN f.source_code as source_code\n   879→        \"\"\"\n   880→        records, _, _ = self.db.run_query(query, {\"function_id\": function_id})\n   881→        return records[0][\"source_code\"] if records and records[0][\"source_code\"] else None\n   882→\n   883→    def get_class_source(self, class_id: str) -> Optional[str]:\n   884→        \"\"\"Get the source code of a specific class.\"\"\"\n   885→        query = \"\"\"\n   886→        MATCH (c:Class {id: $class_id})\n   887→        RETURN c.source_code as source_code\n   888→        \"\"\"\n   889→        records, _, _ = self.db.run_query(query, {\"class_id\": class_id})\n   890→        return records[0][\"source_code\"] if records and records[0][\"source_code\"] else None\n   891→    \n   892→    # =========================================================================\n   893→    # Config File Queries\n   894→    # =========================================================================\n   895→    \n   896→    def get_repo_config_files(self, repo_id: str) -> List[Dict[str, Any]]:\n   897→        \"\"\"Get all config files in a repository.\"\"\"\n   898→        query = \"\"\"\n   899→        MATCH (r:Repository)\n   900→        WHERE r.id = $repo_id OR r.repo = $repo_id\n   901→        MATCH (r)-[:HAS_CONFIG]->(cf:ConfigFile)\n   902→        RETURN cf.id as id, cf.path as path, cf.file_type as file_type,\n   903→               cf.project_name as project_name, cf.version as version,\n   904→               cf.lines_count as lines_count\n   905→        ORDER BY cf.path\n   906→        \"\"\"\n   907→        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n   908→        return [\n   909→            {\n   910→                \"id\": record[\"id\"],\n   911→                \"path\": record[\"path\"],\n   912→                \"file_type\": record[\"file_type\"],\n   913→                \"project_name\": record[\"project_name\"],\n   914→                \"version\": record[\"version\"],\n   915→                \"lines_count\": record[\"lines_count\"]\n   916→            }\n   917→            for record in records\n   918→        ]\n   919→    \n   920→    def get_repo_dependencies(self, repo_id: str) -> List[Dict[str, Any]]:\n   921→        \"\"\"Get all dependencies in a repository.\"\"\"\n   922→        query = \"\"\"\n   923→        MATCH (r:Repository)\n   924→        WHERE r.id = $repo_id OR r.repo = $repo_id\n   925→        MATCH (r)-[:HAS_CONFIG]->(cf:ConfigFile)-[:HAS_DEPENDENCY]->(d:Dependency)\n   926→        RETURN d.name as name, d.version_spec as version, d.is_dev as is_dev,\n   927→               d.source as source, cf.path as config_file\n   928→        ORDER BY d.is_dev, d.name\n   929→        \"\"\"\n   930→        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n   931→        return [\n   932→            {\n   933→                \"name\": record[\"name\"],\n   934→                \"version\": record[\"version\"],\n   935→                \"is_dev\": record[\"is_dev\"],\n   936→                \"source\": record[\"source\"],\n   937→                \"config_file\": record[\"config_file\"]\n   938→            }\n   939→            for record in records\n   940→        ]\n   941→    \n   942→    def delete_repository(self, repo_id: str) -> bool:\n   943→        \"\"\"Delete a repository and all its data.\"\"\"\n   944→        if not self.db.connected:\n   945→            # Mock success for testing\n   946→            return True\n   947→\n   948→        query = \"\"\"\n   949→        MATCH (r:Repository)\n   950→        WHERE r.id = $repo_id OR r.repo = $repo_id\n   951→        DETACH DELETE r\n   952→        RETURN count(r) as deleted_count\n   953→        \"\"\"\n   954→        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n   955→\n   956→        return len(records) > 0 and records[0].get(\"deleted_count\", 0) > 0\n   957→    \n   958→    def get_repo_overview_extended(self, repo_id: str) -> Dict[str, Any]:\n   959→        \"\"\"Get extended repository overview including config files and dependencies.\"\"\"\n   960→        # Get basic stats\n   961→        basic = self.get_repo_overview(repo_id)\n   962→        \n   963→        # Get config file count\n   964→        config_query = \"\"\"\n   965→        MATCH (r:Repository {id: $repo_id})-[:HAS_CONFIG]->(cf:ConfigFile)\n   966→        OPTIONAL MATCH (cf)-[:HAS_DEPENDENCY]->(d:Dependency)\n   967→        RETURN count(DISTINCT cf) as config_count, count(DISTINCT d) as dep_count\n   968→        \"\"\"\n   969→        records, _, _ = self.db.run_query(config_query, {\"repo_id\": repo_id})\n   970→        \n   971→        if records:\n   972→            basic[\"config_files\"] = records[0][\"config_count\"]\n   973→            basic[\"dependencies\"] = records[0][\"dep_count\"]\n   974→        else:\n   975→            basic[\"config_files\"] = 0\n   976→            basic[\"dependencies\"] = 0\n   977→        \n   978→        return basic\n   979→\n   980→    def get_all_ingested_repositories(self, owner: str) -> List[Dict[str, Any]]:\n   981→        \"\"\"Get all ingested repositories.\"\"\"\n   982→        query = \"\"\"\n   983→        MATCH (r:Repository {owner: $owner})\n   984→        RETURN r.id as repo_id, r.owner as owner, r.name as name, r.url as url\n   985→        ORDER BY r.owner, r.name\n   986→        \"\"\"\n   987→        records, _, _ = self.db.run_query(query, {\"owner\": owner})\n   988→        return [\n   989→            {\n   990→                \"repo_id\": record[\"repo_id\"],\n   991→                \"owner\": record[\"owner\"],\n   992→                \"name\": record[\"name\"],\n   993→                \"url\": record[\"url\"]\n   994→            }\n   995→            for record in records\n   996→        ]\n   997→\n   998→    # =========================================================================\n   999→    # Hierarchy Navigation\n  1000→    # =========================================================================\n  1001→\n  1002→    def get_module_tree(self, repo_id: str) -> List[Dict[str, Any]]:\n  1003→        \"\"\"\n  1004→        Get the complete module/directory tree for a repository.\n  1005→\n  1006→        Args:\n  1007→            repo_id: Repository ID\n  1008→\n  1009→        Returns:\n  1010→            List of modules with hierarchy information\n  1011→        \"\"\"\n  1012→        query = CYPHER_QUERIES[\"get_module_tree\"]\n  1013→        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n  1014→\n  1015→        return [\n  1016→            {\n  1017→                \"path\": record[\"path\"],\n  1018→                \"name\": record[\"name\"],\n  1019→                \"parent_path\": record[\"parent_path\"],\n  1020→                \"is_package\": record[\"is_package\"],\n  1021→                \"depth\": record[\"depth\"]\n  1022→            }\n  1023→            for record in records\n  1024→        ]\n  1025→\n  1026→    def get_file_hierarchy(self, file_id: str) -> List[Dict[str, Any]]:\n  1027→        \"\"\"\n  1028→        Get the breadcrumb hierarchy for a file.\n  1029→\n  1030→        Args:\n  1031→            file_id: File ID\n  1032→\n  1033→        Returns:\n  1034→            Ordered list from repository to file\n  1035→        \"\"\"\n  1036→        query = CYPHER_QUERIES[\"get_file_hierarchy\"]\n  1037→        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n  1038→\n  1039→        return [\n  1040→            {\n  1041→                \"type\": record[\"type\"],\n  1042→                \"name\": record[\"name\"],\n  1043→                \"path\": record[\"path\"],\n  1044→                \"depth\": record[\"depth\"]\n  1045→            }\n  1046→            for record in records\n  1047→        ]\n  1048→\n  1049→    def get_directory_contents(\n  1050→        self,\n  1051→        repo_id: str,\n  1052→        dir_path: str\n  1053→    ) -> List[Dict[str, Any]]:\n  1054→        \"\"\"\n  1055→        Get contents of a specific directory.\n  1056→\n  1057→        Args:\n  1058→            repo_id: Repository ID\n  1059→            dir_path: Directory path\n  1060→\n  1061→        Returns:\n  1062→            List of files and subdirectories\n  1063→        \"\"\"\n  1064→        query = CYPHER_QUERIES[\"get_directory_contents\"]\n  1065→        records, _, _ = self.db.run_query(query, {\n  1066→            \"repo_id\": repo_id,\n  1067→            \"dir_path\": dir_path\n  1068→        })\n  1069→\n  1070→        return [\n  1071→            {\n  1072→                \"type\": record[\"type\"],\n  1073→                \"name\": record[\"name\"],\n  1074→                \"path\": record[\"path\"],\n  1075→                \"is_package\": record[\"is_package\"]\n  1076→            }\n  1077→            for record in records\n  1078→        ]\n  1079→\n  1080→    def get_symbols_at_lines(self, file_path: str, start_line: int, end_line: int) -> List[Dict[str, Any]]:\n  1081→        \"\"\"\n  1082→        Find all symbols (functions, classes, variables) that overlap a line range in a file.\n  1083→        Used to map diff hunks to affected code symbols.\n  1084→        \"\"\"\n  1085→        query = \"\"\"\n  1086→        MATCH (f:File {path: $file_path})-[:CONTAINS]->(n)\n  1087→        WHERE (n:Function OR n:Class OR n:Variable)\n  1088→          AND n.line_number IS NOT NULL\n  1089→          AND n.line_number <= $end_line\n  1090→          AND coalesce(n.end_line, n.line_number) >= $start_line\n  1091→        RETURN\n  1092→            CASE\n  1093→                WHEN n:Function THEN 'function'\n  1094→                WHEN n:Class THEN 'class'\n  1095→                ELSE 'variable'\n  1096→            END as type,\n  1097→            n.name as name,\n  1098→            n.line_number as start_line,\n  1099→            coalesce(n.end_line, n.line_number) as end_line,\n  1100→            n.source as source,\n  1101→            n.docstring as docstring,\n  1102→            n.path as path\n  1103→        ORDER BY n.line_number\n  1104→        \"\"\"\n  1105→        records, _, _ = self.db.run_query(query, {\n  1106→            \"file_path\": file_path,\n  1107→            \"start_line\": start_line,\n  1108→            \"end_line\": end_line,\n  1109→        })\n  1110→        return [dict(r) for r in records]\n  1111→\n  1112→    def get_symbols_at_lines_by_relative_path(self, repo_id: str, relative_path: str, start_line: int, end_line: int) -> List[Dict[str, Any]]:\n  1113→        \"\"\"\n  1114→        Find all symbols overlapping a line range using repo-relative file path.\n  1115→        \"\"\"\n  1116→        query = \"\"\"\n  1117→        MATCH (f:File)\n  1118→        WHERE f.relative_path = $relative_path\n  1119→          AND f.path CONTAINS $repo_id\n  1120→        WITH f\n  1121→        MATCH (f)-[:CONTAINS]->(n)\n  1122→        WHERE (n:Function OR n:Class OR n:Variable)\n  1123→          AND n.line_number IS NOT NULL\n  1124→          AND n.line_number <= $end_line\n  1125→          AND coalesce(n.end_line, n.line_number) >= $start_line\n  1126→        RETURN\n  1127→            CASE\n  1128→                WHEN n:Function THEN 'function'\n  1129→                WHEN n:Class THEN 'class'\n  1130→                ELSE 'variable'\n  1131→            END as type,\n  1132→            n.name as name,\n  1133→            n.line_number as start_line,\n  1134→            coalesce(n.end_line, n.line_number) as end_line,\n  1135→            n.source as source,\n  1136→            n.docstring as docstring,\n  1137→            f.relative_path as file_path\n  1138→        ORDER BY n.line_number\n  1139→        \"\"\"\n  1140→        records, _, _ = self.db.run_query(query, {\n  1141→            \"repo_id\": repo_id,\n  1142→            \"relative_path\": relative_path,\n  1143→            \"start_line\": start_line,\n  1144→            \"end_line\": end_line,\n  1145→        })\n  1146→        return [dict(r) for r in records]\n  1147→\n  1148→    def get_diff_context(self, repo_id: str, changes: List[Dict[str, Any]]) -> Dict[str, Any]:\n  1149→        \"\"\"\n  1150→        Build full RAG context for a set of file changes (diff).\n  1151→\n  1152→        Args:\n  1153→            repo_id: Repository ID (e.g. \"owner/repo\")\n  1154→            changes: List of {\"file_path\": \"relative/path.py\", \"start_line\": 10, \"end_line\": 30}\n  1155→\n  1156→        Returns:\n  1157→            Dict with affected_symbols, callers, hierarchy, and file_sources.\n  1158→        \"\"\"\n  1159→        all_affected = []\n  1160→        all_callers = []\n  1161→        all_hierarchy = []\n  1162→        file_sources = {}\n  1163→\n  1164→        for change in changes:\n  1165→            file_path = change[\"file_path\"]\n  1166→            start_line = change.get(\"start_line\", 1)\n  1167→            end_line = change.get(\"end_line\", 999999)\n  1168→\n  1169→            # 1. Find affected symbols\n  1170→            symbols = self.get_symbols_at_lines_by_relative_path(\n  1171→                repo_id, file_path, start_line, end_line\n  1172→            )\n  1173→            for s in symbols:\n  1174→                s[\"change_file\"] = file_path\n  1175→            all_affected.extend(symbols)\n  1176→\n  1177→            # 2. For each affected symbol, find callers\n  1178→            for sym in symbols:\n  1179→                caller_query = \"\"\"\n  1180→                MATCH (caller)-[:CALLS]->(target)\n  1181→                WHERE target.name = $name AND target.path CONTAINS $repo_id\n  1182→                RETURN\n  1183→                    CASE\n  1184→                        WHEN caller:Function THEN 'function'\n  1185→                        WHEN caller:Class THEN 'class'\n  1186→                        ELSE 'other'\n  1187→                    END as type,\n  1188→                    caller.name as name,\n  1189→                    caller.path as path,\n  1190→                    caller.line_number as line_number,\n  1191→                    caller.source as source\n  1192→                LIMIT 20\n  1193→                \"\"\"\n  1194→                records, _, _ = self.db.run_query(caller_query, {\n  1195→                    \"name\": sym[\"name\"],\n  1196→                    \"repo_id\": repo_id,\n  1197→                })\n  1198→                callers = [dict(r) for r in records]\n  1199→                if callers:\n  1200→                    all_callers.append({\n  1201→                        \"symbol\": sym[\"name\"],\n  1202→                        \"symbol_type\": sym[\"type\"],\n  1203→                        \"callers\": callers,\n  1204→                    })\n  1205→\n  1206→            # 3. For affected classes, get hierarchy\n  1207→            class_symbols = [s for s in symbols if s[\"type\"] == \"class\"]\n  1208→            for cls in class_symbols:\n  1209→                hier_query = \"\"\"\n  1210→                MATCH (c:Class {name: $name})-[:INHERITS*0..5]->(parent:Class)\n  1211→                WHERE c.path CONTAINS $repo_id\n  1212→                RETURN parent.name as name, parent.path as path,\n  1213→                       parent.source as source, parent.docstring as docstring\n  1214→                \"\"\"\n  1215→                records, _, _ = self.db.run_query(hier_query, {\n  1216→                    \"name\": cls[\"name\"],\n  1217→                    \"repo_id\": repo_id,\n  1218→                })\n  1219→                if records:\n  1220→                    all_hierarchy.append({\n  1221→                        \"class\": cls[\"name\"],\n  1222→                        \"hierarchy\": [dict(r) for r in records],\n  1223→                    })\n  1224→\n  1225→            # 4. Get file source\n  1226→            file_src_query = \"\"\"\n  1227→            MATCH (f:File)\n  1228→            WHERE f.relative_path = $relative_path AND f.path CONTAINS $repo_id\n  1229→            RETURN f.source_code as source_code, f.relative_path as path\n  1230→            LIMIT 1\n  1231→            \"\"\"\n  1232→            records, _, _ = self.db.run_query(file_src_query, {\n  1233→                \"relative_path\": file_path,\n  1234→                \"repo_id\": repo_id,\n  1235→            })\n  1236→            if records and records[0].get(\"source_code\"):\n  1237→                file_sources[file_path] = records[0][\"source_code\"]\n  1238→\n  1239→        return {\n  1240→            \"affected_symbols\": all_affected,\n  1241→            \"callers\": all_callers,\n  1242→            \"class_hierarchy\": all_hierarchy,\n  1243→            \"file_sources\": file_sources,\n  1244→            \"total_affected\": len(all_affected),\n  1245→            \"total_files\": len(changes),\n  1246→        }\n  1247→\n  1248→    def get_diff_context_condensed(\n  1249→        self, repo_id: str, changes: List[Dict[str, Any]]\n  1250→    ) -> Dict[str, Any]:\n  1251→        \"\"\"\n  1252→        Build lean context for a set of file changes — optimized for LLM prompts.\n  1253→\n  1254→        Compared to get_diff_context:\n  1255→        - Only returns functions/classes/methods (skips variables)\n  1256→        - Returns symbol source snippets (the changed code chunk, not the whole file)\n  1257→        - Returns caller names + file paths only (no caller source code)\n  1258→        - Returns hierarchy as name chains only (no parent source)\n  1259→        - No full file sources at all\n  1260→\n  1261→        Args:\n  1262→            repo_id: Repository ID (e.g. \"owner/repo\")\n  1263→            changes: List of {\"file_path\": \"relative/path.py\", \"start_line\": 10, \"end_line\": 30}\n  1264→\n  1265→        Returns:\n  1266→            Dict with affected_symbols, callers, hierarchy.\n  1267→        \"\"\"\n  1268→        all_affected: List[Dict[str, Any]] = []\n  1269→        all_callers: List[Dict[str, Any]] = []\n  1270→        all_hierarchy: List[Dict[str, Any]] = []\n  1271→        seen_symbols: set = set()\n  1272→\n  1273→        for change in changes:\n  1274→            file_path = change[\"file_path\"]\n  1275→            start_line = change.get(\"start_line\", 1)\n  1276→            end_line = change.get(\"end_line\", 999999)\n  1277→\n  1278→            # 1. Find affected symbols — functions and classes only\n  1279→            query = \"\"\"\n  1280→            MATCH (f:File)\n  1281→            WHERE f.relative_path = $relative_path\n  1282→              AND f.path CONTAINS $repo_id\n  1283→            WITH f\n  1284→            MATCH (f)-[:CONTAINS]->(n)\n  1285→            WHERE (n:Function OR n:Class OR n:Method)\n  1286→              AND n.line_number IS NOT NULL\n  1287→              AND n.line_number <= $end_line\n  1288→              AND coalesce(n.end_line, n.line_number) >= $start_line\n  1289→            RETURN\n  1290→                CASE\n  1291→                    WHEN n:Function THEN 'function'\n  1292→                    WHEN n:Method THEN 'method'\n  1293→                    WHEN n:Class THEN 'class'\n  1294→                END as type,\n  1295→                n.name as name,\n  1296→                n.line_number as start_line,\n  1297→                coalesce(n.end_line, n.line_number) as end_line,\n  1298→                n.source as source,\n  1299→                n.docstring as docstring,\n  1300→                f.relative_path as file_path\n  1301→            ORDER BY n.line_number\n  1302→            \"\"\"\n  1303→            records, _, _ = self.db.run_query(query, {\n  1304→                \"repo_id\": repo_id,\n  1305→                \"relative_path\": file_path,\n  1306→                \"start_line\": start_line,\n  1307→                \"end_line\": end_line,\n  1308→            })\n  1309→\n  1310→            symbols = [dict(r) for r in records]\n  1311→            for s in symbols:\n  1312→                s[\"change_file\"] = file_path\n  1313→                # Truncate source to keep prompts lean\n  1314→                if s.get(\"source\") and len(s[\"source\"]) > 500:\n  1315→                    s[\"source\"] = s[\"source\"][:500] + \"\\n... (truncated)\"\n  1316→            all_affected.extend(symbols)\n  1317→\n  1318→            # 2. For each symbol, find caller names only (no source)\n  1319→            for sym in symbols:\n  1320→                sym_key = f\"{file_path}:{sym['name']}\"\n  1321→                if sym_key in seen_symbols:\n  1322→                    continue\n  1323→                seen_symbols.add(sym_key)\n  1324→\n  1325→                caller_query = \"\"\"\n  1326→                MATCH (caller)-[:CALLS]->(target)\n  1327→                WHERE target.name = $name AND target.path CONTAINS $repo_id\n  1328→                RETURN DISTINCT\n  1329→                    caller.name as name,\n  1330→                    CASE\n  1331→                        WHEN caller:Function THEN 'function'\n  1332→                        WHEN caller:Method THEN 'method'\n  1333→                        WHEN caller:Class THEN 'class'\n  1334→                        ELSE 'other'\n  1335→                    END as type,\n  1336→                    caller.path as path\n  1337→                LIMIT 10\n  1338→                \"\"\"\n  1339→                records, _, _ = self.db.run_query(caller_query, {\n  1340→                    \"name\": sym[\"name\"],\n  1341→                    \"repo_id\": repo_id,\n  1342→                })\n  1343→                callers = [dict(r) for r in records]\n  1344→                if callers:\n  1345→                    all_callers.append({\n  1346→                        \"symbol\": sym[\"name\"],\n  1347→                        \"symbol_type\": sym[\"type\"],\n  1348→                        \"callers\": callers,\n  1349→                    })\n  1350→\n  1351→            # 3. For affected classes, get hierarchy names only\n  1352→            class_symbols = [s for s in symbols if s[\"type\"] == \"class\"]\n  1353→            for cls in class_symbols:\n  1354→                hier_query = \"\"\"\n  1355→                MATCH (c:Class {name: $name})-[:INHERITS*0..3]->(parent:Class)\n  1356→                WHERE c.path CONTAINS $repo_id\n  1357→                RETURN parent.name as name, parent.path as path\n  1358→                \"\"\"\n  1359→                records, _, _ = self.db.run_query(hier_query, {\n  1360→                    \"name\": cls[\"name\"],\n  1361→                    \"repo_id\": repo_id,\n  1362→                })\n  1363→                if records:\n  1364→                    all_hierarchy.append({\n  1365→                        \"class\": cls[\"name\"],\n  1366→                        \"hierarchy\": [{\"name\": r[\"name\"], \"path\": r[\"path\"]} for r in records],\n  1367→                    })\n  1368→\n  1369→        return {\n  1370→            \"affected_symbols\": all_affected,\n  1371→            \"callers\": all_callers,\n  1372→            \"class_hierarchy\": all_hierarchy,\n  1373→            \"total_affected\": len(all_affected),\n  1374→            \"total_files\": len(set(c[\"file_path\"] for c in changes)),\n  1375→        }\n  1376→\n  1377→    def get_diff_context_enhanced(\n  1378→        self, repo_id: str, changes: List[Dict[str, Any]]\n  1379→    ) -> Dict[str, Any]:\n  1380→        \"\"\"\n  1381→        Build full relationship context for every changed Function, Method, and Class.\n  1382→\n  1383→        For each symbol in the diff line ranges:\n  1384→          - Full source code of the symbol itself\n  1385→          - Methods belonging to each changed Class (with source)\n  1386→          - Callers: every Function/Method that calls this symbol via CALLS edges\n  1387→          - Dependencies: every Function/Method this symbol calls via CALLS edges\n  1388→          - Imports: other in-repo symbols imported by the changed file\n  1389→          - Class hierarchy: parent/child classes for any changed Class\n  1390→\n  1391→        Both Function and Method node types are handled throughout — the graph\n  1392→        stores class methods as Function nodes under the class via CONTAINS.\n  1393→        \"\"\"\n  1394→        from api.services.code_search import CodeFinder\n  1395→\n  1396→        code_finder = CodeFinder(self.db)\n  1397→\n  1398→        all_affected: List[Dict[str, Any]] = []\n  1399→        all_callers: List[Dict[str, Any]] = []\n  1400→        all_imports: List[Dict[str, Any]] = []\n  1401→        all_dependencies: List[Dict[str, Any]] = []\n  1402→        all_hierarchy: List[Dict[str, Any]] = []\n  1403→        seen_affected: set = set()\n  1404→        seen_callers: set = set()\n  1405→        seen_imports: set = set()\n  1406→\n  1407→        for change in changes:\n  1408→            file_path = change[\"file_path\"]\n  1409→            start_line = change.get(\"start_line\", 1)\n  1410→            end_line = change.get(\"end_line\", 999999)\n  1411→\n  1412→            # ── 1. Affected symbols (Function, Class, and Method) ─────────────\n  1413→            # Method nodes are stored under Class via CONTAINS — we surface them\n  1414→            # here so the agent sees both the class body and individual methods.\n  1415→            affected_query = \"\"\"\n  1416→            MATCH (f:File {repo: $repo_id, path: $file_path})\n  1417→            MATCH (f)-[:CONTAINS]->(n)\n  1418→            WHERE (n:Function OR n:Class OR n:Method)\n  1419→              AND n.line_number IS NOT NULL\n  1420→              AND n.line_number <= $end_line\n  1421→              AND coalesce(n.end_line, n.line_number) >= $start_line\n  1422→            RETURN\n  1423→                CASE\n  1424→                    WHEN n:Class    THEN 'class'\n  1425→                    WHEN n:Method   THEN 'method'\n  1426→                    ELSE                 'function'\n  1427→                END AS type,\n  1428→                n.name          AS name,\n  1429→                n.line_number   AS start_line,\n  1430→                coalesce(n.end_line, n.line_number) AS end_line,\n  1431→                n.source        AS source,\n  1432→                n.docstring     AS docstring,\n  1433→                n.args          AS args,\n  1434→                f.path          AS file_path\n  1435→            ORDER BY n.line_number\n  1436→            \"\"\"\n  1437→            records, _, _ = self.db.run_query(affected_query, {\n  1438→                \"repo_id\": repo_id,\n  1439→                \"file_path\": file_path,\n  1440→                \"start_line\": start_line,\n  1441→                \"end_line\": end_line,\n  1442→            })\n  1443→            symbols = [dict(r) for r in records]\n  1444→\n  1445→            for s in symbols:\n  1446→                s[\"change_file\"] = file_path\n  1447→                sym_key = f\"{s['file_path']}:{s['name']}:{s['start_line']}\"\n  1448→                if sym_key not in seen_affected:\n  1449→                    seen_affected.add(sym_key)\n  1450→                    all_affected.append(s)\n  1451→\n  1452→            for sym in symbols:\n  1453→                caller_key = f\"{sym['file_path']}:{sym['name']}\"\n  1454→                if caller_key in seen_callers:\n  1455→                    continue\n  1456→                seen_callers.add(caller_key)\n  1457→\n  1458→                # ── 2. Callers: who calls this symbol? ────────────────────────\n  1459→                # Match both Function and Method callers so class methods that\n  1460→                # call the changed code are not missed.\n  1461→                try:\n  1462→                    caller_query = \"\"\"\n  1463→                    MATCH (target)\n  1464→                    WHERE (target:Function OR target:Method OR target:Class)\n  1465→                      AND target.name = $name\n  1466→                      AND coalesce(target.path, '') CONTAINS $repo_id\n  1467→                    WITH target\n  1468→                    MATCH (caller)-[call:CALLS]->(target)\n  1469→                    WHERE (caller:Function OR caller:Method)\n  1470→                      AND NOT coalesce(caller.is_dependency, false)\n  1471→                    OPTIONAL MATCH (caller_file:File)-[:CONTAINS]->(caller)\n  1472→                    RETURN DISTINCT\n  1473→                        caller.name             AS caller_name,\n  1474→                        CASE WHEN caller:Method THEN 'method' ELSE 'function' END AS caller_type,\n  1475→                        coalesce(caller.path, caller_file.path) AS caller_path,\n  1476→                        caller.line_number      AS caller_line,\n  1477→                        call.line_number        AS call_line,\n  1478→                        call.args               AS call_args\n  1479→                    ORDER BY caller_path, caller.line_number\n  1480→                    LIMIT 10\n  1481→                    \"\"\"\n  1482→                    caller_records, _, _ = self.db.run_query(\n  1483→                        caller_query, {\"name\": sym[\"name\"], \"repo_id\": repo_id}\n  1484→                    )\n  1485→                    callers_list = [dict(r) for r in caller_records]\n  1486→                    if callers_list:\n  1487→                        all_callers.append({\n  1488→                            \"symbol\": sym[\"name\"],\n  1489→                            \"symbol_type\": sym[\"type\"],\n  1490→                            \"callers\": callers_list,\n  1491→                        })\n  1492→                except Exception as e:\n  1493→                    logger.warning(f\"Error finding callers for {sym['name']}: {e}\")\n  1494→\n  1495→                # ── 3. Dependencies: what does this symbol call? ──────────────\n  1496→                # Match both Function and Method targets to catch calls to methods.\n  1497→                try:\n  1498→                    dep_query = \"\"\"\n  1499→                    MATCH (caller)\n  1500→                    WHERE (caller:Function OR caller:Method)\n  1501→                      AND caller.name = $name\n  1502→                      AND caller.path = $path\n  1503→                    MATCH (caller)-[call:CALLS]->(called)\n  1504→                    WHERE (called:Function OR called:Method)\n  1505→                      AND NOT coalesce(called.is_dependency, false)\n  1506→                    RETURN DISTINCT\n  1507→                        called.name  AS called_name,\n  1508→                        CASE WHEN called:Method THEN 'method' ELSE 'function' END AS called_type,\n  1509→                        called.path  AS called_path,\n  1510→                        call.line_number AS call_line,\n  1511→                        call.args    AS call_args\n  1512→                    ORDER BY call.line_number\n  1513→                    LIMIT 15\n  1514→                    \"\"\"\n  1515→                    dep_records, _, _ = self.db.run_query(dep_query, {\n  1516→                        \"name\": sym[\"name\"],\n  1517→                        \"path\": sym[\"file_path\"],\n  1518→                    })\n  1519→                    deps_list = [dict(r) for r in dep_records]\n  1520→                    if deps_list:\n  1521→                        all_dependencies.append({\n  1522→                            \"symbol\": sym[\"name\"],\n  1523→                            \"dependencies\": deps_list,\n  1524→                        })\n  1525→                except Exception as e:\n  1526→                    logger.warning(f\"Error finding dependencies for {sym['name']}: {e}\")\n  1527→\n  1528→                # ── 4. Class methods: when a Class is affected, fetch all ──────\n  1529→                # its methods with full source so the agent sees what each\n  1530→                # method does — not just the class skeleton.\n  1531→                if sym[\"type\"] == \"class\":\n  1532→                    try:\n  1533→                        methods_query = \"\"\"\n  1534→                        MATCH (cls:Class {name: $class_name, path: $path})\n  1535→                        MATCH (cls)-[:CONTAINS]->(m:Function)\n  1536→                        RETURN\n  1537→                            m.name          AS name,\n  1538→                            m.line_number   AS line_number,\n  1539→                            coalesce(m.end_line, m.line_number) AS end_line,\n  1540→                            m.source        AS source,\n  1541→                            m.docstring     AS docstring,\n  1542→                            m.args          AS args\n  1543→                        ORDER BY m.line_number\n  1544→                        \"\"\"\n  1545→                        method_records, _, _ = self.db.run_query(methods_query, {\n  1546→                            \"class_name\": sym[\"name\"],\n  1547→                            \"path\": sym[\"file_path\"],\n  1548→                        })\n  1549→                        methods_list = [dict(r) for r in method_records]\n  1550→                        if methods_list:\n  1551→                            sym[\"methods\"] = methods_list\n  1552→                    except Exception as e:\n  1553→                        logger.warning(f\"Error fetching methods for class {sym['name']}: {e}\")\n  1554→\n  1555→            # ── 5. Imports: resolve imported names to in-repo source ──────────\n  1556→            import_query = \"\"\"\n  1557→            MATCH (f:File {repo: $repo_id, path: $file_path})\n  1558→            MATCH (f)-[r:IMPORTS]->(m)\n  1559→            RETURN\n  1560→                r.alias          AS alias,\n  1561→                r.imported_name  AS imported_name,\n  1562→                m.name           AS module_name,\n  1563→                r.line_number    AS line_number\n  1564→            ORDER BY r.line_number\n  1565→            LIMIT 20\n  1566→            \"\"\"\n  1567→            import_records, _, _ = self.db.run_query(import_query, {\n  1568→                \"repo_id\": repo_id,\n  1569→                \"file_path\": file_path,\n  1570→            })\n  1571→\n  1572→            for imp in import_records:\n  1573→                imported_name = imp.get(\"imported_name\") or imp.get(\"alias\")\n  1574→                if not imported_name or imported_name in seen_imports:\n  1575→                    continue\n  1576→                seen_imports.add(imported_name)\n  1577→\n  1578→                try:\n  1579→                    func_results = code_finder.find_by_function_name(imported_name, fuzzy_search=False)\n  1580→                    if func_results:\n  1581→                        for func in func_results[:1]:\n  1582→                            if func.get(\"path\") and repo_id in func.get(\"path\", \"\"):\n  1583→                                all_imports.append({\n  1584→                                    \"name\": imported_name,\n  1585→                                    \"type\": \"function\",\n  1586→                                    \"source\": func.get(\"source\", \"\"),\n  1587→                                    \"path\": func.get(\"path\"),\n  1588→                                    \"line\": func.get(\"line_number\"),\n  1589→                                    \"docstring\": func.get(\"docstring\"),\n  1590→                                    \"from_file\": file_path,\n  1591→                                })\n  1592→                    else:\n  1593→                        class_results = code_finder.find_by_class_name(imported_name, fuzzy_search=False)\n  1594→                        if class_results:\n  1595→                            for cls in class_results[:1]:\n  1596→                                if cls.get(\"path\") and repo_id in cls.get(\"path\", \"\"):\n  1597→                                    all_imports.append({\n  1598→                                        \"name\": imported_name,\n  1599→                                        \"type\": \"class\",\n  1600→                                        \"source\": cls.get(\"source\", \"\"),\n  1601→                                        \"path\": cls.get(\"path\"),\n  1602→                                        \"line\": cls.get(\"line_number\"),\n  1603→                                        \"docstring\": cls.get(\"docstring\"),\n  1604→                                        \"from_file\": file_path,\n  1605→                                    })\n  1606→                except Exception as e:\n  1607→                    logger.warning(f\"Error resolving import {imported_name}: {e}\")\n  1608→\n  1609→            # ── 6. Class hierarchy for affected classes ───────────────────────\n  1610→            for cls in [s for s in symbols if s[\"type\"] == \"class\"]:\n  1611→                try:\n  1612→                    hierarchy_info = code_finder.find_class_hierarchy(\n  1613→                        cls[\"name\"], cls.get(\"file_path\")\n  1614→                    )\n  1615→                    if hierarchy_info:\n  1616→                        all_hierarchy.append({\n  1617→                            \"class\": cls[\"name\"],\n  1618→                            \"parents\": hierarchy_info.get(\"parent_classes\", []),\n  1619→                            \"children\": hierarchy_info.get(\"child_classes\", []),\n  1620→                            \"methods\": hierarchy_info.get(\"methods\", []),\n  1621→                        })\n  1622→                except Exception as e:\n  1623→                    logger.warning(f\"Error finding hierarchy for {cls['name']}: {e}\")\n  1624→\n  1625→        return {\n  1626→            \"affected_symbols\": all_affected,\n  1627→            \"callers\": all_callers,\n  1628→            \"imports\": all_imports,\n  1629→            \"dependencies\": all_dependencies,\n  1630→            \"class_hierarchy\": all_hierarchy,\n  1631→            \"total_affected\": len(all_affected),\n  1632→            \"total_imports\": len(all_imports),\n  1633→            \"total_files\": len(set(c[\"file_path\"] for c in changes)),\n  1634→        }\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"b1ffb9da-7c36-455d-bab8-774aeded20bf","timestamp":"2026-02-21T08:05:46.275Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/db/queries.py","content":"\n\nfrom typing import Dict, List, Any, Optional\nimport re\nimport logging\n\nfrom .client import Neo4jClient\nfrom .schema import CYPHER_QUERIES\n\nlogger = logging.getLogger(__name__)\n\nclass CodeQueryService:\n    \"\"\"\n    Service for querying code elements from the Neo4j graph.\n    \n    Provides methods for:\n    - Finding method/function usages and callers\n    - Analyzing class hierarchies\n    - Searching code by name or content\n    - Reconstructing files from the graph\n    \"\"\"\n    \n    def __init__(self, client: Neo4jClient):\n        self.db = client\n    \n    # =========================================================================\n    # Graph Statistics\n    # =========================================================================\n    \n    def get_graph_stats(self) -> Dict[str, int]:\n        \"\"\"Get statistics about the code graph.\"\"\"\n        query = CYPHER_QUERIES[\"get_graph_stats\"]\n        records, _, _ = self.db.run_query(query)\n        \n        if records:\n            return dict(records[0])\n        return {}\n\n    def list_repositories(self) -> List[Dict[str, Any]]:\n        \"\"\"List all repositories in the database.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        OPTIONAL MATCH (r)-[:CONTAINS*]->(f:File)\n        RETURN r.id as id, r.name as name, r.owner as owner,\n               r.url as url, r.path as local_path,\n               r.last_commit_hash as last_commit,\n               r.created_at as created_at,\n               r.updated_at as updated_at,\n               count(DISTINCT f) as file_count\n        ORDER BY r.updated_at DESC, r.name\n        \"\"\"\n        records, _, _ = self.db.run_query(query)\n        \n        def convert_datetime(value):\n            \"\"\"Convert Neo4j DateTime to ISO string format.\"\"\"\n            if value is None:\n                return None\n            # Check if it's a Neo4j DateTime object\n            if hasattr(value, 'iso_format'):\n                return value.iso_format()\n            # If it's already a string or other type, return as is\n            return str(value) if value is not None else None\n        \n        return [\n            {\n                \"id\": record.get(\"id\"),\n                \"name\": record.get(\"name\"),\n                \"owner\": record.get(\"owner\"),\n                \"url\": record.get(\"url\"),\n                \"local_path\": record.get(\"local_path\"),\n                \"last_commit\": record.get(\"last_commit\"),\n                \"created_at\": convert_datetime(record.get(\"created_at\")),\n                \"updated_at\": convert_datetime(record.get(\"updated_at\")),\n                \"file_count\": record.get(\"file_count\") or 0\n            }\n            for record in records\n        ]\n\n    def delete_repository(self, repo_id: str) -> bool:\n        \"\"\"Delete a repository and all its associated data.\"\"\"\n        try:\n            query = \"\"\"\n            MATCH (r:Repository)\n            WHERE r.id = $repo_id OR r.repo = $repo_id\n            OPTIONAL MATCH (r)-[:CONTAINS*]->(n)\n            DETACH DELETE r, n\n            RETURN count(r) as deleted_count\n            \"\"\"\n            records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n            return records and records[0][\"deleted_count\"] > 0\n        except Exception as e:\n            logger.error(\"Error deleting repository %s: %s\", repo_id, e)\n            return False\n    \n    def get_repository_stats(self, repo_id: str) -> Dict[str, Any]:\n        \"\"\"Get statistics for a specific repository.\"\"\"\n        if not self.db.connected:\n            # Return mock stats\n            return {\n                \"files\": 25,\n                \"classes\": 12,\n                \"functions\": 89,\n                \"methods\": 156,\n                \"lines\": 3420,\n                \"imports\": 67,\n                \"languages\": [\"Python\", \"TypeScript\", \"JavaScript\"]\n            }\n            \n        query = CYPHER_QUERIES[\"get_repo_stats\"]\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        \n        if records:\n            record = records[0]\n            return {\n                \"files\": record[\"file_count\"],\n                \"classes\": record[\"class_count\"],\n                \"functions\": record[\"function_count\"],\n                \"methods\": record[\"method_count\"],\n                \"lines\": record[\"line_count\"],\n                \"imports\": record[\"import_count\"],\n                \"languages\": record[\"languages\"]\n            }\n        return {}\n    \n    # =========================================================================\n    # Method and Function Queries\n    # =========================================================================\n    \n    def find_method_usages(self, method_name: str) -> Dict[str, Any]:\n        \"\"\"Find all usages of a method by name.\"\"\"\n        query = CYPHER_QUERIES[\"find_method_usages\"]\n        records, _, _ = self.db.run_query(query, {\"method_name\": method_name})\n\n        results = []\n        for record in records:\n            # Convert Neo4j Node objects to dictionaries for JSON serialization\n            callers = []\n            for caller_dict in record[\"callers\"]:\n                if caller_dict and caller_dict.get(\"caller\"):\n                    callers.append({\n                        \"caller\": dict(caller_dict[\"caller\"]) if hasattr(caller_dict[\"caller\"], \"__iter__\") and not isinstance(caller_dict[\"caller\"], str) else {\"name\": str(caller_dict[\"caller\"])},\n                        \"line\": caller_dict.get(\"line\")\n                    })\n\n            references = []\n            for ref_dict in record[\"references\"]:\n                if ref_dict and ref_dict.get(\"line\"):\n                    references.append({\n                        \"line\": dict(ref_dict[\"line\"]) if hasattr(ref_dict[\"line\"], \"__iter__\") and not isinstance(ref_dict[\"line\"], str) else {\"line\": str(ref_dict[\"line\"])},\n                        \"col_start\": ref_dict.get(\"col_start\")\n                    })\n\n            results.append({\n                \"method\": dict(record[\"m\"]) if record[\"m\"] else None,\n                \"callers\": callers,\n                \"references\": references\n            })\n        return {\"usages\": results}\n    \n    def find_method_context(self, method_id: str) -> Dict[str, Any]:\n        \"\"\"Find the full context of a method (class, file, repo, user).\"\"\"\n        query = CYPHER_QUERIES[\"find_method_context\"]\n        records, _, _ = self.db.run_query(query, {\"method_id\": method_id})\n        \n        if records:\n            record = records[0]\n            return {\n                \"user\": record[\"user\"],\n                \"repo\": record[\"repo\"],\n                \"file\": record[\"file\"],\n                \"class\": record[\"class_name\"],\n                \"method\": record[\"method\"],\n                \"lines\": f\"{record['start_line']}-{record['end_line']}\"\n            }\n        return {}\n    \n    def find_callers(self, symbol_name: str) -> List[Dict[str, Any]]:\n        \"\"\"Find all methods/functions that call a specific symbol.\"\"\"\n        query = CYPHER_QUERIES[\"find_callers\"]\n        records, _, _ = self.db.run_query(query, {\"name\": symbol_name})\n        \n        return [\n            {\n                \"caller\": record[\"caller_name\"],\n                \"type\": record[\"caller_type\"],\n                \"file\": record[\"file_path\"],\n                \"line\": record[\"call_line\"]\n            }\n            for record in records\n        ]\n    \n    # =========================================================================\n    # Class Queries\n    # =========================================================================\n    \n    def get_class_hierarchy(self, class_name: str) -> Dict[str, Any]:\n        \"\"\"Get the inheritance hierarchy of a class.\"\"\"\n        query = CYPHER_QUERIES[\"get_class_hierarchy\"]\n        records, _, _ = self.db.run_query(query, {\"class_name\": class_name})\n        \n        if records:\n            record = records[0]\n            return {\n                \"class\": dict(record[\"c\"]) if record[\"c\"] else None,\n                \"ancestors\": [dict(n) for n in record[\"ancestors\"]] if record[\"ancestors\"] else [],\n                \"descendants\": [dict(n) for n in record[\"descendants\"]] if record[\"descendants\"] else []\n            }\n        return {}\n    \n    # =========================================================================\n    # File Queries\n    # =========================================================================\n    \n    def get_file_structure(self, file_id: str) -> Dict[str, Any]:\n        \"\"\"Get the structure of a file (classes, functions, imports).\"\"\"\n        query = CYPHER_QUERIES[\"get_file_structure\"]\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n        \n        if records:\n            record = records[0]\n            return {\n                \"file\": dict(record[\"f\"]) if record[\"f\"] else None,\n                \"classes\": record[\"classes\"],\n                \"functions\": [dict(f) for f in record[\"functions\"]] if record[\"functions\"] else [],\n                \"imports\": [dict(i) for i in record[\"imports\"]] if record[\"imports\"] else []\n            }\n        return {}\n    \n    def get_repo_overview(self, repo_id: str) -> Dict[str, Any]:\n        \"\"\"Get an overview of a repository.\"\"\"\n        if not self.db.connected:\n            # Return mock overview\n            return {\n                \"repo\": {\n                    \"id\": repo_id,\n                    \"name\": repo_id.split(\"/\")[-1] if \"/\" in repo_id else repo_id,\n                    \"owner\": repo_id.split(\"/\")[0] if \"/\" in repo_id else \"unknown\"\n                },\n                \"files\": 25,\n                \"classes\": 12,\n                \"functions\": 89,\n                \"languages\": [\"Python\", \"TypeScript\", \"JavaScript\"]\n            }\n            \n        query = CYPHER_QUERIES[\"get_repo_overview\"]\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        \n        if records:\n            record = records[0]\n            return {\n                \"repo\": record[\"repo\"],\n                \"files\": record[\"file_count\"],\n                \"classes\": record[\"class_count\"],\n                \"functions\": record[\"function_count\"],\n                \"languages\": record[\"languages\"]\n            }\n        return {}\n    \n    def get_repo_files(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all files in a repository.\"\"\"\n        query = CYPHER_QUERIES[\"get_repo_files\"]\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        \n        return [\n            {\n                \"file\": dict(record[\"f\"]) if record[\"f\"] else None,\n                \"language\": record[\"language\"],\n                \"lines_count\": record[\"lines_count\"]\n                \n            }\n            for record in records\n        ]\n    \n    # =========================================================================\n    # Search Operations\n    # =========================================================================\n    \n    def _escape_lucene_query(self, query: str) -> str:\n        \"\"\"\n        Escape Lucene special characters in search query.\n\n        Strategy: Wrap the entire query in quotes to treat it as a literal phrase search.\n        This prevents Lucene from interpreting special characters.\n\n        For complex queries, users can use wildcards: *\n        \"\"\"\n        query = query.strip()\n\n        # If query is empty, return a wildcard\n        if not query:\n            return '*'\n\n        # If the query already has quotes, escape internal quotes\n        if '\"' in query:\n            # Escape any existing quotes and wrap in quotes\n            query = query.replace('\"', '\\\\\"')\n\n        # Wrap in quotes to make it a literal phrase search\n        # This treats special characters as literals\n        return f'\"{query}\"'\n\n    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n        \"\"\"Search for code by name or docstring.\"\"\"\n        # Escape Lucene special characters to prevent query parsing errors\n        escaped_term = self._escape_lucene_query(search_term)\n\n        query = CYPHER_QUERIES[\"search_code\"]\n        records, _, _ = self.db.run_query(query, {\"search_term\": escaped_term})\n\n        return [\n            {\n                \"node\": dict(record[\"node\"]) if record[\"node\"] else None,\n                \"type\": record[\"type\"],\n                \"file\": record[\"file\"],\n                \"score\": record[\"score\"]\n            }\n            for record in records\n        ]\n\n    def search_symbols(\n        self,\n        search_term: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search symbols using fulltext index.\n\n        Args:\n            search_term: Search query (supports fuzzy matching)\n            limit: Maximum results to return\n\n        Returns:\n            List of matching symbols with scores\n        \"\"\"\n        query = CYPHER_QUERIES[\"search_symbols\"]\n        records, _, _ = self.db.run_query(query, {\n            \"search_term\": search_term,\n            \"limit\": limit\n        })\n\n        return [\n            {\n                \"name\": record[\"name\"],\n                \"qualified_name\": record[\"qualified_name\"],\n                \"type\": record[\"type\"],\n                \"file_id\": record[\"file_id\"],\n                \"line\": record[\"line\"],\n                \"visibility\": record[\"visibility\"],\n                \"score\": record[\"score\"]\n            }\n            for record in records\n        ]\n\n    def find_symbol_by_qualified_name(\n        self,\n        qualified_name: str,\n        repo_id: str\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a symbol by its exact qualified name.\n\n        Args:\n            qualified_name: Full qualified name (e.g., module.Class.method)\n            repo_id: Repository ID to search in\n\n        Returns:\n            Symbol information if found\n        \"\"\"\n        query = CYPHER_QUERIES[\"search_symbols_by_qualified_name\"]\n        records, _, _ = self.db.run_query(query, {\n            \"qualified_name\": qualified_name,\n            \"repo_id\": repo_id\n        })\n\n        if records:\n            record = records[0]\n            return {\n                \"id\": record[\"id\"],\n                \"name\": record[\"name\"],\n                \"qualified_name\": record[\"qualified_name\"],\n                \"type\": record[\"type\"],\n                \"file_id\": record[\"file_id\"],\n                \"line_start\": record[\"line_start\"],\n                \"line_end\": record[\"line_end\"],\n                \"scope\": record[\"scope\"],\n                \"visibility\": record[\"visibility\"],\n                \"docstring\": record[\"docstring\"]\n            }\n        return None\n\n    def autocomplete_symbols(\n        self,\n        prefix: str,\n        repo_id: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get symbol autocomplete suggestions.\n\n        Args:\n            prefix: Prefix to match (e.g., \"module.Clas\")\n            repo_id: Repository ID\n            limit: Maximum results\n\n        Returns:\n            List of matching symbol qualified names\n        \"\"\"\n        query = CYPHER_QUERIES[\"autocomplete_symbols\"]\n        records, _, _ = self.db.run_query(query, {\n            \"prefix\": prefix,\n            \"repo_id\": repo_id,\n            \"limit\": limit\n        })\n\n        return [\n            {\n                \"qualified_name\": record[\"qualified_name\"],\n                \"type\": record[\"type\"],\n                \"visibility\": record[\"visibility\"],\n                \"file_id\": record[\"file_id\"]\n            }\n            for record in records\n        ]\n\n    def find_symbols_in_scope(\n        self,\n        file_id: str,\n        scope: str = \"module\"\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Find all symbols in a specific scope.\n\n        Args:\n            file_id: File ID to search in\n            scope: Scope type (module, class, function)\n\n        Returns:\n            List of symbols in the scope\n        \"\"\"\n        query = CYPHER_QUERIES[\"find_symbols_in_scope\"]\n        records, _, _ = self.db.run_query(query, {\n            \"file_id\": file_id,\n            \"scope\": scope\n        })\n\n        return [\n            {\n                \"name\": record[\"name\"],\n                \"qualified_name\": record[\"qualified_name\"],\n                \"type\": record[\"type\"],\n                \"line_start\": record[\"line_start\"],\n                \"visibility\": record[\"visibility\"]\n            }\n            for record in records\n        ]\n    \n    def find_symbol_definition(self, symbol_name: str, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Find where a symbol (class, function, method, variable) is defined.\"\"\"\n        query = \"\"\"\n        MATCH (symbol)\n        WHERE symbol.name = $symbol_name\n          AND (symbol.file_id STARTS WITH $repo_id OR symbol.class_id STARTS WITH $repo_id)\n        MATCH (f:File)-[:DEFINES*1..2]->(symbol)\n        RETURN symbol.name as name, labels(symbol)[0] as type,\n               f.path as file, symbol.line_start as line,\n               symbol.docstring as docstring, symbol.source_code as source_code\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\n            \"symbol_name\": symbol_name,\n            \"repo_id\": repo_id\n        })\n\n        return [\n            {\n                \"name\": record[\"name\"],\n                \"type\": record[\"type\"],\n                \"file\": record[\"file\"],\n                \"line\": record[\"line\"],\n                \"docstring\": record[\"docstring\"],\n                \"source_code\": record.get(\"source_code\")\n            }\n            for record in records\n        ]\n    \n    # =========================================================================\n    # Impact Analysis\n    # =========================================================================\n    \n    def analyze_change_impact(self, target_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Analyze the impact of changing a specific code element.\"\"\"\n        query = CYPHER_QUERIES[\"analyze_change_impact\"]\n        records, _, _ = self.db.run_query(query, {\"target_id\": target_id})\n\n        return [\n            {\n                \"affected\": record[\"affected\"],\n                \"type\": record[\"type\"],\n                \"file\": record[\"file\"],\n                \"distance\": record[\"distance\"]\n            }\n            for record in records\n        ]\n\n    def analyze_change_impact_enhanced(\n        self,\n        qualified_name: str,\n        repo_id: str\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Enhanced impact analysis with multi-dimensional impact tracking.\n\n        Analyzes:\n        - Direct callers\n        - Transitive callers (up to 3 levels)\n        - Inheritance impact (for classes/methods)\n        - Import impact (files that import changed file)\n\n        Args:\n            qualified_name: Fully qualified name of the symbol\n            repo_id: Repository ID\n\n        Returns:\n            Dict with categorized impact analysis\n        \"\"\"\n        query = CYPHER_QUERIES[\"analyze_change_impact_enhanced\"]\n        records, _, _ = self.db.run_query(query, {\n            \"qualified_name\": qualified_name,\n            \"repo_id\": repo_id\n        })\n\n        if records:\n            record = records[0]\n            return {\n                \"target\": record[\"target\"],\n                \"direct_calls\": [call for call in record[\"direct_calls\"] if call.get(\"name\")],\n                \"transitive_calls\": [call for call in record[\"transitive_calls\"] if call.get(\"name\")],\n                \"inheritance_impact\": [imp for imp in record[\"inheritance_impact\"] if imp.get(\"name\")],\n                \"import_impact\": [imp for imp in record[\"import_impact\"] if imp.get(\"name\")],\n                \"total_impact\": record[\"total_impact\"]\n            }\n        return {\n            \"target\": qualified_name,\n            \"direct_calls\": [],\n            \"transitive_calls\": [],\n            \"inheritance_impact\": [],\n            \"import_impact\": [],\n            \"total_impact\": 0\n        }\n\n    def get_call_graph(\n        self,\n        qualified_name: str,\n        repo_id: str,\n        max_depth: int = 3\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get the call graph starting from a symbol.\n\n        Args:\n            qualified_name: Starting symbol\n            repo_id: Repository ID\n            max_depth: Maximum depth to traverse\n\n        Returns:\n            List of caller-callee relationships\n        \"\"\"\n        query = CYPHER_QUERIES[\"get_call_graph\"]\n        records, _, _ = self.db.run_query(query, {\n            \"qualified_name\": qualified_name,\n            \"repo_id\": repo_id,\n            \"max_depth\": max_depth\n        })\n\n        return [\n            {\n                \"caller\": record[\"caller\"],\n                \"callee\": record[\"callee\"],\n                \"caller_type\": record[\"caller_type\"],\n                \"callee_type\": record[\"callee_type\"],\n                \"line\": record[\"line\"],\n                \"depth\": record[\"depth\"]\n            }\n            for record in records\n        ]\n    \n    # =========================================================================\n    # Code Retrieval Operations\n    # =========================================================================\n\n    def get_code_at_line(self, file_id: str, line_number: int) -> Optional[str]:\n        \"\"\"\n        Get the code content at a specific line.\n\n        Note: Uses file source_code and extracts the specific line.\n        \"\"\"\n        source_code = self.reconstruct_file(file_id)\n        if not source_code:\n            return None\n\n        lines = source_code.split('\\n')\n        if 0 < line_number <= len(lines):\n            return lines[line_number - 1]\n        return None\n\n    def get_code_range(\n        self,\n        file_id: str,\n        start_line: int,\n        end_line: int\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get code content for a range of lines.\n\n        Note: Uses file source_code and extracts the range.\n        \"\"\"\n        source_code = self.reconstruct_file(file_id)\n        if not source_code:\n            return []\n\n        lines = source_code.split('\\n')\n        result = []\n\n        for i in range(start_line - 1, min(end_line, len(lines))):\n            if i >= 0:\n                line_content = lines[i]\n                result.append({\n                    \"line\": i + 1,\n                    \"content\": line_content,\n                    \"is_comment\": line_content.strip().startswith(('#', '//', '/*')),\n                    \"is_blank\": len(line_content.strip()) == 0\n                })\n\n        return result\n    \n    # =========================================================================\n    # File Reconstruction\n    # =========================================================================\n    \n    def get_repository_files(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all files in a repository.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:CONTAINS*]->(f:File)\n        RETURN f.id as id, f.path as path, f.language as language,\n               f.lines_count as lines_count\n        ORDER BY f.path\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        return [\n            {\n                \"id\": record[\"id\"],\n                \"path\": record[\"path\"],\n                \"language\": record[\"language\"],\n                \"lines_count\": record[\"lines_count\"]\n            }\n            for record in records\n        ]\n    \n    def reconstruct_file(self, file_id: str) -> Optional[str]:\n        \"\"\"\n        Reconstruct a file's complete content from source_code property.\n\n        Returns:\n            Complete file source code or None if not found\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {id: $file_id})\n        RETURN f.source_code as source_code, f.path as path\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n\n        if not records:\n            return None\n\n        source_code = records[0].get(\"source_code\")\n        if not source_code:\n            # Fallback: try to reconstruct from individual code elements\n            # This shouldn't be needed but provides a safety net\n            print(f\"⚠️  Warning: File {records[0].get('path')} has no source_code stored\")\n            return None\n\n        return source_code\n\n    def verify_reconstruction(self, file_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Verify that file reconstruction is possible and show stats.\n\n        Args:\n            file_id: File ID to verify\n\n        Returns:\n            Dict with verification results\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {id: $file_id})\n        OPTIONAL MATCH (f)-[:DEFINES]->(c:Class)\n        OPTIONAL MATCH (f)-[:DEFINES]->(fn:Function)\n        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)\n        RETURN f.path as path,\n               f.language as language,\n               f.lines_count as lines_count,\n               f.source_code IS NOT NULL as has_source_code,\n               size(f.source_code) as source_code_size,\n               count(DISTINCT c) as class_count,\n               count(DISTINCT fn) as function_count,\n               count(DISTINCT m) as method_count\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n\n        if not records:\n            return {\"error\": \"File not found\", \"file_id\": file_id}\n\n        record = records[0]\n        can_reconstruct = record[\"has_source_code\"]\n\n        return {\n            \"file_id\": file_id,\n            \"path\": record[\"path\"],\n            \"language\": record[\"language\"],\n            \"lines_count\": record[\"lines_count\"],\n            \"can_reconstruct\": can_reconstruct,\n            \"source_code_size\": record[\"source_code_size\"] or 0,\n            \"classes\": record[\"class_count\"],\n            \"functions\": record[\"function_count\"],\n            \"methods\": record[\"method_count\"],\n            \"status\": \"✅ Ready\" if can_reconstruct else \"❌ No source_code\"\n        }\n    \n    def get_symbol_source(self, qualified_name: str, repo_id: str) -> Optional[str]:\n        \"\"\"\n        Get source code for a specific symbol.\n\n        Args:\n            qualified_name: Fully qualified name of the symbol\n            repo_id: Repository ID\n\n        Returns:\n            Source code of the symbol or None\n        \"\"\"\n        query = \"\"\"\n        MATCH (s:Symbol {qualified_name: $qualified_name})\n        WHERE s.file_id STARTS WITH $repo_id\n        RETURN s.source_code as source_code\n        LIMIT 1\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\n            \"qualified_name\": qualified_name,\n            \"repo_id\": repo_id\n        })\n\n        if records and records[0][\"source_code\"]:\n            return records[0][\"source_code\"]\n\n        # Fallback: try to get from definition node\n        symbol = self.find_symbol_by_qualified_name(qualified_name, repo_id)\n        if symbol and symbol.get(\"type\"):\n            if symbol[\"type\"] == \"class\":\n                return self.get_class_source(f\"{symbol['file_id']}:class:{symbol['name']}:{symbol['line_start']}\")\n            elif symbol[\"type\"] == \"function\":\n                return self.get_function_source(f\"{symbol['file_id']}:func:{symbol['name']}:{symbol['line_start']}\")\n            elif symbol[\"type\"] == \"method\":\n                # More complex - need to find class first\n                pass\n\n        return None\n\n    def verify_repository_reconstruction(self, repo_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Verify that all files in a repository can be reconstructed.\n\n        Args:\n            repo_id: Repository ID\n\n        Returns:\n            Dict with verification stats\n        \"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:CONTAINS*]->(f:File)\n        RETURN count(f) as total_files,\n               sum(CASE WHEN f.source_code IS NOT NULL THEN 1 ELSE 0 END) as files_with_source,\n               sum(f.lines_count) as total_lines,\n               sum(size(f.source_code)) as total_source_size\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n\n        if not records:\n            return {\"error\": \"Repository not found\", \"repo_id\": repo_id}\n\n        record = records[0]\n        total_files = record[\"total_files\"] or 0\n        files_with_source = record[\"files_with_source\"] or 0\n        success_rate = (files_with_source / total_files * 100) if total_files > 0 else 0\n\n        # Get list of files without source code\n        problem_files_query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:CONTAINS*]->(f:File)\n        WHERE f.source_code IS NULL\n        RETURN f.path as path, f.id as file_id\n        LIMIT 10\n        \"\"\"\n        problem_records, _, _ = self.db.run_query(problem_files_query, {\"repo_id\": repo_id})\n\n        return {\n            \"repo_id\": repo_id,\n            \"total_files\": total_files,\n            \"files_with_source\": files_with_source,\n            \"files_without_source\": total_files - files_with_source,\n            \"success_rate\": f\"{success_rate:.1f}%\",\n            \"total_lines\": record[\"total_lines\"] or 0,\n            \"total_source_size_mb\": (record[\"total_source_size\"] or 0) / 1024 / 1024,\n            \"status\": \"✅ All files ready\" if success_rate == 100 else f\"⚠️  {total_files - files_with_source} files missing source\",\n            \"problem_files\": [r[\"path\"] for r in problem_records] if problem_records else []\n        }\n\n    def reconstruct_repository(self, repo_id: str) -> Dict[str, str]:\n        \"\"\"\n        Reconstruct all files in a repository.\n        \n        Returns:\n            Dict mapping file paths to their reconstructed content\n        \"\"\"\n        files = self.get_repository_files(repo_id)\n        reconstructed = {}\n        \n        for file_info in files:\n            content = self.reconstruct_file(file_info[\"id\"])\n            if content is not None:\n                reconstructed[file_info[\"path\"]] = content\n        \n        return reconstructed\n    \n    def get_file_metadata(self, file_id: str) -> Dict[str, Any]:\n        \"\"\"Get complete metadata for a file including all code elements.\"\"\"\n        query = \"\"\"\n        MATCH (f:File {id: $file_id})\n        OPTIONAL MATCH (f)-[:DEFINES]->(c:Class)\n        OPTIONAL MATCH (f)-[:DEFINES]->(fn:Function)\n        OPTIONAL MATCH (f)-[:HAS_IMPORT]->(i:Import)\n        RETURN f.path as path,\n               f.language as language,\n               f.lines_count as lines_count,\n               collect(DISTINCT {name: c.name, line: c.line_start, bases: c.base_classes}) as classes,\n               collect(DISTINCT {name: fn.name, line: fn.line_start, params: fn.params}) as functions,\n               collect(DISTINCT {module: i.module, names: i.imported_names}) as imports\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n\n        if records:\n            record = records[0]\n            return {\n                \"path\": record[\"path\"],\n                \"language\": record[\"language\"],\n                \"lines_count\": record[\"lines_count\"],\n                \"classes\": [c for c in record[\"classes\"] if c[\"name\"]],\n                \"functions\": [f for f in record[\"functions\"] if f[\"name\"]],\n                \"imports\": [i for i in record[\"imports\"] if i[\"module\"]]\n            }\n        return {}\n\n    def get_method_source(self, method_id: str) -> Optional[str]:\n        \"\"\"Get the source code of a specific method.\"\"\"\n        query = \"\"\"\n        MATCH (m:Method {id: $method_id})\n        RETURN m.source_code as source_code\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"method_id\": method_id})\n        return records[0][\"source_code\"] if records and records[0][\"source_code\"] else None\n\n    def get_function_source(self, function_id: str) -> Optional[str]:\n        \"\"\"Get the source code of a specific function.\"\"\"\n        query = \"\"\"\n        MATCH (f:Function {id: $function_id})\n        RETURN f.source_code as source_code\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"function_id\": function_id})\n        return records[0][\"source_code\"] if records and records[0][\"source_code\"] else None\n\n    def get_class_source(self, class_id: str) -> Optional[str]:\n        \"\"\"Get the source code of a specific class.\"\"\"\n        query = \"\"\"\n        MATCH (c:Class {id: $class_id})\n        RETURN c.source_code as source_code\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"class_id\": class_id})\n        return records[0][\"source_code\"] if records and records[0][\"source_code\"] else None\n    \n    # =========================================================================\n    # Config File Queries\n    # =========================================================================\n    \n    def get_repo_config_files(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all config files in a repository.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:HAS_CONFIG]->(cf:ConfigFile)\n        RETURN cf.id as id, cf.path as path, cf.file_type as file_type,\n               cf.project_name as project_name, cf.version as version,\n               cf.lines_count as lines_count\n        ORDER BY cf.path\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        return [\n            {\n                \"id\": record[\"id\"],\n                \"path\": record[\"path\"],\n                \"file_type\": record[\"file_type\"],\n                \"project_name\": record[\"project_name\"],\n                \"version\": record[\"version\"],\n                \"lines_count\": record[\"lines_count\"]\n            }\n            for record in records\n        ]\n    \n    def get_repo_dependencies(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all dependencies in a repository.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:HAS_CONFIG]->(cf:ConfigFile)-[:HAS_DEPENDENCY]->(d:Dependency)\n        RETURN d.name as name, d.version_spec as version, d.is_dev as is_dev,\n               d.source as source, cf.path as config_file\n        ORDER BY d.is_dev, d.name\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        return [\n            {\n                \"name\": record[\"name\"],\n                \"version\": record[\"version\"],\n                \"is_dev\": record[\"is_dev\"],\n                \"source\": record[\"source\"],\n                \"config_file\": record[\"config_file\"]\n            }\n            for record in records\n        ]\n    \n    def delete_repository(self, repo_id: str) -> bool:\n        \"\"\"Delete a repository and all its data.\"\"\"\n        if not self.db.connected:\n            # Mock success for testing\n            return True\n\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        DETACH DELETE r\n        RETURN count(r) as deleted_count\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n\n        return len(records) > 0 and records[0].get(\"deleted_count\", 0) > 0\n    \n    def get_repo_overview_extended(self, repo_id: str) -> Dict[str, Any]:\n        \"\"\"Get extended repository overview including config files and dependencies.\"\"\"\n        # Get basic stats\n        basic = self.get_repo_overview(repo_id)\n        \n        # Get config file count\n        config_query = \"\"\"\n        MATCH (r:Repository {id: $repo_id})-[:HAS_CONFIG]->(cf:ConfigFile)\n        OPTIONAL MATCH (cf)-[:HAS_DEPENDENCY]->(d:Dependency)\n        RETURN count(DISTINCT cf) as config_count, count(DISTINCT d) as dep_count\n        \"\"\"\n        records, _, _ = self.db.run_query(config_query, {\"repo_id\": repo_id})\n        \n        if records:\n            basic[\"config_files\"] = records[0][\"config_count\"]\n            basic[\"dependencies\"] = records[0][\"dep_count\"]\n        else:\n            basic[\"config_files\"] = 0\n            basic[\"dependencies\"] = 0\n        \n        return basic\n\n    def get_all_ingested_repositories(self, owner: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all ingested repositories.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository {owner: $owner})\n        RETURN r.id as repo_id, r.owner as owner, r.name as name, r.url as url\n        ORDER BY r.owner, r.name\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"owner\": owner})\n        return [\n            {\n                \"repo_id\": record[\"repo_id\"],\n                \"owner\": record[\"owner\"],\n                \"name\": record[\"name\"],\n                \"url\": record[\"url\"]\n            }\n            for record in records\n        ]\n\n    # =========================================================================\n    # Hierarchy Navigation\n    # =========================================================================\n\n    def get_module_tree(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get the complete module/directory tree for a repository.\n\n        Args:\n            repo_id: Repository ID\n\n        Returns:\n            List of modules with hierarchy information\n        \"\"\"\n        query = CYPHER_QUERIES[\"get_module_tree\"]\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n\n        return [\n            {\n                \"path\": record[\"path\"],\n                \"name\": record[\"name\"],\n                \"parent_path\": record[\"parent_path\"],\n                \"is_package\": record[\"is_package\"],\n                \"depth\": record[\"depth\"]\n            }\n            for record in records\n        ]\n\n    def get_file_hierarchy(self, file_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get the breadcrumb hierarchy for a file.\n\n        Args:\n            file_id: File ID\n\n        Returns:\n            Ordered list from repository to file\n        \"\"\"\n        query = CYPHER_QUERIES[\"get_file_hierarchy\"]\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n\n        return [\n            {\n                \"type\": record[\"type\"],\n                \"name\": record[\"name\"],\n                \"path\": record[\"path\"],\n                \"depth\": record[\"depth\"]\n            }\n            for record in records\n        ]\n\n    def get_directory_contents(\n        self,\n        repo_id: str,\n        dir_path: str\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get contents of a specific directory.\n\n        Args:\n            repo_id: Repository ID\n            dir_path: Directory path\n\n        Returns:\n            List of files and subdirectories\n        \"\"\"\n        query = CYPHER_QUERIES[\"get_directory_contents\"]\n        records, _, _ = self.db.run_query(query, {\n            \"repo_id\": repo_id,\n            \"dir_path\": dir_path\n        })\n\n        return [\n            {\n                \"type\": record[\"type\"],\n                \"name\": record[\"name\"],\n                \"path\": record[\"path\"],\n                \"is_package\": record[\"is_package\"]\n            }\n            for record in records\n        ]\n\n    def get_symbols_at_lines(self, file_path: str, start_line: int, end_line: int) -> List[Dict[str, Any]]:\n        \"\"\"\n        Find all symbols (functions, classes, variables) that overlap a line range in a file.\n        Used to map diff hunks to affected code symbols.\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {path: $file_path})-[:CONTAINS]->(n)\n        WHERE (n:Function OR n:Class OR n:Variable)\n          AND n.line_number IS NOT NULL\n          AND n.line_number <= $end_line\n          AND coalesce(n.end_line, n.line_number) >= $start_line\n        RETURN\n            CASE\n                WHEN n:Function THEN 'function'\n                WHEN n:Class THEN 'class'\n                ELSE 'variable'\n            END as type,\n            n.name as name,\n            n.line_number as start_line,\n            coalesce(n.end_line, n.line_number) as end_line,\n            n.source as source,\n            n.docstring as docstring,\n            n.path as path\n        ORDER BY n.line_number\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\n            \"file_path\": file_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n        })\n        return [dict(r) for r in records]\n\n    def get_symbols_at_lines_by_relative_path(self, repo_id: str, relative_path: str, start_line: int, end_line: int) -> List[Dict[str, Any]]:\n        \"\"\"\n        Find all symbols overlapping a line range using repo-relative file path.\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File)\n        WHERE f.relative_path = $relative_path\n          AND f.path CONTAINS $repo_id\n        WITH f\n        MATCH (f)-[:CONTAINS]->(n)\n        WHERE (n:Function OR n:Class OR n:Variable)\n          AND n.line_number IS NOT NULL\n          AND n.line_number <= $end_line\n          AND coalesce(n.end_line, n.line_number) >= $start_line\n        RETURN\n            CASE\n                WHEN n:Function THEN 'function'\n                WHEN n:Class THEN 'class'\n                ELSE 'variable'\n            END as type,\n            n.name as name,\n            n.line_number as start_line,\n            coalesce(n.end_line, n.line_number) as end_line,\n            n.source as source,\n            n.docstring as docstring,\n            f.relative_path as file_path\n        ORDER BY n.line_number\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\n            \"repo_id\": repo_id,\n            \"relative_path\": relative_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n        })\n        return [dict(r) for r in records]\n\n    def get_diff_context(self, repo_id: str, changes: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Build full RAG context for a set of file changes (diff).\n\n        Args:\n            repo_id: Repository ID (e.g. \"owner/repo\")\n            changes: List of {\"file_path\": \"relative/path.py\", \"start_line\": 10, \"end_line\": 30}\n\n        Returns:\n            Dict with affected_symbols, callers, hierarchy, and file_sources.\n        \"\"\"\n        all_affected = []\n        all_callers = []\n        all_hierarchy = []\n        file_sources = {}\n\n        for change in changes:\n            file_path = change[\"file_path\"]\n            start_line = change.get(\"start_line\", 1)\n            end_line = change.get(\"end_line\", 999999)\n\n            # 1. Find affected symbols\n            symbols = self.get_symbols_at_lines_by_relative_path(\n                repo_id, file_path, start_line, end_line\n            )\n            for s in symbols:\n                s[\"change_file\"] = file_path\n            all_affected.extend(symbols)\n\n            # 2. For each affected symbol, find callers\n            for sym in symbols:\n                caller_query = \"\"\"\n                MATCH (caller)-[:CALLS]->(target)\n                WHERE target.name = $name AND target.path CONTAINS $repo_id\n                RETURN\n                    CASE\n                        WHEN caller:Function THEN 'function'\n                        WHEN caller:Class THEN 'class'\n                        ELSE 'other'\n                    END as type,\n                    caller.name as name,\n                    caller.path as path,\n                    caller.line_number as line_number,\n                    caller.source as source\n                LIMIT 20\n                \"\"\"\n                records, _, _ = self.db.run_query(caller_query, {\n                    \"name\": sym[\"name\"],\n                    \"repo_id\": repo_id,\n                })\n                callers = [dict(r) for r in records]\n                if callers:\n                    all_callers.append({\n                        \"symbol\": sym[\"name\"],\n                        \"symbol_type\": sym[\"type\"],\n                        \"callers\": callers,\n                    })\n\n            # 3. For affected classes, get hierarchy\n            class_symbols = [s for s in symbols if s[\"type\"] == \"class\"]\n            for cls in class_symbols:\n                hier_query = \"\"\"\n                MATCH (c:Class {name: $name})-[:INHERITS*0..5]->(parent:Class)\n                WHERE c.path CONTAINS $repo_id\n                RETURN parent.name as name, parent.path as path,\n                       parent.source as source, parent.docstring as docstring\n                \"\"\"\n                records, _, _ = self.db.run_query(hier_query, {\n                    \"name\": cls[\"name\"],\n                    \"repo_id\": repo_id,\n                })\n                if records:\n                    all_hierarchy.append({\n                        \"class\": cls[\"name\"],\n                        \"hierarchy\": [dict(r) for r in records],\n                    })\n\n            # 4. Get file source\n            file_src_query = \"\"\"\n            MATCH (f:File)\n            WHERE f.relative_path = $relative_path AND f.path CONTAINS $repo_id\n            RETURN f.source_code as source_code, f.relative_path as path\n            LIMIT 1\n            \"\"\"\n            records, _, _ = self.db.run_query(file_src_query, {\n                \"relative_path\": file_path,\n                \"repo_id\": repo_id,\n            })\n            if records and records[0].get(\"source_code\"):\n                file_sources[file_path] = records[0][\"source_code\"]\n\n        return {\n            \"affected_symbols\": all_affected,\n            \"callers\": all_callers,\n            \"class_hierarchy\": all_hierarchy,\n            \"file_sources\": file_sources,\n            \"total_affected\": len(all_affected),\n            \"total_files\": len(changes),\n        }\n\n    def get_diff_context_condensed(\n        self, repo_id: str, changes: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Build lean context for a set of file changes — optimized for LLM prompts.\n\n        Compared to get_diff_context:\n        - Only returns functions/classes/methods (skips variables)\n        - Returns symbol source snippets (the changed code chunk, not the whole file)\n        - Returns caller names + file paths only (no caller source code)\n        - Returns hierarchy as name chains only (no parent source)\n        - No full file sources at all\n\n        Args:\n            repo_id: Repository ID (e.g. \"owner/repo\")\n            changes: List of {\"file_path\": \"relative/path.py\", \"start_line\": 10, \"end_line\": 30}\n\n        Returns:\n            Dict with affected_symbols, callers, hierarchy.\n        \"\"\"\n        all_affected: List[Dict[str, Any]] = []\n        all_callers: List[Dict[str, Any]] = []\n        all_hierarchy: List[Dict[str, Any]] = []\n        seen_symbols: set = set()\n\n        for change in changes:\n            file_path = change[\"file_path\"]\n            start_line = change.get(\"start_line\", 1)\n            end_line = change.get(\"end_line\", 999999)\n\n            # 1. Find affected symbols — functions and classes only\n            query = \"\"\"\n            MATCH (f:File)\n            WHERE f.relative_path = $relative_path\n              AND f.path CONTAINS $repo_id\n            WITH f\n            MATCH (f)-[:CONTAINS]->(n)\n            WHERE (n:Function OR n:Class OR n:Method)\n              AND n.line_number IS NOT NULL\n              AND n.line_number <= $end_line\n              AND coalesce(n.end_line, n.line_number) >= $start_line\n            RETURN\n                CASE\n                    WHEN n:Function THEN 'function'\n                    WHEN n:Method THEN 'method'\n                    WHEN n:Class THEN 'class'\n                END as type,\n                n.name as name,\n                n.line_number as start_line,\n                coalesce(n.end_line, n.line_number) as end_line,\n                n.source as source,\n                n.docstring as docstring,\n                f.relative_path as file_path\n            ORDER BY n.line_number\n            \"\"\"\n            records, _, _ = self.db.run_query(query, {\n                \"repo_id\": repo_id,\n                \"relative_path\": file_path,\n                \"start_line\": start_line,\n                \"end_line\": end_line,\n            })\n\n            symbols = [dict(r) for r in records]\n            for s in symbols:\n                s[\"change_file\"] = file_path\n                # Truncate source to keep prompts lean\n                if s.get(\"source\") and len(s[\"source\"]) > 500:\n                    s[\"source\"] = s[\"source\"][:500] + \"\\n... (truncated)\"\n            all_affected.extend(symbols)\n\n            # 2. For each symbol, find caller names only (no source)\n            for sym in symbols:\n                sym_key = f\"{file_path}:{sym['name']}\"\n                if sym_key in seen_symbols:\n                    continue\n                seen_symbols.add(sym_key)\n\n                caller_query = \"\"\"\n                MATCH (caller)-[:CALLS]->(target)\n                WHERE target.name = $name AND target.path CONTAINS $repo_id\n                RETURN DISTINCT\n                    caller.name as name,\n                    CASE\n                        WHEN caller:Function THEN 'function'\n                        WHEN caller:Method THEN 'method'\n                        WHEN caller:Class THEN 'class'\n                        ELSE 'other'\n                    END as type,\n                    caller.path as path\n                LIMIT 10\n                \"\"\"\n                records, _, _ = self.db.run_query(caller_query, {\n                    \"name\": sym[\"name\"],\n                    \"repo_id\": repo_id,\n                })\n                callers = [dict(r) for r in records]\n                if callers:\n                    all_callers.append({\n                        \"symbol\": sym[\"name\"],\n                        \"symbol_type\": sym[\"type\"],\n                        \"callers\": callers,\n                    })\n\n            # 3. For affected classes, get hierarchy names only\n            class_symbols = [s for s in symbols if s[\"type\"] == \"class\"]\n            for cls in class_symbols:\n                hier_query = \"\"\"\n                MATCH (c:Class {name: $name})-[:INHERITS*0..3]->(parent:Class)\n                WHERE c.path CONTAINS $repo_id\n                RETURN parent.name as name, parent.path as path\n                \"\"\"\n                records, _, _ = self.db.run_query(hier_query, {\n                    \"name\": cls[\"name\"],\n                    \"repo_id\": repo_id,\n                })\n                if records:\n                    all_hierarchy.append({\n                        \"class\": cls[\"name\"],\n                        \"hierarchy\": [{\"name\": r[\"name\"], \"path\": r[\"path\"]} for r in records],\n                    })\n\n        return {\n            \"affected_symbols\": all_affected,\n            \"callers\": all_callers,\n            \"class_hierarchy\": all_hierarchy,\n            \"total_affected\": len(all_affected),\n            \"total_files\": len(set(c[\"file_path\"] for c in changes)),\n        }\n\n    def get_diff_context_enhanced(\n        self, repo_id: str, changes: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Build full relationship context for every changed Function, Method, and Class.\n\n        For each symbol in the diff line ranges:\n          - Full source code of the symbol itself\n          - Methods belonging to each changed Class (with source)\n          - Callers: every Function/Method that calls this symbol via CALLS edges\n          - Dependencies: every Function/Method this symbol calls via CALLS edges\n          - Imports: other in-repo symbols imported by the changed file\n          - Class hierarchy: parent/child classes for any changed Class\n\n        Both Function and Method node types are handled throughout — the graph\n        stores class methods as Function nodes under the class via CONTAINS.\n        \"\"\"\n        from api.services.code_search import CodeFinder\n\n        code_finder = CodeFinder(self.db)\n\n        all_affected: List[Dict[str, Any]] = []\n        all_callers: List[Dict[str, Any]] = []\n        all_imports: List[Dict[str, Any]] = []\n        all_dependencies: List[Dict[str, Any]] = []\n        all_hierarchy: List[Dict[str, Any]] = []\n        seen_affected: set = set()\n        seen_callers: set = set()\n        seen_imports: set = set()\n\n        for change in changes:\n            file_path = change[\"file_path\"]\n            start_line = change.get(\"start_line\", 1)\n            end_line = change.get(\"end_line\", 999999)\n\n            # ── 1. Affected symbols (Function, Class, and Method) ─────────────\n            # Method nodes are stored under Class via CONTAINS — we surface them\n            # here so the agent sees both the class body and individual methods.\n            affected_query = \"\"\"\n            MATCH (f:File {repo: $repo_id, path: $file_path})\n            MATCH (f)-[:CONTAINS]->(n)\n            WHERE (n:Function OR n:Class OR n:Method)\n              AND n.line_number IS NOT NULL\n              AND n.line_number <= $end_line\n              AND coalesce(n.end_line, n.line_number) >= $start_line\n            RETURN\n                CASE\n                    WHEN n:Class    THEN 'class'\n                    WHEN n:Method   THEN 'method'\n                    ELSE                 'function'\n                END AS type,\n                n.name          AS name,\n                n.line_number   AS start_line,\n                coalesce(n.end_line, n.line_number) AS end_line,\n                n.source        AS source,\n                n.docstring     AS docstring,\n                n.args          AS args,\n                f.path          AS file_path\n            ORDER BY n.line_number\n            \"\"\"\n            records, _, _ = self.db.run_query(affected_query, {\n                \"repo_id\": repo_id,\n                \"file_path\": file_path,\n                \"start_line\": start_line,\n                \"end_line\": end_line,\n            })\n            symbols = [dict(r) for r in records]\n\n            for s in symbols:\n                s[\"change_file\"] = file_path\n                sym_key = f\"{s['file_path']}:{s['name']}:{s['start_line']}\"\n                if sym_key not in seen_affected:\n                    seen_affected.add(sym_key)\n                    all_affected.append(s)\n\n            for sym in symbols:\n                caller_key = f\"{sym['file_path']}:{sym['name']}\"\n                if caller_key in seen_callers:\n                    continue\n                seen_callers.add(caller_key)\n\n                # ── 2. Callers: who calls this symbol? ────────────────────────\n                # Match both Function and Method callers so class methods that\n                # call the changed code are not missed.\n                try:\n                    caller_query = \"\"\"\n                    MATCH (target)\n                    WHERE (target:Function OR target:Method OR target:Class)\n                      AND target.name = $name\n                      AND coalesce(target.path, '') CONTAINS $repo_id\n                    WITH target\n                    MATCH (caller)-[call:CALLS]->(target)\n                    WHERE (caller:Function OR caller:Method)\n                      AND NOT coalesce(caller.is_dependency, false)\n                    OPTIONAL MATCH (caller_file:File)-[:CONTAINS]->(caller)\n                    RETURN DISTINCT\n                        caller.name             AS caller_name,\n                        CASE WHEN caller:Method THEN 'method' ELSE 'function' END AS caller_type,\n                        coalesce(caller.path, caller_file.path) AS caller_path,\n                        caller.line_number      AS caller_line,\n                        call.line_number        AS call_line,\n                        call.args               AS call_args\n                    ORDER BY caller_path, caller.line_number\n                    LIMIT 10\n                    \"\"\"\n                    caller_records, _, _ = self.db.run_query(\n                        caller_query, {\"name\": sym[\"name\"], \"repo_id\": repo_id}\n                    )\n                    callers_list = [dict(r) for r in caller_records]\n                    if callers_list:\n                        all_callers.append({\n                            \"symbol\": sym[\"name\"],\n                            \"symbol_type\": sym[\"type\"],\n                            \"callers\": callers_list,\n                        })\n                except Exception as e:\n                    logger.warning(f\"Error finding callers for {sym['name']}: {e}\")\n\n                # ── 3. Dependencies: what does this symbol call? ──────────────\n                # Match both Function and Method targets to catch calls to methods.\n                try:\n                    dep_query = \"\"\"\n                    MATCH (caller)\n                    WHERE (caller:Function OR caller:Method)\n                      AND caller.name = $name\n                      AND caller.path = $path\n                    MATCH (caller)-[call:CALLS]->(called)\n                    WHERE (called:Function OR called:Method)\n                      AND NOT coalesce(called.is_dependency, false)\n                    RETURN DISTINCT\n                        called.name  AS called_name,\n                        CASE WHEN called:Method THEN 'method' ELSE 'function' END AS called_type,\n                        called.path  AS called_path,\n                        call.line_number AS call_line,\n                        call.args    AS call_args\n                    ORDER BY call.line_number\n                    LIMIT 15\n                    \"\"\"\n                    dep_records, _, _ = self.db.run_query(dep_query, {\n                        \"name\": sym[\"name\"],\n                        \"path\": sym[\"file_path\"],\n                    })\n                    deps_list = [dict(r) for r in dep_records]\n                    if deps_list:\n                        all_dependencies.append({\n                            \"symbol\": sym[\"name\"],\n                            \"dependencies\": deps_list,\n                        })\n                except Exception as e:\n                    logger.warning(f\"Error finding dependencies for {sym['name']}: {e}\")\n\n                # ── 4. Class methods: when a Class is affected, fetch all ──────\n                # its methods with full source so the agent sees what each\n                # method does — not just the class skeleton.\n                if sym[\"type\"] == \"class\":\n                    try:\n                        methods_query = \"\"\"\n                        MATCH (cls:Class {name: $class_name, path: $path})\n                        MATCH (cls)-[:CONTAINS]->(m:Function)\n                        RETURN\n                            m.name          AS name,\n                            m.line_number   AS line_number,\n                            coalesce(m.end_line, m.line_number) AS end_line,\n                            m.source        AS source,\n                            m.docstring     AS docstring,\n                            m.args          AS args\n                        ORDER BY m.line_number\n                        \"\"\"\n                        method_records, _, _ = self.db.run_query(methods_query, {\n                            \"class_name\": sym[\"name\"],\n                            \"path\": sym[\"file_path\"],\n                        })\n                        methods_list = [dict(r) for r in method_records]\n                        if methods_list:\n                            sym[\"methods\"] = methods_list\n                    except Exception as e:\n                        logger.warning(f\"Error fetching methods for class {sym['name']}: {e}\")\n\n            # ── 5. Imports: resolve imported names to in-repo source ──────────\n            import_query = \"\"\"\n            MATCH (f:File {repo: $repo_id, path: $file_path})\n            MATCH (f)-[r:IMPORTS]->(m)\n            RETURN\n                r.alias          AS alias,\n                r.imported_name  AS imported_name,\n                m.name           AS module_name,\n                r.line_number    AS line_number\n            ORDER BY r.line_number\n            LIMIT 20\n            \"\"\"\n            import_records, _, _ = self.db.run_query(import_query, {\n                \"repo_id\": repo_id,\n                \"file_path\": file_path,\n            })\n\n            for imp in import_records:\n                imported_name = imp.get(\"imported_name\") or imp.get(\"alias\")\n                if not imported_name or imported_name in seen_imports:\n                    continue\n                seen_imports.add(imported_name)\n\n                try:\n                    func_results = code_finder.find_by_function_name(imported_name, fuzzy_search=False)\n                    if func_results:\n                        for func in func_results[:1]:\n                            if func.get(\"path\") and repo_id in func.get(\"path\", \"\"):\n                                all_imports.append({\n                                    \"name\": imported_name,\n                                    \"type\": \"function\",\n                                    \"source\": func.get(\"source\", \"\"),\n                                    \"path\": func.get(\"path\"),\n                                    \"line\": func.get(\"line_number\"),\n                                    \"docstring\": func.get(\"docstring\"),\n                                    \"from_file\": file_path,\n                                })\n                    else:\n                        class_results = code_finder.find_by_class_name(imported_name, fuzzy_search=False)\n                        if class_results:\n                            for cls in class_results[:1]:\n                                if cls.get(\"path\") and repo_id in cls.get(\"path\", \"\"):\n                                    all_imports.append({\n                                        \"name\": imported_name,\n                                        \"type\": \"class\",\n                                        \"source\": cls.get(\"source\", \"\"),\n                                        \"path\": cls.get(\"path\"),\n                                        \"line\": cls.get(\"line_number\"),\n                                        \"docstring\": cls.get(\"docstring\"),\n                                        \"from_file\": file_path,\n                                    })\n                except Exception as e:\n                    logger.warning(f\"Error resolving import {imported_name}: {e}\")\n\n            # ── 6. Class hierarchy for affected classes ───────────────────────\n            for cls in [s for s in symbols if s[\"type\"] == \"class\"]:\n                try:\n                    hierarchy_info = code_finder.find_class_hierarchy(\n                        cls[\"name\"], cls.get(\"file_path\")\n                    )\n                    if hierarchy_info:\n                        all_hierarchy.append({\n                            \"class\": cls[\"name\"],\n                            \"parents\": hierarchy_info.get(\"parent_classes\", []),\n                            \"children\": hierarchy_info.get(\"child_classes\", []),\n                            \"methods\": hierarchy_info.get(\"methods\", []),\n                        })\n                except Exception as e:\n                    logger.warning(f\"Error finding hierarchy for {cls['name']}: {e}\")\n\n        return {\n            \"affected_symbols\": all_affected,\n            \"callers\": all_callers,\n            \"imports\": all_imports,\n            \"dependencies\": all_dependencies,\n            \"class_hierarchy\": all_hierarchy,\n            \"total_affected\": len(all_affected),\n            \"total_imports\": len(all_imports),\n            \"total_files\": len(set(c[\"file_path\"] for c in changes)),\n        }","numLines":1634,"startLine":1,"totalLines":1634}},"sourceToolAssistantUUID":"42035809-e451-493c-930a-51d9789023a9"}
{"parentUuid":"b1ffb9da-7c36-455d-bab8-774aeded20bf","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_0122TktPqNpW6a6aUR4Nw5ZW","toolUseID":"toolu_0122TktPqNpW6a6aUR4Nw5ZW","timestamp":"2026-02-21T08:05:46.605Z","uuid":"9abb6577-8453-48a4-82ef-177a8000d61f"}
{"parentUuid":"f7103b1d-54fe-4495-b2d1-b9d2ab8acc2e","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0122TktPqNpW6a6aUR4Nw5ZW","type":"tool_result","content":"     1→\"\"\"\n     2→Code query endpoints - Advanced implementation with Neo4j integration.\n     3→\"\"\"\n     4→\n     5→from fastapi import APIRouter, HTTPException, Query, Depends, Body\n     6→from pydantic import BaseModel\n     7→from typing import Dict, Any, List, Optional\n     8→import os\n     9→\n    10→from db.client import Neo4jClient\n    11→from db.queries import CodeQueryService\n    12→from api.dependencies import get_neo4j_client\n    13→from api.services.code_search import CodeFinder\n    14→\n    15→router = APIRouter()\n    16→\n    17→\n    18→def get_query_service(db: Neo4jClient = Depends(get_neo4j_client)) -> CodeQueryService:\n    19→    \"\"\"Dependency to get query service.\"\"\"\n    20→    return CodeQueryService(db)\n    21→\n    22→\n    23→def get_code_finder(db: Neo4jClient = Depends(get_neo4j_client)) -> CodeFinder:\n    24→    \"\"\"Dependency to get code finder.\"\"\"\n    25→    return CodeFinder(db)\n    26→\n    27→\n    28→@router.get(\"/search\")\n    29→async def search_code(\n    30→    query: str = Query(..., description=\"Search term for code\"),\n    31→    repo_id: str = Query(None, description=\"Optional repository ID to filter by\"),\n    32→    query_service: CodeQueryService = Depends(get_query_service)\n    33→) -> Dict[str, Any]:\n    34→    \"\"\"\n    35→    Search for code by content or name using fulltext search.\n    36→    \"\"\"\n    37→    try:\n    38→        results = query_service.search_code(query)\n    39→        \n    40→        # Filter by repo if provided\n    41→        if repo_id:\n    42→            filtered_results = []\n    43→            for result in results:\n    44→                if result.get('file', {}).get('repo_id') == repo_id:\n    45→                    filtered_results.append(result)\n    46→            results = filtered_results\n    47→        \n    48→        return {\n    49→            \"results\": results,\n    50→            \"total\": len(results),\n    51→            \"query\": query,\n    52→            \"repo_filter\": repo_id\n    53→        }\n    54→    except Exception as e:\n    55→        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")\n    56→\n    57→\n    58→@router.get(\"/search-symbols\")\n    59→async def search_symbols(\n    60→    query: str = Query(..., description=\"Search term for symbols\"),\n    61→    limit: int = Query(20, description=\"Maximum number of results\"),\n    62→    query_service: CodeQueryService = Depends(get_query_service)\n    63→) -> Dict[str, Any]:\n    64→    \"\"\"\n    65→    Search for symbols (functions, classes, variables) by name.\n    66→    \"\"\"\n    67→    try:\n    68→        results = query_service.search_symbols(query, limit)\n    69→        return {\n    70→            \"symbols\": results,\n    71→            \"total\": len(results),\n    72→            \"query\": query\n    73→        }\n    74→    except Exception as e:\n    75→        raise HTTPException(status_code=500, detail=f\"Symbol search failed: {str(e)}\")\n    76→\n    77→\n    78→@router.get(\"/method-usages\")\n    79→async def find_method_usages(\n    80→    method_name: str = Query(..., description=\"Name of the method to find usages for\"),\n    81→    query_service: CodeQueryService = Depends(get_query_service)\n    82→) -> Dict[str, Any]:\n    83→    \"\"\"\n    84→    Find all usages of a specific method.\n    85→    \"\"\"\n    86→    try:\n    87→        usages = query_service.find_method_usages(method_name)\n    88→        return usages\n    89→    except Exception as e:\n    90→        raise HTTPException(status_code=500, detail=f\"Failed to find method usages: {str(e)}\")\n    91→\n    92→\n    93→@router.get(\"/find_usages\")\n    94→async def find_usages(\n    95→    symbol_name: str = Query(..., description=\"Symbol name to find usages for\"),\n    96→    query_service: CodeQueryService = Depends(get_query_service)\n    97→) -> Dict[str, Any]:\n    98→    \"\"\"\n    99→    Find all usages of a specific symbol (alias for method-usages).\n   100→    \"\"\"\n   101→    try:\n   102→        usages = query_service.find_method_usages(symbol_name)\n   103→        return usages\n   104→    except Exception as e:\n   105→        raise HTTPException(status_code=500, detail=f\"Failed to find usages: {str(e)}\")\n   106→\n   107→\n   108→@router.get(\"/find_callers\")\n   109→async def find_callers(\n   110→    symbol_name: str = Query(..., description=\"Symbol name to find callers for\"),\n   111→    query_service: CodeQueryService = Depends(get_query_service)\n   112→) -> Dict[str, Any]:\n   113→    \"\"\"\n   114→    Find all methods/functions that call a specific symbol.\n   115→    \"\"\"\n   116→    try:\n   117→        callers = query_service.find_callers(symbol_name)\n   118→        return {\n   119→            \"callers\": callers,\n   120→            \"symbol\": symbol_name,\n   121→            \"total\": len(callers)\n   122→        }\n   123→    except Exception as e:\n   124→        raise HTTPException(status_code=500, detail=f\"Failed to find callers: {str(e)}\")\n   125→\n   126→\n   127→@router.get(\"/class_hierarchy\")\n   128→async def get_class_hierarchy(\n   129→    class_name: str = Query(..., description=\"Name of the class to analyze\"),\n   130→    query_service: CodeQueryService = Depends(get_query_service)\n   131→) -> Dict[str, Any]:\n   132→    \"\"\"\n   133→    Get class hierarchy (inheritance tree).\n   134→    \"\"\"\n   135→    try:\n   136→        hierarchy = query_service.get_class_hierarchy(class_name)\n   137→        return hierarchy\n   138→    except Exception as e:\n   139→        raise HTTPException(status_code=500, detail=f\"Failed to get class hierarchy: {str(e)}\")\n   140→\n   141→\n   142→@router.get(\"/class-hierarchy\")\n   143→async def get_class_hierarchy_alt(\n   144→    class_name: str = Query(..., description=\"Name of the class to analyze\"),\n   145→    query_service: CodeQueryService = Depends(get_query_service)\n   146→) -> Dict[str, Any]:\n   147→    \"\"\"\n   148→    Get class hierarchy (inheritance tree) - alternative endpoint.\n   149→    \"\"\"\n   150→    try:\n   151→        hierarchy = query_service.get_class_hierarchy(class_name)\n   152→        return hierarchy\n   153→    except Exception as e:\n   154→        raise HTTPException(status_code=500, detail=f\"Failed to get class hierarchy: {str(e)}\")\n   155→\n   156→\n   157→@router.get(\"/file-structure\")\n   158→async def analyze_file_structure(\n   159→    file_id: str = Query(..., description=\"File ID to analyze\"),\n   160→    query_service: CodeQueryService = Depends(get_query_service)\n   161→) -> Dict[str, Any]:\n   162→    \"\"\"\n   163→    Analyze the structure of a specific file.\n   164→    \"\"\"\n   165→    try:\n   166→        structure = query_service.get_file_structure(file_id)\n   167→        return structure\n   168→    except Exception as e:\n   169→        raise HTTPException(status_code=500, detail=f\"Failed to analyze file structure: {str(e)}\")\n   170→\n   171→\n   172→@router.get(\"/change_impact\")\n   173→async def analyze_change_impact(\n   174→    symbol_name: str = Query(..., description=\"Symbol to analyze impact for\"),\n   175→    query_service: CodeQueryService = Depends(get_query_service)\n   176→) -> Dict[str, Any]:\n   177→    \"\"\"\n   178→    Analyze the impact of changing a specific symbol.\n   179→    \"\"\"\n   180→    try:\n   181→        # Get all usages of the symbol to understand impact\n   182→        usages = query_service.find_method_usages(symbol_name)\n   183→        callers = query_service.find_callers(symbol_name)\n   184→        \n   185→        return {\n   186→            \"symbol\": symbol_name,\n   187→            \"usages\": usages,\n   188→            \"callers\": callers,\n   189→            \"impact_level\": \"high\" if len(callers) > 5 else \"medium\" if len(callers) > 0 else \"low\"\n   190→        }\n   191→    except Exception as e:\n   192→        raise HTTPException(status_code=500, detail=f\"Failed to analyze change impact: {str(e)}\")\n   193→\n   194→\n   195→@router.get(\"/relationships\")\n   196→async def get_code_relationships(\n   197→    symbol_name: str = Query(..., description=\"Symbol to find relationships for\"),\n   198→    query_service: CodeQueryService = Depends(get_query_service)\n   199→) -> Dict[str, Any]:\n   200→    \"\"\"\n   201→    Get code relationship analysis for a symbol.\n   202→    \"\"\"\n   203→    try:\n   204→        # Get comprehensive relationship data\n   205→        usages = query_service.find_method_usages(symbol_name)\n   206→        callers = query_service.find_callers(symbol_name)\n   207→        \n   208→        return {\n   209→            \"symbol\": symbol_name,\n   210→            \"relationships\": {\n   211→                \"usages\": usages,\n   212→                \"callers\": callers,\n   213→                \"usage_count\": len(usages.get('usages', [])),\n   214→                \"caller_count\": len(callers)\n   215→            }\n   216→        }\n   217→    except Exception as e:\n   218→        raise HTTPException(status_code=500, detail=f\"Failed to get code relationships: {str(e)}\")\n   219→\n   220→\n   221→@router.get(\"/metrics\")\n   222→async def get_code_metrics(\n   223→    repo_id: str = Query(None, description=\"Repository ID for repo-specific metrics\"),\n   224→    query_service: CodeQueryService = Depends(get_query_service)\n   225→) -> Dict[str, Any]:\n   226→    \"\"\"\n   227→    Get code metrics and statistics.\n   228→    \"\"\"\n   229→    try:\n   230→        if repo_id:\n   231→            # Get repository-specific stats\n   232→            stats = query_service.get_repository_stats(repo_id)\n   233→            return {\n   234→                \"repository_id\": repo_id,\n   235→                \"metrics\": stats\n   236→            }\n   237→        else:\n   238→            # Get global graph stats\n   239→            stats = query_service.get_graph_stats()\n   240→            return {\n   241→                \"global_metrics\": stats\n   242→            }\n   243→    except Exception as e:\n   244→        raise HTTPException(status_code=500, detail=f\"Failed to get code metrics: {str(e)}\")\n   245→\n   246→\n   247→@router.get(\"/stats\")\n   248→async def get_graph_stats(\n   249→    query_service: CodeQueryService = Depends(get_query_service)\n   250→) -> Dict[str, Any]:\n   251→    \"\"\"\n   252→    Get overall graph statistics.\n   253→    \"\"\"\n   254→    try:\n   255→        stats = query_service.get_graph_stats()\n   256→        return stats\n   257→    except Exception as e:\n   258→        raise HTTPException(status_code=500, detail=f\"Failed to get graph stats: {str(e)}\")\n   259→\n   260→\n   261→@router.get(\"/symbol/{qualified_name}\")\n   262→async def get_symbol_by_qualified_name(\n   263→    qualified_name: str,\n   264→    repo_id: str = Query(..., description=\"Repository ID\"),\n   265→    query_service: CodeQueryService = Depends(get_query_service)\n   266→) -> Dict[str, Any]:\n   267→    \"\"\"\n   268→    Get symbol information by its qualified name.\n   269→    \"\"\"\n   270→    try:\n   271→        symbol = query_service.find_symbol_by_qualified_name(qualified_name, repo_id)\n   272→        if not symbol:\n   273→            raise HTTPException(status_code=404, detail=\"Symbol not found\")\n   274→        return symbol\n   275→    except HTTPException:\n   276→        raise\n   277→    except Exception as e:\n   278→        raise HTTPException(status_code=500, detail=f\"Failed to find symbol: {str(e)}\")\n   279→\n   280→\n   281→# =========================================================================\n   282→# CodeFinder Tool Integration Endpoints\n   283→# =========================================================================\n   284→\n   285→@router.get(\"/code-finder/function\")\n   286→async def find_function_by_name(\n   287→    name: str = Query(..., description=\"Function name to search for\"),\n   288→    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n   289→    code_finder: CodeFinder = Depends(get_code_finder)\n   290→) -> Dict[str, Any]:\n   291→    \"\"\"\n   292→    Find functions by name using the CodeFinder tool.\n   293→    \"\"\"\n   294→    try:\n   295→        results = code_finder.find_by_function_name(name, fuzzy)\n   296→        return {\n   297→            \"function_name\": name,\n   298→            \"fuzzy_search\": fuzzy,\n   299→            \"results\": results,\n   300→            \"total\": len(results)\n   301→        }\n   302→    except Exception as e:\n   303→        raise HTTPException(status_code=500, detail=f\"Function search failed: {str(e)}\")\n   304→\n   305→\n   306→@router.get(\"/code-finder/class\")\n   307→async def find_class_by_name(\n   308→    name: str = Query(..., description=\"Class name to search for\"),\n   309→    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n   310→    code_finder: CodeFinder = Depends(get_code_finder)\n   311→) -> Dict[str, Any]:\n   312→    \"\"\"\n   313→    Find classes by name using the CodeFinder tool.\n   314→    \"\"\"\n   315→    try:\n   316→        results = code_finder.find_by_class_name(name, fuzzy)\n   317→        return {\n   318→            \"class_name\": name,\n   319→            \"fuzzy_search\": fuzzy,\n   320→            \"results\": results,\n   321→            \"total\": len(results)\n   322→        }\n   323→    except Exception as e:\n   324→        raise HTTPException(status_code=500, detail=f\"Class search failed: {str(e)}\")\n   325→\n   326→\n   327→@router.get(\"/code-finder/variable\")\n   328→async def find_variable_by_name(\n   329→    name: str = Query(..., description=\"Variable name to search for\"),\n   330→    code_finder: CodeFinder = Depends(get_code_finder)\n   331→) -> Dict[str, Any]:\n   332→    \"\"\"\n   333→    Find variables by name using the CodeFinder tool.\n   334→    \"\"\"\n   335→    try:\n   336→        results = code_finder.find_by_variable_name(name)\n   337→        return {\n   338→            \"variable_name\": name,\n   339→            \"results\": results,\n   340→            \"total\": len(results)\n   341→        }\n   342→    except Exception as e:\n   343→        raise HTTPException(status_code=500, detail=f\"Variable search failed: {str(e)}\")\n   344→\n   345→\n   346→@router.get(\"/code-finder/content\")\n   347→async def find_by_content(\n   348→    query: str = Query(..., description=\"Content search term\"),\n   349→    code_finder: CodeFinder = Depends(get_code_finder)\n   350→) -> Dict[str, Any]:\n   351→    \"\"\"\n   352→    Find code by content matching using the CodeFinder tool.\n   353→    \"\"\"\n   354→    try:\n   355→        results = code_finder.find_by_content(query)\n   356→        return {\n   357→            \"search_query\": query,\n   358→            \"results\": results,\n   359→            \"total\": len(results)\n   360→        }\n   361→    except Exception as e:\n   362→        raise HTTPException(status_code=500, detail=f\"Content search failed: {str(e)}\")\n   363→\n   364→\n   365→@router.get(\"/code-finder/module\")\n   366→async def find_module_by_name(\n   367→    name: str = Query(..., description=\"Module name to search for\"),\n   368→    code_finder: CodeFinder = Depends(get_code_finder)\n   369→) -> Dict[str, Any]:\n   370→    \"\"\"\n   371→    Find modules by name using the CodeFinder tool.\n   372→    \"\"\"\n   373→    try:\n   374→        results = code_finder.find_by_module_name(name)\n   375→        return {\n   376→            \"module_name\": name,\n   377→            \"results\": results,\n   378→            \"total\": len(results)\n   379→        }\n   380→    except Exception as e:\n   381→        raise HTTPException(status_code=500, detail=f\"Module search failed: {str(e)}\")\n   382→\n   383→\n   384→@router.get(\"/code-finder/imports\")\n   385→async def find_imports(\n   386→    name: str = Query(..., description=\"Import name to search for\"),\n   387→    code_finder: CodeFinder = Depends(get_code_finder)\n   388→) -> Dict[str, Any]:\n   389→    \"\"\"\n   390→    Find import statements using the CodeFinder tool.\n   391→    \"\"\"\n   392→    try:\n   393→        results = code_finder.find_imports(name)\n   394→        return {\n   395→            \"import_name\": name,\n   396→            \"results\": results,\n   397→            \"total\": len(results)\n   398→        }\n   399→    except Exception as e:\n   400→        raise HTTPException(status_code=500, detail=f\"Import search failed: {str(e)}\")\n   401→\n   402→\n   403→@router.get(\"/code-finder/related\")\n   404→async def find_related_code(\n   405→    query: str = Query(..., description=\"Search query for related code\"),\n   406→    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n   407→    edit_distance: int = Query(2, description=\"Edit distance for fuzzy search\"),\n   408→    code_finder: CodeFinder = Depends(get_code_finder)\n   409→) -> Dict[str, Any]:\n   410→    \"\"\"\n   411→    Find code related to a query using multiple search strategies.\n   412→    \"\"\"\n   413→    try:\n   414→        results = code_finder.find_related_code(query, fuzzy, edit_distance)\n   415→        return {\n   416→            \"search_query\": query,\n   417→            \"fuzzy_search\": fuzzy,\n   418→            \"edit_distance\": edit_distance,\n   419→            **results\n   420→        }\n   421→    except Exception as e:\n   422→        raise HTTPException(status_code=500, detail=f\"Related code search failed: {str(e)}\")\n   423→\n   424→\n   425→@router.get(\"/code-finder/function/arguments\")\n   426→async def find_functions_by_argument(\n   427→    argument_name: str = Query(..., description=\"Argument name to search for\"),\n   428→    path: str = Query(None, description=\"Optional file path to filter by\"),\n   429→    code_finder: CodeFinder = Depends(get_code_finder)\n   430→) -> Dict[str, Any]:\n   431→    \"\"\"\n   432→    Find functions that take a specific argument.\n   433→    \"\"\"\n   434→    try:\n   435→        results = code_finder.find_functions_by_argument(argument_name, path)\n   436→        return {\n   437→            \"argument_name\": argument_name,\n   438→            \"path_filter\": path,\n   439→            \"results\": results,\n   440→            \"total\": len(results)\n   441→        }\n   442→    except Exception as e:\n   443→        raise HTTPException(status_code=500, detail=f\"Function argument search failed: {str(e)}\")\n   444→\n   445→\n   446→@router.get(\"/code-finder/function/decorator\")\n   447→async def find_functions_by_decorator(\n   448→    decorator_name: str = Query(..., description=\"Decorator name to search for\"),\n   449→    path: str = Query(None, description=\"Optional file path to filter by\"),\n   450→    code_finder: CodeFinder = Depends(get_code_finder)\n   451→) -> Dict[str, Any]:\n   452→    \"\"\"\n   453→    Find functions that have a specific decorator.\n   454→    \"\"\"\n   455→    try:\n   456→        results = code_finder.find_functions_by_decorator(decorator_name, path)\n   457→        return {\n   458→            \"decorator_name\": decorator_name,\n   459→            \"path_filter\": path,\n   460→            \"results\": results,\n   461→            \"total\": len(results)\n   462→        }\n   463→    except Exception as e:\n   464→        raise HTTPException(status_code=500, detail=f\"Function decorator search failed: {str(e)}\")\n   465→\n   466→\n   467→@router.get(\"/code-finder/complexity\")\n   468→async def get_cyclomatic_complexity(\n   469→    function_name: str = Query(..., description=\"Function name to analyze\"),\n   470→    path: str = Query(None, description=\"Optional file path to filter by\"),\n   471→    code_finder: CodeFinder = Depends(get_code_finder)\n   472→) -> Dict[str, Any]:\n   473→    \"\"\"\n   474→    Get cyclomatic complexity of a function.\n   475→    \"\"\"\n   476→    try:\n   477→        result = code_finder.get_cyclomatic_complexity(function_name, path)\n   478→        if not result:\n   479→            raise HTTPException(status_code=404, detail=\"Function not found\")\n   480→        return {\n   481→            \"function_name\": function_name,\n   482→            \"path_filter\": path,\n   483→            \"complexity\": result\n   484→        }\n   485→    except HTTPException:\n   486→        raise\n   487→    except Exception as e:\n   488→        raise HTTPException(status_code=500, detail=f\"Complexity analysis failed: {str(e)}\")\n   489→\n   490→\n   491→@router.get(\"/code-finder/complexity/top\")\n   492→async def find_most_complex_functions(\n   493→    limit: int = Query(10, description=\"Number of results to return\"),\n   494→    code_finder: CodeFinder = Depends(get_code_finder)\n   495→) -> Dict[str, Any]:\n   496→    \"\"\"\n   497→    Find the most complex functions by cyclomatic complexity.\n   498→    \"\"\"\n   499→    try:\n   500→        results = code_finder.find_most_complex_functions(limit)\n   501→        return {\n   502→            \"limit\": limit,\n   503→            \"results\": results,\n   504→            \"total\": len(results)\n   505→        }\n   506→    except Exception as e:\n   507→        raise HTTPException(status_code=500, detail=f\"Complex function search failed: {str(e)}\")\n   508→\n   509→\n   510→@router.get(\"/code-finder/relationships\")\n   511→async def analyze_code_relationships(\n   512→    query_type: str = Query(..., description=\"Type of relationship query\"),\n   513→    target: str = Query(..., description=\"Target symbol for analysis\"),\n   514→    context: str = Query(None, description=\"Additional context for the query\"),\n   515→    code_finder: CodeFinder = Depends(get_code_finder)\n   516→) -> Dict[str, Any]:\n   517→    \"\"\"\n   518→    Analyze code relationships using the CodeFinder's relationship query system.\n   519→    \n   520→    Supported query types:\n   521→    - find_callers: Find all functions that call the target function\n   522→    - find_callees: Find all functions called by the target function\n   523→    - find_importers: Find all files that import the target module\n   524→    - who_modifies: Find what functions modify a target variable\n   525→    - class_hierarchy: Find inheritance relationships for a class\n   526→    - call_chain: Find call paths between functions (format: 'start->end')\n   527→    - module_deps: Find module dependencies\n   528→    - variable_scope: Find variable usage across scopes\n   529→    \"\"\"\n   530→    try:\n   531→        results = code_finder.execute_relationship_query(query_type, target, context)\n   532→        return results\n   533→    except Exception as e:\n   534→        raise HTTPException(status_code=500, detail=f\"Relationship analysis failed: {str(e)}\")\n   535→\n   536→\n   537→@router.get(\"/repositories/indexed\")\n   538→async def list_indexed_repositories(\n   539→    code_finder: CodeFinder = Depends(get_code_finder)\n   540→) -> Dict[str, Any]:\n   541→    \"\"\"\n   542→    List all indexed repositories using the CodeFinder tool.\n   543→    \"\"\"\n   544→    try:\n   545→        results = code_finder.list_indexed_repositories()\n   546→        return {\n   547→            \"repositories\": results,\n   548→            \"total\": len(results)\n   549→        }\n   550→    except Exception as e:\n   551→        raise HTTPException(status_code=500, detail=f\"Failed to list repositories: {str(e)}\")\n   552→\n   553→\n   554→\n   555→@router.get(\"/language/{language}/symbols\")\n   556→async def get_language_symbols(\n   557→    language: str,\n   558→    symbol_type: str = Query(..., description=\"Symbol type: function, class, variable, etc.\"),\n   559→    limit: int = Query(50, description=\"Maximum number of results\"),\n   560→    query_service: CodeQueryService = Depends(get_query_service)\n   561→) -> Dict[str, Any]:\n   562→    \"\"\"\n   563→    Get all symbols of a specific type for a given language.\n   564→    \n   565→    Supported symbol types:\n   566→    - function: All functions\n   567→    - class: All classes  \n   568→    - variable: All variables\n   569→    - module: All modules\n   570→    - file: All files\n   571→    \"\"\"\n   572→    try:\n   573→        # Use Neo4j to query symbols by type and language\n   574→        if symbol_type.lower() == \"function\":\n   575→            query = f\"\"\"\n   576→                MATCH (n:Function)\n   577→                OPTIONAL MATCH (f:File)-[:CONTAINS]->(n)\n   578→                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n   579→                RETURN n.name as name, n.path as path, n.line_number as line_number,\n   580→                       n.docstring as docstring, n.is_dependency as is_dependency,\n   581→                       f.language as file_language\n   582→                ORDER BY n.is_dependency ASC, n.name\n   583→                LIMIT $limit\n   584→            \"\"\"\n   585→        elif symbol_type.lower() == \"class\":\n   586→            query = f\"\"\"\n   587→                MATCH (n:Class)\n   588→                OPTIONAL MATCH (f:File)-[:CONTAINS]->(n)\n   589→                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n   590→                RETURN n.name as name, n.path as path, n.line_number as line_number,\n   591→                       n.docstring as docstring, n.is_dependency as is_dependency,\n   592→                       f.language as file_language\n   593→                ORDER BY n.is_dependency ASC, n.name\n   594→                LIMIT $limit\n   595→            \"\"\"\n   596→        elif symbol_type.lower() == \"variable\":\n   597→            query = f\"\"\"\n   598→                MATCH (n:Variable)\n   599→                OPTIONAL MATCH (f:File)-[:CONTAINS*]->(n)\n   600→                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n   601→                RETURN n.name as name, n.path as path, n.line_number as line_number,\n   602→                       n.value as value, n.context as context, n.is_dependency as is_dependency,\n   603→                       f.language as file_language\n   604→                ORDER BY n.is_dependency ASC, n.name\n   605→                LIMIT $limit\n   606→            \"\"\"\n   607→        elif symbol_type.lower() == \"file\":\n   608→            query = f\"\"\"\n   609→                MATCH (n:File)\n   610→                WHERE n.language = $language OR n.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n   611→                RETURN n.name as name, n.path as path, n.relative_path as relative_path,\n   612→                       n.language as language, n.extension as extension,\n   613→                       n.is_dependency as is_dependency\n   614→                ORDER BY n.is_dependency ASC, n.path\n   615→                LIMIT $limit\n   616→            \"\"\"\n   617→        elif symbol_type.lower() == \"module\":\n   618→            query = f\"\"\"\n   619→                MATCH (n:Module)\n   620→                WHERE n.lang = $language\n   621→                RETURN n.name as name, n.lang as language,\n   622→                       n.full_import_name as full_import_name\n   623→                ORDER BY n.name\n   624→                LIMIT $limit\n   625→            \"\"\"\n   626→        else:\n   627→            raise HTTPException(status_code=400, detail=f\"Unsupported symbol type: {symbol_type}\")\n   628→        \n   629→        records, _, _ = query_service.db.run_query(query, {\"language\": language, \"limit\": limit})\n   630→        \n   631→        return {\n   632→            \"language\": language,\n   633→            \"symbol_type\": symbol_type,\n   634→            \"results\": [dict(record) for record in records],\n   635→            \"total\": len(records),\n   636→            \"limit\": limit\n   637→        }\n   638→    except HTTPException:\n   639→        raise\n   640→    except Exception as e:\n   641→        raise HTTPException(status_code=500, detail=f\"Language symbol query failed: {str(e)}\")\n   642→\n   643→\n   644→@router.get(\"/language/stats\")\n   645→async def get_language_statistics(\n   646→    language: str = Query(None, description=\"Optional language filter\"),\n   647→    query_service: CodeQueryService = Depends(get_query_service)\n   648→) -> Dict[str, Any]:\n   649→    \"\"\"\n   650→    Get statistics about programming languages in the codebase.\n   651→    \"\"\"\n   652→    try:\n   653→        if language:\n   654→            # Get stats for specific language\n   655→            query = \"\"\"\n   656→                MATCH (f:File)\n   657→                WHERE f.language = $language OR f.extension IN ['.{}'.format($language.lower()), '.{}'.format($language[:2].lower())]\n   658→                OPTIONAL MATCH (f)-[:CONTAINS]->(func:Function)\n   659→                OPTIONAL MATCH (f)-[:CONTAINS]->(cls:Class)\n   660→                OPTIONAL MATCH (f)-[:CONTAINS]->(var:Variable)\n   661→                RETURN \n   662→                    count(DISTINCT f) as file_count,\n   663→                    count(DISTINCT func) as function_count,\n   664→                    count(DISTINCT cls) as class_count,\n   665→                    count(DISTINCT var) as variable_count\n   666→            \"\"\"\n   667→            records, _, _ = query_service.db.run_query(query, {\"language\": language})\n   668→            result = dict(records[0]) if records else {}\n   669→            result[\"language\"] = language\n   670→            return result\n   671→        else:\n   672→            # Get stats for all languages\n   673→            query = \"\"\"\n   674→                MATCH (f:File)\n   675→                WHERE f.language IS NOT NULL\n   676→                OPTIONAL MATCH (f)-[:CONTAINS]->(func:Function)\n   677→                OPTIONAL MATCH (f)-[:CONTAINS]->(cls:Class)\n   678→                OPTIONAL MATCH (f)-[:CONTAINS]->(var:Variable)\n   679→                RETURN \n   680→                    f.language as language,\n   681→                    count(DISTINCT f) as file_count,\n   682→                    count(DISTINCT func) as function_count,\n   683→                    count(DISTINCT cls) as class_count,\n   684→                    count(DISTINCT var) as variable_count\n   685→                ORDER BY file_count DESC\n   686→            \"\"\"\n   687→            records, _, _ = query_service.db.run_query(query)\n   688→            return {\n   689→                \"languages\": [dict(record) for record in records],\n   690→                \"total_languages\": len(records)\n   691→            }\n   692→    except Exception as e:\n   693→        raise HTTPException(status_code=500, detail=f\"Language statistics query failed: {str(e)}\")\n   694→\n   695→\n   696→# --- Code Review / Diff Context Endpoints ---\n   697→\n   698→\n   699→@router.get(\"/symbols-at-lines\")\n   700→async def get_symbols_at_lines(\n   701→    file_path: str = Query(..., description=\"Absolute file path\"),\n   702→    start_line: int = Query(..., description=\"Start line number\"),\n   703→    end_line: int = Query(..., description=\"End line number\"),\n   704→    query_service: CodeQueryService = Depends(get_query_service)\n   705→) -> Dict[str, Any]:\n   706→    \"\"\"\n   707→    Find all symbols (functions, classes, variables) overlapping a line range.\n   708→    Useful for mapping diff hunks to affected code.\n   709→    \"\"\"\n   710→    try:\n   711→        results = query_service.get_symbols_at_lines(file_path, start_line, end_line)\n   712→        return {\n   713→            \"file_path\": file_path,\n   714→            \"start_line\": start_line,\n   715→            \"end_line\": end_line,\n   716→            \"symbols\": results,\n   717→            \"total\": len(results),\n   718→        }\n   719→    except Exception as e:\n   720→        raise HTTPException(status_code=500, detail=f\"Symbol lookup failed: {str(e)}\")\n   721→\n   722→\n   723→@router.get(\"/symbols-at-lines-relative\")\n   724→async def get_symbols_at_lines_relative(\n   725→    repo_id: str = Query(..., description=\"Repository ID (e.g. owner/repo)\"),\n   726→    file_path: str = Query(..., description=\"Repo-relative file path (e.g. src/main.py)\"),\n   727→    start_line: int = Query(..., description=\"Start line number\"),\n   728→    end_line: int = Query(..., description=\"End line number\"),\n   729→    query_service: CodeQueryService = Depends(get_query_service)\n   730→) -> Dict[str, Any]:\n   731→    \"\"\"\n   732→    Find all symbols overlapping a line range using repo-relative path.\n   733→    \"\"\"\n   734→    try:\n   735→        results = query_service.get_symbols_at_lines_by_relative_path(\n   736→            repo_id, file_path, start_line, end_line\n   737→        )\n   738→        return {\n   739→            \"repo_id\": repo_id,\n   740→            \"file_path\": file_path,\n   741→            \"start_line\": start_line,\n   742→            \"end_line\": end_line,\n   743→            \"symbols\": results,\n   744→            \"total\": len(results),\n   745→        }\n   746→    except Exception as e:\n   747→        raise HTTPException(status_code=500, detail=f\"Symbol lookup failed: {str(e)}\")\n   748→\n   749→\n   750→class FileChange(BaseModel):\n   751→    file_path: str\n   752→    start_line: int = 1\n   753→    end_line: int = 999999\n   754→\n   755→\n   756→class DiffContextRequest(BaseModel):\n   757→    repo_id: str\n   758→    changes: List[FileChange]\n   759→\n   760→\n   761→@router.post(\"/diff-context\")\n   762→async def get_diff_context(\n   763→    request: DiffContextRequest,\n   764→    query_service: CodeQueryService = Depends(get_query_service)\n   765→) -> Dict[str, Any]:\n   766→    \"\"\"\n   767→    Build full RAG context for a code diff.\n   768→\n   769→    Given a repository and a list of file changes (path + line ranges),\n   770→    returns affected symbols with source code, their callers, class hierarchy,\n   771→    and full file sources. Designed for AI-powered code review.\n   772→\n   773→    Example request:\n   774→    ```json\n   775→    {\n   776→        \"repo_id\": \"owner/repo\",\n   777→        \"changes\": [\n   778→            {\"file_path\": \"src/main.py\", \"start_line\": 10, \"end_line\": 30},\n   779→            {\"file_path\": \"src/utils.py\", \"start_line\": 1, \"end_line\": 50}\n   780→        ]\n   781→    }\n   782→    ```\n   783→    \"\"\"\n   784→    try:\n   785→        changes_dicts = [c.model_dump() for c in request.changes]\n   786→        result = query_service.get_diff_context(request.repo_id, changes_dicts)\n   787→        return result\n   788→    except Exception as e:\n   789→        raise HTTPException(status_code=500, detail=f\"Diff context failed: {str(e)}\")\n   790→\n   791→\n   792→@router.get(\"/file-source\")\n   793→async def get_file_source(\n   794→    repo_id: str = Query(..., description=\"Repository ID\"),\n   795→    file_path: str = Query(..., description=\"Repo-relative file path\"),\n   796→    query_service: CodeQueryService = Depends(get_query_service)\n   797→) -> Dict[str, Any]:\n   798→    \"\"\"\n   799→    Get the full source code of a file from the graph.\n   800→    \"\"\"\n   801→    try:\n   802→        query = \"\"\"\n   803→        MATCH (f:File)\n   804→        WHERE f.relative_path = $relative_path AND f.path CONTAINS $repo_id\n   805→        RETURN f.source_code as source_code, f.relative_path as path,\n   806→               f.language as language, f.lines_count as lines_count\n   807→        LIMIT 1\n   808→        \"\"\"\n   809→        records, _, _ = query_service.db.run_query(query, {\n   810→            \"relative_path\": file_path,\n   811→            \"repo_id\": repo_id,\n   812→        })\n   813→        if not records:\n   814→            raise HTTPException(status_code=404, detail=\"File not found\")\n   815→        record = records[0]\n   816→        return {\n   817→            \"file_path\": record.get(\"path\"),\n   818→            \"language\": record.get(\"language\"),\n   819→            \"lines_count\": record.get(\"lines_count\"),\n   820→            \"source_code\": record.get(\"source_code\"),\n   821→        }\n   822→    except HTTPException:\n   823→        raise\n   824→    except Exception as e:\n   825→        raise HTTPException(status_code=500, detail=f\"File source retrieval failed: {str(e)}\")\n   826→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"9bb3a71f-ff1c-4ad8-899e-bc84c63a4fd8","timestamp":"2026-02-21T08:05:46.598Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","content":"\"\"\"\nCode query endpoints - Advanced implementation with Neo4j integration.\n\"\"\"\n\nfrom fastapi import APIRouter, HTTPException, Query, Depends, Body\nfrom pydantic import BaseModel\nfrom typing import Dict, Any, List, Optional\nimport os\n\nfrom db.client import Neo4jClient\nfrom db.queries import CodeQueryService\nfrom api.dependencies import get_neo4j_client\nfrom api.services.code_search import CodeFinder\n\nrouter = APIRouter()\n\n\ndef get_query_service(db: Neo4jClient = Depends(get_neo4j_client)) -> CodeQueryService:\n    \"\"\"Dependency to get query service.\"\"\"\n    return CodeQueryService(db)\n\n\ndef get_code_finder(db: Neo4jClient = Depends(get_neo4j_client)) -> CodeFinder:\n    \"\"\"Dependency to get code finder.\"\"\"\n    return CodeFinder(db)\n\n\n@router.get(\"/search\")\nasync def search_code(\n    query: str = Query(..., description=\"Search term for code\"),\n    repo_id: str = Query(None, description=\"Optional repository ID to filter by\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Search for code by content or name using fulltext search.\n    \"\"\"\n    try:\n        results = query_service.search_code(query)\n        \n        # Filter by repo if provided\n        if repo_id:\n            filtered_results = []\n            for result in results:\n                if result.get('file', {}).get('repo_id') == repo_id:\n                    filtered_results.append(result)\n            results = filtered_results\n        \n        return {\n            \"results\": results,\n            \"total\": len(results),\n            \"query\": query,\n            \"repo_filter\": repo_id\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")\n\n\n@router.get(\"/search-symbols\")\nasync def search_symbols(\n    query: str = Query(..., description=\"Search term for symbols\"),\n    limit: int = Query(20, description=\"Maximum number of results\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Search for symbols (functions, classes, variables) by name.\n    \"\"\"\n    try:\n        results = query_service.search_symbols(query, limit)\n        return {\n            \"symbols\": results,\n            \"total\": len(results),\n            \"query\": query\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol search failed: {str(e)}\")\n\n\n@router.get(\"/method-usages\")\nasync def find_method_usages(\n    method_name: str = Query(..., description=\"Name of the method to find usages for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all usages of a specific method.\n    \"\"\"\n    try:\n        usages = query_service.find_method_usages(method_name)\n        return usages\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find method usages: {str(e)}\")\n\n\n@router.get(\"/find_usages\")\nasync def find_usages(\n    symbol_name: str = Query(..., description=\"Symbol name to find usages for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all usages of a specific symbol (alias for method-usages).\n    \"\"\"\n    try:\n        usages = query_service.find_method_usages(symbol_name)\n        return usages\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find usages: {str(e)}\")\n\n\n@router.get(\"/find_callers\")\nasync def find_callers(\n    symbol_name: str = Query(..., description=\"Symbol name to find callers for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all methods/functions that call a specific symbol.\n    \"\"\"\n    try:\n        callers = query_service.find_callers(symbol_name)\n        return {\n            \"callers\": callers,\n            \"symbol\": symbol_name,\n            \"total\": len(callers)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find callers: {str(e)}\")\n\n\n@router.get(\"/class_hierarchy\")\nasync def get_class_hierarchy(\n    class_name: str = Query(..., description=\"Name of the class to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get class hierarchy (inheritance tree).\n    \"\"\"\n    try:\n        hierarchy = query_service.get_class_hierarchy(class_name)\n        return hierarchy\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get class hierarchy: {str(e)}\")\n\n\n@router.get(\"/class-hierarchy\")\nasync def get_class_hierarchy_alt(\n    class_name: str = Query(..., description=\"Name of the class to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get class hierarchy (inheritance tree) - alternative endpoint.\n    \"\"\"\n    try:\n        hierarchy = query_service.get_class_hierarchy(class_name)\n        return hierarchy\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get class hierarchy: {str(e)}\")\n\n\n@router.get(\"/file-structure\")\nasync def analyze_file_structure(\n    file_id: str = Query(..., description=\"File ID to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze the structure of a specific file.\n    \"\"\"\n    try:\n        structure = query_service.get_file_structure(file_id)\n        return structure\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to analyze file structure: {str(e)}\")\n\n\n@router.get(\"/change_impact\")\nasync def analyze_change_impact(\n    symbol_name: str = Query(..., description=\"Symbol to analyze impact for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze the impact of changing a specific symbol.\n    \"\"\"\n    try:\n        # Get all usages of the symbol to understand impact\n        usages = query_service.find_method_usages(symbol_name)\n        callers = query_service.find_callers(symbol_name)\n        \n        return {\n            \"symbol\": symbol_name,\n            \"usages\": usages,\n            \"callers\": callers,\n            \"impact_level\": \"high\" if len(callers) > 5 else \"medium\" if len(callers) > 0 else \"low\"\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to analyze change impact: {str(e)}\")\n\n\n@router.get(\"/relationships\")\nasync def get_code_relationships(\n    symbol_name: str = Query(..., description=\"Symbol to find relationships for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get code relationship analysis for a symbol.\n    \"\"\"\n    try:\n        # Get comprehensive relationship data\n        usages = query_service.find_method_usages(symbol_name)\n        callers = query_service.find_callers(symbol_name)\n        \n        return {\n            \"symbol\": symbol_name,\n            \"relationships\": {\n                \"usages\": usages,\n                \"callers\": callers,\n                \"usage_count\": len(usages.get('usages', [])),\n                \"caller_count\": len(callers)\n            }\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get code relationships: {str(e)}\")\n\n\n@router.get(\"/metrics\")\nasync def get_code_metrics(\n    repo_id: str = Query(None, description=\"Repository ID for repo-specific metrics\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get code metrics and statistics.\n    \"\"\"\n    try:\n        if repo_id:\n            # Get repository-specific stats\n            stats = query_service.get_repository_stats(repo_id)\n            return {\n                \"repository_id\": repo_id,\n                \"metrics\": stats\n            }\n        else:\n            # Get global graph stats\n            stats = query_service.get_graph_stats()\n            return {\n                \"global_metrics\": stats\n            }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get code metrics: {str(e)}\")\n\n\n@router.get(\"/stats\")\nasync def get_graph_stats(\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get overall graph statistics.\n    \"\"\"\n    try:\n        stats = query_service.get_graph_stats()\n        return stats\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get graph stats: {str(e)}\")\n\n\n@router.get(\"/symbol/{qualified_name}\")\nasync def get_symbol_by_qualified_name(\n    qualified_name: str,\n    repo_id: str = Query(..., description=\"Repository ID\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get symbol information by its qualified name.\n    \"\"\"\n    try:\n        symbol = query_service.find_symbol_by_qualified_name(qualified_name, repo_id)\n        if not symbol:\n            raise HTTPException(status_code=404, detail=\"Symbol not found\")\n        return symbol\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find symbol: {str(e)}\")\n\n\n# =========================================================================\n# CodeFinder Tool Integration Endpoints\n# =========================================================================\n\n@router.get(\"/code-finder/function\")\nasync def find_function_by_name(\n    name: str = Query(..., description=\"Function name to search for\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_function_name(name, fuzzy)\n        return {\n            \"function_name\": name,\n            \"fuzzy_search\": fuzzy,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/class\")\nasync def find_class_by_name(\n    name: str = Query(..., description=\"Class name to search for\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find classes by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_class_name(name, fuzzy)\n        return {\n            \"class_name\": name,\n            \"fuzzy_search\": fuzzy,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Class search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/variable\")\nasync def find_variable_by_name(\n    name: str = Query(..., description=\"Variable name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find variables by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_variable_name(name)\n        return {\n            \"variable_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Variable search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/content\")\nasync def find_by_content(\n    query: str = Query(..., description=\"Content search term\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find code by content matching using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_content(query)\n        return {\n            \"search_query\": query,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Content search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/module\")\nasync def find_module_by_name(\n    name: str = Query(..., description=\"Module name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find modules by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_module_name(name)\n        return {\n            \"module_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Module search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/imports\")\nasync def find_imports(\n    name: str = Query(..., description=\"Import name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find import statements using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_imports(name)\n        return {\n            \"import_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Import search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/related\")\nasync def find_related_code(\n    query: str = Query(..., description=\"Search query for related code\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    edit_distance: int = Query(2, description=\"Edit distance for fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find code related to a query using multiple search strategies.\n    \"\"\"\n    try:\n        results = code_finder.find_related_code(query, fuzzy, edit_distance)\n        return {\n            \"search_query\": query,\n            \"fuzzy_search\": fuzzy,\n            \"edit_distance\": edit_distance,\n            **results\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Related code search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/function/arguments\")\nasync def find_functions_by_argument(\n    argument_name: str = Query(..., description=\"Argument name to search for\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions that take a specific argument.\n    \"\"\"\n    try:\n        results = code_finder.find_functions_by_argument(argument_name, path)\n        return {\n            \"argument_name\": argument_name,\n            \"path_filter\": path,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function argument search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/function/decorator\")\nasync def find_functions_by_decorator(\n    decorator_name: str = Query(..., description=\"Decorator name to search for\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions that have a specific decorator.\n    \"\"\"\n    try:\n        results = code_finder.find_functions_by_decorator(decorator_name, path)\n        return {\n            \"decorator_name\": decorator_name,\n            \"path_filter\": path,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function decorator search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/complexity\")\nasync def get_cyclomatic_complexity(\n    function_name: str = Query(..., description=\"Function name to analyze\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get cyclomatic complexity of a function.\n    \"\"\"\n    try:\n        result = code_finder.get_cyclomatic_complexity(function_name, path)\n        if not result:\n            raise HTTPException(status_code=404, detail=\"Function not found\")\n        return {\n            \"function_name\": function_name,\n            \"path_filter\": path,\n            \"complexity\": result\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complexity analysis failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/complexity/top\")\nasync def find_most_complex_functions(\n    limit: int = Query(10, description=\"Number of results to return\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find the most complex functions by cyclomatic complexity.\n    \"\"\"\n    try:\n        results = code_finder.find_most_complex_functions(limit)\n        return {\n            \"limit\": limit,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complex function search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/relationships\")\nasync def analyze_code_relationships(\n    query_type: str = Query(..., description=\"Type of relationship query\"),\n    target: str = Query(..., description=\"Target symbol for analysis\"),\n    context: str = Query(None, description=\"Additional context for the query\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze code relationships using the CodeFinder's relationship query system.\n    \n    Supported query types:\n    - find_callers: Find all functions that call the target function\n    - find_callees: Find all functions called by the target function\n    - find_importers: Find all files that import the target module\n    - who_modifies: Find what functions modify a target variable\n    - class_hierarchy: Find inheritance relationships for a class\n    - call_chain: Find call paths between functions (format: 'start->end')\n    - module_deps: Find module dependencies\n    - variable_scope: Find variable usage across scopes\n    \"\"\"\n    try:\n        results = code_finder.execute_relationship_query(query_type, target, context)\n        return results\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Relationship analysis failed: {str(e)}\")\n\n\n@router.get(\"/repositories/indexed\")\nasync def list_indexed_repositories(\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    List all indexed repositories using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.list_indexed_repositories()\n        return {\n            \"repositories\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to list repositories: {str(e)}\")\n\n\n\n@router.get(\"/language/{language}/symbols\")\nasync def get_language_symbols(\n    language: str,\n    symbol_type: str = Query(..., description=\"Symbol type: function, class, variable, etc.\"),\n    limit: int = Query(50, description=\"Maximum number of results\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get all symbols of a specific type for a given language.\n    \n    Supported symbol types:\n    - function: All functions\n    - class: All classes  \n    - variable: All variables\n    - module: All modules\n    - file: All files\n    \"\"\"\n    try:\n        # Use Neo4j to query symbols by type and language\n        if symbol_type.lower() == \"function\":\n            query = f\"\"\"\n                MATCH (n:Function)\n                OPTIONAL MATCH (f:File)-[:CONTAINS]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.docstring as docstring, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"class\":\n            query = f\"\"\"\n                MATCH (n:Class)\n                OPTIONAL MATCH (f:File)-[:CONTAINS]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.docstring as docstring, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"variable\":\n            query = f\"\"\"\n                MATCH (n:Variable)\n                OPTIONAL MATCH (f:File)-[:CONTAINS*]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.value as value, n.context as context, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"file\":\n            query = f\"\"\"\n                MATCH (n:File)\n                WHERE n.language = $language OR n.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.relative_path as relative_path,\n                       n.language as language, n.extension as extension,\n                       n.is_dependency as is_dependency\n                ORDER BY n.is_dependency ASC, n.path\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"module\":\n            query = f\"\"\"\n                MATCH (n:Module)\n                WHERE n.lang = $language\n                RETURN n.name as name, n.lang as language,\n                       n.full_import_name as full_import_name\n                ORDER BY n.name\n                LIMIT $limit\n            \"\"\"\n        else:\n            raise HTTPException(status_code=400, detail=f\"Unsupported symbol type: {symbol_type}\")\n        \n        records, _, _ = query_service.db.run_query(query, {\"language\": language, \"limit\": limit})\n        \n        return {\n            \"language\": language,\n            \"symbol_type\": symbol_type,\n            \"results\": [dict(record) for record in records],\n            \"total\": len(records),\n            \"limit\": limit\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Language symbol query failed: {str(e)}\")\n\n\n@router.get(\"/language/stats\")\nasync def get_language_statistics(\n    language: str = Query(None, description=\"Optional language filter\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get statistics about programming languages in the codebase.\n    \"\"\"\n    try:\n        if language:\n            # Get stats for specific language\n            query = \"\"\"\n                MATCH (f:File)\n                WHERE f.language = $language OR f.extension IN ['.{}'.format($language.lower()), '.{}'.format($language[:2].lower())]\n                OPTIONAL MATCH (f)-[:CONTAINS]->(func:Function)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(cls:Class)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(var:Variable)\n                RETURN \n                    count(DISTINCT f) as file_count,\n                    count(DISTINCT func) as function_count,\n                    count(DISTINCT cls) as class_count,\n                    count(DISTINCT var) as variable_count\n            \"\"\"\n            records, _, _ = query_service.db.run_query(query, {\"language\": language})\n            result = dict(records[0]) if records else {}\n            result[\"language\"] = language\n            return result\n        else:\n            # Get stats for all languages\n            query = \"\"\"\n                MATCH (f:File)\n                WHERE f.language IS NOT NULL\n                OPTIONAL MATCH (f)-[:CONTAINS]->(func:Function)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(cls:Class)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(var:Variable)\n                RETURN \n                    f.language as language,\n                    count(DISTINCT f) as file_count,\n                    count(DISTINCT func) as function_count,\n                    count(DISTINCT cls) as class_count,\n                    count(DISTINCT var) as variable_count\n                ORDER BY file_count DESC\n            \"\"\"\n            records, _, _ = query_service.db.run_query(query)\n            return {\n                \"languages\": [dict(record) for record in records],\n                \"total_languages\": len(records)\n            }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Language statistics query failed: {str(e)}\")\n\n\n# --- Code Review / Diff Context Endpoints ---\n\n\n@router.get(\"/symbols-at-lines\")\nasync def get_symbols_at_lines(\n    file_path: str = Query(..., description=\"Absolute file path\"),\n    start_line: int = Query(..., description=\"Start line number\"),\n    end_line: int = Query(..., description=\"End line number\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all symbols (functions, classes, variables) overlapping a line range.\n    Useful for mapping diff hunks to affected code.\n    \"\"\"\n    try:\n        results = query_service.get_symbols_at_lines(file_path, start_line, end_line)\n        return {\n            \"file_path\": file_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n            \"symbols\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol lookup failed: {str(e)}\")\n\n\n@router.get(\"/symbols-at-lines-relative\")\nasync def get_symbols_at_lines_relative(\n    repo_id: str = Query(..., description=\"Repository ID (e.g. owner/repo)\"),\n    file_path: str = Query(..., description=\"Repo-relative file path (e.g. src/main.py)\"),\n    start_line: int = Query(..., description=\"Start line number\"),\n    end_line: int = Query(..., description=\"End line number\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all symbols overlapping a line range using repo-relative path.\n    \"\"\"\n    try:\n        results = query_service.get_symbols_at_lines_by_relative_path(\n            repo_id, file_path, start_line, end_line\n        )\n        return {\n            \"repo_id\": repo_id,\n            \"file_path\": file_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n            \"symbols\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol lookup failed: {str(e)}\")\n\n\nclass FileChange(BaseModel):\n    file_path: str\n    start_line: int = 1\n    end_line: int = 999999\n\n\nclass DiffContextRequest(BaseModel):\n    repo_id: str\n    changes: List[FileChange]\n\n\n@router.post(\"/diff-context\")\nasync def get_diff_context(\n    request: DiffContextRequest,\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Build full RAG context for a code diff.\n\n    Given a repository and a list of file changes (path + line ranges),\n    returns affected symbols with source code, their callers, class hierarchy,\n    and full file sources. Designed for AI-powered code review.\n\n    Example request:\n    ```json\n    {\n        \"repo_id\": \"owner/repo\",\n        \"changes\": [\n            {\"file_path\": \"src/main.py\", \"start_line\": 10, \"end_line\": 30},\n            {\"file_path\": \"src/utils.py\", \"start_line\": 1, \"end_line\": 50}\n        ]\n    }\n    ```\n    \"\"\"\n    try:\n        changes_dicts = [c.model_dump() for c in request.changes]\n        result = query_service.get_diff_context(request.repo_id, changes_dicts)\n        return result\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Diff context failed: {str(e)}\")\n\n\n@router.get(\"/file-source\")\nasync def get_file_source(\n    repo_id: str = Query(..., description=\"Repository ID\"),\n    file_path: str = Query(..., description=\"Repo-relative file path\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get the full source code of a file from the graph.\n    \"\"\"\n    try:\n        query = \"\"\"\n        MATCH (f:File)\n        WHERE f.relative_path = $relative_path AND f.path CONTAINS $repo_id\n        RETURN f.source_code as source_code, f.relative_path as path,\n               f.language as language, f.lines_count as lines_count\n        LIMIT 1\n        \"\"\"\n        records, _, _ = query_service.db.run_query(query, {\n            \"relative_path\": file_path,\n            \"repo_id\": repo_id,\n        })\n        if not records:\n            raise HTTPException(status_code=404, detail=\"File not found\")\n        record = records[0]\n        return {\n            \"file_path\": record.get(\"path\"),\n            \"language\": record.get(\"language\"),\n            \"lines_count\": record.get(\"lines_count\"),\n            \"source_code\": record.get(\"source_code\"),\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"File source retrieval failed: {str(e)}\")\n","numLines":826,"startLine":1,"totalLines":826}},"sourceToolAssistantUUID":"f7103b1d-54fe-4495-b2d1-b9d2ab8acc2e"}
{"parentUuid":"9bb3a71f-ff1c-4ad8-899e-bc84c63a4fd8","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01FyzkUisAuWJxeETKBTsY7T","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I need to understand the full picture. There are two issues:\n\n1. **Full-text search** (`/search`) doesn't return file/line info properly - it returns full node objects rather than lean results with file path + line number\n2. **Symbol search** (`/search-symbols`) is broken because `search_symbols` in `db/queries.py` passes the raw `search_term` to the Lucene query without escaping - special chars like `(`, `)`, `:` in `class LoginRequest(BaseModel):` cause a Lucene parse error\n\nLet me also check the CYPHER_QUERIES to understand what the `search_code` and `search_symbols` queries look like, and also the `code-finder/line` and `code-finder/peek` endpoints which are supposed to be the proper way to do file-level search with line context.\n\n\nNow I'm looking at the schema file to see how these Cypher queries are defined.","signature":"EsYHCkYICxgCKkBNoQNwnfTWefED+j96gm6nIwtSK1JvDd0Mlaiatp0WS+a7fNh+eSLX3gmrzGN9q4Xs/YSslxPlfQuERDevwWkZEgzyT84uS2qkkIHZsywaDFmkKKMOprcNafOxziIwVPqV08ZCnliAlLCmmZxBmKl9aJG8f9U+c8p7Qsc4aEOXmQcDgfkwmLIA+wK25EasKq0G2rjK5kXDqp5wkNDnRA337O2uMBUvtHzDAPHJBhu7a5Fd+czZC4DadnHG1uYRB0biPFjH/Cubt5LO3TBGu+DB6AO6aI70T7Y0ibYbZpPvMt9UxMTleqwmrxnmm4u6kj538HSwdcre7NO2b2i2nyZDGZQUrXV7rKxTd5YwTsSP1O0rtopWT3l1D5ddV3pRB22lzpQD1lOF1wFCr97aRQ4MAU0PzjUwxuahxw0mRZh8DO6HVFCdC9vcLlvHSlNN/sybNZb81FOZUa7kh9lIVkmCUPeiPBScet44p8tqpTRVBf5nXLEam/4klPpCdY8Tti1/7x9QMPJL6Y1lOcwJegOJf1v4OOW5jcyZP5tIJkj7IqZ+1Pn7DjAQDiqK59q/fr3wNiJpqFCpdAKHug0RdwpHL9FTozY9d5OnmHZS3LWC9VlaJgNsoIF5XqseYgQ6h6okEKDYKkVjXvhrFsLCaRGt9WgmjBd21kqEe1NzxEZINIGhsdWqOh+4ex7tXgGTNIFY766e7S0jPMSzRRgA9OCPu2MC1MwnU/UeJnyCR4BeO8+secEE+eN1Zu/BFUF2SeGs222hI8OlOWh4XlZQ/QXhnr7m2HEDLcvNaRf4l4J8tjlBmk7e3HyMJLrWlg0X1ZUHiS6tk2DoRKgWruhTtFb2EkAHgS2CNWZQ6ctKLTUDnotGwHJPGe7V8gq42i2A7MWAAaSCH0fOG9JG8/Naig7pSuw4vvuC2QYS2/3u2lmPdTtxRUVRGjBHd+RVz8s2/jsyVThHeir8qKiKAXoaXRZXL6FSHprxZbhhJzQEhhqlrFHc6Ji5kXxw04IQTMxxEeDVYF5eH0oHsy1b/a2oR+NW05z++XdbqNzTWGSuFMXBec3nP+FJvG93a3ENMLZB40XyUgpM8CL7qZkQWwinaws0MGYQIF0pzUWn9ysvPbL19z54S13nkBlTWoOmBm4jGv7fGGDzUM+bRozukNiH9F4dZbTQacjZDFfTgtrZyPQJB06OtBx7J+2DKvZEaWlru0P0GBUonqMNckyxdnmDgHJP9PibPexCKE0tl5XuG91RlIHSYdVfWiLlE0+2ElQGGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":33468,"cache_read_input_tokens":28411,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":33468},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsMPRuhdx1mWJ54SN3Y","type":"assistant","uuid":"4f2956b2-d034-4653-ab73-7dd2d0a83cf5","timestamp":"2026-02-21T08:05:54.636Z"}
{"parentUuid":"4f2956b2-d034-4653-ab73-7dd2d0a83cf5","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01FyzkUisAuWJxeETKBTsY7T","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me read the schema for the Cypher queries and the code-finder line/peek endpoints."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":33468,"cache_read_input_tokens":28411,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":33468},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsMPRuhdx1mWJ54SN3Y","type":"assistant","uuid":"b68f5f59-9431-483d-8be5-56fc416d5ec2","timestamp":"2026-02-21T08:05:54.811Z"}
{"parentUuid":"b68f5f59-9431-483d-8be5-56fc416d5ec2","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01FyzkUisAuWJxeETKBTsY7T","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HrzGX6SCJ6Q7WSqsjgfLxy","name":"Grep","input":{"pattern":"search_code|search_symbols|code-finder/line|code-finder/peek","path":"/Users/skmabudalam/Documents/BugViper/db/schema.py","output_mode":"content"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":33468,"cache_read_input_tokens":28411,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":33468},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsMPRuhdx1mWJ54SN3Y","type":"assistant","uuid":"b366d902-8406-4904-bd4f-2f748cc6ef75","timestamp":"2026-02-21T08:05:56.439Z"}
{"parentUuid":"b366d902-8406-4904-bd4f-2f748cc6ef75","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01FyzkUisAuWJxeETKBTsY7T","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019e1c7Cd8qmzdaKJnCwpYFm","name":"Glob","input":{"pattern":"/Users/skmabudalam/Documents/BugViper/api/services/code_search.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":33468,"cache_read_input_tokens":28411,"output_tokens":435,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":33468,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLsMPRuhdx1mWJ54SN3Y","type":"assistant","uuid":"1b324e41-331f-466c-8599-14bcb52dd317","timestamp":"2026-02-21T08:05:57.015Z"}
{"parentUuid":"1b324e41-331f-466c-8599-14bcb52dd317","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01HrzGX6SCJ6Q7WSqsjgfLxy","toolUseID":"toolu_01HrzGX6SCJ6Q7WSqsjgfLxy","timestamp":"2026-02-21T08:05:57.073Z","uuid":"cfe76d04-05ef-43c1-8029-3d0f055b5b7b"}
{"parentUuid":"b366d902-8406-4904-bd4f-2f748cc6ef75","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HrzGX6SCJ6Q7WSqsjgfLxy","type":"tool_result","content":"811:    \"search_code\": \"\"\"\n820:    \"search_symbols\": \"\"\"\n834:    \"search_symbols_by_qualified_name\": \"\"\""}]},"uuid":"04550bcd-8067-4ea6-8dad-a4cbb1aef703","timestamp":"2026-02-21T08:05:57.072Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"811:    \"search_code\": \"\"\"\n820:    \"search_symbols\": \"\"\"\n834:    \"search_symbols_by_qualified_name\": \"\"\"","numLines":3},"sourceToolAssistantUUID":"b366d902-8406-4904-bd4f-2f748cc6ef75"}
{"parentUuid":"04550bcd-8067-4ea6-8dad-a4cbb1aef703","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Glob","command":"callback"},"parentToolUseID":"toolu_019e1c7Cd8qmzdaKJnCwpYFm","toolUseID":"toolu_019e1c7Cd8qmzdaKJnCwpYFm","timestamp":"2026-02-21T08:05:57.346Z","uuid":"82f72483-135d-4382-a602-032f3f5655b6"}
{"parentUuid":"1b324e41-331f-466c-8599-14bcb52dd317","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019e1c7Cd8qmzdaKJnCwpYFm","type":"tool_result","content":"/Users/skmabudalam/Documents/BugViper/api/services/code_search.py"}]},"uuid":"4a582251-f4d8-4ab9-853a-12dbb91535ea","timestamp":"2026-02-21T08:05:57.345Z","toolUseResult":{"filenames":["/Users/skmabudalam/Documents/BugViper/api/services/code_search.py"],"durationMs":327,"numFiles":1,"truncated":false},"sourceToolAssistantUUID":"1b324e41-331f-466c-8599-14bcb52dd317"}
{"parentUuid":"4a582251-f4d8-4ab9-853a-12dbb91535ea","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01XKXAXisYahqkiiSYYL1fSU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01K1aMY9dqHNvXxqZa9cFoSf","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/db/schema.py","offset":800,"limit":80},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":551,"cache_read_input_tokens":61879,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":551},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsNBNeJsECJakdVM7wk","type":"assistant","uuid":"fb892dab-45f3-4185-ae2f-8d28e8c56d53","timestamp":"2026-02-21T08:05:59.763Z"}
{"parentUuid":"fb892dab-45f3-4185-ae2f-8d28e8c56d53","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01K1aMY9dqHNvXxqZa9cFoSf","toolUseID":"toolu_01K1aMY9dqHNvXxqZa9cFoSf","timestamp":"2026-02-21T08:05:59.773Z","uuid":"e8bbbddc-eb3e-4e82-9558-f8f89c0c7db1"}
{"parentUuid":"fb892dab-45f3-4185-ae2f-8d28e8c56d53","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01K1aMY9dqHNvXxqZa9cFoSf","type":"tool_result","content":"   800→    \"test_symbol_resolution\": \"\"\"\n   801→        MATCH (s:Symbol)\n   802→        WHERE s.file_id STARTS WITH $repo_id\n   803→        WITH count(s) as total_symbols,\n   804→             sum(CASE WHEN s.source_code IS NOT NULL THEN 1 ELSE 0 END) as symbols_with_source\n   805→        RETURN total_symbols,\n   806→               symbols_with_source,\n   807→               (symbols_with_source * 100.0 / total_symbols) as symbol_source_rate\n   808→    \"\"\",\n   809→\n   810→    \n   811→    \"search_code\": \"\"\"\n   812→        CALL db.index.fulltext.queryNodes('code_search', $search_term)\n   813→        YIELD node, score\n   814→        MATCH (f:File)-[:DEFINES*1..2]->(node)\n   815→        RETURN node, labels(node)[0] as type, f.path as file, score\n   816→        ORDER BY score DESC\n   817→        LIMIT 20\n   818→    \"\"\",\n   819→\n   820→    \"search_symbols\": \"\"\"\n   821→        CALL db.index.fulltext.queryNodes('symbol_search', $search_term)\n   822→        YIELD node, score\n   823→        RETURN node.name as name,\n   824→               node.qualified_name as qualified_name,\n   825→               node.type as type,\n   826→               node.file_id as file_id,\n   827→               node.line_start as line,\n   828→               node.visibility as visibility,\n   829→               score\n   830→        ORDER BY score DESC\n   831→        LIMIT $limit\n   832→    \"\"\",\n   833→\n   834→    \"search_symbols_by_qualified_name\": \"\"\"\n   835→        MATCH (s:Symbol)\n   836→        WHERE s.qualified_name = $qualified_name\n   837→          AND s.file_id STARTS WITH $repo_id\n   838→        RETURN s.id as id,\n   839→               s.name as name,\n   840→               s.qualified_name as qualified_name,\n   841→               s.type as type,\n   842→               s.file_id as file_id,\n   843→               s.line_start as line_start,\n   844→               s.line_end as line_end,\n   845→               s.scope as scope,\n   846→               s.visibility as visibility,\n   847→               s.docstring as docstring\n   848→        LIMIT 1\n   849→    \"\"\",\n   850→\n   851→    \"autocomplete_symbols\": \"\"\"\n   852→        MATCH (s:Symbol)\n   853→        WHERE s.qualified_name STARTS WITH $prefix\n   854→          AND s.file_id STARTS WITH $repo_id\n   855→        RETURN s.qualified_name as qualified_name,\n   856→               s.type as type,\n   857→               s.visibility as visibility,\n   858→               s.file_id as file_id\n   859→        ORDER BY s.qualified_name\n   860→        LIMIT $limit\n   861→    \"\"\",\n   862→\n   863→    \"find_symbols_in_scope\": \"\"\"\n   864→        MATCH (s:Symbol {file_id: $file_id, scope: $scope})\n   865→        RETURN s.name as name,\n   866→               s.qualified_name as qualified_name,\n   867→               s.type as type,\n   868→               s.line_start as line_start,\n   869→               s.visibility as visibility\n   870→        ORDER BY s.line_start\n   871→    \"\"\",\n   872→    \n   873→    \"analyze_change_impact\": \"\"\"\n   874→        MATCH (target {id: $target_id})\n   875→        MATCH path = (caller)-[:CALLS*1..3]->(target)\n   876→        WITH caller, length(path) as distance\n   877→        MATCH (f:File)-[:DEFINES*1..2]->(caller)\n   878→        RETURN DISTINCT caller.name as affected, labels(caller)[0] as type,\n   879→               f.path as file, distance\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"3d2c2c10-2d1e-478d-8b53-315d91190cd2","timestamp":"2026-02-21T08:05:59.772Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/db/schema.py","content":"    \"test_symbol_resolution\": \"\"\"\n        MATCH (s:Symbol)\n        WHERE s.file_id STARTS WITH $repo_id\n        WITH count(s) as total_symbols,\n             sum(CASE WHEN s.source_code IS NOT NULL THEN 1 ELSE 0 END) as symbols_with_source\n        RETURN total_symbols,\n               symbols_with_source,\n               (symbols_with_source * 100.0 / total_symbols) as symbol_source_rate\n    \"\"\",\n\n    \n    \"search_code\": \"\"\"\n        CALL db.index.fulltext.queryNodes('code_search', $search_term)\n        YIELD node, score\n        MATCH (f:File)-[:DEFINES*1..2]->(node)\n        RETURN node, labels(node)[0] as type, f.path as file, score\n        ORDER BY score DESC\n        LIMIT 20\n    \"\"\",\n\n    \"search_symbols\": \"\"\"\n        CALL db.index.fulltext.queryNodes('symbol_search', $search_term)\n        YIELD node, score\n        RETURN node.name as name,\n               node.qualified_name as qualified_name,\n               node.type as type,\n               node.file_id as file_id,\n               node.line_start as line,\n               node.visibility as visibility,\n               score\n        ORDER BY score DESC\n        LIMIT $limit\n    \"\"\",\n\n    \"search_symbols_by_qualified_name\": \"\"\"\n        MATCH (s:Symbol)\n        WHERE s.qualified_name = $qualified_name\n          AND s.file_id STARTS WITH $repo_id\n        RETURN s.id as id,\n               s.name as name,\n               s.qualified_name as qualified_name,\n               s.type as type,\n               s.file_id as file_id,\n               s.line_start as line_start,\n               s.line_end as line_end,\n               s.scope as scope,\n               s.visibility as visibility,\n               s.docstring as docstring\n        LIMIT 1\n    \"\"\",\n\n    \"autocomplete_symbols\": \"\"\"\n        MATCH (s:Symbol)\n        WHERE s.qualified_name STARTS WITH $prefix\n          AND s.file_id STARTS WITH $repo_id\n        RETURN s.qualified_name as qualified_name,\n               s.type as type,\n               s.visibility as visibility,\n               s.file_id as file_id\n        ORDER BY s.qualified_name\n        LIMIT $limit\n    \"\"\",\n\n    \"find_symbols_in_scope\": \"\"\"\n        MATCH (s:Symbol {file_id: $file_id, scope: $scope})\n        RETURN s.name as name,\n               s.qualified_name as qualified_name,\n               s.type as type,\n               s.line_start as line_start,\n               s.visibility as visibility\n        ORDER BY s.line_start\n    \"\"\",\n    \n    \"analyze_change_impact\": \"\"\"\n        MATCH (target {id: $target_id})\n        MATCH path = (caller)-[:CALLS*1..3]->(target)\n        WITH caller, length(path) as distance\n        MATCH (f:File)-[:DEFINES*1..2]->(caller)\n        RETURN DISTINCT caller.name as affected, labels(caller)[0] as type,\n               f.path as file, distance","numLines":80,"startLine":800,"totalLines":1254}},"sourceToolAssistantUUID":"fb892dab-45f3-4185-ae2f-8d28e8c56d53"}
{"parentUuid":"3d2c2c10-2d1e-478d-8b53-315d91190cd2","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01XKXAXisYahqkiiSYYL1fSU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01F1Tmvyc7umpARdK5SoqUMM","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/api/services/code_search.py","limit":150},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":551,"cache_read_input_tokens":61879,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":551},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsNBNeJsECJakdVM7wk","type":"assistant","uuid":"64fd7fbb-6370-441c-b77c-47d5e2e7657d","timestamp":"2026-02-21T08:06:00.415Z"}
{"parentUuid":"64fd7fbb-6370-441c-b77c-47d5e2e7657d","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01F1Tmvyc7umpARdK5SoqUMM","toolUseID":"toolu_01F1Tmvyc7umpARdK5SoqUMM","timestamp":"2026-02-21T08:06:00.431Z","uuid":"a048b80a-cced-4be1-bafa-5851e0cfe924"}
{"parentUuid":"64fd7fbb-6370-441c-b77c-47d5e2e7657d","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01F1Tmvyc7umpARdK5SoqUMM","type":"tool_result","content":"     1→import logging\n     2→import re\n     3→from typing import Any, Dict, List, Literal, Optional\n     4→from pathlib import Path\n     5→\n     6→from db import Neo4jClient\n     7→\n     8→logger = logging.getLogger(__name__)\n     9→\n    10→class CodeFinder:\n    11→    \"\"\"Module for finding relevant code snippets and analyzing relationships.\"\"\"\n    12→\n    13→    def __init__(self, neo4j_client: Neo4jClient):\n    14→        self.neo4j_client = neo4j_client\n    15→        self.driver = self.neo4j_client.driver\n    16→\n    17→    def format_query(self, find_by: Literal[\"Class\", \"Function\"], fuzzy_search:bool) -> str:\n    18→        \"\"\"Format the search query based on the search type and fuzzy search settings.\"\"\"\n    19→        return f\"\"\"\n    20→            CALL db.index.fulltext.queryNodes(\"code_search_index\", $search_term) YIELD node, score\n    21→                WITH node, score\n    22→                WHERE node:{find_by} {'AND node.name CONTAINS $search_term' if not fuzzy_search else ''}\n    23→                RETURN node.name as name, node.path as path, node.line_number as line_number,\n    24→                    node.source as source, node.docstring as docstring, node.is_dependency as is_dependency\n    25→                ORDER BY score DESC\n    26→                LIMIT 20\n    27→            \"\"\"\n    28→\n    29→    def find_by_function_name(self, search_term: str, fuzzy_search: bool) -> List[Dict]:\n    30→        \"\"\"Find functions by name matching.\"\"\"\n    31→        with self.driver.session() as session:\n    32→            if not fuzzy_search:\n    33→                # Use simple match for exact search to avoid fulltext index dependency\n    34→                result = session.run(\"\"\"\n    35→                    MATCH (node:Function {name: $name})\n    36→                    RETURN node.name as name, node.path as path, node.line_number as line_number,\n    37→                           node.source as source, node.docstring as docstring, node.is_dependency as is_dependency\n    38→                    LIMIT 20\n    39→                \"\"\", name=search_term)\n    40→                return result.data()\n    41→            \n    42→            # Fuzzy search using fulltext index\n    43→            formatted_search_term = f\"name:{search_term}\"\n    44→            result = session.run(self.format_query(\"Function\", fuzzy_search), search_term=formatted_search_term)\n    45→            return result.data()\n    46→\n    47→    def find_by_class_name(self, search_term: str, fuzzy_search: bool) -> List[Dict]:\n    48→        \"\"\"Find classes by name matching.\"\"\"\n    49→        with self.driver.session() as session:\n    50→            if not fuzzy_search:\n    51→                # Use simple match for exact search to avoid fulltext index dependency\n    52→                result = session.run(\"\"\"\n    53→                    MATCH (node:Class {name: $name})\n    54→                    RETURN node.name as name, node.path as path, node.line_number as line_number,\n    55→                           node.source as source, node.docstring as docstring, node.is_dependency as is_dependency\n    56→                    LIMIT 20\n    57→                \"\"\", name=search_term)\n    58→                return result.data()\n    59→\n    60→            formatted_search_term = f\"name:{search_term}\"\n    61→            result = session.run(self.format_query(\"Class\", fuzzy_search), search_term=formatted_search_term)\n    62→            return result.data()\n    63→\n    64→    def find_by_variable_name(self, search_term: str) -> List[Dict]:\n    65→        \"\"\"Find variables by name matching\"\"\"\n    66→        with self.driver.session() as session:\n    67→            result = session.run(\"\"\"\n    68→                MATCH (v:Variable)\n    69→                WHERE v.name CONTAINS $search_term\n    70→                RETURN v.name as name, v.path as path, v.line_number as line_number,\n    71→                       v.value as value, v.context as context, v.is_dependency as is_dependency\n    72→                ORDER BY v.is_dependency ASC, v.name\n    73→                LIMIT 20\n    74→            \"\"\", search_term=search_term)\n    75→            \n    76→            return result.data()\n    77→\n    78→    def find_by_content(self, search_term: str) -> List[Dict]:\n    79→        \"\"\"Find code by content matching in source or docstrings.\"\"\"\n    80→        with self.driver.session() as session:\n    81→            try:\n    82→                result = session.run(\"\"\"\n    83→                    CALL db.index.fulltext.queryNodes(\"code_search_index\", $search_term) YIELD node, score\n    84→                    WITH node, score\n    85→                    WHERE node:Function OR node:Class OR node:Variable\n    86→                    RETURN\n    87→                        CASE\n    88→                            WHEN node:Function THEN 'function'\n    89→                            WHEN node:Class THEN 'class'\n    90→                            ELSE 'variable'\n    91→                        END as type,\n    92→                        node.name as name, node.path as path,\n    93→                        node.line_number as line_number, node.source as source,\n    94→                        node.docstring as docstring, node.is_dependency as is_dependency\n    95→                    ORDER BY score DESC\n    96→                    LIMIT 20\n    97→                \"\"\", search_term=search_term)\n    98→                return result.data()\n    99→            except Exception:\n   100→                result = session.run(\"\"\"\n   101→                    MATCH (node)\n   102→                    WHERE (node:Function OR node:Class OR node:Variable)\n   103→                      AND (node.name CONTAINS $search_term\n   104→                           OR node.source CONTAINS $search_term\n   105→                           OR node.docstring CONTAINS $search_term)\n   106→                    RETURN\n   107→                        CASE\n   108→                            WHEN node:Function THEN 'function'\n   109→                            WHEN node:Class THEN 'class'\n   110→                            ELSE 'variable'\n   111→                        END as type,\n   112→                        node.name as name, node.path as path,\n   113→                        node.line_number as line_number, node.source as source,\n   114→                        node.docstring as docstring, node.is_dependency as is_dependency\n   115→                    LIMIT 20\n   116→                \"\"\", search_term=search_term)\n   117→                return result.data()\n   118→    \n   119→    def find_by_module_name(self, search_term: str) -> List[Dict]:\n   120→        \"\"\"Find modules by name matching\"\"\"\n   121→        with self.driver.session() as session:\n   122→            result = session.run(\"\"\"\n   123→                MATCH (m:Module)\n   124→                WHERE m.name CONTAINS $search_term\n   125→                RETURN m.name as name, m.lang as lang\n   126→                ORDER BY m.name\n   127→                LIMIT 20\n   128→            \"\"\", search_term=search_term)\n   129→            return result.data()\n   130→\n   131→    def find_imports(self, search_term: str) -> List[Dict]:\n   132→        \"\"\"Find imported symbols (aliases or original names).\"\"\"\n   133→        with self.driver.session() as session:\n   134→            result = session.run(\"\"\"\n   135→                MATCH (f:File)-[r:IMPORTS]->(m:Module)\n   136→                WHERE r.alias = $search_term OR r.imported_name = $search_term\n   137→                RETURN \n   138→                    r.alias as alias, \n   139→                    r.imported_name as imported_name, \n   140→                    m.name as module_name, \n   141→                    f.path as path, \n   142→                    r.line_number as line_number\n   143→                ORDER BY f.path\n   144→                LIMIT 20\n   145→            \"\"\", search_term=search_term)\n   146→            return result.data()\n   147→\n   148→    def find_related_code(self, user_query: str, fuzzy_search: bool, edit_distance: int) -> Dict[str, Any]:\n   149→        \"\"\"Find code related to a query using multiple search strategies\"\"\"\n   150→        if fuzzy_search:\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"d3db73da-01d4-41af-8ae9-8166d6b2f5f4","timestamp":"2026-02-21T08:06:00.430Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/api/services/code_search.py","content":"import logging\nimport re\nfrom typing import Any, Dict, List, Literal, Optional\nfrom pathlib import Path\n\nfrom db import Neo4jClient\n\nlogger = logging.getLogger(__name__)\n\nclass CodeFinder:\n    \"\"\"Module for finding relevant code snippets and analyzing relationships.\"\"\"\n\n    def __init__(self, neo4j_client: Neo4jClient):\n        self.neo4j_client = neo4j_client\n        self.driver = self.neo4j_client.driver\n\n    def format_query(self, find_by: Literal[\"Class\", \"Function\"], fuzzy_search:bool) -> str:\n        \"\"\"Format the search query based on the search type and fuzzy search settings.\"\"\"\n        return f\"\"\"\n            CALL db.index.fulltext.queryNodes(\"code_search_index\", $search_term) YIELD node, score\n                WITH node, score\n                WHERE node:{find_by} {'AND node.name CONTAINS $search_term' if not fuzzy_search else ''}\n                RETURN node.name as name, node.path as path, node.line_number as line_number,\n                    node.source as source, node.docstring as docstring, node.is_dependency as is_dependency\n                ORDER BY score DESC\n                LIMIT 20\n            \"\"\"\n\n    def find_by_function_name(self, search_term: str, fuzzy_search: bool) -> List[Dict]:\n        \"\"\"Find functions by name matching.\"\"\"\n        with self.driver.session() as session:\n            if not fuzzy_search:\n                # Use simple match for exact search to avoid fulltext index dependency\n                result = session.run(\"\"\"\n                    MATCH (node:Function {name: $name})\n                    RETURN node.name as name, node.path as path, node.line_number as line_number,\n                           node.source as source, node.docstring as docstring, node.is_dependency as is_dependency\n                    LIMIT 20\n                \"\"\", name=search_term)\n                return result.data()\n            \n            # Fuzzy search using fulltext index\n            formatted_search_term = f\"name:{search_term}\"\n            result = session.run(self.format_query(\"Function\", fuzzy_search), search_term=formatted_search_term)\n            return result.data()\n\n    def find_by_class_name(self, search_term: str, fuzzy_search: bool) -> List[Dict]:\n        \"\"\"Find classes by name matching.\"\"\"\n        with self.driver.session() as session:\n            if not fuzzy_search:\n                # Use simple match for exact search to avoid fulltext index dependency\n                result = session.run(\"\"\"\n                    MATCH (node:Class {name: $name})\n                    RETURN node.name as name, node.path as path, node.line_number as line_number,\n                           node.source as source, node.docstring as docstring, node.is_dependency as is_dependency\n                    LIMIT 20\n                \"\"\", name=search_term)\n                return result.data()\n\n            formatted_search_term = f\"name:{search_term}\"\n            result = session.run(self.format_query(\"Class\", fuzzy_search), search_term=formatted_search_term)\n            return result.data()\n\n    def find_by_variable_name(self, search_term: str) -> List[Dict]:\n        \"\"\"Find variables by name matching\"\"\"\n        with self.driver.session() as session:\n            result = session.run(\"\"\"\n                MATCH (v:Variable)\n                WHERE v.name CONTAINS $search_term\n                RETURN v.name as name, v.path as path, v.line_number as line_number,\n                       v.value as value, v.context as context, v.is_dependency as is_dependency\n                ORDER BY v.is_dependency ASC, v.name\n                LIMIT 20\n            \"\"\", search_term=search_term)\n            \n            return result.data()\n\n    def find_by_content(self, search_term: str) -> List[Dict]:\n        \"\"\"Find code by content matching in source or docstrings.\"\"\"\n        with self.driver.session() as session:\n            try:\n                result = session.run(\"\"\"\n                    CALL db.index.fulltext.queryNodes(\"code_search_index\", $search_term) YIELD node, score\n                    WITH node, score\n                    WHERE node:Function OR node:Class OR node:Variable\n                    RETURN\n                        CASE\n                            WHEN node:Function THEN 'function'\n                            WHEN node:Class THEN 'class'\n                            ELSE 'variable'\n                        END as type,\n                        node.name as name, node.path as path,\n                        node.line_number as line_number, node.source as source,\n                        node.docstring as docstring, node.is_dependency as is_dependency\n                    ORDER BY score DESC\n                    LIMIT 20\n                \"\"\", search_term=search_term)\n                return result.data()\n            except Exception:\n                result = session.run(\"\"\"\n                    MATCH (node)\n                    WHERE (node:Function OR node:Class OR node:Variable)\n                      AND (node.name CONTAINS $search_term\n                           OR node.source CONTAINS $search_term\n                           OR node.docstring CONTAINS $search_term)\n                    RETURN\n                        CASE\n                            WHEN node:Function THEN 'function'\n                            WHEN node:Class THEN 'class'\n                            ELSE 'variable'\n                        END as type,\n                        node.name as name, node.path as path,\n                        node.line_number as line_number, node.source as source,\n                        node.docstring as docstring, node.is_dependency as is_dependency\n                    LIMIT 20\n                \"\"\", search_term=search_term)\n                return result.data()\n    \n    def find_by_module_name(self, search_term: str) -> List[Dict]:\n        \"\"\"Find modules by name matching\"\"\"\n        with self.driver.session() as session:\n            result = session.run(\"\"\"\n                MATCH (m:Module)\n                WHERE m.name CONTAINS $search_term\n                RETURN m.name as name, m.lang as lang\n                ORDER BY m.name\n                LIMIT 20\n            \"\"\", search_term=search_term)\n            return result.data()\n\n    def find_imports(self, search_term: str) -> List[Dict]:\n        \"\"\"Find imported symbols (aliases or original names).\"\"\"\n        with self.driver.session() as session:\n            result = session.run(\"\"\"\n                MATCH (f:File)-[r:IMPORTS]->(m:Module)\n                WHERE r.alias = $search_term OR r.imported_name = $search_term\n                RETURN \n                    r.alias as alias, \n                    r.imported_name as imported_name, \n                    m.name as module_name, \n                    f.path as path, \n                    r.line_number as line_number\n                ORDER BY f.path\n                LIMIT 20\n            \"\"\", search_term=search_term)\n            return result.data()\n\n    def find_related_code(self, user_query: str, fuzzy_search: bool, edit_distance: int) -> Dict[str, Any]:\n        \"\"\"Find code related to a query using multiple search strategies\"\"\"\n        if fuzzy_search:","numLines":150,"startLine":1,"totalLines":922}},"sourceToolAssistantUUID":"64fd7fbb-6370-441c-b77c-47d5e2e7657d"}
{"parentUuid":"d3db73da-01d4-41af-8ae9-8166d6b2f5f4","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01CdySzEEAfEJBpoRiGgtbta","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I understand the issues clearly. Let me also check if there are `code-finder/line` and `code-finder/peek` endpoints registered in the router.","signature":"EroCCkYICxgCKkBOfROm0ccSIrT8jErmM3QAFx/k6bIuYe1AlYSh+BFShhHAUopDwYQzV6hf+1yOfCA/yfjhM/piv4yDjlpGhm+AEgzvo4e1e/aYKsEoFaEaDIrIMAYov2GcugDWmiIwBh4gakqUe96XglELchkYRvJvXqqdRX6fG4a2q85Sw7XZnOzQApokMPif9vOxlwnCKqEBMfyNzXOPEjl46CXDwXW59/KokenX44pGJ/OUDdt/LRfVj+5lyZTXdn93wtiEvvftYgez8o1bAdZG1pBqTVCoJvBpOoSA87qO+i2x+QRhn1duAHJ0E5NSH8IRk2a/5o3lmeIFJbtx98CwerJWbVBQqmJnqhSi6j/a9pWDPQShBrw/wWkM8KzlljnyZStDYYvr6dJDT/68OwdN64VhcD366OgYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3703,"cache_read_input_tokens":62430,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3703},"output_tokens":12,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsNQk4e99yToQgfgRZc","type":"assistant","uuid":"453ed3cd-3713-4e9d-a0cd-d5cea3815241","timestamp":"2026-02-21T08:06:02.500Z"}
{"parentUuid":"453ed3cd-3713-4e9d-a0cd-d5cea3815241","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01CdySzEEAfEJBpoRiGgtbta","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me check if the `/code-finder/line` and `/code-finder/peek` endpoints exist, and read the rest of code_search.py."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3703,"cache_read_input_tokens":62430,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3703},"output_tokens":12,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsNQk4e99yToQgfgRZc","type":"assistant","uuid":"a4c34b59-e388-49ac-bda0-ae800cc1a403","timestamp":"2026-02-21T08:06:03.477Z"}
{"parentUuid":"a4c34b59-e388-49ac-bda0-ae800cc1a403","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01CdySzEEAfEJBpoRiGgtbta","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011Wvy8FhHBt6CKGmuGaW3ia","name":"Grep","input":{"pattern":"code-finder/line|code-finder/peek|find_line|peek","path":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","output_mode":"content"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3703,"cache_read_input_tokens":62430,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3703},"output_tokens":12,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsNQk4e99yToQgfgRZc","type":"assistant","uuid":"9e6dbc15-3aa7-445c-a099-4918f1421405","timestamp":"2026-02-21T08:06:05.284Z"}
{"parentUuid":"9e6dbc15-3aa7-445c-a099-4918f1421405","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_011Wvy8FhHBt6CKGmuGaW3ia","toolUseID":"toolu_011Wvy8FhHBt6CKGmuGaW3ia","timestamp":"2026-02-21T08:06:05.622Z","uuid":"5d8130d2-5ebd-491e-bcb1-422f79afc8cf"}
{"parentUuid":"9e6dbc15-3aa7-445c-a099-4918f1421405","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011Wvy8FhHBt6CKGmuGaW3ia","type":"tool_result","content":"No matches found"}]},"uuid":"29a58890-5ebd-4275-8bbf-3d0fbd2ab413","timestamp":"2026-02-21T08:06:05.620Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"","numLines":0},"sourceToolAssistantUUID":"9e6dbc15-3aa7-445c-a099-4918f1421405"}
{"parentUuid":"29a58890-5ebd-4275-8bbf-3d0fbd2ab413","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01CdySzEEAfEJBpoRiGgtbta","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Re4fTUXPNeLxSwgj9h79Ex","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/api/services/code_search.py","offset":150,"limit":100},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3703,"cache_read_input_tokens":62430,"output_tokens":305,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":3703,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLsNQk4e99yToQgfgRZc","type":"assistant","uuid":"156808d7-2dd8-49a5-a61e-235f12893c49","timestamp":"2026-02-21T08:06:06.043Z"}
{"parentUuid":"156808d7-2dd8-49a5-a61e-235f12893c49","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01Re4fTUXPNeLxSwgj9h79Ex","toolUseID":"toolu_01Re4fTUXPNeLxSwgj9h79Ex","timestamp":"2026-02-21T08:06:06.056Z","uuid":"f3d9d8e8-8ddb-4a44-b57d-52f39636ed6c"}
{"parentUuid":"156808d7-2dd8-49a5-a61e-235f12893c49","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Re4fTUXPNeLxSwgj9h79Ex","type":"tool_result","content":"   150→        if fuzzy_search:\n   151→            user_query_normalized = \" \".join(map(lambda x: f\"{x}~{edit_distance}\", user_query.split(\" \")))\n   152→        else:\n   153→            user_query_normalized = user_query\n   154→\n   155→        results = {\n   156→            \"query\": user_query_normalized,\n   157→            \"functions_by_name\": self.find_by_function_name(user_query_normalized, fuzzy_search),\n   158→            \"classes_by_name\": self.find_by_class_name(user_query_normalized, fuzzy_search),\n   159→            \"variables_by_name\": self.find_by_variable_name(user_query),  # no fuzzy for variables as they are not using full-text index\n   160→            \"content_matches\": self.find_by_content(user_query_normalized)\n   161→        }\n   162→        \n   163→        all_results = []\n   164→        \n   165→        for func in results[\"functions_by_name\"]:\n   166→            func[\"search_type\"] = \"function_name\"\n   167→            func[\"relevance_score\"] = 0.9 if not func[\"is_dependency\"] else 0.7\n   168→            all_results.append(func)\n   169→        \n   170→        for cls in results[\"classes_by_name\"]:\n   171→            cls[\"search_type\"] = \"class_name\"\n   172→            cls[\"relevance_score\"] = 0.8 if not cls[\"is_dependency\"] else 0.6\n   173→            all_results.append(cls)\n   174→\n   175→        for var in results[\"variables_by_name\"]:\n   176→            var[\"search_type\"] = \"variable_name\"\n   177→            var[\"relevance_score\"] = 0.7 if not var[\"is_dependency\"] else 0.5\n   178→            all_results.append(var)\n   179→        \n   180→        for content in results[\"content_matches\"]:\n   181→            content[\"search_type\"] = \"content\"\n   182→            content[\"relevance_score\"] = 0.6 if not content[\"is_dependency\"] else 0.4\n   183→            all_results.append(content)\n   184→        \n   185→        all_results.sort(key=lambda x: x[\"relevance_score\"], reverse=True)\n   186→        \n   187→        results[\"ranked_results\"] = all_results[:15]\n   188→        results[\"total_matches\"] = len(all_results)\n   189→        \n   190→        return results\n   191→    \n   192→    def find_functions_by_argument(self, argument_name: str, path: str = None) -> List[Dict]:\n   193→        \"\"\"Find functions that take a specific argument name.\"\"\"\n   194→        with self.driver.session() as session:\n   195→            if path:\n   196→                query = \"\"\"\n   197→                    MATCH (f:Function)-[:HAS_PARAMETER]->(p:Parameter)\n   198→                    WHERE p.name = $argument_name AND f.path = $path\n   199→                    RETURN f.name AS function_name, f.path AS path, f.line_number AS line_number,\n   200→                           f.docstring AS docstring, f.is_dependency AS is_dependency\n   201→                    ORDER BY f.is_dependency ASC, f.path, f.line_number\n   202→                    LIMIT 20\n   203→                \"\"\"\n   204→                result = session.run(query, argument_name=argument_name, path=path)\n   205→            else:\n   206→                query = \"\"\"\n   207→                    MATCH (f:Function)-[:HAS_PARAMETER]->(p:Parameter)\n   208→                    WHERE p.name = $argument_name\n   209→                    RETURN f.name AS function_name, f.path AS path, f.line_number AS line_number,\n   210→                           f.docstring AS docstring, f.is_dependency AS is_dependency\n   211→                    ORDER BY f.is_dependency ASC, f.path, f.line_number\n   212→                    LIMIT 20\n   213→                \"\"\"\n   214→                result = session.run(query, argument_name=argument_name)\n   215→            return result.data()\n   216→\n   217→    def find_functions_by_decorator(self, decorator_name: str, path: str = None) -> List[Dict]:\n   218→        \"\"\"Find functions that have a specific decorator applied to them.\"\"\"\n   219→        with self.driver.session() as session:\n   220→            if path:\n   221→                query = \"\"\"\n   222→                    MATCH (f:Function)\n   223→                    WHERE f.path = $path AND $decorator_name IN f.decorators\n   224→                    RETURN f.name AS function_name, f.path AS path, f.line_number AS line_number,\n   225→                           f.docstring AS docstring, f.is_dependency AS is_dependency, f.decorators AS decorators\n   226→                    ORDER BY f.is_dependency ASC, f.path, f.line_number\n   227→                    LIMIT 20\n   228→                \"\"\"\n   229→                result = session.run(query, decorator_name=decorator_name, path=path)\n   230→            else:\n   231→                query = \"\"\"\n   232→                    MATCH (f:Function)\n   233→                    WHERE $decorator_name IN f.decorators\n   234→                    RETURN f.name AS function_name, f.path AS path, f.line_number AS line_number,\n   235→                           f.docstring AS docstring, f.is_dependency AS is_dependency, f.decorators AS decorators\n   236→                    ORDER BY f.is_dependency ASC, f.path, f.line_number\n   237→                    LIMIT 20\n   238→                \"\"\"\n   239→                result = session.run(query, decorator_name=decorator_name)\n   240→            return result.data()\n   241→    \n   242→    def who_calls_function(self, function_name: str, path: str = None) -> List[Dict]:\n   243→        \"\"\"Find what functions call a specific function using CALLS relationships with improved matching\"\"\"\n   244→        with self.driver.session() as session:\n   245→            if path:\n   246→                result = session.run(\"\"\"\n   247→                    MATCH (caller:Function)-[call:CALLS]->(target:Function {name: $function_name, path: $path})\n   248→                    OPTIONAL MATCH (caller_file:File)-[:CONTAINS]->(caller)\n   249→                    RETURN DISTINCT\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"9f3a3a6c-f7f8-4a14-ba7f-04f9dea3b392","timestamp":"2026-02-21T08:06:06.056Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/api/services/code_search.py","content":"        if fuzzy_search:\n            user_query_normalized = \" \".join(map(lambda x: f\"{x}~{edit_distance}\", user_query.split(\" \")))\n        else:\n            user_query_normalized = user_query\n\n        results = {\n            \"query\": user_query_normalized,\n            \"functions_by_name\": self.find_by_function_name(user_query_normalized, fuzzy_search),\n            \"classes_by_name\": self.find_by_class_name(user_query_normalized, fuzzy_search),\n            \"variables_by_name\": self.find_by_variable_name(user_query),  # no fuzzy for variables as they are not using full-text index\n            \"content_matches\": self.find_by_content(user_query_normalized)\n        }\n        \n        all_results = []\n        \n        for func in results[\"functions_by_name\"]:\n            func[\"search_type\"] = \"function_name\"\n            func[\"relevance_score\"] = 0.9 if not func[\"is_dependency\"] else 0.7\n            all_results.append(func)\n        \n        for cls in results[\"classes_by_name\"]:\n            cls[\"search_type\"] = \"class_name\"\n            cls[\"relevance_score\"] = 0.8 if not cls[\"is_dependency\"] else 0.6\n            all_results.append(cls)\n\n        for var in results[\"variables_by_name\"]:\n            var[\"search_type\"] = \"variable_name\"\n            var[\"relevance_score\"] = 0.7 if not var[\"is_dependency\"] else 0.5\n            all_results.append(var)\n        \n        for content in results[\"content_matches\"]:\n            content[\"search_type\"] = \"content\"\n            content[\"relevance_score\"] = 0.6 if not content[\"is_dependency\"] else 0.4\n            all_results.append(content)\n        \n        all_results.sort(key=lambda x: x[\"relevance_score\"], reverse=True)\n        \n        results[\"ranked_results\"] = all_results[:15]\n        results[\"total_matches\"] = len(all_results)\n        \n        return results\n    \n    def find_functions_by_argument(self, argument_name: str, path: str = None) -> List[Dict]:\n        \"\"\"Find functions that take a specific argument name.\"\"\"\n        with self.driver.session() as session:\n            if path:\n                query = \"\"\"\n                    MATCH (f:Function)-[:HAS_PARAMETER]->(p:Parameter)\n                    WHERE p.name = $argument_name AND f.path = $path\n                    RETURN f.name AS function_name, f.path AS path, f.line_number AS line_number,\n                           f.docstring AS docstring, f.is_dependency AS is_dependency\n                    ORDER BY f.is_dependency ASC, f.path, f.line_number\n                    LIMIT 20\n                \"\"\"\n                result = session.run(query, argument_name=argument_name, path=path)\n            else:\n                query = \"\"\"\n                    MATCH (f:Function)-[:HAS_PARAMETER]->(p:Parameter)\n                    WHERE p.name = $argument_name\n                    RETURN f.name AS function_name, f.path AS path, f.line_number AS line_number,\n                           f.docstring AS docstring, f.is_dependency AS is_dependency\n                    ORDER BY f.is_dependency ASC, f.path, f.line_number\n                    LIMIT 20\n                \"\"\"\n                result = session.run(query, argument_name=argument_name)\n            return result.data()\n\n    def find_functions_by_decorator(self, decorator_name: str, path: str = None) -> List[Dict]:\n        \"\"\"Find functions that have a specific decorator applied to them.\"\"\"\n        with self.driver.session() as session:\n            if path:\n                query = \"\"\"\n                    MATCH (f:Function)\n                    WHERE f.path = $path AND $decorator_name IN f.decorators\n                    RETURN f.name AS function_name, f.path AS path, f.line_number AS line_number,\n                           f.docstring AS docstring, f.is_dependency AS is_dependency, f.decorators AS decorators\n                    ORDER BY f.is_dependency ASC, f.path, f.line_number\n                    LIMIT 20\n                \"\"\"\n                result = session.run(query, decorator_name=decorator_name, path=path)\n            else:\n                query = \"\"\"\n                    MATCH (f:Function)\n                    WHERE $decorator_name IN f.decorators\n                    RETURN f.name AS function_name, f.path AS path, f.line_number AS line_number,\n                           f.docstring AS docstring, f.is_dependency AS is_dependency, f.decorators AS decorators\n                    ORDER BY f.is_dependency ASC, f.path, f.line_number\n                    LIMIT 20\n                \"\"\"\n                result = session.run(query, decorator_name=decorator_name)\n            return result.data()\n    \n    def who_calls_function(self, function_name: str, path: str = None) -> List[Dict]:\n        \"\"\"Find what functions call a specific function using CALLS relationships with improved matching\"\"\"\n        with self.driver.session() as session:\n            if path:\n                result = session.run(\"\"\"\n                    MATCH (caller:Function)-[call:CALLS]->(target:Function {name: $function_name, path: $path})\n                    OPTIONAL MATCH (caller_file:File)-[:CONTAINS]->(caller)\n                    RETURN DISTINCT","numLines":100,"startLine":150,"totalLines":922}},"sourceToolAssistantUUID":"156808d7-2dd8-49a5-a61e-235f12893c49"}
{"parentUuid":"9f3a3a6c-f7f8-4a14-ba7f-04f9dea3b392","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_014YeqhR9mVSSAoHQS9hHv3e","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I have a clear picture of the issues:\n\n1. **`/search` endpoint** (`search_code`):\n   - The Cypher query uses `(f:File)-[:DEFINES*1..2]->(node)` but the actual schema uses `[:CONTAINS]` not `[:DEFINES]`\n   - Returns raw node objects rather than lean `path`, `line_number`, `match_line` results\n   - No line number info in the response\n\n2. **`/search-symbols` endpoint** (`search_symbols`):\n   - Uses `symbol_search` index (not sure if it exists - the actual indexes are `code_search` and `file_content_search`)\n   - Doesn't escape the query before passing to Lucene, so special characters like parentheses and colons in queries like `class LoginRequest(BaseModel):` break the search\n\n3. **Missing endpoints**: `/code-finder/line` and `/code-finder/peek` mentioned in CLAUDE.md but don't exist in the router\n\nI need to fix the backend by correcting the Cypher queries to use the right relationships and indexes, escaping Lucene queries properly, and implementing the missing endpoints. Now I need to add a `/code-finder/peek` endpoint that retrieves a window of lines around a specified line in a file, and update the frontend to display file paths with line numbers and add a PeekViewer component. Looking at the core issues, the search queries are using incorrect relationship types and missing Lucene escaping, plus the results lack proper file path and line information, so I should focus on fixing those query problems and building out the missing endpoints.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2241,"cache_read_input_tokens":66133,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2241},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsNpaXYFN3z8fMubAm9","type":"assistant","uuid":"ec705533-e40d-4ef1-b77a-4a1e73f64dd6","timestamp":"2026-02-21T08:06:24.600Z"}
{"parentUuid":"ec705533-e40d-4ef1-b77a-4a1e73f64dd6","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_014YeqhR9mVSSAoHQS9hHv3e","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me look at the frontend query page and schema index creation."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2241,"cache_read_input_tokens":66133,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2241},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsNpaXYFN3z8fMubAm9","type":"assistant","uuid":"36940674-32ae-4243-b5bb-d5309566577a","timestamp":"2026-02-21T08:06:24.618Z"}
{"parentUuid":"36940674-32ae-4243-b5bb-d5309566577a","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_014YeqhR9mVSSAoHQS9hHv3e","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01XRzGrhzXM4uT8xzbsSBqkc","name":"Glob","input":{"pattern":"/Users/skmabudalam/Documents/BugViper/frontend/app/**/query/**"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2241,"cache_read_input_tokens":66133,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2241},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsNpaXYFN3z8fMubAm9","type":"assistant","uuid":"e5716852-fa3a-42a9-9473-c2e98d910322","timestamp":"2026-02-21T08:06:24.643Z"}
{"parentUuid":"e5716852-fa3a-42a9-9473-c2e98d910322","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Glob","command":"callback"},"parentToolUseID":"toolu_01XRzGrhzXM4uT8xzbsSBqkc","toolUseID":"toolu_01XRzGrhzXM4uT8xzbsSBqkc","timestamp":"2026-02-21T08:06:25.065Z","uuid":"7fce2ca8-bff8-44dd-96ee-be760dd460a8"}
{"parentUuid":"e5716852-fa3a-42a9-9473-c2e98d910322","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01XRzGrhzXM4uT8xzbsSBqkc","type":"tool_result","content":"/Users/skmabudalam/Documents/BugViper/frontend/app/(protected)/query/page.tsx"}]},"uuid":"15f2bc49-d827-4747-8f4e-8ff009d77ea6","timestamp":"2026-02-21T08:06:25.064Z","toolUseResult":{"filenames":["/Users/skmabudalam/Documents/BugViper/frontend/app/(protected)/query/page.tsx"],"durationMs":417,"numFiles":1,"truncated":false},"sourceToolAssistantUUID":"e5716852-fa3a-42a9-9473-c2e98d910322"}
{"parentUuid":"15f2bc49-d827-4747-8f4e-8ff009d77ea6","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_014YeqhR9mVSSAoHQS9hHv3e","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01M3Rsck3o2VEtkh9TGt6JZG","name":"Grep","input":{"pattern":"fulltext|FULLTEXT|code_search|file_content_search|symbol_search","path":"/Users/skmabudalam/Documents/BugViper/db/schema.py","output_mode":"content"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2241,"cache_read_input_tokens":66133,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2241},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsNpaXYFN3z8fMubAm9","type":"assistant","uuid":"0d14fb33-94f1-4a5a-9221-3bdf04d1dc74","timestamp":"2026-02-21T08:06:25.666Z"}
{"parentUuid":"0d14fb33-94f1-4a5a-9221-3bdf04d1dc74","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01M3Rsck3o2VEtkh9TGt6JZG","toolUseID":"toolu_01M3Rsck3o2VEtkh9TGt6JZG","timestamp":"2026-02-21T08:06:26.076Z","uuid":"db0a8258-869e-45ea-b345-24a9a8fbb147"}
{"parentUuid":"0d14fb33-94f1-4a5a-9221-3bdf04d1dc74","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01M3Rsck3o2VEtkh9TGt6JZG","type":"tool_result","content":"74:            \"CREATE FULLTEXT INDEX code_search IF NOT EXISTS FOR (n:Class|Function|Method|Variable|Symbol) ON EACH [n.name, n.docstring, n.source_code]\",\n75:            \"CREATE FULLTEXT INDEX symbol_search IF NOT EXISTS FOR (s:Symbol) ON EACH [s.name, s.qualified_name, s.docstring]\",\n76:            \"CREATE FULLTEXT INDEX file_content_search IF NOT EXISTS FOR (f:File) ON EACH [f.source_code]\",\n812:        CALL db.index.fulltext.queryNodes('code_search', $search_term)\n821:        CALL db.index.fulltext.queryNodes('symbol_search', $search_term)"}]},"uuid":"f06944a6-9eae-4294-98b4-4c258243f7fb","timestamp":"2026-02-21T08:06:26.075Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"74:            \"CREATE FULLTEXT INDEX code_search IF NOT EXISTS FOR (n:Class|Function|Method|Variable|Symbol) ON EACH [n.name, n.docstring, n.source_code]\",\n75:            \"CREATE FULLTEXT INDEX symbol_search IF NOT EXISTS FOR (s:Symbol) ON EACH [s.name, s.qualified_name, s.docstring]\",\n76:            \"CREATE FULLTEXT INDEX file_content_search IF NOT EXISTS FOR (f:File) ON EACH [f.source_code]\",\n812:        CALL db.index.fulltext.queryNodes('code_search', $search_term)\n821:        CALL db.index.fulltext.queryNodes('symbol_search', $search_term)","numLines":5},"sourceToolAssistantUUID":"0d14fb33-94f1-4a5a-9221-3bdf04d1dc74"}
{"parentUuid":"f06944a6-9eae-4294-98b4-4c258243f7fb","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_014zwF2cPbp2uA76VXrpSxQU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01X9oxT3ZegYDtWtXZheVMom","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/frontend/app/(protected)/query/page.tsx"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1172,"cache_read_input_tokens":68374,"output_tokens":78,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":1172,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLsQJVLH5XpHZqwuXpAG","type":"assistant","uuid":"d229f269-2631-4bab-a867-067a2d9460fe","timestamp":"2026-02-21T08:06:27.959Z"}
{"parentUuid":"d229f269-2631-4bab-a867-067a2d9460fe","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01X9oxT3ZegYDtWtXZheVMom","toolUseID":"toolu_01X9oxT3ZegYDtWtXZheVMom","timestamp":"2026-02-21T08:06:27.971Z","uuid":"ad7c4c3f-a78c-4f4c-9942-3a0741c2f8f7"}
{"parentUuid":"d229f269-2631-4bab-a867-067a2d9460fe","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01X9oxT3ZegYDtWtXZheVMom","type":"tool_result","content":"     1→\"use client\";\n     2→\n     3→import { useState } from \"react\";\n     4→import { Card, CardContent, CardHeader, CardTitle } from \"@/components/ui/card\";\n     5→import { Button } from \"@/components/ui/button\";\n     6→import { Input } from \"@/components/ui/input\";\n     7→import { Label } from \"@/components/ui/label\";\n     8→import { Textarea } from \"@/components/ui/textarea\";\n     9→import { Tabs, TabsContent, TabsList, TabsTrigger } from \"@/components/ui/tabs\";\n    10→import { Badge } from \"@/components/ui/badge\";\n    11→import { CodeBlock } from \"@/components/ui/code-block\";\n    12→import { toast } from \"sonner\";\n    13→import * as api from \"@/lib/api\";\n    14→\n    15→type QueryDef = {\n    16→  label: string;\n    17→  placeholder: string;\n    18→  fn: (q: string) => Promise<unknown>;\n    19→  needsInput: boolean;\n    20→};\n    21→\n    22→const queryGroups: Record<string, QueryDef[]> = {\n    23→  Search: [\n    24→    { label: \"Full-text Search\", placeholder: \"Search query...\", fn: api.searchCode, needsInput: true },\n    25→    { label: \"Symbol Search\", placeholder: \"Symbol name...\", fn: api.searchSymbols, needsInput: true },\n    26→  ],\n    27→  Analysis: [\n    28→    { label: \"Method Usages\", placeholder: \"Method name...\", fn: api.getMethodUsages, needsInput: true },\n    29→    { label: \"Find Callers\", placeholder: \"Symbol name...\", fn: api.findCallers, needsInput: true },\n    30→    { label: \"Class Hierarchy\", placeholder: \"Class name...\", fn: api.getClassHierarchy, needsInput: true },\n    31→    { label: \"Change Impact\", placeholder: \"Symbol name...\", fn: api.getChangeImpact, needsInput: true },\n    32→  ],\n    33→  CodeFinder: [\n    34→    { label: \"Function\", placeholder: \"Function name...\", fn: api.findFunction, needsInput: true },\n    35→    { label: \"Class\", placeholder: \"Class name...\", fn: api.findClass, needsInput: true },\n    36→    { label: \"Variable\", placeholder: \"Variable name...\", fn: api.findVariable, needsInput: true },\n    37→    { label: \"Content\", placeholder: \"Content query...\", fn: api.findContent, needsInput: true },\n    38→    { label: \"Module\", placeholder: \"Module name...\", fn: api.findModule, needsInput: true },\n    39→    { label: \"Imports\", placeholder: \"Import name...\", fn: api.findImports, needsInput: true },\n    40→  ],\n    41→  Metrics: [\n    42→    { label: \"Graph Stats\", placeholder: \"\", fn: api.getGraphStats, needsInput: false },\n    43→    { label: \"Language Stats\", placeholder: \"\", fn: api.getLanguageStats, needsInput: false },\n    44→    { label: \"Top Complex Functions\", placeholder: \"\", fn: api.getTopComplexFunctions, needsInput: false },\n    45→  ],\n    46→};\n    47→\n    48→export default function QueryPage() {\n    49→  const [input, setInput] = useState(\"\");\n    50→  const [loading, setLoading] = useState(false);\n    51→  const [results, setResults] = useState<unknown>(null);\n    52→  const [activeQuery, setActiveQuery] = useState<string>(\"\");\n    53→\n    54→  // Diff context state\n    55→  const [diffRepoId, setDiffRepoId] = useState(\"\");\n    56→  const [diffChangesText, setDiffChangesText] = useState(\"\");\n    57→  const [diffLoading, setDiffLoading] = useState(false);\n    58→  const [diffResults, setDiffResults] = useState<unknown>(null);\n    59→\n    60→  const runQuery = async (qDef: QueryDef) => {\n    61→    if (qDef.needsInput && !input.trim()) {\n    62→      toast.error(\"Please enter a query\");\n    63→      return;\n    64→    }\n    65→    setLoading(true);\n    66→    setActiveQuery(qDef.label);\n    67→    try {\n    68→      const data = await qDef.fn(input.trim());\n    69→      setResults(data);\n    70→    } catch (e) {\n    71→      toast.error(`Query failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);\n    72→      setResults(null);\n    73→    } finally {\n    74→      setLoading(false);\n    75→    }\n    76→  };\n    77→\n    78→  const runDiffContext = async () => {\n    79→    if (!diffRepoId.trim()) {\n    80→      toast.error(\"Please enter a repository ID\");\n    81→      return;\n    82→    }\n    83→    // Parse changes: one per line, format: file_path:start_line-end_line\n    84→    const lines = diffChangesText.trim().split(\"\\n\").filter(Boolean);\n    85→    const changes = lines.map((line) => {\n    86→      const [filePath, range] = line.split(\":\");\n    87→      if (range) {\n    88→        const [start, end] = range.split(\"-\").map(Number);\n    89→        return { file_path: filePath.trim(), start_line: start || 1, end_line: end || 999999 };\n    90→      }\n    91→      return { file_path: filePath.trim() };\n    92→    });\n    93→\n    94→    if (changes.length === 0) {\n    95→      toast.error(\"Please enter at least one file change\");\n    96→      return;\n    97→    }\n    98→\n    99→    setDiffLoading(true);\n   100→    setDiffResults(null);\n   101→    try {\n   102→      const data = await api.getDiffContext({ repo_id: diffRepoId.trim(), changes });\n   103→      setDiffResults(data);\n   104→    } catch (e) {\n   105→      toast.error(`Diff context failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);\n   106→    } finally {\n   107→      setDiffLoading(false);\n   108→    }\n   109→  };\n   110→\n   111→  return (\n   112→    <div className=\"max-w-5xl mx-auto space-y-6\">\n   113→      <h1 className=\"text-2xl font-bold\">Query</h1>\n   114→\n   115→      <Tabs defaultValue=\"Search\">\n   116→        <TabsList>\n   117→          {Object.keys(queryGroups).map((group) => (\n   118→            <TabsTrigger key={group} value={group}>\n   119→              {group}\n   120→            </TabsTrigger>\n   121→          ))}\n   122→          <TabsTrigger value=\"DiffContext\">Code Review</TabsTrigger>\n   123→        </TabsList>\n   124→\n   125→        {Object.entries(queryGroups).map(([group, queries]) => (\n   126→          <TabsContent key={group} value={group} className=\"space-y-4 pt-4\">\n   127→            <Input\n   128→              placeholder=\"Enter search term or symbol name...\"\n   129→              value={input}\n   130→              onChange={(e) => setInput(e.target.value)}\n   131→              className=\"text-base\"\n   132→              onKeyDown={(e) => {\n   133→                if (e.key === \"Enter\" && activeQuery) {\n   134→                  const allQueries = Object.values(queryGroups).flat();\n   135→                  const q = allQueries.find((q) => q.label === activeQuery);\n   136→                  if (q) runQuery(q);\n   137→                }\n   138→              }}\n   139→            />\n   140→            <div className=\"flex flex-wrap gap-2\">\n   141→              {queries.map((q) => (\n   142→                <Button\n   143→                  key={q.label}\n   144→                  variant={activeQuery === q.label ? \"default\" : \"secondary\"}\n   145→                  size=\"sm\"\n   146→                  onClick={() => runQuery(q)}\n   147→                  disabled={loading}\n   148→                >\n   149→                  {q.label}\n   150→                </Button>\n   151→              ))}\n   152→            </div>\n   153→          </TabsContent>\n   154→        ))}\n   155→\n   156→        <TabsContent value=\"DiffContext\" className=\"space-y-4 pt-4\">\n   157→          <Card>\n   158→            <CardHeader>\n   159→              <CardTitle>Diff Context Builder</CardTitle>\n   160→            </CardHeader>\n   161→            <CardContent className=\"space-y-4\">\n   162→              <p className=\"text-sm text-muted-foreground\">\n   163→                Build RAG context for code review. Provide the repository and changed files\n   164→                to get affected symbols, their callers, class hierarchy, and source code.\n   165→              </p>\n   166→              <div className=\"space-y-2\">\n   167→                <Label>Repository ID</Label>\n   168→                <Input\n   169→                  placeholder=\"owner/repo_name\"\n   170→                  value={diffRepoId}\n   171→                  onChange={(e) => setDiffRepoId(e.target.value)}\n   172→                />\n   173→              </div>\n   174→              <div className=\"space-y-2\">\n   175→                <Label>Changed Files</Label>\n   176→                <Textarea\n   177→                  placeholder={\"One per line — file_path:start_line-end_line\\n\\nExamples:\\nsrc/main.py:10-30\\nsrc/utils.py:1-50\\nREADME.md\"}\n   178→                  value={diffChangesText}\n   179→                  onChange={(e) => setDiffChangesText(e.target.value)}\n   180→                  rows={6}\n   181→                  className=\"font-mono text-sm\"\n   182→                />\n   183→              </div>\n   184→              <Button onClick={runDiffContext} disabled={diffLoading}>\n   185→                {diffLoading ? \"Loading...\" : \"Get Diff Context\"}\n   186→              </Button>\n   187→            </CardContent>\n   188→          </Card>\n   189→\n   190→          {diffResults !== null && (\n   191→            <DiffContextResults data={diffResults as DiffContextData} />\n   192→          )}\n   193→        </TabsContent>\n   194→      </Tabs>\n   195→\n   196→      {/* Standard query results */}\n   197→      {loading && (\n   198→        <Card>\n   199→          <CardContent className=\"py-8 text-center text-muted-foreground\">\n   200→            Loading...\n   201→          </CardContent>\n   202→        </Card>\n   203→      )}\n   204→\n   205→      {!loading && results !== null && activeQuery !== \"\" && (\n   206→        <Card>\n   207→          <CardHeader>\n   208→            <CardTitle className=\"text-sm text-muted-foreground\">\n   209→              Results: {activeQuery}\n   210→            </CardTitle>\n   211→          </CardHeader>\n   212→          <CardContent>\n   213→            <ResultsView data={results} />\n   214→          </CardContent>\n   215→        </Card>\n   216→      )}\n   217→    </div>\n   218→  );\n   219→}\n   220→\n   221→// --- Diff Context Results ---\n   222→\n   223→interface DiffContextData {\n   224→  affected_symbols: {\n   225→    type: string;\n   226→    name: string;\n   227→    start_line: number;\n   228→    end_line: number;\n   229→    source: string | null;\n   230→    docstring: string | null;\n   231→    change_file: string;\n   232→    file_path?: string;\n   233→  }[];\n   234→  callers: {\n   235→    symbol: string;\n   236→    symbol_type: string;\n   237→    callers: { type: string; name: string; path: string; source: string | null }[];\n   238→  }[];\n   239→  class_hierarchy: {\n   240→    class: string;\n   241→    hierarchy: { name: string; path: string; source: string | null }[];\n   242→  }[];\n   243→  file_sources: Record<string, string>;\n   244→  total_affected: number;\n   245→  total_files: number;\n   246→}\n   247→\n   248→function DiffContextResults({ data }: { data: DiffContextData }) {\n   249→  return (\n   250→    <div className=\"space-y-4\">\n   251→      {/* Summary */}\n   252→      <div className=\"flex gap-3\">\n   253→        <Badge variant=\"secondary\">{data.total_files} files</Badge>\n   254→        <Badge variant=\"secondary\">{data.total_affected} affected symbols</Badge>\n   255→        <Badge variant=\"secondary\">{data.callers.length} caller chains</Badge>\n   256→        <Badge variant=\"secondary\">{data.class_hierarchy.length} class hierarchies</Badge>\n   257→      </div>\n   258→\n   259→      {/* Affected Symbols */}\n   260→      {data.affected_symbols.length > 0 && (\n   261→        <Card>\n   262→          <CardHeader>\n   263→            <CardTitle className=\"text-sm\">Affected Symbols</CardTitle>\n   264→          </CardHeader>\n   265→          <CardContent className=\"space-y-2 max-h-[400px] overflow-y-auto\">\n   266→            {data.affected_symbols.map((sym, i) => (\n   267→              <div key={i} className=\"p-3 rounded border border-border space-y-1\">\n   268→                <div className=\"flex items-center gap-2\">\n   269→                  <Badge variant={sym.type === \"function\" ? \"default\" : \"secondary\"}>{sym.type}</Badge>\n   270→                  <span className=\"font-medium font-mono\">{sym.name}</span>\n   271→                  <span className=\"text-xs text-muted-foreground\">\n   272→                    {sym.change_file}:{sym.start_line}-{sym.end_line}\n   273→                  </span>\n   274→                </div>\n   275→                {sym.docstring && (\n   276→                  <p className=\"text-xs text-muted-foreground\">{sym.docstring}</p>\n   277→                )}\n   278→                {sym.source && (\n   279→                  <CodeBlock\n   280→                    code={sym.source}\n   281→                    startLine={sym.start_line}\n   282→                    maxHeight=\"max-h-48\"\n   283→                  />\n   284→                )}\n   285→              </div>\n   286→            ))}\n   287→          </CardContent>\n   288→        </Card>\n   289→      )}\n   290→\n   291→      {/* Callers */}\n   292→      {data.callers.length > 0 && (\n   293→        <Card>\n   294→          <CardHeader>\n   295→            <CardTitle className=\"text-sm\">Callers of Affected Symbols</CardTitle>\n   296→          </CardHeader>\n   297→          <CardContent className=\"space-y-3 max-h-[400px] overflow-y-auto\">\n   298→            {data.callers.map((group, i) => (\n   299→              <div key={i} className=\"space-y-1\">\n   300→                <p className=\"text-sm font-medium\">\n   301→                  <Badge variant=\"outline\" className=\"mr-1\">{group.symbol_type}</Badge>\n   302→                  <span className=\"font-mono\">{group.symbol}</span>\n   303→                  <span className=\"text-muted-foreground ml-1\">called by:</span>\n   304→                </p>\n   305→                {group.callers.map((caller, j) => (\n   306→                  <div key={j} className=\"ml-4 p-2 rounded border border-border text-sm\">\n   307→                    <span className=\"font-mono\">{caller.name}</span>\n   308→                    <span className=\"text-xs text-muted-foreground ml-2\">{caller.path}</span>\n   309→                    {caller.source && (\n   310→                      <CodeBlock\n   311→                        code={caller.source}\n   312→                        maxHeight=\"max-h-32\"\n   313→                        className=\"mt-1\"\n   314→                      />\n   315→                    )}\n   316→                  </div>\n   317→                ))}\n   318→              </div>\n   319→            ))}\n   320→          </CardContent>\n   321→        </Card>\n   322→      )}\n   323→\n   324→      {/* Class Hierarchy */}\n   325→      {data.class_hierarchy.length > 0 && (\n   326→        <Card>\n   327→          <CardHeader>\n   328→            <CardTitle className=\"text-sm\">Class Hierarchy</CardTitle>\n   329→          </CardHeader>\n   330→          <CardContent className=\"space-y-2 max-h-[300px] overflow-y-auto\">\n   331→            {data.class_hierarchy.map((h, i) => (\n   332→              <div key={i} className=\"space-y-1\">\n   333→                <p className=\"text-sm font-medium font-mono\">{h.class}</p>\n   334→                <div className=\"ml-4 space-y-1\">\n   335→                  {h.hierarchy.map((parent, j) => (\n   336→                    <div key={j} className=\"flex items-center gap-2 text-sm\">\n   337→                      <span className=\"text-muted-foreground\">{j === 0 ? \"\" : \"\\u2514\\u2500\"}</span>\n   338→                      <span className=\"font-mono\">{parent.name}</span>\n   339→                      <span className=\"text-xs text-muted-foreground\">{parent.path}</span>\n   340→                    </div>\n   341→                  ))}\n   342→                </div>\n   343→              </div>\n   344→            ))}\n   345→          </CardContent>\n   346→        </Card>\n   347→      )}\n   348→\n   349→      {/* File Sources */}\n   350→      {Object.keys(data.file_sources).length > 0 && (\n   351→        <Card>\n   352→          <CardHeader>\n   353→            <CardTitle className=\"text-sm\">File Sources</CardTitle>\n   354→          </CardHeader>\n   355→          <CardContent className=\"space-y-3 max-h-[400px] overflow-y-auto\">\n   356→            {Object.entries(data.file_sources).map(([path, source]) => (\n   357→              <div key={path} className=\"space-y-1\">\n   358→                <p className=\"text-sm font-mono text-primary\">{path}</p>\n   359→                <CodeBlock code={source} maxHeight=\"max-h-64\" />\n   360→              </div>\n   361→            ))}\n   362→          </CardContent>\n   363→        </Card>\n   364→      )}\n   365→    </div>\n   366→  );\n   367→}\n   368→\n   369→// --- Generic Results ---\n   370→\n   371→function ResultsView({ data }: { data: unknown }) {\n   372→  if (data === null || data === undefined) {\n   373→    return <p className=\"text-muted-foreground\">No results</p>;\n   374→  }\n   375→\n   376→  if (Array.isArray(data)) {\n   377→    if (data.length === 0) return <p className=\"text-muted-foreground\">No results found</p>;\n   378→    return (\n   379→      <div className=\"space-y-2 max-h-[600px] overflow-y-auto\">\n   380→        {data.map((item, i) => (\n   381→          <div key={i} className=\"p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n   382→            {typeof item === \"object\" ? <ObjectView obj={item} /> : String(item)}\n   383→          </div>\n   384→        ))}\n   385→      </div>\n   386→    );\n   387→  }\n   388→\n   389→  if (typeof data === \"object\") {\n   390→    return <ObjectView obj={data as Record<string, unknown>} />;\n   391→  }\n   392→\n   393→  return <pre className=\"text-sm font-mono\">{String(data)}</pre>;\n   394→}\n   395→\n   396→function ObjectView({ obj }: { obj: Record<string, unknown> }) {\n   397→  return (\n   398→    <div className=\"space-y-1\">\n   399→      {Object.entries(obj).map(([key, value]) => {\n   400→        // Render source code fields with CodeBlock\n   401→        if (key === \"source\" && typeof value === \"string\" && value) {\n   402→          const startLine = (obj.line_number as number) || (obj.start_line as number) || 1;\n   403→          return (\n   404→            <div key={key} className=\"space-y-1\">\n   405→              <span className=\"text-primary font-medium\">{key}:</span>\n   406→              <CodeBlock code={value} startLine={startLine} maxHeight=\"max-h-64\" />\n   407→            </div>\n   408→          );\n   409→        }\n   410→\n   411→        // Render nested arrays recursively\n   412→        if (Array.isArray(value)) {\n   413→          if (value.length === 0) {\n   414→            return (\n   415→              <div key={key} className=\"flex gap-2\">\n   416→                <span className=\"text-primary font-medium shrink-0\">{key}:</span>\n   417→                <span className=\"text-muted-foreground\">[]</span>\n   418→              </div>\n   419→            );\n   420→          }\n   421→          return (\n   422→            <div key={key} className=\"space-y-1\">\n   423→              <span className=\"text-primary font-medium\">{key}:</span>\n   424→              <div className=\"ml-4 space-y-2\">\n   425→                {value.map((item, i) => (\n   426→                  <div key={i} className=\"p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n   427→                    {typeof item === \"object\" && item !== null\n   428→                      ? <ObjectView obj={item as Record<string, unknown>} />\n   429→                      : String(item)}\n   430→                  </div>\n   431→                ))}\n   432→              </div>\n   433→            </div>\n   434→          );\n   435→        }\n   436→\n   437→        // Render nested objects recursively\n   438→        if (typeof value === \"object\" && value !== null) {\n   439→          return (\n   440→            <div key={key} className=\"space-y-1\">\n   441→              <span className=\"text-primary font-medium\">{key}:</span>\n   442→              <div className=\"ml-4 p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n   443→                <ObjectView obj={value as Record<string, unknown>} />\n   444→              </div>\n   445→            </div>\n   446→          );\n   447→        }\n   448→\n   449→        return (\n   450→          <div key={key} className=\"flex gap-2\">\n   451→            <span className=\"text-primary font-medium shrink-0\">{key}:</span>\n   452→            <span className=\"text-muted-foreground break-all\">\n   453→              {String(value ?? \"\\u2014\")}\n   454→            </span>\n   455→          </div>\n   456→        );\n   457→      })}\n   458→    </div>\n   459→  );\n   460→}\n   461→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"67b14368-310e-460f-b6f1-76081ff474b6","timestamp":"2026-02-21T08:06:27.970Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/frontend/app/(protected)/query/page.tsx","content":"\"use client\";\n\nimport { useState } from \"react\";\nimport { Card, CardContent, CardHeader, CardTitle } from \"@/components/ui/card\";\nimport { Button } from \"@/components/ui/button\";\nimport { Input } from \"@/components/ui/input\";\nimport { Label } from \"@/components/ui/label\";\nimport { Textarea } from \"@/components/ui/textarea\";\nimport { Tabs, TabsContent, TabsList, TabsTrigger } from \"@/components/ui/tabs\";\nimport { Badge } from \"@/components/ui/badge\";\nimport { CodeBlock } from \"@/components/ui/code-block\";\nimport { toast } from \"sonner\";\nimport * as api from \"@/lib/api\";\n\ntype QueryDef = {\n  label: string;\n  placeholder: string;\n  fn: (q: string) => Promise<unknown>;\n  needsInput: boolean;\n};\n\nconst queryGroups: Record<string, QueryDef[]> = {\n  Search: [\n    { label: \"Full-text Search\", placeholder: \"Search query...\", fn: api.searchCode, needsInput: true },\n    { label: \"Symbol Search\", placeholder: \"Symbol name...\", fn: api.searchSymbols, needsInput: true },\n  ],\n  Analysis: [\n    { label: \"Method Usages\", placeholder: \"Method name...\", fn: api.getMethodUsages, needsInput: true },\n    { label: \"Find Callers\", placeholder: \"Symbol name...\", fn: api.findCallers, needsInput: true },\n    { label: \"Class Hierarchy\", placeholder: \"Class name...\", fn: api.getClassHierarchy, needsInput: true },\n    { label: \"Change Impact\", placeholder: \"Symbol name...\", fn: api.getChangeImpact, needsInput: true },\n  ],\n  CodeFinder: [\n    { label: \"Function\", placeholder: \"Function name...\", fn: api.findFunction, needsInput: true },\n    { label: \"Class\", placeholder: \"Class name...\", fn: api.findClass, needsInput: true },\n    { label: \"Variable\", placeholder: \"Variable name...\", fn: api.findVariable, needsInput: true },\n    { label: \"Content\", placeholder: \"Content query...\", fn: api.findContent, needsInput: true },\n    { label: \"Module\", placeholder: \"Module name...\", fn: api.findModule, needsInput: true },\n    { label: \"Imports\", placeholder: \"Import name...\", fn: api.findImports, needsInput: true },\n  ],\n  Metrics: [\n    { label: \"Graph Stats\", placeholder: \"\", fn: api.getGraphStats, needsInput: false },\n    { label: \"Language Stats\", placeholder: \"\", fn: api.getLanguageStats, needsInput: false },\n    { label: \"Top Complex Functions\", placeholder: \"\", fn: api.getTopComplexFunctions, needsInput: false },\n  ],\n};\n\nexport default function QueryPage() {\n  const [input, setInput] = useState(\"\");\n  const [loading, setLoading] = useState(false);\n  const [results, setResults] = useState<unknown>(null);\n  const [activeQuery, setActiveQuery] = useState<string>(\"\");\n\n  // Diff context state\n  const [diffRepoId, setDiffRepoId] = useState(\"\");\n  const [diffChangesText, setDiffChangesText] = useState(\"\");\n  const [diffLoading, setDiffLoading] = useState(false);\n  const [diffResults, setDiffResults] = useState<unknown>(null);\n\n  const runQuery = async (qDef: QueryDef) => {\n    if (qDef.needsInput && !input.trim()) {\n      toast.error(\"Please enter a query\");\n      return;\n    }\n    setLoading(true);\n    setActiveQuery(qDef.label);\n    try {\n      const data = await qDef.fn(input.trim());\n      setResults(data);\n    } catch (e) {\n      toast.error(`Query failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);\n      setResults(null);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  const runDiffContext = async () => {\n    if (!diffRepoId.trim()) {\n      toast.error(\"Please enter a repository ID\");\n      return;\n    }\n    // Parse changes: one per line, format: file_path:start_line-end_line\n    const lines = diffChangesText.trim().split(\"\\n\").filter(Boolean);\n    const changes = lines.map((line) => {\n      const [filePath, range] = line.split(\":\");\n      if (range) {\n        const [start, end] = range.split(\"-\").map(Number);\n        return { file_path: filePath.trim(), start_line: start || 1, end_line: end || 999999 };\n      }\n      return { file_path: filePath.trim() };\n    });\n\n    if (changes.length === 0) {\n      toast.error(\"Please enter at least one file change\");\n      return;\n    }\n\n    setDiffLoading(true);\n    setDiffResults(null);\n    try {\n      const data = await api.getDiffContext({ repo_id: diffRepoId.trim(), changes });\n      setDiffResults(data);\n    } catch (e) {\n      toast.error(`Diff context failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);\n    } finally {\n      setDiffLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"max-w-5xl mx-auto space-y-6\">\n      <h1 className=\"text-2xl font-bold\">Query</h1>\n\n      <Tabs defaultValue=\"Search\">\n        <TabsList>\n          {Object.keys(queryGroups).map((group) => (\n            <TabsTrigger key={group} value={group}>\n              {group}\n            </TabsTrigger>\n          ))}\n          <TabsTrigger value=\"DiffContext\">Code Review</TabsTrigger>\n        </TabsList>\n\n        {Object.entries(queryGroups).map(([group, queries]) => (\n          <TabsContent key={group} value={group} className=\"space-y-4 pt-4\">\n            <Input\n              placeholder=\"Enter search term or symbol name...\"\n              value={input}\n              onChange={(e) => setInput(e.target.value)}\n              className=\"text-base\"\n              onKeyDown={(e) => {\n                if (e.key === \"Enter\" && activeQuery) {\n                  const allQueries = Object.values(queryGroups).flat();\n                  const q = allQueries.find((q) => q.label === activeQuery);\n                  if (q) runQuery(q);\n                }\n              }}\n            />\n            <div className=\"flex flex-wrap gap-2\">\n              {queries.map((q) => (\n                <Button\n                  key={q.label}\n                  variant={activeQuery === q.label ? \"default\" : \"secondary\"}\n                  size=\"sm\"\n                  onClick={() => runQuery(q)}\n                  disabled={loading}\n                >\n                  {q.label}\n                </Button>\n              ))}\n            </div>\n          </TabsContent>\n        ))}\n\n        <TabsContent value=\"DiffContext\" className=\"space-y-4 pt-4\">\n          <Card>\n            <CardHeader>\n              <CardTitle>Diff Context Builder</CardTitle>\n            </CardHeader>\n            <CardContent className=\"space-y-4\">\n              <p className=\"text-sm text-muted-foreground\">\n                Build RAG context for code review. Provide the repository and changed files\n                to get affected symbols, their callers, class hierarchy, and source code.\n              </p>\n              <div className=\"space-y-2\">\n                <Label>Repository ID</Label>\n                <Input\n                  placeholder=\"owner/repo_name\"\n                  value={diffRepoId}\n                  onChange={(e) => setDiffRepoId(e.target.value)}\n                />\n              </div>\n              <div className=\"space-y-2\">\n                <Label>Changed Files</Label>\n                <Textarea\n                  placeholder={\"One per line — file_path:start_line-end_line\\n\\nExamples:\\nsrc/main.py:10-30\\nsrc/utils.py:1-50\\nREADME.md\"}\n                  value={diffChangesText}\n                  onChange={(e) => setDiffChangesText(e.target.value)}\n                  rows={6}\n                  className=\"font-mono text-sm\"\n                />\n              </div>\n              <Button onClick={runDiffContext} disabled={diffLoading}>\n                {diffLoading ? \"Loading...\" : \"Get Diff Context\"}\n              </Button>\n            </CardContent>\n          </Card>\n\n          {diffResults !== null && (\n            <DiffContextResults data={diffResults as DiffContextData} />\n          )}\n        </TabsContent>\n      </Tabs>\n\n      {/* Standard query results */}\n      {loading && (\n        <Card>\n          <CardContent className=\"py-8 text-center text-muted-foreground\">\n            Loading...\n          </CardContent>\n        </Card>\n      )}\n\n      {!loading && results !== null && activeQuery !== \"\" && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm text-muted-foreground\">\n              Results: {activeQuery}\n            </CardTitle>\n          </CardHeader>\n          <CardContent>\n            <ResultsView data={results} />\n          </CardContent>\n        </Card>\n      )}\n    </div>\n  );\n}\n\n// --- Diff Context Results ---\n\ninterface DiffContextData {\n  affected_symbols: {\n    type: string;\n    name: string;\n    start_line: number;\n    end_line: number;\n    source: string | null;\n    docstring: string | null;\n    change_file: string;\n    file_path?: string;\n  }[];\n  callers: {\n    symbol: string;\n    symbol_type: string;\n    callers: { type: string; name: string; path: string; source: string | null }[];\n  }[];\n  class_hierarchy: {\n    class: string;\n    hierarchy: { name: string; path: string; source: string | null }[];\n  }[];\n  file_sources: Record<string, string>;\n  total_affected: number;\n  total_files: number;\n}\n\nfunction DiffContextResults({ data }: { data: DiffContextData }) {\n  return (\n    <div className=\"space-y-4\">\n      {/* Summary */}\n      <div className=\"flex gap-3\">\n        <Badge variant=\"secondary\">{data.total_files} files</Badge>\n        <Badge variant=\"secondary\">{data.total_affected} affected symbols</Badge>\n        <Badge variant=\"secondary\">{data.callers.length} caller chains</Badge>\n        <Badge variant=\"secondary\">{data.class_hierarchy.length} class hierarchies</Badge>\n      </div>\n\n      {/* Affected Symbols */}\n      {data.affected_symbols.length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">Affected Symbols</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-2 max-h-[400px] overflow-y-auto\">\n            {data.affected_symbols.map((sym, i) => (\n              <div key={i} className=\"p-3 rounded border border-border space-y-1\">\n                <div className=\"flex items-center gap-2\">\n                  <Badge variant={sym.type === \"function\" ? \"default\" : \"secondary\"}>{sym.type}</Badge>\n                  <span className=\"font-medium font-mono\">{sym.name}</span>\n                  <span className=\"text-xs text-muted-foreground\">\n                    {sym.change_file}:{sym.start_line}-{sym.end_line}\n                  </span>\n                </div>\n                {sym.docstring && (\n                  <p className=\"text-xs text-muted-foreground\">{sym.docstring}</p>\n                )}\n                {sym.source && (\n                  <CodeBlock\n                    code={sym.source}\n                    startLine={sym.start_line}\n                    maxHeight=\"max-h-48\"\n                  />\n                )}\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {/* Callers */}\n      {data.callers.length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">Callers of Affected Symbols</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-3 max-h-[400px] overflow-y-auto\">\n            {data.callers.map((group, i) => (\n              <div key={i} className=\"space-y-1\">\n                <p className=\"text-sm font-medium\">\n                  <Badge variant=\"outline\" className=\"mr-1\">{group.symbol_type}</Badge>\n                  <span className=\"font-mono\">{group.symbol}</span>\n                  <span className=\"text-muted-foreground ml-1\">called by:</span>\n                </p>\n                {group.callers.map((caller, j) => (\n                  <div key={j} className=\"ml-4 p-2 rounded border border-border text-sm\">\n                    <span className=\"font-mono\">{caller.name}</span>\n                    <span className=\"text-xs text-muted-foreground ml-2\">{caller.path}</span>\n                    {caller.source && (\n                      <CodeBlock\n                        code={caller.source}\n                        maxHeight=\"max-h-32\"\n                        className=\"mt-1\"\n                      />\n                    )}\n                  </div>\n                ))}\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {/* Class Hierarchy */}\n      {data.class_hierarchy.length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">Class Hierarchy</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-2 max-h-[300px] overflow-y-auto\">\n            {data.class_hierarchy.map((h, i) => (\n              <div key={i} className=\"space-y-1\">\n                <p className=\"text-sm font-medium font-mono\">{h.class}</p>\n                <div className=\"ml-4 space-y-1\">\n                  {h.hierarchy.map((parent, j) => (\n                    <div key={j} className=\"flex items-center gap-2 text-sm\">\n                      <span className=\"text-muted-foreground\">{j === 0 ? \"\" : \"\\u2514\\u2500\"}</span>\n                      <span className=\"font-mono\">{parent.name}</span>\n                      <span className=\"text-xs text-muted-foreground\">{parent.path}</span>\n                    </div>\n                  ))}\n                </div>\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {/* File Sources */}\n      {Object.keys(data.file_sources).length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">File Sources</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-3 max-h-[400px] overflow-y-auto\">\n            {Object.entries(data.file_sources).map(([path, source]) => (\n              <div key={path} className=\"space-y-1\">\n                <p className=\"text-sm font-mono text-primary\">{path}</p>\n                <CodeBlock code={source} maxHeight=\"max-h-64\" />\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n    </div>\n  );\n}\n\n// --- Generic Results ---\n\nfunction ResultsView({ data }: { data: unknown }) {\n  if (data === null || data === undefined) {\n    return <p className=\"text-muted-foreground\">No results</p>;\n  }\n\n  if (Array.isArray(data)) {\n    if (data.length === 0) return <p className=\"text-muted-foreground\">No results found</p>;\n    return (\n      <div className=\"space-y-2 max-h-[600px] overflow-y-auto\">\n        {data.map((item, i) => (\n          <div key={i} className=\"p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n            {typeof item === \"object\" ? <ObjectView obj={item} /> : String(item)}\n          </div>\n        ))}\n      </div>\n    );\n  }\n\n  if (typeof data === \"object\") {\n    return <ObjectView obj={data as Record<string, unknown>} />;\n  }\n\n  return <pre className=\"text-sm font-mono\">{String(data)}</pre>;\n}\n\nfunction ObjectView({ obj }: { obj: Record<string, unknown> }) {\n  return (\n    <div className=\"space-y-1\">\n      {Object.entries(obj).map(([key, value]) => {\n        // Render source code fields with CodeBlock\n        if (key === \"source\" && typeof value === \"string\" && value) {\n          const startLine = (obj.line_number as number) || (obj.start_line as number) || 1;\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <CodeBlock code={value} startLine={startLine} maxHeight=\"max-h-64\" />\n            </div>\n          );\n        }\n\n        // Render nested arrays recursively\n        if (Array.isArray(value)) {\n          if (value.length === 0) {\n            return (\n              <div key={key} className=\"flex gap-2\">\n                <span className=\"text-primary font-medium shrink-0\">{key}:</span>\n                <span className=\"text-muted-foreground\">[]</span>\n              </div>\n            );\n          }\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <div className=\"ml-4 space-y-2\">\n                {value.map((item, i) => (\n                  <div key={i} className=\"p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n                    {typeof item === \"object\" && item !== null\n                      ? <ObjectView obj={item as Record<string, unknown>} />\n                      : String(item)}\n                  </div>\n                ))}\n              </div>\n            </div>\n          );\n        }\n\n        // Render nested objects recursively\n        if (typeof value === \"object\" && value !== null) {\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <div className=\"ml-4 p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n                <ObjectView obj={value as Record<string, unknown>} />\n              </div>\n            </div>\n          );\n        }\n\n        return (\n          <div key={key} className=\"flex gap-2\">\n            <span className=\"text-primary font-medium shrink-0\">{key}:</span>\n            <span className=\"text-muted-foreground break-all\">\n              {String(value ?? \"\\u2014\")}\n            </span>\n          </div>\n        );\n      })}\n    </div>\n  );\n}\n","numLines":461,"startLine":1,"totalLines":461}},"sourceToolAssistantUUID":"d229f269-2631-4bab-a867-067a2d9460fe"}
{"parentUuid":"67b14368-310e-460f-b6f1-76081ff474b6","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_013zYaew4TP5KnNsJG6254T2","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I have a full picture of the issues. Let me also check the API client to understand the existing endpoints.\n\nLet me look at `frontend/lib/api.ts` to understand how search is currently called.","signature":"EuoCCkYICxgCKkAodTAHtL8UAoLd3CqW8dUnBiX+7ZOHaIDkiVNErtPl46NiUon7PYk5LPeiStfR8ob5Y5POUKzX0vZ46h46iWGMEgw+7ZDnADxQ1VipxYAaDKyeioIf6L0sqzbe2CIwL7oF08mYc4TD/gbQ4Gsmi5ScwsLgPCDG2kT/gDeyurIbmdL0/zdAaEM8czztolBDKtEBSS94ovkhCJ3TbscrEm2cBCkkfEYky4eyQQU9Lwcl/B5bre6aLNa5ljewWttjaiaTKQ8a4E5mPA1yVtyfhH+ruYfGJr1upgNKPgccfp5ChK6lkh1CKx+F2cknnh/QIYDNScZBWsXJBvYefvtAkcDdDghcbeJvSw5igcir8oHMVm397jilSFBpYUUOIwLrP/4CFoViDjEC0n9DdruNvVsaY/CpburFc2ZTmnXaLfcDN9cJxGpa5N+HJ5B4IGs1clt0die1glzZMYYwuGt6uTWlytcYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":6563,"cache_read_input_tokens":69546,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":6563},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsQSW2woFYmZ91iS4gP","type":"assistant","uuid":"48cbb068-d376-4446-ada3-802acdc2c703","timestamp":"2026-02-21T08:06:30.647Z"}
{"parentUuid":"48cbb068-d376-4446-ada3-802acdc2c703","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_013zYaew4TP5KnNsJG6254T2","type":"message","role":"assistant","content":[{"type":"text","text":"Let me check the frontend API client."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":6563,"cache_read_input_tokens":69546,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":6563},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsQSW2woFYmZ91iS4gP","type":"assistant","uuid":"8788e73f-3011-462d-ba58-c723d36ed194","timestamp":"2026-02-21T08:06:30.955Z"}
{"parentUuid":"8788e73f-3011-462d-ba58-c723d36ed194","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_013zYaew4TP5KnNsJG6254T2","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011RiX8ziS4Fen5tWyYsion5","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/frontend/lib/api.ts"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":6563,"cache_read_input_tokens":69546,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":6563},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsQSW2woFYmZ91iS4gP","type":"assistant","uuid":"9a5559af-f182-45c5-8681-cddb7da8894d","timestamp":"2026-02-21T08:06:31.673Z"}
{"parentUuid":"9a5559af-f182-45c5-8681-cddb7da8894d","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_011RiX8ziS4Fen5tWyYsion5","toolUseID":"toolu_011RiX8ziS4Fen5tWyYsion5","timestamp":"2026-02-21T08:06:31.700Z","uuid":"a304176c-048d-4847-88ab-1733de2fb6a6"}
{"parentUuid":"9a5559af-f182-45c5-8681-cddb7da8894d","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011RiX8ziS4Fen5tWyYsion5","type":"tool_result","content":"     1→const API_BASE = process.env.NEXT_PUBLIC_API_URL || \"http://localhost:8000\";\n     2→\n     3→// Auth token injection\n     4→let tokenGetter: (() => Promise<string | null>) | null = null;\n     5→\n     6→export function setTokenGetter(getter: () => Promise<string | null>) {\n     7→  tokenGetter = getter;\n     8→}\n     9→\n    10→// Type definitions for repository statistics\n    11→export interface RepositoryStatistics {\n    12→  files: number;\n    13→  classes: number;\n    14→  functions: number;\n    15→  methods: number;\n    16→  lines: number;\n    17→  imports: number;\n    18→  languages: string[];\n    19→}\n    20→\n    21→export interface RepositoryStatsResponse {\n    22→  repository_id: string;\n    23→  statistics: RepositoryStatistics;\n    24→}\n    25→\n    26→export interface GitHubRepo {\n    27→  name: string;\n    28→  full_name: string;\n    29→  description: string | null;\n    30→  language: string | null;\n    31→  stargazers_count: number;\n    32→  private: boolean;\n    33→  default_branch: string;\n    34→  html_url: string;\n    35→}\n    36→\n    37→async function apiFetch(path: string, options?: RequestInit) {\n    38→  const headers: Record<string, string> = {\n    39→    \"Content-Type\": \"application/json\",\n    40→    ...(options?.headers as Record<string, string>),\n    41→  };\n    42→\n    43→  if (tokenGetter) {\n    44→    const token = await tokenGetter();\n    45→    if (token) {\n    46→      headers[\"Authorization\"] = `Bearer ${token}`;\n    47→    }\n    48→  }\n    49→\n    50→  const res = await fetch(`${API_BASE}${path}`, {\n    51→    ...options,\n    52→    headers,\n    53→  });\n    54→  if (!res.ok) {\n    55→    const text = await res.text();\n    56→    throw new Error(text || `API error: ${res.status}`);\n    57→  }\n    58→  return res.json();\n    59→}\n    60→\n    61→// Repositories\n    62→export const listRepositories = () => apiFetch(\"/api/v1/repos/\");\n    63→export const deleteRepository = (id: string) =>\n    64→  apiFetch(`/api/v1/repos/${id}`, { method: \"DELETE\" });\n    65→export const getRepositoryStats = (owner: string, repoName: string) =>\n    66→  apiFetch(`/api/v1/repos/${owner}/${repoName}/stats`);\n    67→\n    68→// Ingestion\n    69→export interface IngestionJobResponse {\n    70→  job_id: string;\n    71→  status: string;\n    72→  message: string;\n    73→  poll_url: string;\n    74→}\n    75→\n    76→export interface JobStatusResponse {\n    77→  job_id: string;\n    78→  owner: string;\n    79→  repo_name: string;\n    80→  branch: string | null;\n    81→  status: string;\n    82→  created_at: string;\n    83→  updated_at: string;\n    84→  started_at: string | null;\n    85→  completed_at: string | null;\n    86→  stats: {\n    87→    files_processed: number;\n    88→    files_skipped: number;\n    89→    classes_found: number;\n    90→    functions_found: number;\n    91→    imports_found: number;\n    92→    total_lines: number;\n    93→    errors: string[];\n    94→  } | null;\n    95→  error_message: string | null;\n    96→}\n    97→\n    98→export const ingestGithub = (data: {\n    99→  owner: string;\n   100→  repo_name: string;\n   101→  branch?: string;\n   102→  clear_existing?: boolean;\n   103→}): Promise<IngestionJobResponse> =>\n   104→  apiFetch(\"/api/v1/ingest/github\", { method: \"POST\", body: JSON.stringify(data) });\n   105→\n   106→export const getIngestionJobStatus = (jobId: string): Promise<JobStatusResponse> =>\n   107→  apiFetch(`/api/v1/ingest/jobs/${jobId}`);\n   108→\n   109→export const listIngestionJobs = (): Promise<JobStatusResponse[]> =>\n   110→  apiFetch(\"/api/v1/ingest/jobs\");\n   111→\n   112→export const ingestRepository = (data: {\n   113→  repo_url: string;\n   114→  username: string;\n   115→  repo_name: string;\n   116→  clear_existing?: boolean;\n   117→}) => apiFetch(\"/api/v1/ingest/repository\", { method: \"POST\", body: JSON.stringify(data) });\n   118→\n   119→// Query - Search\n   120→export const searchCode = (query: string) =>\n   121→  apiFetch(`/api/v1/query/search?query=${encodeURIComponent(query)}`);\n   122→export const searchSymbols = (query: string) =>\n   123→  apiFetch(`/api/v1/query/search-symbols?query=${encodeURIComponent(query)}`);\n   124→\n   125→// Query - Analysis\n   126→export const getMethodUsages = (name: string) =>\n   127→  apiFetch(`/api/v1/query/method-usages?method_name=${encodeURIComponent(name)}`);\n   128→export const findCallers = (name: string) =>\n   129→  apiFetch(`/api/v1/query/find_callers?symbol_name=${encodeURIComponent(name)}`);\n   130→export const getClassHierarchy = (name: string) =>\n   131→  apiFetch(`/api/v1/query/class_hierarchy?class_name=${encodeURIComponent(name)}`);\n   132→export const getChangeImpact = (name: string) =>\n   133→  apiFetch(`/api/v1/query/change_impact?symbol_name=${encodeURIComponent(name)}`);\n   134→\n   135→// Query - CodeFinder\n   136→export const findFunction = (name: string) =>\n   137→  apiFetch(`/api/v1/query/code-finder/function?name=${encodeURIComponent(name)}`);\n   138→export const findClass = (name: string) =>\n   139→  apiFetch(`/api/v1/query/code-finder/class?name=${encodeURIComponent(name)}`);\n   140→export const findVariable = (name: string) =>\n   141→  apiFetch(`/api/v1/query/code-finder/variable?name=${encodeURIComponent(name)}`);\n   142→export const findContent = (query: string) =>\n   143→  apiFetch(`/api/v1/query/code-finder/content?query=${encodeURIComponent(query)}`);\n   144→export const findModule = (name: string) =>\n   145→  apiFetch(`/api/v1/query/code-finder/module?name=${encodeURIComponent(name)}`);\n   146→export const findImports = (name: string) =>\n   147→  apiFetch(`/api/v1/query/code-finder/imports?name=${encodeURIComponent(name)}`);\n   148→export const findByLine = (query: string) =>\n   149→  apiFetch(`/api/v1/query/code-finder/line?query=${encodeURIComponent(query)}`);\n   150→export const peekFileLines = (path: string, line: number, above: number, below: number) =>\n   151→  apiFetch(`/api/v1/query/code-finder/peek?path=${encodeURIComponent(path)}&line=${line}&above=${above}&below=${below}`);\n   152→\n   153→// Query - Metrics\n   154→export const getGraphStats = () => apiFetch(\"/api/v1/query/stats\");\n   155→export const getLanguageStats = () => apiFetch(\"/api/v1/query/language/stats\");\n   156→export const getTopComplexFunctions = () =>\n   157→  apiFetch(\"/api/v1/query/code-finder/complexity/top\");\n   158→\n   159→// Query - Code Review / Diff Context\n   160→export const getSymbolsAtLines = (repoId: string, filePath: string, startLine: number, endLine: number) =>\n   161→  apiFetch(`/api/v1/query/symbols-at-lines-relative?repo_id=${encodeURIComponent(repoId)}&file_path=${encodeURIComponent(filePath)}&start_line=${startLine}&end_line=${endLine}`);\n   162→\n   163→export const getDiffContext = (data: {\n   164→  repo_id: string;\n   165→  changes: { file_path: string; start_line?: number; end_line?: number }[];\n   166→}) => apiFetch(\"/api/v1/query/diff-context\", { method: \"POST\", body: JSON.stringify(data) });\n   167→\n   168→export const getFileSource = (repoId: string, filePath: string) =>\n   169→  apiFetch(`/api/v1/query/file-source?repo_id=${encodeURIComponent(repoId)}&file_path=${encodeURIComponent(filePath)}`);\n   170→\n   171→// Auth\n   172→export const loginUser = (data: { github_access_token: string }) =>\n   173→  apiFetch(\"/api/v1/auth/login\", { method: \"POST\", body: JSON.stringify(data) });\n   174→\n   175→export const ensureUser = () =>\n   176→  apiFetch(\"/api/v1/auth/ensure\", { method: \"POST\" });\n   177→\n   178→export const getCurrentUser = () => apiFetch(\"/api/v1/auth/me\");\n   179→\n   180→export const getGitHubRepos = (): Promise<GitHubRepo[]> =>\n   181→  apiFetch(\"/api/v1/auth/github/repos\");\n   182→\n   183→// Additional query functions\n   184→export const getComplexity = (functionName: string, path?: string) => {\n   185→  const params = new URLSearchParams({ function_name: functionName });\n   186→  if (path) params.set(\"path\", path);\n   187→  return apiFetch(`/api/v1/query/code-finder/complexity?${params}`);\n   188→};\n   189→\n   190→export const findRelatedCode = (query: string, fuzzy = false, depth = 2) =>\n   191→  apiFetch(\n   192→    `/api/v1/query/code-finder/content?query=${encodeURIComponent(query)}&fuzzy=${fuzzy}&depth=${depth}`\n   193→  );\n   194→\n   195→export const getLanguageSymbols = (language: string, symbolType: string, limit = 50) =>\n   196→  apiFetch(\n   197→    `/api/v1/query/language/symbols?language=${encodeURIComponent(language)}&symbol_type=${encodeURIComponent(symbolType)}&limit=${limit}`\n   198→  );\n   199→\n   200→export const findDefinition = (symbolName: string, repoId: string) =>\n   201→  apiFetch(\n   202→    `/api/v1/query/search-symbols?query=${encodeURIComponent(symbolName)}&repo_id=${encodeURIComponent(repoId)}`\n   203→  );\n   204→\n   205→export const findMethodUsages = (methodName: string) =>\n   206→  apiFetch(`/api/v1/query/method-usages?method_name=${encodeURIComponent(methodName)}`);\n   207→\n   208→export const getFileStructure = (repoId: string, filePath: string) =>\n   209→  apiFetch(\n   210→    `/api/v1/query/file-source?repo_id=${encodeURIComponent(repoId)}&file_path=${encodeURIComponent(filePath)}`\n   211→  );\n   212→\n   213→export const analyzeRelationships = (queryType: string, target: string, context?: string) => {\n   214→  const params = new URLSearchParams({ symbol_name: target });\n   215→  if (context) params.set(\"context\", context);\n   216→  const endpoint =\n   217→    queryType === \"class_hierarchy\"\n   218→      ? `/api/v1/query/class_hierarchy?class_name=${encodeURIComponent(target)}`\n   219→      : queryType === \"change_impact\"\n   220→      ? `/api/v1/query/change_impact?symbol_name=${encodeURIComponent(target)}`\n   221→      : `/api/v1/query/find_callers?symbol_name=${encodeURIComponent(target)}&query_type=${encodeURIComponent(queryType)}`;\n   222→  return apiFetch(endpoint);\n   223→};\n   224→\n   225→// Default export for direct api.X() usage in components\n   226→const api = {\n   227→  findMethodUsages,\n   228→  getFileStructure,\n   229→  analyzeRelationships,\n   230→  findDefinition,\n   231→  getComplexity,\n   232→  findRelatedCode,\n   233→  getLanguageSymbols,\n   234→};\n   235→\n   236→export default api;\n   237→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"8e8232db-f5ba-4746-9a83-49ecf57fde55","timestamp":"2026-02-21T08:06:31.699Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/frontend/lib/api.ts","content":"const API_BASE = process.env.NEXT_PUBLIC_API_URL || \"http://localhost:8000\";\n\n// Auth token injection\nlet tokenGetter: (() => Promise<string | null>) | null = null;\n\nexport function setTokenGetter(getter: () => Promise<string | null>) {\n  tokenGetter = getter;\n}\n\n// Type definitions for repository statistics\nexport interface RepositoryStatistics {\n  files: number;\n  classes: number;\n  functions: number;\n  methods: number;\n  lines: number;\n  imports: number;\n  languages: string[];\n}\n\nexport interface RepositoryStatsResponse {\n  repository_id: string;\n  statistics: RepositoryStatistics;\n}\n\nexport interface GitHubRepo {\n  name: string;\n  full_name: string;\n  description: string | null;\n  language: string | null;\n  stargazers_count: number;\n  private: boolean;\n  default_branch: string;\n  html_url: string;\n}\n\nasync function apiFetch(path: string, options?: RequestInit) {\n  const headers: Record<string, string> = {\n    \"Content-Type\": \"application/json\",\n    ...(options?.headers as Record<string, string>),\n  };\n\n  if (tokenGetter) {\n    const token = await tokenGetter();\n    if (token) {\n      headers[\"Authorization\"] = `Bearer ${token}`;\n    }\n  }\n\n  const res = await fetch(`${API_BASE}${path}`, {\n    ...options,\n    headers,\n  });\n  if (!res.ok) {\n    const text = await res.text();\n    throw new Error(text || `API error: ${res.status}`);\n  }\n  return res.json();\n}\n\n// Repositories\nexport const listRepositories = () => apiFetch(\"/api/v1/repos/\");\nexport const deleteRepository = (id: string) =>\n  apiFetch(`/api/v1/repos/${id}`, { method: \"DELETE\" });\nexport const getRepositoryStats = (owner: string, repoName: string) =>\n  apiFetch(`/api/v1/repos/${owner}/${repoName}/stats`);\n\n// Ingestion\nexport interface IngestionJobResponse {\n  job_id: string;\n  status: string;\n  message: string;\n  poll_url: string;\n}\n\nexport interface JobStatusResponse {\n  job_id: string;\n  owner: string;\n  repo_name: string;\n  branch: string | null;\n  status: string;\n  created_at: string;\n  updated_at: string;\n  started_at: string | null;\n  completed_at: string | null;\n  stats: {\n    files_processed: number;\n    files_skipped: number;\n    classes_found: number;\n    functions_found: number;\n    imports_found: number;\n    total_lines: number;\n    errors: string[];\n  } | null;\n  error_message: string | null;\n}\n\nexport const ingestGithub = (data: {\n  owner: string;\n  repo_name: string;\n  branch?: string;\n  clear_existing?: boolean;\n}): Promise<IngestionJobResponse> =>\n  apiFetch(\"/api/v1/ingest/github\", { method: \"POST\", body: JSON.stringify(data) });\n\nexport const getIngestionJobStatus = (jobId: string): Promise<JobStatusResponse> =>\n  apiFetch(`/api/v1/ingest/jobs/${jobId}`);\n\nexport const listIngestionJobs = (): Promise<JobStatusResponse[]> =>\n  apiFetch(\"/api/v1/ingest/jobs\");\n\nexport const ingestRepository = (data: {\n  repo_url: string;\n  username: string;\n  repo_name: string;\n  clear_existing?: boolean;\n}) => apiFetch(\"/api/v1/ingest/repository\", { method: \"POST\", body: JSON.stringify(data) });\n\n// Query - Search\nexport const searchCode = (query: string) =>\n  apiFetch(`/api/v1/query/search?query=${encodeURIComponent(query)}`);\nexport const searchSymbols = (query: string) =>\n  apiFetch(`/api/v1/query/search-symbols?query=${encodeURIComponent(query)}`);\n\n// Query - Analysis\nexport const getMethodUsages = (name: string) =>\n  apiFetch(`/api/v1/query/method-usages?method_name=${encodeURIComponent(name)}`);\nexport const findCallers = (name: string) =>\n  apiFetch(`/api/v1/query/find_callers?symbol_name=${encodeURIComponent(name)}`);\nexport const getClassHierarchy = (name: string) =>\n  apiFetch(`/api/v1/query/class_hierarchy?class_name=${encodeURIComponent(name)}`);\nexport const getChangeImpact = (name: string) =>\n  apiFetch(`/api/v1/query/change_impact?symbol_name=${encodeURIComponent(name)}`);\n\n// Query - CodeFinder\nexport const findFunction = (name: string) =>\n  apiFetch(`/api/v1/query/code-finder/function?name=${encodeURIComponent(name)}`);\nexport const findClass = (name: string) =>\n  apiFetch(`/api/v1/query/code-finder/class?name=${encodeURIComponent(name)}`);\nexport const findVariable = (name: string) =>\n  apiFetch(`/api/v1/query/code-finder/variable?name=${encodeURIComponent(name)}`);\nexport const findContent = (query: string) =>\n  apiFetch(`/api/v1/query/code-finder/content?query=${encodeURIComponent(query)}`);\nexport const findModule = (name: string) =>\n  apiFetch(`/api/v1/query/code-finder/module?name=${encodeURIComponent(name)}`);\nexport const findImports = (name: string) =>\n  apiFetch(`/api/v1/query/code-finder/imports?name=${encodeURIComponent(name)}`);\nexport const findByLine = (query: string) =>\n  apiFetch(`/api/v1/query/code-finder/line?query=${encodeURIComponent(query)}`);\nexport const peekFileLines = (path: string, line: number, above: number, below: number) =>\n  apiFetch(`/api/v1/query/code-finder/peek?path=${encodeURIComponent(path)}&line=${line}&above=${above}&below=${below}`);\n\n// Query - Metrics\nexport const getGraphStats = () => apiFetch(\"/api/v1/query/stats\");\nexport const getLanguageStats = () => apiFetch(\"/api/v1/query/language/stats\");\nexport const getTopComplexFunctions = () =>\n  apiFetch(\"/api/v1/query/code-finder/complexity/top\");\n\n// Query - Code Review / Diff Context\nexport const getSymbolsAtLines = (repoId: string, filePath: string, startLine: number, endLine: number) =>\n  apiFetch(`/api/v1/query/symbols-at-lines-relative?repo_id=${encodeURIComponent(repoId)}&file_path=${encodeURIComponent(filePath)}&start_line=${startLine}&end_line=${endLine}`);\n\nexport const getDiffContext = (data: {\n  repo_id: string;\n  changes: { file_path: string; start_line?: number; end_line?: number }[];\n}) => apiFetch(\"/api/v1/query/diff-context\", { method: \"POST\", body: JSON.stringify(data) });\n\nexport const getFileSource = (repoId: string, filePath: string) =>\n  apiFetch(`/api/v1/query/file-source?repo_id=${encodeURIComponent(repoId)}&file_path=${encodeURIComponent(filePath)}`);\n\n// Auth\nexport const loginUser = (data: { github_access_token: string }) =>\n  apiFetch(\"/api/v1/auth/login\", { method: \"POST\", body: JSON.stringify(data) });\n\nexport const ensureUser = () =>\n  apiFetch(\"/api/v1/auth/ensure\", { method: \"POST\" });\n\nexport const getCurrentUser = () => apiFetch(\"/api/v1/auth/me\");\n\nexport const getGitHubRepos = (): Promise<GitHubRepo[]> =>\n  apiFetch(\"/api/v1/auth/github/repos\");\n\n// Additional query functions\nexport const getComplexity = (functionName: string, path?: string) => {\n  const params = new URLSearchParams({ function_name: functionName });\n  if (path) params.set(\"path\", path);\n  return apiFetch(`/api/v1/query/code-finder/complexity?${params}`);\n};\n\nexport const findRelatedCode = (query: string, fuzzy = false, depth = 2) =>\n  apiFetch(\n    `/api/v1/query/code-finder/content?query=${encodeURIComponent(query)}&fuzzy=${fuzzy}&depth=${depth}`\n  );\n\nexport const getLanguageSymbols = (language: string, symbolType: string, limit = 50) =>\n  apiFetch(\n    `/api/v1/query/language/symbols?language=${encodeURIComponent(language)}&symbol_type=${encodeURIComponent(symbolType)}&limit=${limit}`\n  );\n\nexport const findDefinition = (symbolName: string, repoId: string) =>\n  apiFetch(\n    `/api/v1/query/search-symbols?query=${encodeURIComponent(symbolName)}&repo_id=${encodeURIComponent(repoId)}`\n  );\n\nexport const findMethodUsages = (methodName: string) =>\n  apiFetch(`/api/v1/query/method-usages?method_name=${encodeURIComponent(methodName)}`);\n\nexport const getFileStructure = (repoId: string, filePath: string) =>\n  apiFetch(\n    `/api/v1/query/file-source?repo_id=${encodeURIComponent(repoId)}&file_path=${encodeURIComponent(filePath)}`\n  );\n\nexport const analyzeRelationships = (queryType: string, target: string, context?: string) => {\n  const params = new URLSearchParams({ symbol_name: target });\n  if (context) params.set(\"context\", context);\n  const endpoint =\n    queryType === \"class_hierarchy\"\n      ? `/api/v1/query/class_hierarchy?class_name=${encodeURIComponent(target)}`\n      : queryType === \"change_impact\"\n      ? `/api/v1/query/change_impact?symbol_name=${encodeURIComponent(target)}`\n      : `/api/v1/query/find_callers?symbol_name=${encodeURIComponent(target)}&query_type=${encodeURIComponent(queryType)}`;\n  return apiFetch(endpoint);\n};\n\n// Default export for direct api.X() usage in components\nconst api = {\n  findMethodUsages,\n  getFileStructure,\n  analyzeRelationships,\n  findDefinition,\n  getComplexity,\n  findRelatedCode,\n  getLanguageSymbols,\n};\n\nexport default api;\n","numLines":237,"startLine":1,"totalLines":237}},"sourceToolAssistantUUID":"9a5559af-f182-45c5-8681-cddb7da8894d"}
{"parentUuid":"8e8232db-f5ba-4746-9a83-49ecf57fde55","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01MBbAyUTo33aSwzM9rGCAhZ","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I have a full picture of what needs to be fixed. Let me plan the changes:\n\n## Issues Identified:\n\n### 1. `/search` (Full-text search) — `search_code` in `db/queries.py`\n**Problems:**\n- Uses `(f:File)-[:DEFINES*1..2]->(node)` but actual schema uses `[:CONTAINS]`\n- Returns raw node objects rather than lean results\n- No clean file path + line_number in response\n\n**Fix:** Fix the Cypher query to use `[:CONTAINS]` and add lean output with fallback to CONTAINS matching.\n\n\n### 2. `/search-symbols` — `search_symbols` in `db/queries.py`  \n**Problems:**\n- Doesn't escape the Lucene query (special chars like `(`, `)`, `:` break it)\n- Returns `file_id` and `line` but not a usable `path`\n\n**Fix:** Apply `_escape_lucene_query()` to `search_term` before passing to Lucene.\n\n### 3. Missing `/code-finder/line` endpoint\n- The CLAUDE.md documents this endpoint but it doesn't exist in `query.py`\n- `api.ts` references it but there's no corresponding implementation\n\n**Fix:** Add the endpoint to `query.py` using the `file_content_search` fulltext index with a CONTAINS fallback.\n\n### 4. Missing `/code-finder/peek` endpoint\n- CLAUDE.md and `api.ts` both reference this endpoint, but it's not implemented in `query.py`\n- Needs to accept `path`, `line`, `above`, `below` parameters and return a slice of the file\n\n**Fix:** Implement the endpoint to fetch `File.source_code` from Neo4j and return the requested line window.\n\n### 5. Frontend UI improvements for search results\n- `ResultsView` currently displays raw JSON instead of formatted results with file paths and line numbers\n- Need to support querying larger context windows beyond the current limits\n\nNow I'm mapping out the implementation plan. On the backend, I need to refactor the query methods to return cleaner results with proper fields, fix the Lucene escaping in symbol search, and add the two missing methods for file content search and line peeking. Then I'll add the corresponding API endpoints to handle these operations.\n\nFor the frontend, I need to build out the Search tab with a proper results component that shows file paths and line numbers, create a PeekViewer that can fetch and display surrounding context, and expose the line search functionality in the UI since it's already wired up in the API layer.\n\nThis covers all four requirements the user asked for: fixing full-text search to show lines and files, resolving the Lucene error, enabling context expansion, and building the UI to support it.\n\nNow I'm refining the Cypher query to properly return file paths and line information...\n\nActually, I'm realizing the core issue is that `search_symbols` isn't escaping Lucene special characters like parentheses and colons the way `search_code` does, so queries with class definitions break the fulltext search. I need to make sure both methods handle query escaping consistently. I'm modifying the `search_symbols` function to escape the search term using the same Lucene escaping method that `search_code` already uses. But I'm realizing there's a schema mismatch here—the CLAUDE.md documentation doesn't actually list `Symbol` nodes as part of the database schema, so I need to check what node types are actually being indexed. I need to fix both search functions: `search_symbols` should query the `code_search` index instead of the non-existent `symbol_search` index and return clean results with path and line number, while `search_code` needs to use the correct `[:CONTAINS]` relationship, add a fallback to name-based search if fulltext returns nothing, and return lean results including path, line number, name, type, and match line. The line search endpoint also needs to return path and line number from the file content index.\n\nFor the peek endpoint, I'm querying the file by path, splitting the source code by newlines, and returning a window of lines around the requested line number. Looking at why `search_code` is failing—the user's error was actually from `/search-symbols`, not `/search`, and the query escaping wraps the whole thing in quotes to handle special characters like parentheses and colons.\n\nI'm identifying two core issues: the `search_code` query references a non-existent relationship type `[:DEFINES*1..2]`, and `search_symbols` doesn't escape the search term at all. I need to fix both the Cypher query in the schema and add proper escaping to the symbols endpoint.\n\nFor the `search_code` fix, I'm replacing the invalid relationship with `[:CONTAINS]` and restructuring the return clause to provide cleaner results with proper type mapping and line number information.\n\nFixing the second issue... I need to fix the `search_symbols` method by adding Lucene query escaping, and I'm realizing the `symbol_search` index references non-existent `Symbol` nodes. Rather than overcomplicating this, I'll use the `code_search` index as a fallback with a CONTAINS relationship on the name field, keeping the fixes targeted and minimal.\n\nNow I'm mapping out the remaining changes: updating `search_code` to use an optional CONTAINS match instead of the problematic relationship chain, adding a new `search_file_content` method that leverages the file content index to return results with line numbers, and creating a `peek_file_lines` utility method...\n\nThen I'll add the two new API endpoints for line-based search and file peeking, and update the frontend to display these results properly with a file:line format and an inline preview viewer.\n\nI'm ready to implement this carefully while maintaining backward compatibility. For the file content search, I'm building a Cypher query that searches the full-text index on source code, splits the content by newlines, and returns each matching line with its line number...\n\nActually, I realize the Cypher approach for line iteration gets complex and could have performance issues. A better strategy is to use the full-text index to identify which files contain the search term, then handle the line-by-line matching in Python where I have more flexibility for finding exact matches within each file.\n\nFor the peek endpoint, I can keep it straightforward—just fetch the file's source code and split it by lines in Python to return the requested window.\n\nLet me implement this approach now, keeping in mind the spec says the line search should use the fulltext index with a fallback to simple CONTAINS matching. Writing the search implementation... Writing the peek function...\n\nNow I need to update the frontend to display search results properly with file paths and line numbers, then build out a peek viewer component that shows context around a specific line. I need to map out the implementation across four files: the database schema, query methods, API endpoints, and the frontend UI. Let me start by reconsidering the Cypher query for `search_code` — I want to make sure it properly matches code nodes and returns the right context.\n\nThe issue is that the relationship should be `[:CONTAINS]` instead of `[:DEFINES*1..2]`, and I need to handle cases where a code node might not have a direct file parent. I'll update the schema with the corrected query, then adjust the corresponding method in queries.py to work with the new return fields.\n\nWriting the updated schema and query methods... Continuing with the search implementation, I'm executing the query and transforming the results into a structured format with type, name, path, line number, and score. If the fulltext search fails, I'm falling back to a simpler CONTAINS query that searches for the term directly in node names. Writing the search query... Writing the fallback query...\n\nNow I'm realizing the core issue: the `search_symbols` query targets `Symbol` nodes that don't actually exist in the database, so it either returns nothing or fails entirely. The Lucene parse error comes from the unescaped search term, and even if I fix that, the index won't help without the proper node types being present.\n\nI need to tackle this in steps: first escape the query properly to fix the immediate error, then repoint `search_symbols` to use the `code_search` index instead, and return clean results with just the path and line number. I'm also noticing the `/search` endpoint has a relationship issue—it's using `[:DEFINES*1..2]` which probably doesn't exist and should be `[:CONTAINS]` instead, plus the node object isn't serializing cleanly.\n\nLet me work through these fixes systematically, starting with the escaping and index issues. For the frontend, I'll need to build out a proper SearchResult component for the Search tab.\n\nLooking at the current code structure, the generic `ResultsView` won't cut it for search results that need to display file paths and line numbers with peek capability. I'm going to create a specialized `SearchResultsView` component that handles the formatting and peek functionality, then wire it up for all three search types.\n\nBuilding the search results component... Now I'm organizing the implementation plan - I need to update the database schema and queries, add two new API endpoints for line search and file peeking, and build out the frontend components to display and interact with the results.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3788,"cache_read_input_tokens":76109,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3788},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsQiaRKboDu1NjCEb9Q","type":"assistant","uuid":"6efa0c0e-c84b-40ee-88b6-a973ebb4a545","timestamp":"2026-02-21T08:08:25.702Z"}
{"parentUuid":"6efa0c0e-c84b-40ee-88b6-a973ebb4a545","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01MBbAyUTo33aSwzM9rGCAhZ","type":"message","role":"assistant","content":[{"type":"text","text":"Now I have a clear picture of all the issues. Let me create a task list and fix everything:\n\n**Issues found:**\n1. `search_symbols` — doesn't escape Lucene query (special chars `(`, `)`, `:` crash it)\n2. `search_code` — uses `[:DEFINES*1..2]` which doesn't exist (should be `[:CONTAINS]`), returns raw unserializable node objects\n3. Both miss `symbol_search` index targeting non-existent `Symbol` nodes\n4. `/code-finder/line` and `/code-finder/peek` endpoints are missing entirely (referenced in api.ts but never registered)\n5. Frontend has no proper search results view — just dumps JSON"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3788,"cache_read_input_tokens":76109,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3788},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsQiaRKboDu1NjCEb9Q","type":"assistant","uuid":"3498f8c3-8091-4491-85b7-da79b93e29a2","timestamp":"2026-02-21T08:08:28.481Z"}
{"parentUuid":"3498f8c3-8091-4491-85b7-da79b93e29a2","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01MBbAyUTo33aSwzM9rGCAhZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01AXfGcRRxWirhXKFZa6wG6X","name":"TaskCreate","input":{"subject":"Fix search_code and search_symbols in db/queries.py + schema.py","description":"Fix Lucene escaping for search_symbols, fix [:DEFINES] → [:CONTAINS] in search_code Cypher, return lean results (path, line_number, name, type, score), add CONTAINS fallback when fulltext returns empty","activeForm":"Fixing backend search queries"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3788,"cache_read_input_tokens":76109,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3788},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsQiaRKboDu1NjCEb9Q","type":"assistant","uuid":"365fbdd0-3b2b-40ee-8e0e-6dde59b3bb34","timestamp":"2026-02-21T08:08:30.787Z"}
{"parentUuid":"365fbdd0-3b2b-40ee-8e0e-6dde59b3bb34","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01AXfGcRRxWirhXKFZa6wG6X","type":"tool_result","content":"Task #1 created successfully: Fix search_code and search_symbols in db/queries.py + schema.py"}]},"uuid":"14e5ec2c-23b4-44f9-88ca-4fa1f9596a1e","timestamp":"2026-02-21T08:08:30.799Z","toolUseResult":{"task":{"id":"1","subject":"Fix search_code and search_symbols in db/queries.py + schema.py"}},"sourceToolAssistantUUID":"365fbdd0-3b2b-40ee-8e0e-6dde59b3bb34"}
{"parentUuid":"14e5ec2c-23b4-44f9-88ca-4fa1f9596a1e","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01MBbAyUTo33aSwzM9rGCAhZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WpbASbEVFjAUVSMDndPvSv","name":"TaskCreate","input":{"subject":"Add /code-finder/line and /code-finder/peek endpoints to query.py","description":"Add search_file_content and peek_file_lines methods to db/queries.py, then register /code-finder/line and /code-finder/peek routes in api/routers/query.py","activeForm":"Adding line search and peek endpoints"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3788,"cache_read_input_tokens":76109,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3788},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsQiaRKboDu1NjCEb9Q","type":"assistant","uuid":"7a95f985-83dc-489a-adef-1315f6a19f82","timestamp":"2026-02-21T08:08:32.154Z"}
{"parentUuid":"7a95f985-83dc-489a-adef-1315f6a19f82","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WpbASbEVFjAUVSMDndPvSv","type":"tool_result","content":"Task #2 created successfully: Add /code-finder/line and /code-finder/peek endpoints to query.py"}]},"uuid":"bc6179fc-ddac-47f8-bd3e-20da0a163e74","timestamp":"2026-02-21T08:08:32.159Z","toolUseResult":{"task":{"id":"2","subject":"Add /code-finder/line and /code-finder/peek endpoints to query.py"}},"sourceToolAssistantUUID":"7a95f985-83dc-489a-adef-1315f6a19f82"}
{"parentUuid":"bc6179fc-ddac-47f8-bd3e-20da0a163e74","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01MBbAyUTo33aSwzM9rGCAhZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0187FXPa2Fj8jKyYEDKj3jiz","name":"TaskCreate","input":{"subject":"Update frontend query page with SearchResultsView + PeekViewer","description":"Replace generic JSON dump for search results with a proper SearchResultsView showing file:line badges and a PeekViewer that loads 10+ lines above/below the match. Add Line Search button to CodeFinder tab.","activeForm":"Updating frontend search UI"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3788,"cache_read_input_tokens":76109,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3788},"output_tokens":10,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsQiaRKboDu1NjCEb9Q","type":"assistant","uuid":"e3a03378-64d1-4605-adf9-3d004ff4b1e8","timestamp":"2026-02-21T08:08:34.027Z"}
{"parentUuid":"e3a03378-64d1-4605-adf9-3d004ff4b1e8","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0187FXPa2Fj8jKyYEDKj3jiz","type":"tool_result","content":"Task #3 created successfully: Update frontend query page with SearchResultsView + PeekViewer"}]},"uuid":"e9a7cfc5-fcc7-40a3-bd84-a557adffc131","timestamp":"2026-02-21T08:08:34.028Z","toolUseResult":{"task":{"id":"3","subject":"Update frontend query page with SearchResultsView + PeekViewer"}},"sourceToolAssistantUUID":"e3a03378-64d1-4605-adf9-3d004ff4b1e8"}
{"parentUuid":"e9a7cfc5-fcc7-40a3-bd84-a557adffc131","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_017XhhbR91q96zAzLeFFpG3S","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01GRn87zRGhBkHtqwERwWtx4","name":"TaskUpdate","input":{"taskId":"1","status":"in_progress"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":8293,"cache_read_input_tokens":79897,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":8293},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsZjUzoLaJXA1W385a5","type":"assistant","uuid":"513eb01b-e646-4157-a9a8-31aac45d359d","timestamp":"2026-02-21T08:08:36.553Z"}
{"parentUuid":"513eb01b-e646-4157-a9a8-31aac45d359d","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01GRn87zRGhBkHtqwERwWtx4","type":"tool_result","content":"Updated task #1 status"}]},"uuid":"10dc3817-bfd3-466c-b35d-2ebcfacace6c","timestamp":"2026-02-21T08:08:36.555Z","toolUseResult":{"success":true,"taskId":"1","updatedFields":["status"],"statusChange":{"from":"pending","to":"in_progress"}},"sourceToolAssistantUUID":"513eb01b-e646-4157-a9a8-31aac45d359d"}
{"parentUuid":"10dc3817-bfd3-466c-b35d-2ebcfacace6c","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01MBbvwWNGshrVaZ65rtnK5e","type":"message","role":"assistant","content":[{"type":"text","text":"**Step 1: Fix `search_code` Cypher in `db/schema.py`**"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":90,"cache_read_input_tokens":88190,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":90},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsZvbj5tm7SbwJscmyL","type":"assistant","uuid":"e51f211a-a178-4951-b64f-53a2b60056a4","timestamp":"2026-02-21T08:08:38.238Z"}
{"parentUuid":"e51f211a-a178-4951-b64f-53a2b60056a4","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01MBbvwWNGshrVaZ65rtnK5e","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JJTBHsjbRnwchvPWdDxzTs","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/db/schema.py","offset":810,"limit":25},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":90,"cache_read_input_tokens":88190,"output_tokens":130,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":90,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLsZvbj5tm7SbwJscmyL","type":"assistant","uuid":"c9fa049e-55de-489d-b60e-f496fc12033c","timestamp":"2026-02-21T08:08:39.432Z"}
{"parentUuid":"c9fa049e-55de-489d-b60e-f496fc12033c","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01JJTBHsjbRnwchvPWdDxzTs","toolUseID":"toolu_01JJTBHsjbRnwchvPWdDxzTs","timestamp":"2026-02-21T08:08:39.448Z","uuid":"59a0e983-027c-4354-8d51-fd4cf187c561"}
{"parentUuid":"c9fa049e-55de-489d-b60e-f496fc12033c","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JJTBHsjbRnwchvPWdDxzTs","type":"tool_result","content":"   810→    \n   811→    \"search_code\": \"\"\"\n   812→        CALL db.index.fulltext.queryNodes('code_search', $search_term)\n   813→        YIELD node, score\n   814→        MATCH (f:File)-[:DEFINES*1..2]->(node)\n   815→        RETURN node, labels(node)[0] as type, f.path as file, score\n   816→        ORDER BY score DESC\n   817→        LIMIT 20\n   818→    \"\"\",\n   819→\n   820→    \"search_symbols\": \"\"\"\n   821→        CALL db.index.fulltext.queryNodes('symbol_search', $search_term)\n   822→        YIELD node, score\n   823→        RETURN node.name as name,\n   824→               node.qualified_name as qualified_name,\n   825→               node.type as type,\n   826→               node.file_id as file_id,\n   827→               node.line_start as line,\n   828→               node.visibility as visibility,\n   829→               score\n   830→        ORDER BY score DESC\n   831→        LIMIT $limit\n   832→    \"\"\",\n   833→\n   834→    \"search_symbols_by_qualified_name\": \"\"\"\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"d256e43a-3b73-4794-bb0a-260ccc7abe5a","timestamp":"2026-02-21T08:08:39.447Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/db/schema.py","content":"    \n    \"search_code\": \"\"\"\n        CALL db.index.fulltext.queryNodes('code_search', $search_term)\n        YIELD node, score\n        MATCH (f:File)-[:DEFINES*1..2]->(node)\n        RETURN node, labels(node)[0] as type, f.path as file, score\n        ORDER BY score DESC\n        LIMIT 20\n    \"\"\",\n\n    \"search_symbols\": \"\"\"\n        CALL db.index.fulltext.queryNodes('symbol_search', $search_term)\n        YIELD node, score\n        RETURN node.name as name,\n               node.qualified_name as qualified_name,\n               node.type as type,\n               node.file_id as file_id,\n               node.line_start as line,\n               node.visibility as visibility,\n               score\n        ORDER BY score DESC\n        LIMIT $limit\n    \"\"\",\n\n    \"search_symbols_by_qualified_name\": \"\"\"","numLines":25,"startLine":810,"totalLines":1254}},"sourceToolAssistantUUID":"c9fa049e-55de-489d-b60e-f496fc12033c"}
{"parentUuid":"d256e43a-3b73-4794-bb0a-260ccc7abe5a","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01PaZ7cjgNjSi9Fop74tXjJF","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WfByHfv3h5zqMRjR8DnQby","name":"Edit","input":{"replace_all":false,"file_path":"/Users/skmabudalam/Documents/BugViper/db/schema.py","old_string":"    \"search_code\": \"\"\"\n        CALL db.index.fulltext.queryNodes('code_search', $search_term)\n        YIELD node, score\n        MATCH (f:File)-[:DEFINES*1..2]->(node)\n        RETURN node, labels(node)[0] as type, f.path as file, score\n        ORDER BY score DESC\n        LIMIT 20\n    \"\"\",\n\n    \"search_symbols\": \"\"\"\n        CALL db.index.fulltext.queryNodes('symbol_search', $search_term)\n        YIELD node, score\n        RETURN node.name as name,\n               node.qualified_name as qualified_name,\n               node.type as type,\n               node.file_id as file_id,\n               node.line_start as line,\n               node.visibility as visibility,\n               score\n        ORDER BY score DESC\n        LIMIT $limit\n    \"\"\",","new_string":"    \"search_code\": \"\"\"\n        CALL db.index.fulltext.queryNodes('code_search', $search_term)\n        YIELD node, score\n        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n        RETURN\n            CASE WHEN node:Function THEN 'function'\n                 WHEN node:Class THEN 'class'\n                 ELSE 'variable' END as type,\n            node.name as name,\n            coalesce(f.path, node.path) as path,\n            coalesce(node.line_number, 0) as line_number,\n            score\n        ORDER BY score DESC\n        LIMIT 20\n    \"\"\",\n\n    \"search_symbols\": \"\"\"\n        CALL db.index.fulltext.queryNodes('code_search', $search_term)\n        YIELD node, score\n        WHERE node:Function OR node:Class OR node:Variable\n        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n        RETURN\n            node.name as name,\n            CASE WHEN node:Function THEN 'function'\n                 WHEN node:Class THEN 'class'\n                 ELSE 'variable' END as type,\n            coalesce(f.path, node.path) as path,\n            coalesce(node.line_number, 0) as line_number,\n            score\n        ORDER BY score DESC\n        LIMIT $limit\n    \"\"\","},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":527,"cache_read_input_tokens":88280,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":527},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLsa8ZK38tEBucJTxFVF","type":"assistant","uuid":"600b5f6d-d85d-4d3c-876d-de6c9ed7864a","timestamp":"2026-02-21T08:08:46.153Z"}
{"type":"file-history-snapshot","messageId":"600b5f6d-d85d-4d3c-876d-de6c9ed7864a","snapshot":{"messageId":"c24e474a-29dd-4bc8-afe3-07caafdf094e","trackedFileBackups":{"db/schema.py":{"backupFileName":"283975a9ba984ffc@v1","version":1,"backupTime":"2026-02-21T08:25:31.646Z"}},"timestamp":"2026-02-21T08:05:38.177Z"},"isSnapshotUpdate":true}
{"parentUuid":"600b5f6d-d85d-4d3c-876d-de6c9ed7864a","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01WfByHfv3h5zqMRjR8DnQby","toolUseID":"toolu_01WfByHfv3h5zqMRjR8DnQby","timestamp":"2026-02-21T08:25:31.654Z","uuid":"5c471cbc-bf1d-4282-8909-cb8356a15e61"}
{"parentUuid":"600b5f6d-d85d-4d3c-876d-de6c9ed7864a","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WfByHfv3h5zqMRjR8DnQby","type":"tool_result","content":"The file /Users/skmabudalam/Documents/BugViper/db/schema.py has been updated successfully."}]},"uuid":"9aeaa23b-683b-4ed1-a193-0db5915225e8","timestamp":"2026-02-21T08:25:31.651Z","toolUseResult":{"filePath":"/Users/skmabudalam/Documents/BugViper/db/schema.py","oldString":"    \"search_code\": \"\"\"\n        CALL db.index.fulltext.queryNodes('code_search', $search_term)\n        YIELD node, score\n        MATCH (f:File)-[:DEFINES*1..2]->(node)\n        RETURN node, labels(node)[0] as type, f.path as file, score\n        ORDER BY score DESC\n        LIMIT 20\n    \"\"\",\n\n    \"search_symbols\": \"\"\"\n        CALL db.index.fulltext.queryNodes('symbol_search', $search_term)\n        YIELD node, score\n        RETURN node.name as name,\n               node.qualified_name as qualified_name,\n               node.type as type,\n               node.file_id as file_id,\n               node.line_start as line,\n               node.visibility as visibility,\n               score\n        ORDER BY score DESC\n        LIMIT $limit\n    \"\"\",","newString":"    \"search_code\": \"\"\"\n        CALL db.index.fulltext.queryNodes('code_search', $search_term)\n        YIELD node, score\n        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n        RETURN\n            CASE WHEN node:Function THEN 'function'\n                 WHEN node:Class THEN 'class'\n                 ELSE 'variable' END as type,\n            node.name as name,\n            coalesce(f.path, node.path) as path,\n            coalesce(node.line_number, 0) as line_number,\n            score\n        ORDER BY score DESC\n        LIMIT 20\n    \"\"\",\n\n    \"search_symbols\": \"\"\"\n        CALL db.index.fulltext.queryNodes('code_search', $search_term)\n        YIELD node, score\n        WHERE node:Function OR node:Class OR node:Variable\n        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n        RETURN\n            node.name as name,\n            CASE WHEN node:Function THEN 'function'\n                 WHEN node:Class THEN 'class'\n                 ELSE 'variable' END as type,\n            coalesce(f.path, node.path) as path,\n            coalesce(node.line_number, 0) as line_number,\n            score\n        ORDER BY score DESC\n        LIMIT $limit\n    \"\"\",","originalFile":"\"\"\"\nNeo4j Graph Schema for Code Ingestion\n\nDefines the graph structure, constraints, indexes, and Cypher queries\nfor storing and querying code in Neo4j.\n\nGraph Structure:\n================\n(:User) -[:OWNS]-> (:Repository) -[:CONTAINS]-> (:Module) -[:CONTAINS]-> (:File)\n(:File) -[:DEFINES]-> (:Class|:Function|:Variable)\n(:File) -[:HAS_IMPORT]-> (:Import)\n(:File) -[:IMPORTS]-> (:File|:Module)\n(:Class) -[:HAS_METHOD]-> (:Method)\n(:Class) -[:HAS_ATTRIBUTE]-> (:Attribute)\n(:Class) -[:INHERITS]-> (:Class)\n(:Method|:Function) -[:CALLS]-> (:Symbol)\n(:Symbol) - Persistent symbol table for all code elements with qualified names\n(:Module) -[:CONTAINS {depth: int}]-> (:Module|:File) - Hierarchical navigation\n\"\"\"\n\nfrom typing import Optional, Dict, Any\nfrom .client import Neo4jClient\n\n\nclass CodeGraphSchema:\n    \"\"\"Manages the Neo4j schema for code ingestion.\"\"\"\n    \n    def __init__(self, client: Neo4jClient):\n        \"\"\"\n        Initialize schema manager.\n        \n        Args:\n            client: Neo4j database client\n        \"\"\"\n        self.db = client\n    \n    def create_constraints_and_indexes(self) -> None:\n        \"\"\"Create all necessary constraints and indexes for the code graph.\"\"\"\n        \n        constraints = [\n            # Unique constraints\n            \"CREATE CONSTRAINT user_username IF NOT EXISTS FOR (u:User) REQUIRE u.username IS UNIQUE\",\n            # Repository uniqueness is handled by graph_builder's constraint on r.repo (owner/name format)\n            # \"CREATE CONSTRAINT repo_unique IF NOT EXISTS FOR (r:Repository) REQUIRE (r.owner, r.name) IS UNIQUE\",\n            \"CREATE CONSTRAINT file_path IF NOT EXISTS FOR (f:File) REQUIRE (f.repo_id, f.path) IS UNIQUE\",\n            \"CREATE CONSTRAINT branch_unique IF NOT EXISTS FOR (b:Branch) REQUIRE (b.repo_id, b.name) IS UNIQUE\",\n            \"CREATE CONSTRAINT config_file_path IF NOT EXISTS FOR (cf:ConfigFile) REQUIRE (cf.repo_id, cf.path) IS UNIQUE\",\n            \"CREATE CONSTRAINT symbol_id IF NOT EXISTS FOR (s:Symbol) REQUIRE s.id IS UNIQUE\",\n        ]\n        \n        indexes = [\n            # Performance indexes\n            \"CREATE INDEX file_language IF NOT EXISTS FOR (f:File) ON (f.language)\",\n            \"CREATE INDEX class_name IF NOT EXISTS FOR (c:Class) ON (c.name)\",\n            \"CREATE INDEX function_name IF NOT EXISTS FOR (f:Function) ON (f.name)\",\n            \"CREATE INDEX method_name IF NOT EXISTS FOR (m:Method) ON (m.name)\",\n            \"CREATE INDEX module_path IF NOT EXISTS FOR (m:Module) ON (m.path)\",\n            \"CREATE INDEX module_hierarchy IF NOT EXISTS FOR (m:Module) ON (m.repo_id, m.depth)\",\n            \"CREATE INDEX import_module IF NOT EXISTS FOR (i:Import) ON (i.module)\",\n            \"CREATE INDEX variable_name IF NOT EXISTS FOR (v:Variable) ON (v.name)\",\n\n            # Symbol table indexes\n            \"CREATE INDEX symbol_name IF NOT EXISTS FOR (s:Symbol) ON (s.name)\",\n            \"CREATE INDEX symbol_qualified_name IF NOT EXISTS FOR (s:Symbol) ON (s.qualified_name)\",\n            \"CREATE INDEX symbol_scope_lookup IF NOT EXISTS FOR (s:Symbol) ON (s.file_id, s.scope)\",\n            \"CREATE INDEX symbol_type IF NOT EXISTS FOR (s:Symbol) ON (s.type)\",\n\n            # Config file indexes\n            \"CREATE INDEX config_file_type IF NOT EXISTS FOR (cf:ConfigFile) ON (cf.file_type)\",\n            \"CREATE INDEX dependency_name IF NOT EXISTS FOR (d:Dependency) ON (d.name)\",\n            \"CREATE INDEX dependency_source IF NOT EXISTS FOR (d:Dependency) ON (d.source)\",\n\n            # Full-text search indexes for code search (including source_code)\n            \"CREATE FULLTEXT INDEX code_search IF NOT EXISTS FOR (n:Class|Function|Method|Variable|Symbol) ON EACH [n.name, n.docstring, n.source_code]\",\n            \"CREATE FULLTEXT INDEX symbol_search IF NOT EXISTS FOR (s:Symbol) ON EACH [s.name, s.qualified_name, s.docstring]\",\n            \"CREATE FULLTEXT INDEX file_content_search IF NOT EXISTS FOR (f:File) ON EACH [f.source_code]\",\n        ]\n        \n        for constraint in constraints:\n            try:\n                self.db.run_query(constraint)\n                print(\"✓ Created constraint\")\n            except Exception as e:\n                if \"already exists\" not in str(e).lower():\n                    print(f\"⚠ Constraint warning: {e}\")\n        \n        for index in indexes:\n            try:\n                self.db.run_query(index)\n                print(\"✓ Created index\")\n            except Exception as e:\n                if \"already exists\" not in str(e).lower():\n                    print(f\"⚠ Index warning: {e}\")\n    \n    def clear_repository(self, repo_id: str) -> None:\n        \"\"\"\n        Clear all data for a specific repository before re-ingestion.\n        \n        Args:\n            repo_id: Repository ID (format: username/repo_name)\n        \"\"\"\n        query = \"\"\"\n        MATCH (r:Repository {id: $repo_id})\n        OPTIONAL MATCH (r)-[*]->(n)\n        DETACH DELETE n, r\n        \"\"\"\n        self.db.run_query(query, {\"repo_id\": repo_id})\n        print(f\"✓ Cleared repository: {repo_id}\")\n    \n    def update_repository_commit(self, repo_id: str, commit_hash: str) -> None:\n        \"\"\"\n        Update the last commit hash for a repository.\n        \n        Args:\n            repo_id: Repository ID\n            commit_hash: Git commit hash\n        \"\"\"\n        query = \"\"\"\n        MATCH (r:Repository {id: $repo_id})\n        SET r.last_commit_hash = $commit_hash,\n            r.last_updated_at = datetime()\n        RETURN r\n        \"\"\"\n        self.db.run_query(query, {\"repo_id\": repo_id, \"commit_hash\": commit_hash})\n    \n    def get_repository_commit(self, repo_id: str) -> Optional[str]:\n        \"\"\"\n        Get the last ingested commit hash for a repository.\n        \n        Args:\n            repo_id: Repository ID\n            \n        Returns:\n            Commit hash or None if not set\n        \"\"\"\n        query = \"\"\"\n        MATCH (r:Repository {id: $repo_id})\n        RETURN r.last_commit_hash as commit_hash\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        if records and records[0][\"commit_hash\"]:\n            return records[0][\"commit_hash\"]\n        return None\n    \n    def get_repository_metadata(self, repo_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Get repository metadata including local path, URL, etc.\n        \n        Args:\n            repo_id: Repository ID\n            \n        Returns:\n            Dictionary with repository metadata or None if not found\n        \"\"\"\n        query = \"\"\"\n        MATCH (r:Repository {id: $repo_id})\n        RETURN r.id as id,\n               r.name as name,\n               r.owner as owner,\n               r.path as local_path,\n               r.url as url,\n               r.default_branch as default_branch,\n               r.last_commit_hash as last_commit_hash\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        if records:\n            return dict(records[0])\n        return None\n    \n    def delete_file_nodes(self, repo_id: str, file_path: str) -> None:\n        \"\"\"\n        Delete all nodes associated with a specific file.\n\n        Deletes the File node and all code entities (classes, functions, methods, variables)\n        that belong to this file, including their relationships.\n\n        Args:\n            repo_id: Repository ID\n            file_path: Path to the file\n        \"\"\"\n        # Delete all nodes associated with the file in a single transaction\n        query = \"\"\"\n        // Find the file\n        MATCH (f:File {repo_id: $repo_id, path: $file_path})\n\n        // Find all classes in the file\n        OPTIONAL MATCH (f)-[:CONTAINS_CLASS]->(c:Class)\n        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)\n\n        // Find all functions in the file\n        OPTIONAL MATCH (f)-[:CONTAINS_FUNCTION]->(func:Function)\n\n        // Find all variables in the file\n        OPTIONAL MATCH (f)-[:DEFINES_VARIABLE]->(v:Variable)\n\n        // Find all imports in the file\n        OPTIONAL MATCH (f)-[:IMPORTS]->(i:Import)\n\n        // Detach and delete all nodes (removes all relationships automatically)\n        DETACH DELETE f, c, m, func, v, i\n        \"\"\"\n        self.db.run_query(query, {\"repo_id\": repo_id, \"file_path\": file_path})\n\n\n    \n    def rename_file_in_graph(self, repo_id: str, old_path: str, new_path: str) -> None:\n        \"\"\"\n        Rename a file in the graph database.\n\n        Updates the File node path and all related code entities that reference\n        the file path (qualified names, etc.).\n\n        Args:\n            repo_id: Repository ID\n            old_path: Old file path\n            new_path: New file path\n        \"\"\"\n        query = \"\"\"\n        // Update File node\n        MATCH (f:File {repo_id: $repo_id, path: $old_path})\n        SET f.path = $new_path,\n            f.name = split($new_path, '/')[-1],\n            f.last_updated = datetime()\n\n        // Update all classes in the file\n        WITH f\n        OPTIONAL MATCH (f)-[:CONTAINS_CLASS]->(c:Class)\n        SET c.file_path = $new_path\n\n        // Update all methods in those classes\n        WITH f, c\n        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)\n        SET m.file_path = $new_path\n\n        // Update all functions in the file\n        WITH f\n        OPTIONAL MATCH (f)-[:CONTAINS_FUNCTION]->(func:Function)\n        SET func.file_path = $new_path\n\n        // Update all variables in the file\n        WITH f\n        OPTIONAL MATCH (f)-[:DEFINES_VARIABLE]->(v:Variable)\n        SET v.file_path = $new_path\n\n        RETURN f\n        \"\"\"\n        self.db.run_query(query, {\n            \"repo_id\": repo_id,\n            \"old_path\": old_path,\n            \"new_path\": new_path\n        })\n\n    def delete_module_nodes(self, repo_id: str, module_path: str) -> None:\n        \"\"\"\n        Delete a module (folder) node and its relationships.\n\n        Args:\n            repo_id: Repository ID\n            module_path: Path to the module/folder\n        \"\"\"\n        query = \"\"\"\n        MATCH (m:Module {repo_id: $repo_id, path: $module_path})\n        DETACH DELETE m\n        \"\"\"\n        self.db.run_query(query, {\"repo_id\": repo_id, \"module_path\": module_path})\n\n    def rename_module_in_graph(self, repo_id: str, old_path: str, new_path: str) -> None:\n        \"\"\"\n        Rename a module (folder) in the graph database.\n\n        Updates the Module node path and all descendant modules/files.\n\n        Args:\n            repo_id: Repository ID\n            old_path: Old module path\n            new_path: New module path\n        \"\"\"\n        query = \"\"\"\n        // Update Module node\n        MATCH (m:Module {repo_id: $repo_id, path: $old_path})\n        SET m.path = $new_path,\n            m.name = split($new_path, '/')[-1],\n            m.parent_path = CASE\n                WHEN size(split($new_path, '/')) > 1\n                THEN reduce(s = '', part IN split($new_path, '/')[0..-2] |\n                    CASE WHEN s = '' THEN part ELSE s + '/' + part END)\n                ELSE null\n            END\n\n        // Update all child modules\n        WITH m\n        MATCH (child:Module)\n        WHERE child.repo_id = $repo_id\n          AND child.path STARTS WITH $old_path + '/'\n        WITH child, $old_path as old, $new_path as new\n        SET child.path = new + substring(child.path, size(old)),\n            child.parent_path = CASE\n                WHEN child.parent_path = old THEN new\n                WHEN child.parent_path STARTS WITH old + '/'\n                THEN new + substring(child.parent_path, size(old))\n                ELSE child.parent_path\n            END\n\n        RETURN child\n        \"\"\"\n        self.db.run_query(query, {\n            \"repo_id\": repo_id,\n            \"old_path\": old_path,\n            \"new_path\": new_path\n        })\n\n\n\n# =============================================================================\n# Cypher Queries\n# =============================================================================\n\nCYPHER_QUERIES = {\n    # -------------------------------------------------------------------------\n    # Graph Statistics\n    # -------------------------------------------------------------------------\n    \"get_graph_stats\": \"\"\"\n        MATCH (r:Repository)\n        OPTIONAL MATCH (r)-[:CONTAINS*]->(f:File)\n        OPTIONAL MATCH (f)-[:CONTAINS]->(c:Class)\n        OPTIONAL MATCH (f)-[:CONTAINS]->(fn:Function)\n        OPTIONAL MATCH (f)-[:CONTAINS]->(v:Variable)\n        OPTIONAL MATCH (f)-[:IMPORTS]->(m:Module)\n        RETURN\n            count(DISTINCT r) as repositories,\n            count(DISTINCT f) as files,\n            count(DISTINCT c) as classes,\n            count(DISTINCT fn) as functions,\n            count(DISTINCT v) as variables,\n            count(DISTINCT m) as modules\n    \"\"\",\n\n    \"get_repo_stats\": \"\"\"\n        MATCH (r:Repository)\n        WHERE r.repo = $repo_id OR r.id = $repo_id\n        OPTIONAL MATCH (r)-[:CONTAINS*]->(f:File)\n        WITH r, collect(DISTINCT f) as files\n        WITH r, files,\n             reduce(s = 0, f IN files | s + COALESCE(f.lines_count, 0)) as line_count\n        UNWIND CASE WHEN size(files) = 0 THEN [null] ELSE files END AS f\n        OPTIONAL MATCH (f)-[:CONTAINS]->(c:Class)\n        OPTIONAL MATCH (f)-[:CONTAINS]->(fn:Function)\n        OPTIONAL MATCH (f)-[:IMPORTS]->(m:Module)\n        RETURN\n            count(DISTINCT f) as file_count,\n            count(DISTINCT c) as class_count,\n            count(DISTINCT fn) as function_count,\n            0 as method_count,\n            line_count,\n            count(DISTINCT m) as import_count,\n            [lang IN collect(DISTINCT f.language) WHERE lang IS NOT NULL AND lang <> 'unknown'] as languages\n    \"\"\",\n\n    # -------------------------------------------------------------------------\n    # User Operations\n    # -------------------------------------------------------------------------\n    \"create_user\": \"\"\"\n        MERGE (u:User {username: $username})\n        ON CREATE SET u.email = $email, u.created_at = datetime()\n        RETURN u\n    \"\"\",\n\n    # -------------------------------------------------------------------------\n    # Symbol Table Operations\n    # -------------------------------------------------------------------------\n    \"create_symbol\": \"\"\"\n        MERGE (s:Symbol {id: $symbol_id})\n        ON CREATE SET\n            s.name = $name,\n            s.qualified_name = $qualified_name,\n            s.type = $type,\n            s.scope = $scope,\n            s.file_id = $file_id,\n            s.line_start = $line_start,\n            s.line_end = $line_end,\n            s.visibility = $visibility,\n            s.is_exported = $is_exported,\n            s.docstring = $docstring,\n            s.source_code = $source_code,\n            s.created_at = datetime()\n        ON MATCH SET\n            s.docstring = $docstring,\n            s.source_code = $source_code,\n            s.line_start = $line_start,\n            s.line_end = $line_end,\n            s.updated_at = datetime()\n        RETURN s\n    \"\"\",\n\n    \"link_symbol_to_definition\": \"\"\"\n        MATCH (s:Symbol {id: $symbol_id})\n        MATCH (def) WHERE def.id = $definition_id\n        MERGE (s)-[:REFERENCES]->(def)\n        RETURN s, def\n    \"\"\",\n    \n    # -------------------------------------------------------------------------\n    # Repository Operations\n    # -------------------------------------------------------------------------\n    \"create_repository\": \"\"\"\n        MATCH (u:User {username: $username})\n        MERGE (r:Repository {repo: $repo_id})\n        ON CREATE SET\n            r.owner = $username,\n            r.name = $repo_name,\n            r.url = $url,\n            r.path = $local_path,\n            r.description = $description,\n            r.default_branch = $default_branch,\n            r.created_at = datetime()\n        SET r.last_ingested = datetime()\n        MERGE (u)-[:OWNS]->(r)\n        RETURN r\n    \"\"\",\n    \n    \"create_branch\": \"\"\"\n        MATCH (r:Repository {id: $repo_id})\n        MERGE (b:Branch {repo_id: $repo_id, name: $branch_name})\n        ON CREATE SET b.commit_sha = $commit_sha, b.is_default = $is_default\n        MERGE (r)-[:HAS_BRANCH]->(b)\n        RETURN b\n    \"\"\",\n    \n    # -------------------------------------------------------------------------\n    # Module Operations\n    # -------------------------------------------------------------------------\n    \"create_module\": \"\"\"\n        MATCH (r:Repository {id: $repo_id})\n        MERGE (m:Module {repo_id: $repo_id, path: $path})\n        ON CREATE SET\n            m.name = $name,\n            m.type = $type,\n            m.is_package = $is_package,\n            m.depth = $depth,\n            m.parent_path = $parent_path\n        ON MATCH SET\n            m.depth = $depth,\n            m.parent_path = $parent_path\n        WITH r, m\n        CALL (r, m) {\n            WITH r, m WHERE $parent_path IS NULL\n            MERGE (r)-[:CONTAINS {depth: 0}]->(m)\n            RETURN 1 as done\n            UNION\n            WITH r, m WHERE $parent_path IS NOT NULL\n            MATCH (parent:Module {repo_id: $repo_id, path: $parent_path})\n            MERGE (parent)-[:CONTAINS {depth: $depth}]->(m)\n            RETURN 1 as done\n        }\n        RETURN m\n    \"\"\",\n    \n    # -------------------------------------------------------------------------\n    # File Operations\n    # -------------------------------------------------------------------------\n    \"create_file\": \"\"\"\n        MATCH (r:Repository {id: $repo_id})\n        MERGE (f:File {repo_id: $repo_id, path: $path})\n        ON CREATE SET\n            f.id = $file_id,\n            f.extension = $extension\n        SET f.name = $name,\n            f.language = $language,\n            f.lines_count = $lines_count,\n            f.sha = $sha,\n            f.size = $size,\n            f.source_code = $source_code,\n            f.last_updated = datetime()\n        WITH r, f\n        OPTIONAL MATCH (m:Module {repo_id: $repo_id, path: $module_path})\n        FOREACH (_ IN CASE WHEN m IS NOT NULL THEN [1] ELSE [] END |\n            MERGE (m)-[:CONTAINS]->(f)\n        )\n        FOREACH (_ IN CASE WHEN m IS NULL THEN [1] ELSE [] END |\n            MERGE (r)-[:CONTAINS]->(f)\n        )\n        RETURN f\n    \"\"\",\n    \n    \n    # -------------------------------------------------------------------------\n    # Import Operations\n    # -------------------------------------------------------------------------\n    \"create_import\": \"\"\"\n        MATCH (f:File {id: $file_id})\n        MERGE (i:Import {file_id: $file_id, module: $module, line_start: $line_start})\n        ON CREATE SET \n            i.alias = $alias,\n            i.line_end = $line_end,\n            i.is_from_import = $is_from_import,\n            i.imported_names = $imported_names\n        MERGE (f)-[:HAS_IMPORT]->(i)\n        RETURN i\n    \"\"\",\n    \n    # -------------------------------------------------------------------------\n    # Class Operations\n    # -------------------------------------------------------------------------\n    \"create_class\": \"\"\"\n        MATCH (f:File {id: $file_id})\n        MERGE (c:Class {file_id: $file_id, name: $name, line_start: $line_start})\n        ON CREATE SET\n            c.id = $class_id,\n            c.line_end = $line_end,\n            c.docstring = $docstring,\n            c.decorators = $decorators,\n            c.base_classes = $base_classes,\n            c.is_abstract = $is_abstract,\n            c.source_code = $source_code\n        SET c.source_code = $source_code\n        MERGE (f)-[:DEFINES]->(c)\n        RETURN c\n    \"\"\",\n    \n    \"create_method\": \"\"\"\n        MATCH (c:Class {id: $class_id})\n        MERGE (m:Method {class_id: $class_id, name: $name, line_start: $line_start})\n        ON CREATE SET\n            m.id = $method_id,\n            m.line_end = $line_end,\n            m.params = $params,\n            m.return_type = $return_type,\n            m.docstring = $docstring,\n            m.decorators = $decorators,\n            m.is_async = $is_async,\n            m.is_static = $is_static,\n            m.is_classmethod = $is_classmethod,\n            m.is_property = $is_property,\n            m.visibility = $visibility,\n            m.source_code = $source_code\n        SET m.source_code = $source_code\n        MERGE (c)-[:HAS_METHOD]->(m)\n        RETURN m\n    \"\"\",\n    \n    \"create_attribute\": \"\"\"\n        MATCH (c:Class {id: $class_id})\n        MERGE (a:Attribute {class_id: $class_id, name: $name})\n        ON CREATE SET \n            a.line_start = $line_start,\n            a.line_end = $line_end,\n            a.type_annotation = $type_annotation,\n            a.default_value = $default_value,\n            a.visibility = $visibility\n        MERGE (c)-[:HAS_ATTRIBUTE]->(a)\n        RETURN a\n    \"\"\",\n    \n    # -------------------------------------------------------------------------\n    # Function & Variable Operations\n    # -------------------------------------------------------------------------\n    \"create_function\": \"\"\"\n        MATCH (f:File {id: $file_id})\n        MERGE (fn:Function {file_id: $file_id, name: $name, line_start: $line_start})\n        ON CREATE SET\n            fn.id = $function_id,\n            fn.line_end = $line_end,\n            fn.params = $params,\n            fn.return_type = $return_type,\n            fn.docstring = $docstring,\n            fn.decorators = $decorators,\n            fn.is_async = $is_async,\n            fn.source_code = $source_code\n        SET fn.source_code = $source_code\n        MERGE (f)-[:DEFINES]->(fn)\n        RETURN fn\n    \"\"\",\n    \n    \"create_variable\": \"\"\"\n        MATCH (f:File {id: $file_id})\n        MERGE (v:Variable {file_id: $file_id, name: $name, line_start: $line_start})\n        ON CREATE SET \n            v.id = $variable_id,\n            v.line_end = $line_end,\n            v.type_annotation = $type_annotation,\n            v.is_constant = $is_constant,\n            v.scope = $scope\n        MERGE (f)-[:DEFINES]->(v)\n        RETURN v\n    \"\"\",\n    \n    # -------------------------------------------------------------------------\n    # Relationship Operations\n    # -------------------------------------------------------------------------\n    \"create_call_relationship\": \"\"\"\n        MATCH (caller) WHERE caller.id = $caller_id\n        MATCH (s:Symbol {id: $symbol_id})\n        MERGE (caller)-[r:CALLS {line_number: $line_number}]->(s)\n        ON CREATE SET\n            r.arguments = $arguments,\n            r.column = $column,\n            r.qualified_target = $qualified_target,\n            r.is_resolved = true\n        RETURN r\n    \"\"\",\n\n    \"create_call_relationship_unresolved\": \"\"\"\n        MATCH (caller) WHERE caller.id = $caller_id\n        MERGE (u:UnresolvedSymbol {name: $callee_name, caller_id: $caller_id, line: $line_number})\n        ON CREATE SET u.created_at = datetime()\n        MERGE (caller)-[r:CALLS {line_number: $line_number}]->(u)\n        ON CREATE SET\n            r.arguments = $arguments,\n            r.column = $column,\n            r.is_resolved = false\n        RETURN r\n    \"\"\",\n    \n    \"create_inheritance\": \"\"\"\n        MATCH (child:Class {id: $child_id})\n        MATCH (parent:Class {name: $parent_name})\n        WHERE parent.file_id STARTS WITH split($child_id, ':')[0]\n           OR parent.repo_id = $repo_id\n        MERGE (child)-[:INHERITS]->(parent)\n    \"\"\",\n    \n    \"create_import_relationship\": \"\"\"\n        MATCH (from_file:File {id: $from_file_id})\n        MATCH (to:File {path: $imported_path})\n        WHERE to.repo_id = $repo_id OR to.path CONTAINS $imported_path\n        MERGE (from_file)-[r:IMPORTS {line: $line_number}]->(to)\n        ON CREATE SET r.alias = $alias, r.imported_names = $imported_names\n        RETURN r\n    \"\"\",\n    \n    # -------------------------------------------------------------------------\n    # Query Operations\n    # -------------------------------------------------------------------------\n    \"find_method_usages\": \"\"\"\n        MATCH (m:Method {name: $method_name})\n        OPTIONAL MATCH (caller)-[call:CALLS]->(m)\n        OPTIONAL MATCH (cl:CodeLine)-[ref:REFERENCES]->(m)\n        RETURN m, \n               collect(DISTINCT {caller: caller, line: call.line_number}) as callers,\n               collect(DISTINCT {line: cl, col_start: ref.column_start}) as references\n    \"\"\",\n    \n    \"find_method_context\": \"\"\"\n        MATCH (m:Method {id: $method_id})\n        MATCH (c:Class)-[:HAS_METHOD]->(m)\n        MATCH (f:File)-[:DEFINES]->(c)\n        MATCH (r:Repository)-[:CONTAINS*]->(f)\n        MATCH (u:User)-[:OWNS]->(r)\n        RETURN u.username as user, r.name as repo, f.path as file, \n               c.name as class_name, m.name as method, \n               m.line_start as start_line, m.line_end as end_line\n    \"\"\",\n    \n    \"find_callers\": \"\"\"\n        MATCH (m {name: $name})\n        WHERE m:Method OR m:Function OR m:Class\n        MATCH (caller)-[c:CALLS]->(m)\n        MATCH (f:File)-[:DEFINES*1..2]->(caller)\n        RETURN caller.name as caller_name, labels(caller)[0] as caller_type,\n               f.path as file_path, c.line_number as call_line\n        ORDER BY f.path, c.line_number\n    \"\"\",\n    \n    \"get_class_hierarchy\": \"\"\"\n        MATCH (c:Class {name: $class_name})\n        OPTIONAL MATCH path = (c)-[:INHERITS*]->(parent:Class)\n        OPTIONAL MATCH child_path = (child:Class)-[:INHERITS*]->(c)\n        RETURN c, \n               collect(DISTINCT nodes(path)) as ancestors,\n               collect(DISTINCT nodes(child_path)) as descendants\n    \"\"\",\n    \n    \"get_file_structure\": \"\"\"\n        MATCH (f:File {id: $file_id})\n        \n        // Aggregate methods per class\n        OPTIONAL MATCH (f)-[:DEFINES]->(c:Class)\n        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)\n        WITH f, c, collect(m) as class_methods\n        \n        // Aggregate classes for the file\n        WITH f, collect(CASE WHEN c IS NOT NULL THEN {\n            name: c.name,\n            line_start: c.line_start,\n            line_end: c.line_end,\n            methods: [m in class_methods WHERE m IS NOT NULL | {\n                name: m.name,\n                line_start: m.line_start,\n                line_end: m.line_end,\n                visibility: m.visibility\n            }]\n        } ELSE NULL END) as classes_raw\n        \n        // Filter out nulls\n        WITH f, [x IN classes_raw WHERE x IS NOT NULL] as classes\n        \n        // Collect Functions\n        OPTIONAL MATCH (f)-[:DEFINES]->(fn:Function)\n        WITH f, classes, collect(fn) as functions\n        \n        // Collect Imports\n        OPTIONAL MATCH (f)-[:HAS_IMPORT]->(i:Import)\n        WITH f, classes, functions, collect(i) as imports\n        \n        RETURN f, classes, functions, imports\n    \"\"\",\n    \n    \"get_repo_overview\": \"\"\"\n        MATCH (r:Repository {id: $repo_id})\n        OPTIONAL MATCH (r)-[:CONTAINS*]->(f:File)\n        OPTIONAL MATCH (f)-[:DEFINES]->(c:Class)\n        OPTIONAL MATCH (f)-[:DEFINES]->(fn:Function)\n        RETURN r.name as repo,\n               count(DISTINCT f) as file_count,\n               count(DISTINCT c) as class_count,\n               count(DISTINCT fn) as function_count,\n               collect(DISTINCT f.language) as languages\n    \"\"\",\n\n    \"get_repo_files\": \"\"\"\n        MATCH (r:Repository {id: $repo_id})-[:CONTAINS*]->(f:File)\n        RETURN f, f.language as language, f.lines_count as lines_count\n        ORDER BY f.path\n    \"\"\",\n\n    \"get_module_tree\": \"\"\"\n        MATCH (r:Repository {id: $repo_id})\n        OPTIONAL MATCH path = (r)-[:CONTAINS*]->(m:Module)\n        WITH m, length(path) as depth\n        WHERE m IS NOT NULL\n        RETURN m.path as path,\n               m.name as name,\n               m.parent_path as parent_path,\n               m.is_package as is_package,\n               depth\n        ORDER BY depth, m.path\n    \"\"\",\n\n    \"get_file_hierarchy\": \"\"\"\n        MATCH (f:File {id: $file_id})\n        MATCH path = (r:Repository)-[:CONTAINS*]->(f)\n        WITH nodes(path) as hierarchy\n        UNWIND range(0, size(hierarchy)-1) as idx\n        WITH hierarchy[idx] as node, idx\n        RETURN labels(node)[0] as type,\n               CASE\n                   WHEN 'Repository' IN labels(node) THEN node.name\n                   WHEN 'Module' IN labels(node) THEN node.name\n                   WHEN 'File' IN labels(node) THEN node.name\n               END as name,\n               CASE\n                   WHEN 'Repository' IN labels(node) THEN node.id\n                   WHEN 'Module' IN labels(node) THEN node.path\n                   WHEN 'File' IN labels(node) THEN node.path\n               END as path,\n               idx as depth\n        ORDER BY idx\n    \"\"\",\n\n    \"get_directory_contents\": \"\"\"\n        MATCH (m:Module {repo_id: $repo_id, path: $dir_path})\n        OPTIONAL MATCH (m)-[:CONTAINS]->(child)\n        WHERE child:Module OR child:File\n        RETURN labels(child)[0] as type,\n               child.name as name,\n               CASE\n                   WHEN 'Module' IN labels(child) THEN child.path\n                   WHEN 'File' IN labels(child) THEN child.path\n               END as path,\n               CASE\n                   WHEN 'Module' IN labels(child) THEN child.is_package\n                   ELSE false\n               END as is_package\n        ORDER BY type DESC, name\n    \"\"\",\n\n    # -------------------------------------------------------------------------\n    # Verification and Testing Queries\n    # -------------------------------------------------------------------------\n    \"verify_file_reconstruction\": \"\"\"\n        MATCH (f:File {id: $file_id})\n        RETURN f.path as path,\n               f.source_code IS NOT NULL as has_source,\n               size(f.source_code) as source_size,\n               f.lines_count as lines_count\n    \"\"\",\n\n    \"get_reconstruction_stats\": \"\"\"\n        MATCH (r:Repository {id: $repo_id})-[:CONTAINS*]->(f:File)\n        WITH count(f) as total,\n             sum(CASE WHEN f.source_code IS NOT NULL THEN 1 ELSE 0 END) as with_source,\n             sum(f.lines_count) as total_lines\n        RETURN total as total_files,\n               with_source as files_with_source,\n               total - with_source as files_missing_source,\n               total_lines as total_lines,\n               (with_source * 100.0 / total) as success_rate\n    \"\"\",\n\n    \"test_symbol_resolution\": \"\"\"\n        MATCH (s:Symbol)\n        WHERE s.file_id STARTS WITH $repo_id\n        WITH count(s) as total_symbols,\n             sum(CASE WHEN s.source_code IS NOT NULL THEN 1 ELSE 0 END) as symbols_with_source\n        RETURN total_symbols,\n               symbols_with_source,\n               (symbols_with_source * 100.0 / total_symbols) as symbol_source_rate\n    \"\"\",\n\n    \n    \"search_code\": \"\"\"\n        CALL db.index.fulltext.queryNodes('code_search', $search_term)\n        YIELD node, score\n        MATCH (f:File)-[:DEFINES*1..2]->(node)\n        RETURN node, labels(node)[0] as type, f.path as file, score\n        ORDER BY score DESC\n        LIMIT 20\n    \"\"\",\n\n    \"search_symbols\": \"\"\"\n        CALL db.index.fulltext.queryNodes('symbol_search', $search_term)\n        YIELD node, score\n        RETURN node.name as name,\n               node.qualified_name as qualified_name,\n               node.type as type,\n               node.file_id as file_id,\n               node.line_start as line,\n               node.visibility as visibility,\n               score\n        ORDER BY score DESC\n        LIMIT $limit\n    \"\"\",\n\n    \"search_symbols_by_qualified_name\": \"\"\"\n        MATCH (s:Symbol)\n        WHERE s.qualified_name = $qualified_name\n          AND s.file_id STARTS WITH $repo_id\n        RETURN s.id as id,\n               s.name as name,\n               s.qualified_name as qualified_name,\n               s.type as type,\n               s.file_id as file_id,\n               s.line_start as line_start,\n               s.line_end as line_end,\n               s.scope as scope,\n               s.visibility as visibility,\n               s.docstring as docstring\n        LIMIT 1\n    \"\"\",\n\n    \"autocomplete_symbols\": \"\"\"\n        MATCH (s:Symbol)\n        WHERE s.qualified_name STARTS WITH $prefix\n          AND s.file_id STARTS WITH $repo_id\n        RETURN s.qualified_name as qualified_name,\n               s.type as type,\n               s.visibility as visibility,\n               s.file_id as file_id\n        ORDER BY s.qualified_name\n        LIMIT $limit\n    \"\"\",\n\n    \"find_symbols_in_scope\": \"\"\"\n        MATCH (s:Symbol {file_id: $file_id, scope: $scope})\n        RETURN s.name as name,\n               s.qualified_name as qualified_name,\n               s.type as type,\n               s.line_start as line_start,\n               s.visibility as visibility\n        ORDER BY s.line_start\n    \"\"\",\n    \n    \"analyze_change_impact\": \"\"\"\n        MATCH (target {id: $target_id})\n        MATCH path = (caller)-[:CALLS*1..3]->(target)\n        WITH caller, length(path) as distance\n        MATCH (f:File)-[:DEFINES*1..2]->(caller)\n        RETURN DISTINCT caller.name as affected, labels(caller)[0] as type,\n               f.path as file, distance\n        ORDER BY distance, f.path\n    \"\"\",\n\n    \"analyze_change_impact_enhanced\": \"\"\"\n        MATCH (s:Symbol {qualified_name: $qualified_name})\n        WHERE s.file_id STARTS WITH $repo_id\n\n        // Direct callers\n        OPTIONAL MATCH (direct_caller)-[:CALLS]->(s)\n        OPTIONAL MATCH (direct_file:File)-[:DEFINES*1..2]->(direct_caller)\n\n        // Transitive callers (up to 3 levels)\n        OPTIONAL MATCH path = (transitive_caller)-[:CALLS*2..3]->(s)\n        OPTIONAL MATCH (trans_file:File)-[:DEFINES*1..2]->(transitive_caller)\n\n        // Inheritance impact (for classes/methods)\n        OPTIONAL MATCH (child:Class)-[:INHERITS*]->(parent:Class {name: s.name})\n        OPTIONAL MATCH (inherit_file:File)-[:DEFINES]->(child)\n\n        // Import impact\n        OPTIONAL MATCH (s_file:File {id: s.file_id})<-[:IMPORTS]-(importer:File)\n\n        WITH s,\n             collect(DISTINCT {\n                 name: direct_caller.name,\n                 type: labels(direct_caller)[0],\n                 file: direct_file.path,\n                 line: direct_caller.line_start,\n                 impact_type: 'direct_call',\n                 distance: 1\n             }) as direct_calls,\n             collect(DISTINCT {\n                 name: transitive_caller.name,\n                 type: labels(transitive_caller)[0],\n                 file: trans_file.path,\n                 line: transitive_caller.line_start,\n                 impact_type: 'transitive_call',\n                 distance: length(path)\n             }) as transitive_calls,\n             collect(DISTINCT {\n                 name: child.name,\n                 type: 'Class',\n                 file: inherit_file.path,\n                 line: child.line_start,\n                 impact_type: 'inheritance',\n                 distance: 1\n             }) as inheritance_impact,\n             collect(DISTINCT {\n                 name: importer.name,\n                 type: 'File',\n                 file: importer.path,\n                 line: 1,\n                 impact_type: 'import',\n                 distance: 1\n             }) as import_impact\n\n        RETURN s.qualified_name as target,\n               direct_calls,\n               transitive_calls,\n               inheritance_impact,\n               import_impact,\n               size(direct_calls) + size(transitive_calls) +\n               size(inheritance_impact) + size(import_impact) as total_impact\n    \"\"\",\n\n    \"get_call_graph\": \"\"\"\n        MATCH (s:Symbol {qualified_name: $qualified_name})\n        WHERE s.file_id STARTS WITH $repo_id\n        MATCH path = (s)-[:CALLS*0..$max_depth]->(:Symbol)\n        WITH nodes(path) as call_chain, relationships(path) as calls\n        UNWIND range(0, size(call_chain)-2) as idx\n        RETURN call_chain[idx].qualified_name as caller,\n               call_chain[idx+1].qualified_name as callee,\n               call_chain[idx].type as caller_type,\n               call_chain[idx+1].type as callee_type,\n               calls[idx].line_number as line,\n               idx as depth\n        ORDER BY depth, caller\n    \"\"\",\n    \n    # -------------------------------------------------------------------------\n    # Config File Operations\n    # -------------------------------------------------------------------------\n    \"create_config_file\": \"\"\"\n        MATCH (r:Repository {id: $repo_id})\n        MERGE (cf:ConfigFile {repo_id: $repo_id, path: $path})\n        ON CREATE SET\n            cf.id = $config_id,\n            cf.file_type = $file_type,\n            cf.sha = $sha,\n            cf.lines_count = $lines_count,\n            cf.project_name = $project_name,\n            cf.version = $version,\n            cf.description = $description,\n            cf.source_code = $source_code,\n            cf.created_at = datetime()\n        ON MATCH SET\n            cf.sha = $sha,\n            cf.lines_count = $lines_count,\n            cf.project_name = $project_name,\n            cf.version = $version,\n            cf.description = $description,\n            cf.source_code = $source_code,\n            cf.updated_at = datetime()\n        MERGE (r)-[:HAS_CONFIG]->(cf)\n        RETURN cf.id as config_id\n    \"\"\",\n    \n    \"create_dependency\": \"\"\"\n        MATCH (cf:ConfigFile {id: $config_id})\n        MERGE (d:Dependency {config_id: $config_id, name: $name})\n        ON CREATE SET\n            d.id = $dep_id,\n            d.version_spec = $version_spec,\n            d.is_dev = $is_dev,\n            d.source = $source,\n            d.extras = $extras,\n            d.created_at = datetime()\n        ON MATCH SET\n            d.version_spec = $version_spec,\n            d.is_dev = $is_dev,\n            d.source = $source,\n            d.extras = $extras,\n            d.updated_at = datetime()\n        MERGE (cf)-[:HAS_DEPENDENCY]->(d)\n        RETURN d.id as dep_id\n    \"\"\",\n    \n    \"create_script\": \"\"\"\n        MATCH (cf:ConfigFile {id: $config_id})\n        MERGE (s:Script {config_id: $config_id, name: $name})\n        ON CREATE SET\n            s.id = $script_id,\n            s.command = $command,\n            s.created_at = datetime()\n        ON MATCH SET\n            s.command = $command,\n            s.updated_at = datetime()\n        MERGE (cf)-[:HAS_SCRIPT]->(s)\n        RETURN s.id as script_id\n    \"\"\",\n    \n    \"get_repo_config_files\": \"\"\"\n        MATCH (r:Repository {id: $repo_id})-[:HAS_CONFIG]->(cf:ConfigFile)\n        RETURN cf.id as id, cf.path as path, cf.file_type as file_type,\n               cf.project_name as project_name, cf.version as version\n        ORDER BY cf.path\n    \"\"\",\n    \n    \"get_repo_dependencies\": \"\"\"\n        MATCH (r:Repository {id: $repo_id})-[:HAS_CONFIG]->(cf:ConfigFile)-[:HAS_DEPENDENCY]->(d:Dependency)\n        RETURN d.name as name, d.version_spec as version, d.is_dev as is_dev,\n               d.source as source, cf.path as config_file\n        ORDER BY d.is_dev, d.name\n    \"\"\",\n    \n    \"get_config_file_details\": \"\"\"\n        MATCH (cf:ConfigFile {id: $config_id})\n        OPTIONAL MATCH (cf)-[:HAS_DEPENDENCY]->(d:Dependency)\n        OPTIONAL MATCH (cf)-[:HAS_SCRIPT]->(s:Script)\n        RETURN cf,\n               collect(DISTINCT d) as dependencies,\n               collect(DISTINCT s) as scripts\n    \"\"\",\n\n    # -------------------------------------------------------------------------\n    # Batch Operations (Performance Optimization)\n    # -------------------------------------------------------------------------\n    \"batch_create_classes\": \"\"\"\n        UNWIND $classes as cls\n        MATCH (f:File {id: $file_id})\n        MERGE (c:Class {file_id: $file_id, name: cls.name, line_start: cls.line_start})\n        ON CREATE SET\n            c.id = cls.class_id,\n            c.line_end = cls.line_end,\n            c.docstring = cls.docstring,\n            c.decorators = cls.decorators,\n            c.base_classes = cls.base_classes,\n            c.is_abstract = cls.is_abstract,\n            c.source_code = cls.source_code,\n            c.qualified_name = cls.qualified_name,\n            c.visibility = cls.visibility\n        ON MATCH SET\n            c.source_code = cls.source_code,\n            c.docstring = cls.docstring\n        MERGE (f)-[:DEFINES]->(c)\n\n        // Create Symbol\n        MERGE (s:Symbol {id: 'symbol:' + cls.qualified_name})\n        ON CREATE SET\n            s.name = cls.name,\n            s.qualified_name = cls.qualified_name,\n            s.type = 'class',\n            s.scope = 'module',\n            s.file_id = $file_id,\n            s.line_start = cls.line_start,\n            s.line_end = cls.line_end,\n            s.visibility = cls.visibility,\n            s.docstring = cls.docstring,\n            s.created_at = datetime()\n        ON MATCH SET\n            s.line_start = cls.line_start,\n            s.line_end = cls.line_end,\n            s.updated_at = datetime()\n        MERGE (s)-[:REFERENCES]->(c)\n\n        RETURN c.id as class_id\n    \"\"\",\n\n    \"batch_create_methods\": \"\"\"\n        UNWIND $methods as m\n        MATCH (c:Class {id: $class_id})\n        MERGE (method:Method {class_id: $class_id, name: m.name, line_start: m.line_start})\n        ON CREATE SET\n            method.id = m.method_id,\n            method.line_end = m.line_end,\n            method.params = m.params,\n            method.return_type = m.return_type,\n            method.docstring = m.docstring,\n            method.decorators = m.decorators,\n            method.is_async = m.is_async,\n            method.is_static = m.is_static,\n            method.is_classmethod = m.is_classmethod,\n            method.is_property = m.is_property,\n            method.visibility = m.visibility,\n            method.source_code = m.source_code,\n            method.qualified_name = m.qualified_name\n        ON MATCH SET\n            method.source_code = m.source_code,\n            method.docstring = m.docstring\n        MERGE (c)-[:HAS_METHOD]->(method)\n\n        // Create Symbol\n        MERGE (s:Symbol {id: 'symbol:' + m.qualified_name})\n        ON CREATE SET\n            s.name = m.name,\n            s.qualified_name = m.qualified_name,\n            s.type = 'method',\n            s.scope = 'class',\n            // Retrieve file_id from class_id which is typically file_id:class:ClassName\n            s.file_id = split($class_id, ':class:')[0],\n            s.line_start = m.line_start,\n            s.line_end = m.line_end,\n            s.visibility = m.visibility,\n            s.docstring = m.docstring,\n            s.created_at = datetime()\n        ON MATCH SET\n            s.line_start = m.line_start,\n            s.line_end = m.line_end,\n            s.updated_at = datetime()\n        MERGE (s)-[:REFERENCES]->(method)\n\n        RETURN method.id as method_id\n    \"\"\",\n\n    \"batch_create_functions\": \"\"\"\n        UNWIND $functions as fn\n        MATCH (f:File {id: $file_id})\n        MERGE (func:Function {file_id: $file_id, name: fn.name, line_start: fn.line_start})\n        ON CREATE SET\n            func.id = fn.function_id,\n            func.line_end = fn.line_end,\n            func.params = fn.params,\n            func.return_type = fn.return_type,\n            func.docstring = fn.docstring,\n            func.decorators = fn.decorators,\n            func.is_async = fn.is_async,\n            func.source_code = fn.source_code,\n            func.qualified_name = fn.qualified_name,\n            func.visibility = fn.visibility\n        ON MATCH SET\n            func.source_code = fn.source_code,\n            func.docstring = fn.docstring\n        MERGE (f)-[:DEFINES]->(func)\n\n        // Create Symbol\n        MERGE (s:Symbol {id: 'symbol:' + fn.qualified_name})\n        ON CREATE SET\n            s.name = fn.name,\n            s.qualified_name = fn.qualified_name,\n            s.type = 'function',\n            s.scope = 'module',\n            s.file_id = $file_id,\n            s.line_start = fn.line_start,\n            s.line_end = fn.line_end,\n            s.visibility = fn.visibility,\n            s.docstring = fn.docstring,\n            s.created_at = datetime()\n        ON MATCH SET\n            s.line_start = fn.line_start,\n            s.line_end = fn.line_end,\n            s.updated_at = datetime()\n        MERGE (s)-[:REFERENCES]->(func)\n\n        RETURN func.id as function_id\n    \"\"\",\n\n    \"batch_create_imports\": \"\"\"\n        UNWIND $imports as imp\n        MATCH (f:File {id: $file_id})\n        MERGE (i:Import {file_id: $file_id, module: imp.module, line_start: imp.line_start})\n        ON CREATE SET \n            i.alias = imp.alias,\n            i.line_end = imp.line_end,\n            i.is_from_import = imp.is_from_import,\n            i.imported_names = imp.imported_names\n        MERGE (f)-[:HAS_IMPORT]->(i)\n        RETURN i.module as module\n    \"\"\",\n\n    \"batch_create_variables\": \"\"\"\n        UNWIND $variables as v\n        MATCH (f:File {id: $file_id})\n        MERGE (var:Variable {file_id: $file_id, name: v.name, line_start: v.line_start})\n        ON CREATE SET \n            var.id = v.variable_id,\n            var.line_end = v.line_end,\n            var.type_annotation = v.type_annotation,\n            var.is_constant = v.is_constant,\n            var.scope = v.scope\n        MERGE (f)-[:DEFINES]->(var)\n        RETURN var.id as variable_id\n    \"\"\",\n\n    \"batch_create_call_relationships\": \"\"\"\n        UNWIND $calls as call\n        MATCH (caller) WHERE caller.id = call.caller_id\n\n        // Try to find target: Methods don't have file_id, so match them separately\n        OPTIONAL MATCH (target)\n        WHERE target.name = call.callee_name\n          AND (\n            // For Classes and Functions, check file_id\n            (\n              (target:Class OR target:Function)\n              AND target.file_id STARTS WITH $repo_id\n            )\n            OR\n            // For Methods, check through their class relationship\n            (\n              target:Method\n              AND exists((target)<-[:HAS_METHOD]-(:Class)-[:DEFINES]-(:File))\n            )\n          )\n\n        WITH caller, call, target\n\n        FOREACH (_ IN CASE WHEN target IS NOT NULL THEN [1] ELSE [] END |\n            MERGE (caller)-[r:CALLS {line_number: call.line_number}]->(target)\n            ON CREATE SET\n                r.arguments = call.arguments,\n                r.column = call.column,\n                r.is_resolved = true\n        )\n        FOREACH (_ IN CASE WHEN target IS NULL THEN [1] ELSE [] END |\n            MERGE (u:UnresolvedSymbol {name: call.callee_name})\n            ON CREATE SET u.created_at = datetime()\n            MERGE (caller)-[r:CALLS {line_number: call.line_number}]->(u)\n            ON CREATE SET r.is_resolved = false, r.arguments = call.arguments, r.column = call.column\n        )\n        RETURN call.callee_name as callee\n    \"\"\",\n\n    \"batch_create_inheritance\": \"\"\"\n        UNWIND $relationships as rel\n        MATCH (child:Class {id: rel.child_id})\n        OPTIONAL MATCH (parent:Class {name: rel.parent_name})\n        WHERE parent.file_id STARTS WITH $repo_id OR parent.repo_id = $repo_id\n        WITH child, parent\n        WHERE parent IS NOT NULL\n        MERGE (child)-[:INHERITS]->(parent)\n        RETURN child.id as child_id\n    \"\"\",\n}\n","structuredPatch":[{"oldStart":811,"oldLines":22,"newStart":811,"newLines":32,"lines":["     \"search_code\": \"\"\"","         CALL db.index.fulltext.queryNodes('code_search', $search_term)","         YIELD node, score","-        MATCH (f:File)-[:DEFINES*1..2]->(node)","-        RETURN node, labels(node)[0] as type, f.path as file, score","+        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)","+        RETURN","+            CASE WHEN node:Function THEN 'function'","+                 WHEN node:Class THEN 'class'","+                 ELSE 'variable' END as type,","+            node.name as name,","+            coalesce(f.path, node.path) as path,","+            coalesce(node.line_number, 0) as line_number,","+            score","         ORDER BY score DESC","         LIMIT 20","     \"\"\","," ","     \"search_symbols\": \"\"\"","-        CALL db.index.fulltext.queryNodes('symbol_search', $search_term)","+        CALL db.index.fulltext.queryNodes('code_search', $search_term)","         YIELD node, score","-        RETURN node.name as name,","-               node.qualified_name as qualified_name,","-               node.type as type,","-               node.file_id as file_id,","-               node.line_start as line,","-               node.visibility as visibility,","-               score","+        WHERE node:Function OR node:Class OR node:Variable","+        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)","+        RETURN","+            node.name as name,","+            CASE WHEN node:Function THEN 'function'","+                 WHEN node:Class THEN 'class'","+                 ELSE 'variable' END as type,","+            coalesce(f.path, node.path) as path,","+            coalesce(node.line_number, 0) as line_number,","+            score","         ORDER BY score DESC","         LIMIT $limit","     \"\"\","]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"600b5f6d-d85d-4d3c-876d-de6c9ed7864a"}
{"parentUuid":"9aeaa23b-683b-4ed1-a193-0db5915225e8","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01MhfEa3RdXBccgEoirqPuQG","type":"message","role":"assistant","content":[{"type":"text","text":"**Step 2: Fix `search_code` and `search_symbols` methods in `db/queries.py`, and add `search_file_content` + `peek_file_lines`**"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":722,"cache_read_input_tokens":88807,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":722},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLtrmMT9B8EaYDQMBpmD","type":"assistant","uuid":"2658c34b-f806-45fc-8f84-ef9469a71be6","timestamp":"2026-02-21T08:25:35.845Z"}
{"parentUuid":"2658c34b-f806-45fc-8f84-ef9469a71be6","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01MhfEa3RdXBccgEoirqPuQG","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017zEWT3jfvCuo6at3t4r28F","name":"Edit","input":{"replace_all":false,"file_path":"/Users/skmabudalam/Documents/BugViper/db/queries.py","old_string":"    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n        \"\"\"Search for code by name or docstring.\"\"\"\n        # Escape Lucene special characters to prevent query parsing errors\n        escaped_term = self._escape_lucene_query(search_term)\n\n        query = CYPHER_QUERIES[\"search_code\"]\n        records, _, _ = self.db.run_query(query, {\"search_term\": escaped_term})\n\n        return [\n            {\n                \"node\": dict(record[\"node\"]) if record[\"node\"] else None,\n                \"type\": record[\"type\"],\n                \"file\": record[\"file\"],\n                \"score\": record[\"score\"]\n            }\n            for record in records\n        ]\n\n    def search_symbols(\n        self,\n        search_term: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search symbols using fulltext index.\n\n        Args:\n            search_term: Search query (supports fuzzy matching)\n            limit: Maximum results to return\n\n        Returns:\n            List of matching symbols with scores\n        \"\"\"\n        query = CYPHER_QUERIES[\"search_symbols\"]\n        records, _, _ = self.db.run_query(query, {\n            \"search_term\": search_term,\n            \"limit\": limit\n        })\n\n        return [\n            {\n                \"name\": record[\"name\"],\n                \"qualified_name\": record[\"qualified_name\"],\n                \"type\": record[\"type\"],\n                \"file_id\": record[\"file_id\"],\n                \"line\": record[\"line\"],\n                \"visibility\": record[\"visibility\"],\n                \"score\": record[\"score\"]\n            }\n            for record in records\n        ]","new_string":"    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n        \"\"\"Search for code by name or docstring using fulltext index with CONTAINS fallback.\"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        results: List[Dict[str, Any]] = []\n        try:\n            query = CYPHER_QUERIES[\"search_code\"]\n            records, _, _ = self.db.run_query(query, {\"search_term\": escaped_term})\n            results = [\n                {\n                    \"type\": record[\"type\"],\n                    \"name\": record[\"name\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"Fulltext search failed, falling back to CONTAINS: %s\", e)\n\n        if not results:\n            fallback = \"\"\"\n            MATCH (node)\n            WHERE (node:Function OR node:Class OR node:Variable)\n              AND node.name CONTAINS $search_term\n            OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n            RETURN\n                CASE WHEN node:Function THEN 'function'\n                     WHEN node:Class THEN 'class'\n                     ELSE 'variable' END as type,\n                node.name as name,\n                coalesce(f.path, node.path) as path,\n                coalesce(node.line_number, 0) as line_number,\n                1.0 as score\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})\n            results = [\n                {\n                    \"type\": record[\"type\"],\n                    \"name\": record[\"name\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n\n        return results\n\n    def search_symbols(\n        self,\n        search_term: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Search symbols (Function/Class/Variable) using fulltext index with CONTAINS fallback.\"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        results: List[Dict[str, Any]] = []\n        try:\n            query = CYPHER_QUERIES[\"search_symbols\"]\n            records, _, _ = self.db.run_query(query, {\n                \"search_term\": escaped_term,\n                \"limit\": limit,\n            })\n            results = [\n                {\n                    \"name\": record[\"name\"],\n                    \"type\": record[\"type\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"Symbol fulltext search failed, falling back to CONTAINS: %s\", e)\n\n        if not results:\n            fallback = \"\"\"\n            MATCH (node)\n            WHERE (node:Function OR node:Class OR node:Variable)\n              AND node.name CONTAINS $search_term\n            OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n            RETURN\n                node.name as name,\n                CASE WHEN node:Function THEN 'function'\n                     WHEN node:Class THEN 'class'\n                     ELSE 'variable' END as type,\n                coalesce(f.path, node.path) as path,\n                coalesce(node.line_number, 0) as line_number,\n                1.0 as score\n            ORDER BY node.name\n            LIMIT $limit\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term, \"limit\": limit})\n            results = [\n                {\n                    \"name\": record[\"name\"],\n                    \"type\": record[\"type\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n\n        return results\n\n    def search_file_content(self, search_term: str, limit: int = 50) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search file source code line by line.\n        Uses file_content_search fulltext index to find candidate files,\n        then scans lines in Python to find the exact matching lines.\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n        file_records: List[Dict[str, Any]] = []\n\n        try:\n            ft_query = \"\"\"\n            CALL db.index.fulltext.queryNodes('file_content_search', $search_term) YIELD node, score\n            WHERE node.source_code IS NOT NULL\n            RETURN node.path as path, node.source_code as source_code, score\n            ORDER BY score DESC\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(ft_query, {\"search_term\": escaped_term})\n            file_records = [dict(r) for r in records]\n        except Exception as e:\n            logger.warning(\"file_content_search index failed, falling back to CONTAINS: %s\", e)\n\n        if not file_records:\n            fallback = \"\"\"\n            MATCH (f:File)\n            WHERE f.source_code CONTAINS $search_term\n            RETURN f.path as path, f.source_code as source_code, 1.0 as score\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})\n            file_records = [dict(r) for r in records]\n\n        results: List[Dict[str, Any]] = []\n        term_lower = search_term.lower()\n        for rec in file_records:\n            path = rec.get(\"path\")\n            source = rec.get(\"source_code\")\n            if not path or not source:\n                continue\n            for i, line in enumerate(source.split(\"\\n\")):\n                if search_term in line or term_lower in line.lower():\n                    results.append({\n                        \"path\": path,\n                        \"line_number\": i + 1,\n                        \"match_line\": line.rstrip(),\n                    })\n                    if len(results) >= limit:\n                        return results\n        return results\n\n    def peek_file_lines(\n        self,\n        path: str,\n        line: int,\n        above: int = 10,\n        below: int = 10,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Return a window of lines around `line` in the given file.\n        Lines are 1-indexed. The anchor line is flagged with is_anchor=True.\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {path: $path})\n        RETURN f.source_code as source_code\n        LIMIT 1\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"path\": path})\n        if not records or not records[0].get(\"source_code\"):\n            return {\"error\": \"File not found\", \"path\": path}\n\n        lines = records[0][\"source_code\"].split(\"\\n\")\n        total = len(lines)\n        start = max(0, line - above - 1)   # 0-indexed inclusive\n        end = min(total, line + below)       # 0-indexed exclusive\n\n        window = [\n            {\n                \"line_number\": i + 1,\n                \"content\": lines[i],\n                \"is_anchor\": (i + 1) == line,\n            }\n            for i in range(start, end)\n        ]\n\n        return {\n            \"path\": path,\n            \"anchor_line\": line,\n            \"window\": window,\n            \"total_lines\": total,\n        }"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":722,"cache_read_input_tokens":88807,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":722},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLtrmMT9B8EaYDQMBpmD","type":"assistant","uuid":"22ba6ca2-6f56-4c75-9e74-262e62ee7d8a","timestamp":"2026-02-21T08:26:01.467Z"}
{"type":"file-history-snapshot","messageId":"22ba6ca2-6f56-4c75-9e74-262e62ee7d8a","snapshot":{"messageId":"c24e474a-29dd-4bc8-afe3-07caafdf094e","trackedFileBackups":{"db/schema.py":{"backupFileName":"283975a9ba984ffc@v1","version":1,"backupTime":"2026-02-21T08:25:31.646Z"},"db/queries.py":{"backupFileName":"3dbb7f971a633538@v1","version":1,"backupTime":"2026-02-21T08:31:28.475Z"}},"timestamp":"2026-02-21T08:05:38.177Z"},"isSnapshotUpdate":true}
{"parentUuid":"22ba6ca2-6f56-4c75-9e74-262e62ee7d8a","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_017zEWT3jfvCuo6at3t4r28F","toolUseID":"toolu_017zEWT3jfvCuo6at3t4r28F","timestamp":"2026-02-21T08:31:28.495Z","uuid":"92a9f90b-306b-410b-85e4-f1b926d395f0"}
{"parentUuid":"22ba6ca2-6f56-4c75-9e74-262e62ee7d8a","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017zEWT3jfvCuo6at3t4r28F","type":"tool_result","content":"The file /Users/skmabudalam/Documents/BugViper/db/queries.py has been updated successfully."}]},"uuid":"ea6707c3-e0c5-4279-949b-d683001239ff","timestamp":"2026-02-21T08:31:28.492Z","toolUseResult":{"filePath":"/Users/skmabudalam/Documents/BugViper/db/queries.py","oldString":"    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n        \"\"\"Search for code by name or docstring.\"\"\"\n        # Escape Lucene special characters to prevent query parsing errors\n        escaped_term = self._escape_lucene_query(search_term)\n\n        query = CYPHER_QUERIES[\"search_code\"]\n        records, _, _ = self.db.run_query(query, {\"search_term\": escaped_term})\n\n        return [\n            {\n                \"node\": dict(record[\"node\"]) if record[\"node\"] else None,\n                \"type\": record[\"type\"],\n                \"file\": record[\"file\"],\n                \"score\": record[\"score\"]\n            }\n            for record in records\n        ]\n\n    def search_symbols(\n        self,\n        search_term: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search symbols using fulltext index.\n\n        Args:\n            search_term: Search query (supports fuzzy matching)\n            limit: Maximum results to return\n\n        Returns:\n            List of matching symbols with scores\n        \"\"\"\n        query = CYPHER_QUERIES[\"search_symbols\"]\n        records, _, _ = self.db.run_query(query, {\n            \"search_term\": search_term,\n            \"limit\": limit\n        })\n\n        return [\n            {\n                \"name\": record[\"name\"],\n                \"qualified_name\": record[\"qualified_name\"],\n                \"type\": record[\"type\"],\n                \"file_id\": record[\"file_id\"],\n                \"line\": record[\"line\"],\n                \"visibility\": record[\"visibility\"],\n                \"score\": record[\"score\"]\n            }\n            for record in records\n        ]","newString":"    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n        \"\"\"Search for code by name or docstring using fulltext index with CONTAINS fallback.\"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        results: List[Dict[str, Any]] = []\n        try:\n            query = CYPHER_QUERIES[\"search_code\"]\n            records, _, _ = self.db.run_query(query, {\"search_term\": escaped_term})\n            results = [\n                {\n                    \"type\": record[\"type\"],\n                    \"name\": record[\"name\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"Fulltext search failed, falling back to CONTAINS: %s\", e)\n\n        if not results:\n            fallback = \"\"\"\n            MATCH (node)\n            WHERE (node:Function OR node:Class OR node:Variable)\n              AND node.name CONTAINS $search_term\n            OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n            RETURN\n                CASE WHEN node:Function THEN 'function'\n                     WHEN node:Class THEN 'class'\n                     ELSE 'variable' END as type,\n                node.name as name,\n                coalesce(f.path, node.path) as path,\n                coalesce(node.line_number, 0) as line_number,\n                1.0 as score\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})\n            results = [\n                {\n                    \"type\": record[\"type\"],\n                    \"name\": record[\"name\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n\n        return results\n\n    def search_symbols(\n        self,\n        search_term: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Search symbols (Function/Class/Variable) using fulltext index with CONTAINS fallback.\"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        results: List[Dict[str, Any]] = []\n        try:\n            query = CYPHER_QUERIES[\"search_symbols\"]\n            records, _, _ = self.db.run_query(query, {\n                \"search_term\": escaped_term,\n                \"limit\": limit,\n            })\n            results = [\n                {\n                    \"name\": record[\"name\"],\n                    \"type\": record[\"type\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"Symbol fulltext search failed, falling back to CONTAINS: %s\", e)\n\n        if not results:\n            fallback = \"\"\"\n            MATCH (node)\n            WHERE (node:Function OR node:Class OR node:Variable)\n              AND node.name CONTAINS $search_term\n            OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n            RETURN\n                node.name as name,\n                CASE WHEN node:Function THEN 'function'\n                     WHEN node:Class THEN 'class'\n                     ELSE 'variable' END as type,\n                coalesce(f.path, node.path) as path,\n                coalesce(node.line_number, 0) as line_number,\n                1.0 as score\n            ORDER BY node.name\n            LIMIT $limit\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term, \"limit\": limit})\n            results = [\n                {\n                    \"name\": record[\"name\"],\n                    \"type\": record[\"type\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n\n        return results\n\n    def search_file_content(self, search_term: str, limit: int = 50) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search file source code line by line.\n        Uses file_content_search fulltext index to find candidate files,\n        then scans lines in Python to find the exact matching lines.\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n        file_records: List[Dict[str, Any]] = []\n\n        try:\n            ft_query = \"\"\"\n            CALL db.index.fulltext.queryNodes('file_content_search', $search_term) YIELD node, score\n            WHERE node.source_code IS NOT NULL\n            RETURN node.path as path, node.source_code as source_code, score\n            ORDER BY score DESC\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(ft_query, {\"search_term\": escaped_term})\n            file_records = [dict(r) for r in records]\n        except Exception as e:\n            logger.warning(\"file_content_search index failed, falling back to CONTAINS: %s\", e)\n\n        if not file_records:\n            fallback = \"\"\"\n            MATCH (f:File)\n            WHERE f.source_code CONTAINS $search_term\n            RETURN f.path as path, f.source_code as source_code, 1.0 as score\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})\n            file_records = [dict(r) for r in records]\n\n        results: List[Dict[str, Any]] = []\n        term_lower = search_term.lower()\n        for rec in file_records:\n            path = rec.get(\"path\")\n            source = rec.get(\"source_code\")\n            if not path or not source:\n                continue\n            for i, line in enumerate(source.split(\"\\n\")):\n                if search_term in line or term_lower in line.lower():\n                    results.append({\n                        \"path\": path,\n                        \"line_number\": i + 1,\n                        \"match_line\": line.rstrip(),\n                    })\n                    if len(results) >= limit:\n                        return results\n        return results\n\n    def peek_file_lines(\n        self,\n        path: str,\n        line: int,\n        above: int = 10,\n        below: int = 10,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Return a window of lines around `line` in the given file.\n        Lines are 1-indexed. The anchor line is flagged with is_anchor=True.\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {path: $path})\n        RETURN f.source_code as source_code\n        LIMIT 1\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"path\": path})\n        if not records or not records[0].get(\"source_code\"):\n            return {\"error\": \"File not found\", \"path\": path}\n\n        lines = records[0][\"source_code\"].split(\"\\n\")\n        total = len(lines)\n        start = max(0, line - above - 1)   # 0-indexed inclusive\n        end = min(total, line + below)       # 0-indexed exclusive\n\n        window = [\n            {\n                \"line_number\": i + 1,\n                \"content\": lines[i],\n                \"is_anchor\": (i + 1) == line,\n            }\n            for i in range(start, end)\n        ]\n\n        return {\n            \"path\": path,\n            \"anchor_line\": line,\n            \"window\": window,\n            \"total_lines\": total,\n        }","originalFile":"\n\nfrom typing import Dict, List, Any, Optional\nimport re\nimport logging\n\nfrom .client import Neo4jClient\nfrom .schema import CYPHER_QUERIES\n\nlogger = logging.getLogger(__name__)\n\nclass CodeQueryService:\n    \"\"\"\n    Service for querying code elements from the Neo4j graph.\n    \n    Provides methods for:\n    - Finding method/function usages and callers\n    - Analyzing class hierarchies\n    - Searching code by name or content\n    - Reconstructing files from the graph\n    \"\"\"\n    \n    def __init__(self, client: Neo4jClient):\n        self.db = client\n    \n    # =========================================================================\n    # Graph Statistics\n    # =========================================================================\n    \n    def get_graph_stats(self) -> Dict[str, int]:\n        \"\"\"Get statistics about the code graph.\"\"\"\n        query = CYPHER_QUERIES[\"get_graph_stats\"]\n        records, _, _ = self.db.run_query(query)\n        \n        if records:\n            return dict(records[0])\n        return {}\n\n    def list_repositories(self) -> List[Dict[str, Any]]:\n        \"\"\"List all repositories in the database.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        OPTIONAL MATCH (r)-[:CONTAINS*]->(f:File)\n        RETURN r.id as id, r.name as name, r.owner as owner,\n               r.url as url, r.path as local_path,\n               r.last_commit_hash as last_commit,\n               r.created_at as created_at,\n               r.updated_at as updated_at,\n               count(DISTINCT f) as file_count\n        ORDER BY r.updated_at DESC, r.name\n        \"\"\"\n        records, _, _ = self.db.run_query(query)\n        \n        def convert_datetime(value):\n            \"\"\"Convert Neo4j DateTime to ISO string format.\"\"\"\n            if value is None:\n                return None\n            # Check if it's a Neo4j DateTime object\n            if hasattr(value, 'iso_format'):\n                return value.iso_format()\n            # If it's already a string or other type, return as is\n            return str(value) if value is not None else None\n        \n        return [\n            {\n                \"id\": record.get(\"id\"),\n                \"name\": record.get(\"name\"),\n                \"owner\": record.get(\"owner\"),\n                \"url\": record.get(\"url\"),\n                \"local_path\": record.get(\"local_path\"),\n                \"last_commit\": record.get(\"last_commit\"),\n                \"created_at\": convert_datetime(record.get(\"created_at\")),\n                \"updated_at\": convert_datetime(record.get(\"updated_at\")),\n                \"file_count\": record.get(\"file_count\") or 0\n            }\n            for record in records\n        ]\n\n    def delete_repository(self, repo_id: str) -> bool:\n        \"\"\"Delete a repository and all its associated data.\"\"\"\n        try:\n            query = \"\"\"\n            MATCH (r:Repository)\n            WHERE r.id = $repo_id OR r.repo = $repo_id\n            OPTIONAL MATCH (r)-[:CONTAINS*]->(n)\n            DETACH DELETE r, n\n            RETURN count(r) as deleted_count\n            \"\"\"\n            records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n            return records and records[0][\"deleted_count\"] > 0\n        except Exception as e:\n            logger.error(\"Error deleting repository %s: %s\", repo_id, e)\n            return False\n    \n    def get_repository_stats(self, repo_id: str) -> Dict[str, Any]:\n        \"\"\"Get statistics for a specific repository.\"\"\"\n        if not self.db.connected:\n            # Return mock stats\n            return {\n                \"files\": 25,\n                \"classes\": 12,\n                \"functions\": 89,\n                \"methods\": 156,\n                \"lines\": 3420,\n                \"imports\": 67,\n                \"languages\": [\"Python\", \"TypeScript\", \"JavaScript\"]\n            }\n            \n        query = CYPHER_QUERIES[\"get_repo_stats\"]\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        \n        if records:\n            record = records[0]\n            return {\n                \"files\": record[\"file_count\"],\n                \"classes\": record[\"class_count\"],\n                \"functions\": record[\"function_count\"],\n                \"methods\": record[\"method_count\"],\n                \"lines\": record[\"line_count\"],\n                \"imports\": record[\"import_count\"],\n                \"languages\": record[\"languages\"]\n            }\n        return {}\n    \n    # =========================================================================\n    # Method and Function Queries\n    # =========================================================================\n    \n    def find_method_usages(self, method_name: str) -> Dict[str, Any]:\n        \"\"\"Find all usages of a method by name.\"\"\"\n        query = CYPHER_QUERIES[\"find_method_usages\"]\n        records, _, _ = self.db.run_query(query, {\"method_name\": method_name})\n\n        results = []\n        for record in records:\n            # Convert Neo4j Node objects to dictionaries for JSON serialization\n            callers = []\n            for caller_dict in record[\"callers\"]:\n                if caller_dict and caller_dict.get(\"caller\"):\n                    callers.append({\n                        \"caller\": dict(caller_dict[\"caller\"]) if hasattr(caller_dict[\"caller\"], \"__iter__\") and not isinstance(caller_dict[\"caller\"], str) else {\"name\": str(caller_dict[\"caller\"])},\n                        \"line\": caller_dict.get(\"line\")\n                    })\n\n            references = []\n            for ref_dict in record[\"references\"]:\n                if ref_dict and ref_dict.get(\"line\"):\n                    references.append({\n                        \"line\": dict(ref_dict[\"line\"]) if hasattr(ref_dict[\"line\"], \"__iter__\") and not isinstance(ref_dict[\"line\"], str) else {\"line\": str(ref_dict[\"line\"])},\n                        \"col_start\": ref_dict.get(\"col_start\")\n                    })\n\n            results.append({\n                \"method\": dict(record[\"m\"]) if record[\"m\"] else None,\n                \"callers\": callers,\n                \"references\": references\n            })\n        return {\"usages\": results}\n    \n    def find_method_context(self, method_id: str) -> Dict[str, Any]:\n        \"\"\"Find the full context of a method (class, file, repo, user).\"\"\"\n        query = CYPHER_QUERIES[\"find_method_context\"]\n        records, _, _ = self.db.run_query(query, {\"method_id\": method_id})\n        \n        if records:\n            record = records[0]\n            return {\n                \"user\": record[\"user\"],\n                \"repo\": record[\"repo\"],\n                \"file\": record[\"file\"],\n                \"class\": record[\"class_name\"],\n                \"method\": record[\"method\"],\n                \"lines\": f\"{record['start_line']}-{record['end_line']}\"\n            }\n        return {}\n    \n    def find_callers(self, symbol_name: str) -> List[Dict[str, Any]]:\n        \"\"\"Find all methods/functions that call a specific symbol.\"\"\"\n        query = CYPHER_QUERIES[\"find_callers\"]\n        records, _, _ = self.db.run_query(query, {\"name\": symbol_name})\n        \n        return [\n            {\n                \"caller\": record[\"caller_name\"],\n                \"type\": record[\"caller_type\"],\n                \"file\": record[\"file_path\"],\n                \"line\": record[\"call_line\"]\n            }\n            for record in records\n        ]\n    \n    # =========================================================================\n    # Class Queries\n    # =========================================================================\n    \n    def get_class_hierarchy(self, class_name: str) -> Dict[str, Any]:\n        \"\"\"Get the inheritance hierarchy of a class.\"\"\"\n        query = CYPHER_QUERIES[\"get_class_hierarchy\"]\n        records, _, _ = self.db.run_query(query, {\"class_name\": class_name})\n        \n        if records:\n            record = records[0]\n            return {\n                \"class\": dict(record[\"c\"]) if record[\"c\"] else None,\n                \"ancestors\": [dict(n) for n in record[\"ancestors\"]] if record[\"ancestors\"] else [],\n                \"descendants\": [dict(n) for n in record[\"descendants\"]] if record[\"descendants\"] else []\n            }\n        return {}\n    \n    # =========================================================================\n    # File Queries\n    # =========================================================================\n    \n    def get_file_structure(self, file_id: str) -> Dict[str, Any]:\n        \"\"\"Get the structure of a file (classes, functions, imports).\"\"\"\n        query = CYPHER_QUERIES[\"get_file_structure\"]\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n        \n        if records:\n            record = records[0]\n            return {\n                \"file\": dict(record[\"f\"]) if record[\"f\"] else None,\n                \"classes\": record[\"classes\"],\n                \"functions\": [dict(f) for f in record[\"functions\"]] if record[\"functions\"] else [],\n                \"imports\": [dict(i) for i in record[\"imports\"]] if record[\"imports\"] else []\n            }\n        return {}\n    \n    def get_repo_overview(self, repo_id: str) -> Dict[str, Any]:\n        \"\"\"Get an overview of a repository.\"\"\"\n        if not self.db.connected:\n            # Return mock overview\n            return {\n                \"repo\": {\n                    \"id\": repo_id,\n                    \"name\": repo_id.split(\"/\")[-1] if \"/\" in repo_id else repo_id,\n                    \"owner\": repo_id.split(\"/\")[0] if \"/\" in repo_id else \"unknown\"\n                },\n                \"files\": 25,\n                \"classes\": 12,\n                \"functions\": 89,\n                \"languages\": [\"Python\", \"TypeScript\", \"JavaScript\"]\n            }\n            \n        query = CYPHER_QUERIES[\"get_repo_overview\"]\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        \n        if records:\n            record = records[0]\n            return {\n                \"repo\": record[\"repo\"],\n                \"files\": record[\"file_count\"],\n                \"classes\": record[\"class_count\"],\n                \"functions\": record[\"function_count\"],\n                \"languages\": record[\"languages\"]\n            }\n        return {}\n    \n    def get_repo_files(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all files in a repository.\"\"\"\n        query = CYPHER_QUERIES[\"get_repo_files\"]\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        \n        return [\n            {\n                \"file\": dict(record[\"f\"]) if record[\"f\"] else None,\n                \"language\": record[\"language\"],\n                \"lines_count\": record[\"lines_count\"]\n                \n            }\n            for record in records\n        ]\n    \n    # =========================================================================\n    # Search Operations\n    # =========================================================================\n    \n    def _escape_lucene_query(self, query: str) -> str:\n        \"\"\"\n        Escape Lucene special characters in search query.\n\n        Strategy: Wrap the entire query in quotes to treat it as a literal phrase search.\n        This prevents Lucene from interpreting special characters.\n\n        For complex queries, users can use wildcards: *\n        \"\"\"\n        query = query.strip()\n\n        # If query is empty, return a wildcard\n        if not query:\n            return '*'\n\n        # If the query already has quotes, escape internal quotes\n        if '\"' in query:\n            # Escape any existing quotes and wrap in quotes\n            query = query.replace('\"', '\\\\\"')\n\n        # Wrap in quotes to make it a literal phrase search\n        # This treats special characters as literals\n        return f'\"{query}\"'\n\n    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n        \"\"\"Search for code by name or docstring.\"\"\"\n        # Escape Lucene special characters to prevent query parsing errors\n        escaped_term = self._escape_lucene_query(search_term)\n\n        query = CYPHER_QUERIES[\"search_code\"]\n        records, _, _ = self.db.run_query(query, {\"search_term\": escaped_term})\n\n        return [\n            {\n                \"node\": dict(record[\"node\"]) if record[\"node\"] else None,\n                \"type\": record[\"type\"],\n                \"file\": record[\"file\"],\n                \"score\": record[\"score\"]\n            }\n            for record in records\n        ]\n\n    def search_symbols(\n        self,\n        search_term: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search symbols using fulltext index.\n\n        Args:\n            search_term: Search query (supports fuzzy matching)\n            limit: Maximum results to return\n\n        Returns:\n            List of matching symbols with scores\n        \"\"\"\n        query = CYPHER_QUERIES[\"search_symbols\"]\n        records, _, _ = self.db.run_query(query, {\n            \"search_term\": search_term,\n            \"limit\": limit\n        })\n\n        return [\n            {\n                \"name\": record[\"name\"],\n                \"qualified_name\": record[\"qualified_name\"],\n                \"type\": record[\"type\"],\n                \"file_id\": record[\"file_id\"],\n                \"line\": record[\"line\"],\n                \"visibility\": record[\"visibility\"],\n                \"score\": record[\"score\"]\n            }\n            for record in records\n        ]\n\n    def find_symbol_by_qualified_name(\n        self,\n        qualified_name: str,\n        repo_id: str\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a symbol by its exact qualified name.\n\n        Args:\n            qualified_name: Full qualified name (e.g., module.Class.method)\n            repo_id: Repository ID to search in\n\n        Returns:\n            Symbol information if found\n        \"\"\"\n        query = CYPHER_QUERIES[\"search_symbols_by_qualified_name\"]\n        records, _, _ = self.db.run_query(query, {\n            \"qualified_name\": qualified_name,\n            \"repo_id\": repo_id\n        })\n\n        if records:\n            record = records[0]\n            return {\n                \"id\": record[\"id\"],\n                \"name\": record[\"name\"],\n                \"qualified_name\": record[\"qualified_name\"],\n                \"type\": record[\"type\"],\n                \"file_id\": record[\"file_id\"],\n                \"line_start\": record[\"line_start\"],\n                \"line_end\": record[\"line_end\"],\n                \"scope\": record[\"scope\"],\n                \"visibility\": record[\"visibility\"],\n                \"docstring\": record[\"docstring\"]\n            }\n        return None\n\n    def autocomplete_symbols(\n        self,\n        prefix: str,\n        repo_id: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get symbol autocomplete suggestions.\n\n        Args:\n            prefix: Prefix to match (e.g., \"module.Clas\")\n            repo_id: Repository ID\n            limit: Maximum results\n\n        Returns:\n            List of matching symbol qualified names\n        \"\"\"\n        query = CYPHER_QUERIES[\"autocomplete_symbols\"]\n        records, _, _ = self.db.run_query(query, {\n            \"prefix\": prefix,\n            \"repo_id\": repo_id,\n            \"limit\": limit\n        })\n\n        return [\n            {\n                \"qualified_name\": record[\"qualified_name\"],\n                \"type\": record[\"type\"],\n                \"visibility\": record[\"visibility\"],\n                \"file_id\": record[\"file_id\"]\n            }\n            for record in records\n        ]\n\n    def find_symbols_in_scope(\n        self,\n        file_id: str,\n        scope: str = \"module\"\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Find all symbols in a specific scope.\n\n        Args:\n            file_id: File ID to search in\n            scope: Scope type (module, class, function)\n\n        Returns:\n            List of symbols in the scope\n        \"\"\"\n        query = CYPHER_QUERIES[\"find_symbols_in_scope\"]\n        records, _, _ = self.db.run_query(query, {\n            \"file_id\": file_id,\n            \"scope\": scope\n        })\n\n        return [\n            {\n                \"name\": record[\"name\"],\n                \"qualified_name\": record[\"qualified_name\"],\n                \"type\": record[\"type\"],\n                \"line_start\": record[\"line_start\"],\n                \"visibility\": record[\"visibility\"]\n            }\n            for record in records\n        ]\n    \n    def find_symbol_definition(self, symbol_name: str, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Find where a symbol (class, function, method, variable) is defined.\"\"\"\n        query = \"\"\"\n        MATCH (symbol)\n        WHERE symbol.name = $symbol_name\n          AND (symbol.file_id STARTS WITH $repo_id OR symbol.class_id STARTS WITH $repo_id)\n        MATCH (f:File)-[:DEFINES*1..2]->(symbol)\n        RETURN symbol.name as name, labels(symbol)[0] as type,\n               f.path as file, symbol.line_start as line,\n               symbol.docstring as docstring, symbol.source_code as source_code\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\n            \"symbol_name\": symbol_name,\n            \"repo_id\": repo_id\n        })\n\n        return [\n            {\n                \"name\": record[\"name\"],\n                \"type\": record[\"type\"],\n                \"file\": record[\"file\"],\n                \"line\": record[\"line\"],\n                \"docstring\": record[\"docstring\"],\n                \"source_code\": record.get(\"source_code\")\n            }\n            for record in records\n        ]\n    \n    # =========================================================================\n    # Impact Analysis\n    # =========================================================================\n    \n    def analyze_change_impact(self, target_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Analyze the impact of changing a specific code element.\"\"\"\n        query = CYPHER_QUERIES[\"analyze_change_impact\"]\n        records, _, _ = self.db.run_query(query, {\"target_id\": target_id})\n\n        return [\n            {\n                \"affected\": record[\"affected\"],\n                \"type\": record[\"type\"],\n                \"file\": record[\"file\"],\n                \"distance\": record[\"distance\"]\n            }\n            for record in records\n        ]\n\n    def analyze_change_impact_enhanced(\n        self,\n        qualified_name: str,\n        repo_id: str\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Enhanced impact analysis with multi-dimensional impact tracking.\n\n        Analyzes:\n        - Direct callers\n        - Transitive callers (up to 3 levels)\n        - Inheritance impact (for classes/methods)\n        - Import impact (files that import changed file)\n\n        Args:\n            qualified_name: Fully qualified name of the symbol\n            repo_id: Repository ID\n\n        Returns:\n            Dict with categorized impact analysis\n        \"\"\"\n        query = CYPHER_QUERIES[\"analyze_change_impact_enhanced\"]\n        records, _, _ = self.db.run_query(query, {\n            \"qualified_name\": qualified_name,\n            \"repo_id\": repo_id\n        })\n\n        if records:\n            record = records[0]\n            return {\n                \"target\": record[\"target\"],\n                \"direct_calls\": [call for call in record[\"direct_calls\"] if call.get(\"name\")],\n                \"transitive_calls\": [call for call in record[\"transitive_calls\"] if call.get(\"name\")],\n                \"inheritance_impact\": [imp for imp in record[\"inheritance_impact\"] if imp.get(\"name\")],\n                \"import_impact\": [imp for imp in record[\"import_impact\"] if imp.get(\"name\")],\n                \"total_impact\": record[\"total_impact\"]\n            }\n        return {\n            \"target\": qualified_name,\n            \"direct_calls\": [],\n            \"transitive_calls\": [],\n            \"inheritance_impact\": [],\n            \"import_impact\": [],\n            \"total_impact\": 0\n        }\n\n    def get_call_graph(\n        self,\n        qualified_name: str,\n        repo_id: str,\n        max_depth: int = 3\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get the call graph starting from a symbol.\n\n        Args:\n            qualified_name: Starting symbol\n            repo_id: Repository ID\n            max_depth: Maximum depth to traverse\n\n        Returns:\n            List of caller-callee relationships\n        \"\"\"\n        query = CYPHER_QUERIES[\"get_call_graph\"]\n        records, _, _ = self.db.run_query(query, {\n            \"qualified_name\": qualified_name,\n            \"repo_id\": repo_id,\n            \"max_depth\": max_depth\n        })\n\n        return [\n            {\n                \"caller\": record[\"caller\"],\n                \"callee\": record[\"callee\"],\n                \"caller_type\": record[\"caller_type\"],\n                \"callee_type\": record[\"callee_type\"],\n                \"line\": record[\"line\"],\n                \"depth\": record[\"depth\"]\n            }\n            for record in records\n        ]\n    \n    # =========================================================================\n    # Code Retrieval Operations\n    # =========================================================================\n\n    def get_code_at_line(self, file_id: str, line_number: int) -> Optional[str]:\n        \"\"\"\n        Get the code content at a specific line.\n\n        Note: Uses file source_code and extracts the specific line.\n        \"\"\"\n        source_code = self.reconstruct_file(file_id)\n        if not source_code:\n            return None\n\n        lines = source_code.split('\\n')\n        if 0 < line_number <= len(lines):\n            return lines[line_number - 1]\n        return None\n\n    def get_code_range(\n        self,\n        file_id: str,\n        start_line: int,\n        end_line: int\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get code content for a range of lines.\n\n        Note: Uses file source_code and extracts the range.\n        \"\"\"\n        source_code = self.reconstruct_file(file_id)\n        if not source_code:\n            return []\n\n        lines = source_code.split('\\n')\n        result = []\n\n        for i in range(start_line - 1, min(end_line, len(lines))):\n            if i >= 0:\n                line_content = lines[i]\n                result.append({\n                    \"line\": i + 1,\n                    \"content\": line_content,\n                    \"is_comment\": line_content.strip().startswith(('#', '//', '/*')),\n                    \"is_blank\": len(line_content.strip()) == 0\n                })\n\n        return result\n    \n    # =========================================================================\n    # File Reconstruction\n    # =========================================================================\n    \n    def get_repository_files(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all files in a repository.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:CONTAINS*]->(f:File)\n        RETURN f.id as id, f.path as path, f.language as language,\n               f.lines_count as lines_count\n        ORDER BY f.path\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        return [\n            {\n                \"id\": record[\"id\"],\n                \"path\": record[\"path\"],\n                \"language\": record[\"language\"],\n                \"lines_count\": record[\"lines_count\"]\n            }\n            for record in records\n        ]\n    \n    def reconstruct_file(self, file_id: str) -> Optional[str]:\n        \"\"\"\n        Reconstruct a file's complete content from source_code property.\n\n        Returns:\n            Complete file source code or None if not found\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {id: $file_id})\n        RETURN f.source_code as source_code, f.path as path\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n\n        if not records:\n            return None\n\n        source_code = records[0].get(\"source_code\")\n        if not source_code:\n            # Fallback: try to reconstruct from individual code elements\n            # This shouldn't be needed but provides a safety net\n            print(f\"⚠️  Warning: File {records[0].get('path')} has no source_code stored\")\n            return None\n\n        return source_code\n\n    def verify_reconstruction(self, file_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Verify that file reconstruction is possible and show stats.\n\n        Args:\n            file_id: File ID to verify\n\n        Returns:\n            Dict with verification results\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {id: $file_id})\n        OPTIONAL MATCH (f)-[:DEFINES]->(c:Class)\n        OPTIONAL MATCH (f)-[:DEFINES]->(fn:Function)\n        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)\n        RETURN f.path as path,\n               f.language as language,\n               f.lines_count as lines_count,\n               f.source_code IS NOT NULL as has_source_code,\n               size(f.source_code) as source_code_size,\n               count(DISTINCT c) as class_count,\n               count(DISTINCT fn) as function_count,\n               count(DISTINCT m) as method_count\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n\n        if not records:\n            return {\"error\": \"File not found\", \"file_id\": file_id}\n\n        record = records[0]\n        can_reconstruct = record[\"has_source_code\"]\n\n        return {\n            \"file_id\": file_id,\n            \"path\": record[\"path\"],\n            \"language\": record[\"language\"],\n            \"lines_count\": record[\"lines_count\"],\n            \"can_reconstruct\": can_reconstruct,\n            \"source_code_size\": record[\"source_code_size\"] or 0,\n            \"classes\": record[\"class_count\"],\n            \"functions\": record[\"function_count\"],\n            \"methods\": record[\"method_count\"],\n            \"status\": \"✅ Ready\" if can_reconstruct else \"❌ No source_code\"\n        }\n    \n    def get_symbol_source(self, qualified_name: str, repo_id: str) -> Optional[str]:\n        \"\"\"\n        Get source code for a specific symbol.\n\n        Args:\n            qualified_name: Fully qualified name of the symbol\n            repo_id: Repository ID\n\n        Returns:\n            Source code of the symbol or None\n        \"\"\"\n        query = \"\"\"\n        MATCH (s:Symbol {qualified_name: $qualified_name})\n        WHERE s.file_id STARTS WITH $repo_id\n        RETURN s.source_code as source_code\n        LIMIT 1\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\n            \"qualified_name\": qualified_name,\n            \"repo_id\": repo_id\n        })\n\n        if records and records[0][\"source_code\"]:\n            return records[0][\"source_code\"]\n\n        # Fallback: try to get from definition node\n        symbol = self.find_symbol_by_qualified_name(qualified_name, repo_id)\n        if symbol and symbol.get(\"type\"):\n            if symbol[\"type\"] == \"class\":\n                return self.get_class_source(f\"{symbol['file_id']}:class:{symbol['name']}:{symbol['line_start']}\")\n            elif symbol[\"type\"] == \"function\":\n                return self.get_function_source(f\"{symbol['file_id']}:func:{symbol['name']}:{symbol['line_start']}\")\n            elif symbol[\"type\"] == \"method\":\n                # More complex - need to find class first\n                pass\n\n        return None\n\n    def verify_repository_reconstruction(self, repo_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Verify that all files in a repository can be reconstructed.\n\n        Args:\n            repo_id: Repository ID\n\n        Returns:\n            Dict with verification stats\n        \"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:CONTAINS*]->(f:File)\n        RETURN count(f) as total_files,\n               sum(CASE WHEN f.source_code IS NOT NULL THEN 1 ELSE 0 END) as files_with_source,\n               sum(f.lines_count) as total_lines,\n               sum(size(f.source_code)) as total_source_size\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n\n        if not records:\n            return {\"error\": \"Repository not found\", \"repo_id\": repo_id}\n\n        record = records[0]\n        total_files = record[\"total_files\"] or 0\n        files_with_source = record[\"files_with_source\"] or 0\n        success_rate = (files_with_source / total_files * 100) if total_files > 0 else 0\n\n        # Get list of files without source code\n        problem_files_query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:CONTAINS*]->(f:File)\n        WHERE f.source_code IS NULL\n        RETURN f.path as path, f.id as file_id\n        LIMIT 10\n        \"\"\"\n        problem_records, _, _ = self.db.run_query(problem_files_query, {\"repo_id\": repo_id})\n\n        return {\n            \"repo_id\": repo_id,\n            \"total_files\": total_files,\n            \"files_with_source\": files_with_source,\n            \"files_without_source\": total_files - files_with_source,\n            \"success_rate\": f\"{success_rate:.1f}%\",\n            \"total_lines\": record[\"total_lines\"] or 0,\n            \"total_source_size_mb\": (record[\"total_source_size\"] or 0) / 1024 / 1024,\n            \"status\": \"✅ All files ready\" if success_rate == 100 else f\"⚠️  {total_files - files_with_source} files missing source\",\n            \"problem_files\": [r[\"path\"] for r in problem_records] if problem_records else []\n        }\n\n    def reconstruct_repository(self, repo_id: str) -> Dict[str, str]:\n        \"\"\"\n        Reconstruct all files in a repository.\n        \n        Returns:\n            Dict mapping file paths to their reconstructed content\n        \"\"\"\n        files = self.get_repository_files(repo_id)\n        reconstructed = {}\n        \n        for file_info in files:\n            content = self.reconstruct_file(file_info[\"id\"])\n            if content is not None:\n                reconstructed[file_info[\"path\"]] = content\n        \n        return reconstructed\n    \n    def get_file_metadata(self, file_id: str) -> Dict[str, Any]:\n        \"\"\"Get complete metadata for a file including all code elements.\"\"\"\n        query = \"\"\"\n        MATCH (f:File {id: $file_id})\n        OPTIONAL MATCH (f)-[:DEFINES]->(c:Class)\n        OPTIONAL MATCH (f)-[:DEFINES]->(fn:Function)\n        OPTIONAL MATCH (f)-[:HAS_IMPORT]->(i:Import)\n        RETURN f.path as path,\n               f.language as language,\n               f.lines_count as lines_count,\n               collect(DISTINCT {name: c.name, line: c.line_start, bases: c.base_classes}) as classes,\n               collect(DISTINCT {name: fn.name, line: fn.line_start, params: fn.params}) as functions,\n               collect(DISTINCT {module: i.module, names: i.imported_names}) as imports\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n\n        if records:\n            record = records[0]\n            return {\n                \"path\": record[\"path\"],\n                \"language\": record[\"language\"],\n                \"lines_count\": record[\"lines_count\"],\n                \"classes\": [c for c in record[\"classes\"] if c[\"name\"]],\n                \"functions\": [f for f in record[\"functions\"] if f[\"name\"]],\n                \"imports\": [i for i in record[\"imports\"] if i[\"module\"]]\n            }\n        return {}\n\n    def get_method_source(self, method_id: str) -> Optional[str]:\n        \"\"\"Get the source code of a specific method.\"\"\"\n        query = \"\"\"\n        MATCH (m:Method {id: $method_id})\n        RETURN m.source_code as source_code\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"method_id\": method_id})\n        return records[0][\"source_code\"] if records and records[0][\"source_code\"] else None\n\n    def get_function_source(self, function_id: str) -> Optional[str]:\n        \"\"\"Get the source code of a specific function.\"\"\"\n        query = \"\"\"\n        MATCH (f:Function {id: $function_id})\n        RETURN f.source_code as source_code\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"function_id\": function_id})\n        return records[0][\"source_code\"] if records and records[0][\"source_code\"] else None\n\n    def get_class_source(self, class_id: str) -> Optional[str]:\n        \"\"\"Get the source code of a specific class.\"\"\"\n        query = \"\"\"\n        MATCH (c:Class {id: $class_id})\n        RETURN c.source_code as source_code\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"class_id\": class_id})\n        return records[0][\"source_code\"] if records and records[0][\"source_code\"] else None\n    \n    # =========================================================================\n    # Config File Queries\n    # =========================================================================\n    \n    def get_repo_config_files(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all config files in a repository.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:HAS_CONFIG]->(cf:ConfigFile)\n        RETURN cf.id as id, cf.path as path, cf.file_type as file_type,\n               cf.project_name as project_name, cf.version as version,\n               cf.lines_count as lines_count\n        ORDER BY cf.path\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        return [\n            {\n                \"id\": record[\"id\"],\n                \"path\": record[\"path\"],\n                \"file_type\": record[\"file_type\"],\n                \"project_name\": record[\"project_name\"],\n                \"version\": record[\"version\"],\n                \"lines_count\": record[\"lines_count\"]\n            }\n            for record in records\n        ]\n    \n    def get_repo_dependencies(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all dependencies in a repository.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:HAS_CONFIG]->(cf:ConfigFile)-[:HAS_DEPENDENCY]->(d:Dependency)\n        RETURN d.name as name, d.version_spec as version, d.is_dev as is_dev,\n               d.source as source, cf.path as config_file\n        ORDER BY d.is_dev, d.name\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        return [\n            {\n                \"name\": record[\"name\"],\n                \"version\": record[\"version\"],\n                \"is_dev\": record[\"is_dev\"],\n                \"source\": record[\"source\"],\n                \"config_file\": record[\"config_file\"]\n            }\n            for record in records\n        ]\n    \n    def delete_repository(self, repo_id: str) -> bool:\n        \"\"\"Delete a repository and all its data.\"\"\"\n        if not self.db.connected:\n            # Mock success for testing\n            return True\n\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        DETACH DELETE r\n        RETURN count(r) as deleted_count\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n\n        return len(records) > 0 and records[0].get(\"deleted_count\", 0) > 0\n    \n    def get_repo_overview_extended(self, repo_id: str) -> Dict[str, Any]:\n        \"\"\"Get extended repository overview including config files and dependencies.\"\"\"\n        # Get basic stats\n        basic = self.get_repo_overview(repo_id)\n        \n        # Get config file count\n        config_query = \"\"\"\n        MATCH (r:Repository {id: $repo_id})-[:HAS_CONFIG]->(cf:ConfigFile)\n        OPTIONAL MATCH (cf)-[:HAS_DEPENDENCY]->(d:Dependency)\n        RETURN count(DISTINCT cf) as config_count, count(DISTINCT d) as dep_count\n        \"\"\"\n        records, _, _ = self.db.run_query(config_query, {\"repo_id\": repo_id})\n        \n        if records:\n            basic[\"config_files\"] = records[0][\"config_count\"]\n            basic[\"dependencies\"] = records[0][\"dep_count\"]\n        else:\n            basic[\"config_files\"] = 0\n            basic[\"dependencies\"] = 0\n        \n        return basic\n\n    def get_all_ingested_repositories(self, owner: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all ingested repositories.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository {owner: $owner})\n        RETURN r.id as repo_id, r.owner as owner, r.name as name, r.url as url\n        ORDER BY r.owner, r.name\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"owner\": owner})\n        return [\n            {\n                \"repo_id\": record[\"repo_id\"],\n                \"owner\": record[\"owner\"],\n                \"name\": record[\"name\"],\n                \"url\": record[\"url\"]\n            }\n            for record in records\n        ]\n\n    # =========================================================================\n    # Hierarchy Navigation\n    # =========================================================================\n\n    def get_module_tree(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get the complete module/directory tree for a repository.\n\n        Args:\n            repo_id: Repository ID\n\n        Returns:\n            List of modules with hierarchy information\n        \"\"\"\n        query = CYPHER_QUERIES[\"get_module_tree\"]\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n\n        return [\n            {\n                \"path\": record[\"path\"],\n                \"name\": record[\"name\"],\n                \"parent_path\": record[\"parent_path\"],\n                \"is_package\": record[\"is_package\"],\n                \"depth\": record[\"depth\"]\n            }\n            for record in records\n        ]\n\n    def get_file_hierarchy(self, file_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get the breadcrumb hierarchy for a file.\n\n        Args:\n            file_id: File ID\n\n        Returns:\n            Ordered list from repository to file\n        \"\"\"\n        query = CYPHER_QUERIES[\"get_file_hierarchy\"]\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n\n        return [\n            {\n                \"type\": record[\"type\"],\n                \"name\": record[\"name\"],\n                \"path\": record[\"path\"],\n                \"depth\": record[\"depth\"]\n            }\n            for record in records\n        ]\n\n    def get_directory_contents(\n        self,\n        repo_id: str,\n        dir_path: str\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get contents of a specific directory.\n\n        Args:\n            repo_id: Repository ID\n            dir_path: Directory path\n\n        Returns:\n            List of files and subdirectories\n        \"\"\"\n        query = CYPHER_QUERIES[\"get_directory_contents\"]\n        records, _, _ = self.db.run_query(query, {\n            \"repo_id\": repo_id,\n            \"dir_path\": dir_path\n        })\n\n        return [\n            {\n                \"type\": record[\"type\"],\n                \"name\": record[\"name\"],\n                \"path\": record[\"path\"],\n                \"is_package\": record[\"is_package\"]\n            }\n            for record in records\n        ]\n\n    def get_symbols_at_lines(self, file_path: str, start_line: int, end_line: int) -> List[Dict[str, Any]]:\n        \"\"\"\n        Find all symbols (functions, classes, variables) that overlap a line range in a file.\n        Used to map diff hunks to affected code symbols.\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {path: $file_path})-[:CONTAINS]->(n)\n        WHERE (n:Function OR n:Class OR n:Variable)\n          AND n.line_number IS NOT NULL\n          AND n.line_number <= $end_line\n          AND coalesce(n.end_line, n.line_number) >= $start_line\n        RETURN\n            CASE\n                WHEN n:Function THEN 'function'\n                WHEN n:Class THEN 'class'\n                ELSE 'variable'\n            END as type,\n            n.name as name,\n            n.line_number as start_line,\n            coalesce(n.end_line, n.line_number) as end_line,\n            n.source as source,\n            n.docstring as docstring,\n            n.path as path\n        ORDER BY n.line_number\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\n            \"file_path\": file_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n        })\n        return [dict(r) for r in records]\n\n    def get_symbols_at_lines_by_relative_path(self, repo_id: str, relative_path: str, start_line: int, end_line: int) -> List[Dict[str, Any]]:\n        \"\"\"\n        Find all symbols overlapping a line range using repo-relative file path.\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File)\n        WHERE f.relative_path = $relative_path\n          AND f.path CONTAINS $repo_id\n        WITH f\n        MATCH (f)-[:CONTAINS]->(n)\n        WHERE (n:Function OR n:Class OR n:Variable)\n          AND n.line_number IS NOT NULL\n          AND n.line_number <= $end_line\n          AND coalesce(n.end_line, n.line_number) >= $start_line\n        RETURN\n            CASE\n                WHEN n:Function THEN 'function'\n                WHEN n:Class THEN 'class'\n                ELSE 'variable'\n            END as type,\n            n.name as name,\n            n.line_number as start_line,\n            coalesce(n.end_line, n.line_number) as end_line,\n            n.source as source,\n            n.docstring as docstring,\n            f.relative_path as file_path\n        ORDER BY n.line_number\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\n            \"repo_id\": repo_id,\n            \"relative_path\": relative_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n        })\n        return [dict(r) for r in records]\n\n    def get_diff_context(self, repo_id: str, changes: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Build full RAG context for a set of file changes (diff).\n\n        Args:\n            repo_id: Repository ID (e.g. \"owner/repo\")\n            changes: List of {\"file_path\": \"relative/path.py\", \"start_line\": 10, \"end_line\": 30}\n\n        Returns:\n            Dict with affected_symbols, callers, hierarchy, and file_sources.\n        \"\"\"\n        all_affected = []\n        all_callers = []\n        all_hierarchy = []\n        file_sources = {}\n\n        for change in changes:\n            file_path = change[\"file_path\"]\n            start_line = change.get(\"start_line\", 1)\n            end_line = change.get(\"end_line\", 999999)\n\n            # 1. Find affected symbols\n            symbols = self.get_symbols_at_lines_by_relative_path(\n                repo_id, file_path, start_line, end_line\n            )\n            for s in symbols:\n                s[\"change_file\"] = file_path\n            all_affected.extend(symbols)\n\n            # 2. For each affected symbol, find callers\n            for sym in symbols:\n                caller_query = \"\"\"\n                MATCH (caller)-[:CALLS]->(target)\n                WHERE target.name = $name AND target.path CONTAINS $repo_id\n                RETURN\n                    CASE\n                        WHEN caller:Function THEN 'function'\n                        WHEN caller:Class THEN 'class'\n                        ELSE 'other'\n                    END as type,\n                    caller.name as name,\n                    caller.path as path,\n                    caller.line_number as line_number,\n                    caller.source as source\n                LIMIT 20\n                \"\"\"\n                records, _, _ = self.db.run_query(caller_query, {\n                    \"name\": sym[\"name\"],\n                    \"repo_id\": repo_id,\n                })\n                callers = [dict(r) for r in records]\n                if callers:\n                    all_callers.append({\n                        \"symbol\": sym[\"name\"],\n                        \"symbol_type\": sym[\"type\"],\n                        \"callers\": callers,\n                    })\n\n            # 3. For affected classes, get hierarchy\n            class_symbols = [s for s in symbols if s[\"type\"] == \"class\"]\n            for cls in class_symbols:\n                hier_query = \"\"\"\n                MATCH (c:Class {name: $name})-[:INHERITS*0..5]->(parent:Class)\n                WHERE c.path CONTAINS $repo_id\n                RETURN parent.name as name, parent.path as path,\n                       parent.source as source, parent.docstring as docstring\n                \"\"\"\n                records, _, _ = self.db.run_query(hier_query, {\n                    \"name\": cls[\"name\"],\n                    \"repo_id\": repo_id,\n                })\n                if records:\n                    all_hierarchy.append({\n                        \"class\": cls[\"name\"],\n                        \"hierarchy\": [dict(r) for r in records],\n                    })\n\n            # 4. Get file source\n            file_src_query = \"\"\"\n            MATCH (f:File)\n            WHERE f.relative_path = $relative_path AND f.path CONTAINS $repo_id\n            RETURN f.source_code as source_code, f.relative_path as path\n            LIMIT 1\n            \"\"\"\n            records, _, _ = self.db.run_query(file_src_query, {\n                \"relative_path\": file_path,\n                \"repo_id\": repo_id,\n            })\n            if records and records[0].get(\"source_code\"):\n                file_sources[file_path] = records[0][\"source_code\"]\n\n        return {\n            \"affected_symbols\": all_affected,\n            \"callers\": all_callers,\n            \"class_hierarchy\": all_hierarchy,\n            \"file_sources\": file_sources,\n            \"total_affected\": len(all_affected),\n            \"total_files\": len(changes),\n        }\n\n    def get_diff_context_condensed(\n        self, repo_id: str, changes: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Build lean context for a set of file changes — optimized for LLM prompts.\n\n        Compared to get_diff_context:\n        - Only returns functions/classes/methods (skips variables)\n        - Returns symbol source snippets (the changed code chunk, not the whole file)\n        - Returns caller names + file paths only (no caller source code)\n        - Returns hierarchy as name chains only (no parent source)\n        - No full file sources at all\n\n        Args:\n            repo_id: Repository ID (e.g. \"owner/repo\")\n            changes: List of {\"file_path\": \"relative/path.py\", \"start_line\": 10, \"end_line\": 30}\n\n        Returns:\n            Dict with affected_symbols, callers, hierarchy.\n        \"\"\"\n        all_affected: List[Dict[str, Any]] = []\n        all_callers: List[Dict[str, Any]] = []\n        all_hierarchy: List[Dict[str, Any]] = []\n        seen_symbols: set = set()\n\n        for change in changes:\n            file_path = change[\"file_path\"]\n            start_line = change.get(\"start_line\", 1)\n            end_line = change.get(\"end_line\", 999999)\n\n            # 1. Find affected symbols — functions and classes only\n            query = \"\"\"\n            MATCH (f:File)\n            WHERE f.relative_path = $relative_path\n              AND f.path CONTAINS $repo_id\n            WITH f\n            MATCH (f)-[:CONTAINS]->(n)\n            WHERE (n:Function OR n:Class OR n:Method)\n              AND n.line_number IS NOT NULL\n              AND n.line_number <= $end_line\n              AND coalesce(n.end_line, n.line_number) >= $start_line\n            RETURN\n                CASE\n                    WHEN n:Function THEN 'function'\n                    WHEN n:Method THEN 'method'\n                    WHEN n:Class THEN 'class'\n                END as type,\n                n.name as name,\n                n.line_number as start_line,\n                coalesce(n.end_line, n.line_number) as end_line,\n                n.source as source,\n                n.docstring as docstring,\n                f.relative_path as file_path\n            ORDER BY n.line_number\n            \"\"\"\n            records, _, _ = self.db.run_query(query, {\n                \"repo_id\": repo_id,\n                \"relative_path\": file_path,\n                \"start_line\": start_line,\n                \"end_line\": end_line,\n            })\n\n            symbols = [dict(r) for r in records]\n            for s in symbols:\n                s[\"change_file\"] = file_path\n                # Truncate source to keep prompts lean\n                if s.get(\"source\") and len(s[\"source\"]) > 500:\n                    s[\"source\"] = s[\"source\"][:500] + \"\\n... (truncated)\"\n            all_affected.extend(symbols)\n\n            # 2. For each symbol, find caller names only (no source)\n            for sym in symbols:\n                sym_key = f\"{file_path}:{sym['name']}\"\n                if sym_key in seen_symbols:\n                    continue\n                seen_symbols.add(sym_key)\n\n                caller_query = \"\"\"\n                MATCH (caller)-[:CALLS]->(target)\n                WHERE target.name = $name AND target.path CONTAINS $repo_id\n                RETURN DISTINCT\n                    caller.name as name,\n                    CASE\n                        WHEN caller:Function THEN 'function'\n                        WHEN caller:Method THEN 'method'\n                        WHEN caller:Class THEN 'class'\n                        ELSE 'other'\n                    END as type,\n                    caller.path as path\n                LIMIT 10\n                \"\"\"\n                records, _, _ = self.db.run_query(caller_query, {\n                    \"name\": sym[\"name\"],\n                    \"repo_id\": repo_id,\n                })\n                callers = [dict(r) for r in records]\n                if callers:\n                    all_callers.append({\n                        \"symbol\": sym[\"name\"],\n                        \"symbol_type\": sym[\"type\"],\n                        \"callers\": callers,\n                    })\n\n            # 3. For affected classes, get hierarchy names only\n            class_symbols = [s for s in symbols if s[\"type\"] == \"class\"]\n            for cls in class_symbols:\n                hier_query = \"\"\"\n                MATCH (c:Class {name: $name})-[:INHERITS*0..3]->(parent:Class)\n                WHERE c.path CONTAINS $repo_id\n                RETURN parent.name as name, parent.path as path\n                \"\"\"\n                records, _, _ = self.db.run_query(hier_query, {\n                    \"name\": cls[\"name\"],\n                    \"repo_id\": repo_id,\n                })\n                if records:\n                    all_hierarchy.append({\n                        \"class\": cls[\"name\"],\n                        \"hierarchy\": [{\"name\": r[\"name\"], \"path\": r[\"path\"]} for r in records],\n                    })\n\n        return {\n            \"affected_symbols\": all_affected,\n            \"callers\": all_callers,\n            \"class_hierarchy\": all_hierarchy,\n            \"total_affected\": len(all_affected),\n            \"total_files\": len(set(c[\"file_path\"] for c in changes)),\n        }\n\n    def get_diff_context_enhanced(\n        self, repo_id: str, changes: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Build full relationship context for every changed Function, Method, and Class.\n\n        For each symbol in the diff line ranges:\n          - Full source code of the symbol itself\n          - Methods belonging to each changed Class (with source)\n          - Callers: every Function/Method that calls this symbol via CALLS edges\n          - Dependencies: every Function/Method this symbol calls via CALLS edges\n          - Imports: other in-repo symbols imported by the changed file\n          - Class hierarchy: parent/child classes for any changed Class\n\n        Both Function and Method node types are handled throughout — the graph\n        stores class methods as Function nodes under the class via CONTAINS.\n        \"\"\"\n        from api.services.code_search import CodeFinder\n\n        code_finder = CodeFinder(self.db)\n\n        all_affected: List[Dict[str, Any]] = []\n        all_callers: List[Dict[str, Any]] = []\n        all_imports: List[Dict[str, Any]] = []\n        all_dependencies: List[Dict[str, Any]] = []\n        all_hierarchy: List[Dict[str, Any]] = []\n        seen_affected: set = set()\n        seen_callers: set = set()\n        seen_imports: set = set()\n\n        for change in changes:\n            file_path = change[\"file_path\"]\n            start_line = change.get(\"start_line\", 1)\n            end_line = change.get(\"end_line\", 999999)\n\n            # ── 1. Affected symbols (Function, Class, and Method) ─────────────\n            # Method nodes are stored under Class via CONTAINS — we surface them\n            # here so the agent sees both the class body and individual methods.\n            affected_query = \"\"\"\n            MATCH (f:File {repo: $repo_id, path: $file_path})\n            MATCH (f)-[:CONTAINS]->(n)\n            WHERE (n:Function OR n:Class OR n:Method)\n              AND n.line_number IS NOT NULL\n              AND n.line_number <= $end_line\n              AND coalesce(n.end_line, n.line_number) >= $start_line\n            RETURN\n                CASE\n                    WHEN n:Class    THEN 'class'\n                    WHEN n:Method   THEN 'method'\n                    ELSE                 'function'\n                END AS type,\n                n.name          AS name,\n                n.line_number   AS start_line,\n                coalesce(n.end_line, n.line_number) AS end_line,\n                n.source        AS source,\n                n.docstring     AS docstring,\n                n.args          AS args,\n                f.path          AS file_path\n            ORDER BY n.line_number\n            \"\"\"\n            records, _, _ = self.db.run_query(affected_query, {\n                \"repo_id\": repo_id,\n                \"file_path\": file_path,\n                \"start_line\": start_line,\n                \"end_line\": end_line,\n            })\n            symbols = [dict(r) for r in records]\n\n            for s in symbols:\n                s[\"change_file\"] = file_path\n                sym_key = f\"{s['file_path']}:{s['name']}:{s['start_line']}\"\n                if sym_key not in seen_affected:\n                    seen_affected.add(sym_key)\n                    all_affected.append(s)\n\n            for sym in symbols:\n                caller_key = f\"{sym['file_path']}:{sym['name']}\"\n                if caller_key in seen_callers:\n                    continue\n                seen_callers.add(caller_key)\n\n                # ── 2. Callers: who calls this symbol? ────────────────────────\n                # Match both Function and Method callers so class methods that\n                # call the changed code are not missed.\n                try:\n                    caller_query = \"\"\"\n                    MATCH (target)\n                    WHERE (target:Function OR target:Method OR target:Class)\n                      AND target.name = $name\n                      AND coalesce(target.path, '') CONTAINS $repo_id\n                    WITH target\n                    MATCH (caller)-[call:CALLS]->(target)\n                    WHERE (caller:Function OR caller:Method)\n                      AND NOT coalesce(caller.is_dependency, false)\n                    OPTIONAL MATCH (caller_file:File)-[:CONTAINS]->(caller)\n                    RETURN DISTINCT\n                        caller.name             AS caller_name,\n                        CASE WHEN caller:Method THEN 'method' ELSE 'function' END AS caller_type,\n                        coalesce(caller.path, caller_file.path) AS caller_path,\n                        caller.line_number      AS caller_line,\n                        call.line_number        AS call_line,\n                        call.args               AS call_args\n                    ORDER BY caller_path, caller.line_number\n                    LIMIT 10\n                    \"\"\"\n                    caller_records, _, _ = self.db.run_query(\n                        caller_query, {\"name\": sym[\"name\"], \"repo_id\": repo_id}\n                    )\n                    callers_list = [dict(r) for r in caller_records]\n                    if callers_list:\n                        all_callers.append({\n                            \"symbol\": sym[\"name\"],\n                            \"symbol_type\": sym[\"type\"],\n                            \"callers\": callers_list,\n                        })\n                except Exception as e:\n                    logger.warning(f\"Error finding callers for {sym['name']}: {e}\")\n\n                # ── 3. Dependencies: what does this symbol call? ──────────────\n                # Match both Function and Method targets to catch calls to methods.\n                try:\n                    dep_query = \"\"\"\n                    MATCH (caller)\n                    WHERE (caller:Function OR caller:Method)\n                      AND caller.name = $name\n                      AND caller.path = $path\n                    MATCH (caller)-[call:CALLS]->(called)\n                    WHERE (called:Function OR called:Method)\n                      AND NOT coalesce(called.is_dependency, false)\n                    RETURN DISTINCT\n                        called.name  AS called_name,\n                        CASE WHEN called:Method THEN 'method' ELSE 'function' END AS called_type,\n                        called.path  AS called_path,\n                        call.line_number AS call_line,\n                        call.args    AS call_args\n                    ORDER BY call.line_number\n                    LIMIT 15\n                    \"\"\"\n                    dep_records, _, _ = self.db.run_query(dep_query, {\n                        \"name\": sym[\"name\"],\n                        \"path\": sym[\"file_path\"],\n                    })\n                    deps_list = [dict(r) for r in dep_records]\n                    if deps_list:\n                        all_dependencies.append({\n                            \"symbol\": sym[\"name\"],\n                            \"dependencies\": deps_list,\n                        })\n                except Exception as e:\n                    logger.warning(f\"Error finding dependencies for {sym['name']}: {e}\")\n\n                # ── 4. Class methods: when a Class is affected, fetch all ──────\n                # its methods with full source so the agent sees what each\n                # method does — not just the class skeleton.\n                if sym[\"type\"] == \"class\":\n                    try:\n                        methods_query = \"\"\"\n                        MATCH (cls:Class {name: $class_name, path: $path})\n                        MATCH (cls)-[:CONTAINS]->(m:Function)\n                        RETURN\n                            m.name          AS name,\n                            m.line_number   AS line_number,\n                            coalesce(m.end_line, m.line_number) AS end_line,\n                            m.source        AS source,\n                            m.docstring     AS docstring,\n                            m.args          AS args\n                        ORDER BY m.line_number\n                        \"\"\"\n                        method_records, _, _ = self.db.run_query(methods_query, {\n                            \"class_name\": sym[\"name\"],\n                            \"path\": sym[\"file_path\"],\n                        })\n                        methods_list = [dict(r) for r in method_records]\n                        if methods_list:\n                            sym[\"methods\"] = methods_list\n                    except Exception as e:\n                        logger.warning(f\"Error fetching methods for class {sym['name']}: {e}\")\n\n            # ── 5. Imports: resolve imported names to in-repo source ──────────\n            import_query = \"\"\"\n            MATCH (f:File {repo: $repo_id, path: $file_path})\n            MATCH (f)-[r:IMPORTS]->(m)\n            RETURN\n                r.alias          AS alias,\n                r.imported_name  AS imported_name,\n                m.name           AS module_name,\n                r.line_number    AS line_number\n            ORDER BY r.line_number\n            LIMIT 20\n            \"\"\"\n            import_records, _, _ = self.db.run_query(import_query, {\n                \"repo_id\": repo_id,\n                \"file_path\": file_path,\n            })\n\n            for imp in import_records:\n                imported_name = imp.get(\"imported_name\") or imp.get(\"alias\")\n                if not imported_name or imported_name in seen_imports:\n                    continue\n                seen_imports.add(imported_name)\n\n                try:\n                    func_results = code_finder.find_by_function_name(imported_name, fuzzy_search=False)\n                    if func_results:\n                        for func in func_results[:1]:\n                            if func.get(\"path\") and repo_id in func.get(\"path\", \"\"):\n                                all_imports.append({\n                                    \"name\": imported_name,\n                                    \"type\": \"function\",\n                                    \"source\": func.get(\"source\", \"\"),\n                                    \"path\": func.get(\"path\"),\n                                    \"line\": func.get(\"line_number\"),\n                                    \"docstring\": func.get(\"docstring\"),\n                                    \"from_file\": file_path,\n                                })\n                    else:\n                        class_results = code_finder.find_by_class_name(imported_name, fuzzy_search=False)\n                        if class_results:\n                            for cls in class_results[:1]:\n                                if cls.get(\"path\") and repo_id in cls.get(\"path\", \"\"):\n                                    all_imports.append({\n                                        \"name\": imported_name,\n                                        \"type\": \"class\",\n                                        \"source\": cls.get(\"source\", \"\"),\n                                        \"path\": cls.get(\"path\"),\n                                        \"line\": cls.get(\"line_number\"),\n                                        \"docstring\": cls.get(\"docstring\"),\n                                        \"from_file\": file_path,\n                                    })\n                except Exception as e:\n                    logger.warning(f\"Error resolving import {imported_name}: {e}\")\n\n            # ── 6. Class hierarchy for affected classes ───────────────────────\n            for cls in [s for s in symbols if s[\"type\"] == \"class\"]:\n                try:\n                    hierarchy_info = code_finder.find_class_hierarchy(\n                        cls[\"name\"], cls.get(\"file_path\")\n                    )\n                    if hierarchy_info:\n                        all_hierarchy.append({\n                            \"class\": cls[\"name\"],\n                            \"parents\": hierarchy_info.get(\"parent_classes\", []),\n                            \"children\": hierarchy_info.get(\"child_classes\", []),\n                            \"methods\": hierarchy_info.get(\"methods\", []),\n                        })\n                except Exception as e:\n                    logger.warning(f\"Error finding hierarchy for {cls['name']}: {e}\")\n\n        return {\n            \"affected_symbols\": all_affected,\n            \"callers\": all_callers,\n            \"imports\": all_imports,\n            \"dependencies\": all_dependencies,\n            \"class_hierarchy\": all_hierarchy,\n            \"total_affected\": len(all_affected),\n            \"total_imports\": len(all_imports),\n            \"total_files\": len(set(c[\"file_path\"] for c in changes)),\n        }","structuredPatch":[{"oldStart":300,"oldLines":57,"newStart":300,"newLines":206,"lines":["         return f'\"{query}\"'"," ","     def search_code(self, search_term: str) -> List[Dict[str, Any]]:","-        \"\"\"Search for code by name or docstring.\"\"\"","-        # Escape Lucene special characters to prevent query parsing errors","+        \"\"\"Search for code by name or docstring using fulltext index with CONTAINS fallback.\"\"\"","         escaped_term = self._escape_lucene_query(search_term)"," ","-        query = CYPHER_QUERIES[\"search_code\"]","-        records, _, _ = self.db.run_query(query, {\"search_term\": escaped_term})","+        results: List[Dict[str, Any]] = []","+        try:","+            query = CYPHER_QUERIES[\"search_code\"]","+            records, _, _ = self.db.run_query(query, {\"search_term\": escaped_term})","+            results = [","+                {","+                    \"type\": record[\"type\"],","+                    \"name\": record[\"name\"],","+                    \"path\": record[\"path\"],","+                    \"line_number\": record[\"line_number\"],","+                    \"score\": record[\"score\"],","+                }","+                for record in records","+            ]","+        except Exception as e:","+            logger.warning(\"Fulltext search failed, falling back to CONTAINS: %s\", e)"," ","-        return [","-            {","-                \"node\": dict(record[\"node\"]) if record[\"node\"] else None,","-                \"type\": record[\"type\"],","-                \"file\": record[\"file\"],","-                \"score\": record[\"score\"]","-            }","-            for record in records","-        ]","+        if not results:","+            fallback = \"\"\"","+            MATCH (node)","+            WHERE (node:Function OR node:Class OR node:Variable)","+              AND node.name CONTAINS $search_term","+            OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)","+            RETURN","+                CASE WHEN node:Function THEN 'function'","+                     WHEN node:Class THEN 'class'","+                     ELSE 'variable' END as type,","+                node.name as name,","+                coalesce(f.path, node.path) as path,","+                coalesce(node.line_number, 0) as line_number,","+                1.0 as score","+            LIMIT 20","+            \"\"\"","+            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})","+            results = [","+                {","+                    \"type\": record[\"type\"],","+                    \"name\": record[\"name\"],","+                    \"path\": record[\"path\"],","+                    \"line_number\": record[\"line_number\"],","+                    \"score\": record[\"score\"],","+                }","+                for record in records","+            ]"," ","+        return results","+","     def search_symbols(","         self,","         search_term: str,","         limit: int = 20","     ) -> List[Dict[str, Any]]:","+        \"\"\"Search symbols (Function/Class/Variable) using fulltext index with CONTAINS fallback.\"\"\"","+        escaped_term = self._escape_lucene_query(search_term)","+","+        results: List[Dict[str, Any]] = []","+        try:","+            query = CYPHER_QUERIES[\"search_symbols\"]","+            records, _, _ = self.db.run_query(query, {","+                \"search_term\": escaped_term,","+                \"limit\": limit,","+            })","+            results = [","+                {","+                    \"name\": record[\"name\"],","+                    \"type\": record[\"type\"],","+                    \"path\": record[\"path\"],","+                    \"line_number\": record[\"line_number\"],","+                    \"score\": record[\"score\"],","+                }","+                for record in records","+            ]","+        except Exception as e:","+            logger.warning(\"Symbol fulltext search failed, falling back to CONTAINS: %s\", e)","+","+        if not results:","+            fallback = \"\"\"","+            MATCH (node)","+            WHERE (node:Function OR node:Class OR node:Variable)","+              AND node.name CONTAINS $search_term","+            OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)","+            RETURN","+                node.name as name,","+                CASE WHEN node:Function THEN 'function'","+                     WHEN node:Class THEN 'class'","+                     ELSE 'variable' END as type,","+                coalesce(f.path, node.path) as path,","+                coalesce(node.line_number, 0) as line_number,","+                1.0 as score","+            ORDER BY node.name","+            LIMIT $limit","+            \"\"\"","+            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term, \"limit\": limit})","+            results = [","+                {","+                    \"name\": record[\"name\"],","+                    \"type\": record[\"type\"],","+                    \"path\": record[\"path\"],","+                    \"line_number\": record[\"line_number\"],","+                    \"score\": record[\"score\"],","+                }","+                for record in records","+            ]","+","+        return results","+","+    def search_file_content(self, search_term: str, limit: int = 50) -> List[Dict[str, Any]]:","         \"\"\"","-        Search symbols using fulltext index.","+        Search file source code line by line.","+        Uses file_content_search fulltext index to find candidate files,","+        then scans lines in Python to find the exact matching lines.","+        \"\"\"","+        escaped_term = self._escape_lucene_query(search_term)","+        file_records: List[Dict[str, Any]] = []"," ","-        Args:","-            search_term: Search query (supports fuzzy matching)","-            limit: Maximum results to return","+        try:","+            ft_query = \"\"\"","+            CALL db.index.fulltext.queryNodes('file_content_search', $search_term) YIELD node, score","+            WHERE node.source_code IS NOT NULL","+            RETURN node.path as path, node.source_code as source_code, score","+            ORDER BY score DESC","+            LIMIT 20","+            \"\"\"","+            records, _, _ = self.db.run_query(ft_query, {\"search_term\": escaped_term})","+            file_records = [dict(r) for r in records]","+        except Exception as e:","+            logger.warning(\"file_content_search index failed, falling back to CONTAINS: %s\", e)"," ","-        Returns:","-            List of matching symbols with scores","+        if not file_records:","+            fallback = \"\"\"","+            MATCH (f:File)","+            WHERE f.source_code CONTAINS $search_term","+            RETURN f.path as path, f.source_code as source_code, 1.0 as score","+            LIMIT 20","+            \"\"\"","+            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})","+            file_records = [dict(r) for r in records]","+","+        results: List[Dict[str, Any]] = []","+        term_lower = search_term.lower()","+        for rec in file_records:","+            path = rec.get(\"path\")","+            source = rec.get(\"source_code\")","+            if not path or not source:","+                continue","+            for i, line in enumerate(source.split(\"\\n\")):","+                if search_term in line or term_lower in line.lower():","+                    results.append({","+                        \"path\": path,","+                        \"line_number\": i + 1,","+                        \"match_line\": line.rstrip(),","+                    })","+                    if len(results) >= limit:","+                        return results","+        return results","+","+    def peek_file_lines(","+        self,","+        path: str,","+        line: int,","+        above: int = 10,","+        below: int = 10,","+    ) -> Dict[str, Any]:","         \"\"\"","-        query = CYPHER_QUERIES[\"search_symbols\"]","-        records, _, _ = self.db.run_query(query, {","-            \"search_term\": search_term,","-            \"limit\": limit","-        })","+        Return a window of lines around `line` in the given file.","+        Lines are 1-indexed. The anchor line is flagged with is_anchor=True.","+        \"\"\"","+        query = \"\"\"","+        MATCH (f:File {path: $path})","+        RETURN f.source_code as source_code","+        LIMIT 1","+        \"\"\"","+        records, _, _ = self.db.run_query(query, {\"path\": path})","+        if not records or not records[0].get(\"source_code\"):","+            return {\"error\": \"File not found\", \"path\": path}"," ","-        return [","+        lines = records[0][\"source_code\"].split(\"\\n\")","+        total = len(lines)","+        start = max(0, line - above - 1)   # 0-indexed inclusive","+        end = min(total, line + below)       # 0-indexed exclusive","+","+        window = [","             {","-                \"name\": record[\"name\"],","-                \"qualified_name\": record[\"qualified_name\"],","-                \"type\": record[\"type\"],","-                \"file_id\": record[\"file_id\"],","-                \"line\": record[\"line\"],","-                \"visibility\": record[\"visibility\"],","-                \"score\": record[\"score\"]","+                \"line_number\": i + 1,","+                \"content\": lines[i],","+                \"is_anchor\": (i + 1) == line,","             }","-            for record in records","+            for i in range(start, end)","         ]"," ","+        return {","+            \"path\": path,","+            \"anchor_line\": line,","+            \"window\": window,","+            \"total_lines\": total,","+        }","+","     def find_symbol_by_qualified_name(","         self,","         qualified_name: str,"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"22ba6ca2-6f56-4c75-9e74-262e62ee7d8a"}
{"parentUuid":"ea6707c3-e0c5-4279-949b-d683001239ff","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_017AKfEAQ6SSUn3EMSyPA7J6","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01QDYyB2njsvnP8Xe9gR8s2K","name":"TaskUpdate","input":{"taskId":"1","status":"completed"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2597,"cache_read_input_tokens":89529,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2597},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLuK57m82RSGd2jaRHvv","type":"assistant","uuid":"c5df5dae-b1fc-400c-9f1d-3f8fa7a1778a","timestamp":"2026-02-21T08:31:32.082Z"}
{"parentUuid":"c5df5dae-b1fc-400c-9f1d-3f8fa7a1778a","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01QDYyB2njsvnP8Xe9gR8s2K","type":"tool_result","content":"Updated task #1 status"}]},"uuid":"4c7ef8a4-75a6-4ee6-a653-a09286ec5ffd","timestamp":"2026-02-21T08:31:32.085Z","toolUseResult":{"success":true,"taskId":"1","updatedFields":["status"],"statusChange":{"from":"in_progress","to":"completed"}},"sourceToolAssistantUUID":"c5df5dae-b1fc-400c-9f1d-3f8fa7a1778a"}
{"parentUuid":"4c7ef8a4-75a6-4ee6-a653-a09286ec5ffd","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_017AKfEAQ6SSUn3EMSyPA7J6","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017kEKdtsTdhigw6eong9AXW","name":"TaskUpdate","input":{"taskId":"2","status":"in_progress"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2597,"cache_read_input_tokens":89529,"output_tokens":125,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":2597,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLuK57m82RSGd2jaRHvv","type":"assistant","uuid":"0b2f7f08-dd3d-4475-bacd-66e2ac7e60c0","timestamp":"2026-02-21T08:31:32.519Z"}
{"parentUuid":"0b2f7f08-dd3d-4475-bacd-66e2ac7e60c0","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017kEKdtsTdhigw6eong9AXW","type":"tool_result","content":"Updated task #2 status"}]},"uuid":"98890ebc-145f-4dfd-9bd6-bdbbc0ced96e","timestamp":"2026-02-21T08:31:32.521Z","toolUseResult":{"success":true,"taskId":"2","updatedFields":["status"],"statusChange":{"from":"pending","to":"in_progress"}},"sourceToolAssistantUUID":"0b2f7f08-dd3d-4475-bacd-66e2ac7e60c0"}
{"parentUuid":"98890ebc-145f-4dfd-9bd6-bdbbc0ced96e","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01NQvPHzefufJy92qoyx4q6B","type":"message","role":"assistant","content":[{"type":"text","text":"**Step 3: Add `/code-finder/line` and `/code-finder/peek` endpoints to `api/routers/query.py`**"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":198,"cache_read_input_tokens":92126,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":198},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLuKLyzbygje9a1avPSQ","type":"assistant","uuid":"83a7a283-de87-40ff-b275-36ed470af875","timestamp":"2026-02-21T08:31:34.647Z"}
{"parentUuid":"83a7a283-de87-40ff-b275-36ed470af875","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01NQvPHzefufJy92qoyx4q6B","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01BVnieRt378VuyoAw5Annwc","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","offset":490,"limit":20},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":198,"cache_read_input_tokens":92126,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":198},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLuKLyzbygje9a1avPSQ","type":"assistant","uuid":"ac947447-1da0-4ae3-b7a7-eeb487f19db7","timestamp":"2026-02-21T08:31:35.414Z"}
{"parentUuid":"ac947447-1da0-4ae3-b7a7-eeb487f19db7","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01BVnieRt378VuyoAw5Annwc","toolUseID":"toolu_01BVnieRt378VuyoAw5Annwc","timestamp":"2026-02-21T08:31:35.458Z","uuid":"39c1ae9e-f3f3-470a-bb4d-6daeaff13ac4"}
{"parentUuid":"ac947447-1da0-4ae3-b7a7-eeb487f19db7","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01BVnieRt378VuyoAw5Annwc","type":"tool_result","content":"   490→\n   491→@router.get(\"/code-finder/complexity/top\")\n   492→async def find_most_complex_functions(\n   493→    limit: int = Query(10, description=\"Number of results to return\"),\n   494→    code_finder: CodeFinder = Depends(get_code_finder)\n   495→) -> Dict[str, Any]:\n   496→    \"\"\"\n   497→    Find the most complex functions by cyclomatic complexity.\n   498→    \"\"\"\n   499→    try:\n   500→        results = code_finder.find_most_complex_functions(limit)\n   501→        return {\n   502→            \"limit\": limit,\n   503→            \"results\": results,\n   504→            \"total\": len(results)\n   505→        }\n   506→    except Exception as e:\n   507→        raise HTTPException(status_code=500, detail=f\"Complex function search failed: {str(e)}\")\n   508→\n   509→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"235e2367-0f5e-44a2-abb0-6e5bd502ef1e","timestamp":"2026-02-21T08:31:35.455Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","content":"\n@router.get(\"/code-finder/complexity/top\")\nasync def find_most_complex_functions(\n    limit: int = Query(10, description=\"Number of results to return\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find the most complex functions by cyclomatic complexity.\n    \"\"\"\n    try:\n        results = code_finder.find_most_complex_functions(limit)\n        return {\n            \"limit\": limit,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complex function search failed: {str(e)}\")\n\n","numLines":20,"startLine":490,"totalLines":826}},"sourceToolAssistantUUID":"ac947447-1da0-4ae3-b7a7-eeb487f19db7"}
{"parentUuid":"235e2367-0f5e-44a2-abb0-6e5bd502ef1e","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01XYfJJ4rkhVFm4vn3C2388P","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EmPS1Lt1gBb4gCTVcQXa1c","name":"Edit","input":{"replace_all":false,"file_path":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","old_string":"@router.get(\"/code-finder/complexity/top\")\nasync def find_most_complex_functions(\n    limit: int = Query(10, description=\"Number of results to return\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find the most complex functions by cyclomatic complexity.\n    \"\"\"\n    try:\n        results = code_finder.find_most_complex_functions(limit)\n        return {\n            \"limit\": limit,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complex function search failed: {str(e)}\")","new_string":"@router.get(\"/code-finder/complexity/top\")\nasync def find_most_complex_functions(\n    limit: int = Query(10, description=\"Number of results to return\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find the most complex functions by cyclomatic complexity.\n    \"\"\"\n    try:\n        results = code_finder.find_most_complex_functions(limit)\n        return {\n            \"limit\": limit,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complex function search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/line\")\nasync def find_by_line(\n    query: str = Query(..., description=\"Search term to find in file content\"),\n    limit: int = Query(50, description=\"Maximum number of line matches to return\"),\n    query_service: CodeQueryService = Depends(get_query_service),\n) -> Dict[str, Any]:\n    \"\"\"\n    Search raw file content line-by-line.\n    Uses file_content_search fulltext index (falls back to CONTAINS).\n    Returns path + line_number + match_line for each hit — no source dumps.\n    Pair with /code-finder/peek to view context around a hit.\n    \"\"\"\n    try:\n        results = query_service.search_file_content(query, limit)\n        return {\n            \"query\": query,\n            \"results\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Line search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/peek\")\nasync def peek_file_lines(\n    path: str = Query(..., description=\"Absolute file path (as stored in graph)\"),\n    line: int = Query(..., description=\"Anchor line number (1-indexed)\"),\n    above: int = Query(10, description=\"Lines to show above the anchor\"),\n    below: int = Query(10, description=\"Lines to show below the anchor\"),\n    query_service: CodeQueryService = Depends(get_query_service),\n) -> Dict[str, Any]:\n    \"\"\"\n    Return a window of lines around a given line in a file.\n    The anchor line is flagged with is_anchor=true.\n    Use above/below to control the context window size.\n    \"\"\"\n    try:\n        result = query_service.peek_file_lines(path, line, above, below)\n        if \"error\" in result:\n            raise HTTPException(status_code=404, detail=result[\"error\"])\n        return result\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Peek failed: {str(e)}\")"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":474,"cache_read_input_tokens":92324,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":474},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLuKZLtSReekp5SpgzxS","type":"assistant","uuid":"f4ed98d3-93f3-4537-b93d-1a374b141ed7","timestamp":"2026-02-21T08:31:46.787Z"}
{"type":"file-history-snapshot","messageId":"f4ed98d3-93f3-4537-b93d-1a374b141ed7","snapshot":{"messageId":"c24e474a-29dd-4bc8-afe3-07caafdf094e","trackedFileBackups":{"db/schema.py":{"backupFileName":"283975a9ba984ffc@v1","version":1,"backupTime":"2026-02-21T08:25:31.646Z"},"db/queries.py":{"backupFileName":"3dbb7f971a633538@v1","version":1,"backupTime":"2026-02-21T08:31:28.475Z"},"api/routers/query.py":{"backupFileName":"e6ad69c83e8fb9b0@v1","version":1,"backupTime":"2026-02-21T08:31:48.989Z"}},"timestamp":"2026-02-21T08:05:38.177Z"},"isSnapshotUpdate":true}
{"parentUuid":"f4ed98d3-93f3-4537-b93d-1a374b141ed7","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01EmPS1Lt1gBb4gCTVcQXa1c","toolUseID":"toolu_01EmPS1Lt1gBb4gCTVcQXa1c","timestamp":"2026-02-21T08:31:48.993Z","uuid":"60ba1166-42f4-4be5-97bd-da3720c161b3"}
{"parentUuid":"f4ed98d3-93f3-4537-b93d-1a374b141ed7","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EmPS1Lt1gBb4gCTVcQXa1c","type":"tool_result","content":"The file /Users/skmabudalam/Documents/BugViper/api/routers/query.py has been updated successfully."}]},"uuid":"cfd1c190-09a7-489a-9d85-878528bcc12a","timestamp":"2026-02-21T08:31:48.992Z","toolUseResult":{"filePath":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","oldString":"@router.get(\"/code-finder/complexity/top\")\nasync def find_most_complex_functions(\n    limit: int = Query(10, description=\"Number of results to return\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find the most complex functions by cyclomatic complexity.\n    \"\"\"\n    try:\n        results = code_finder.find_most_complex_functions(limit)\n        return {\n            \"limit\": limit,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complex function search failed: {str(e)}\")","newString":"@router.get(\"/code-finder/complexity/top\")\nasync def find_most_complex_functions(\n    limit: int = Query(10, description=\"Number of results to return\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find the most complex functions by cyclomatic complexity.\n    \"\"\"\n    try:\n        results = code_finder.find_most_complex_functions(limit)\n        return {\n            \"limit\": limit,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complex function search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/line\")\nasync def find_by_line(\n    query: str = Query(..., description=\"Search term to find in file content\"),\n    limit: int = Query(50, description=\"Maximum number of line matches to return\"),\n    query_service: CodeQueryService = Depends(get_query_service),\n) -> Dict[str, Any]:\n    \"\"\"\n    Search raw file content line-by-line.\n    Uses file_content_search fulltext index (falls back to CONTAINS).\n    Returns path + line_number + match_line for each hit — no source dumps.\n    Pair with /code-finder/peek to view context around a hit.\n    \"\"\"\n    try:\n        results = query_service.search_file_content(query, limit)\n        return {\n            \"query\": query,\n            \"results\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Line search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/peek\")\nasync def peek_file_lines(\n    path: str = Query(..., description=\"Absolute file path (as stored in graph)\"),\n    line: int = Query(..., description=\"Anchor line number (1-indexed)\"),\n    above: int = Query(10, description=\"Lines to show above the anchor\"),\n    below: int = Query(10, description=\"Lines to show below the anchor\"),\n    query_service: CodeQueryService = Depends(get_query_service),\n) -> Dict[str, Any]:\n    \"\"\"\n    Return a window of lines around a given line in a file.\n    The anchor line is flagged with is_anchor=true.\n    Use above/below to control the context window size.\n    \"\"\"\n    try:\n        result = query_service.peek_file_lines(path, line, above, below)\n        if \"error\" in result:\n            raise HTTPException(status_code=404, detail=result[\"error\"])\n        return result\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Peek failed: {str(e)}\")","originalFile":"\"\"\"\nCode query endpoints - Advanced implementation with Neo4j integration.\n\"\"\"\n\nfrom fastapi import APIRouter, HTTPException, Query, Depends, Body\nfrom pydantic import BaseModel\nfrom typing import Dict, Any, List, Optional\nimport os\n\nfrom db.client import Neo4jClient\nfrom db.queries import CodeQueryService\nfrom api.dependencies import get_neo4j_client\nfrom api.services.code_search import CodeFinder\n\nrouter = APIRouter()\n\n\ndef get_query_service(db: Neo4jClient = Depends(get_neo4j_client)) -> CodeQueryService:\n    \"\"\"Dependency to get query service.\"\"\"\n    return CodeQueryService(db)\n\n\ndef get_code_finder(db: Neo4jClient = Depends(get_neo4j_client)) -> CodeFinder:\n    \"\"\"Dependency to get code finder.\"\"\"\n    return CodeFinder(db)\n\n\n@router.get(\"/search\")\nasync def search_code(\n    query: str = Query(..., description=\"Search term for code\"),\n    repo_id: str = Query(None, description=\"Optional repository ID to filter by\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Search for code by content or name using fulltext search.\n    \"\"\"\n    try:\n        results = query_service.search_code(query)\n        \n        # Filter by repo if provided\n        if repo_id:\n            filtered_results = []\n            for result in results:\n                if result.get('file', {}).get('repo_id') == repo_id:\n                    filtered_results.append(result)\n            results = filtered_results\n        \n        return {\n            \"results\": results,\n            \"total\": len(results),\n            \"query\": query,\n            \"repo_filter\": repo_id\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")\n\n\n@router.get(\"/search-symbols\")\nasync def search_symbols(\n    query: str = Query(..., description=\"Search term for symbols\"),\n    limit: int = Query(20, description=\"Maximum number of results\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Search for symbols (functions, classes, variables) by name.\n    \"\"\"\n    try:\n        results = query_service.search_symbols(query, limit)\n        return {\n            \"symbols\": results,\n            \"total\": len(results),\n            \"query\": query\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol search failed: {str(e)}\")\n\n\n@router.get(\"/method-usages\")\nasync def find_method_usages(\n    method_name: str = Query(..., description=\"Name of the method to find usages for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all usages of a specific method.\n    \"\"\"\n    try:\n        usages = query_service.find_method_usages(method_name)\n        return usages\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find method usages: {str(e)}\")\n\n\n@router.get(\"/find_usages\")\nasync def find_usages(\n    symbol_name: str = Query(..., description=\"Symbol name to find usages for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all usages of a specific symbol (alias for method-usages).\n    \"\"\"\n    try:\n        usages = query_service.find_method_usages(symbol_name)\n        return usages\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find usages: {str(e)}\")\n\n\n@router.get(\"/find_callers\")\nasync def find_callers(\n    symbol_name: str = Query(..., description=\"Symbol name to find callers for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all methods/functions that call a specific symbol.\n    \"\"\"\n    try:\n        callers = query_service.find_callers(symbol_name)\n        return {\n            \"callers\": callers,\n            \"symbol\": symbol_name,\n            \"total\": len(callers)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find callers: {str(e)}\")\n\n\n@router.get(\"/class_hierarchy\")\nasync def get_class_hierarchy(\n    class_name: str = Query(..., description=\"Name of the class to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get class hierarchy (inheritance tree).\n    \"\"\"\n    try:\n        hierarchy = query_service.get_class_hierarchy(class_name)\n        return hierarchy\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get class hierarchy: {str(e)}\")\n\n\n@router.get(\"/class-hierarchy\")\nasync def get_class_hierarchy_alt(\n    class_name: str = Query(..., description=\"Name of the class to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get class hierarchy (inheritance tree) - alternative endpoint.\n    \"\"\"\n    try:\n        hierarchy = query_service.get_class_hierarchy(class_name)\n        return hierarchy\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get class hierarchy: {str(e)}\")\n\n\n@router.get(\"/file-structure\")\nasync def analyze_file_structure(\n    file_id: str = Query(..., description=\"File ID to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze the structure of a specific file.\n    \"\"\"\n    try:\n        structure = query_service.get_file_structure(file_id)\n        return structure\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to analyze file structure: {str(e)}\")\n\n\n@router.get(\"/change_impact\")\nasync def analyze_change_impact(\n    symbol_name: str = Query(..., description=\"Symbol to analyze impact for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze the impact of changing a specific symbol.\n    \"\"\"\n    try:\n        # Get all usages of the symbol to understand impact\n        usages = query_service.find_method_usages(symbol_name)\n        callers = query_service.find_callers(symbol_name)\n        \n        return {\n            \"symbol\": symbol_name,\n            \"usages\": usages,\n            \"callers\": callers,\n            \"impact_level\": \"high\" if len(callers) > 5 else \"medium\" if len(callers) > 0 else \"low\"\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to analyze change impact: {str(e)}\")\n\n\n@router.get(\"/relationships\")\nasync def get_code_relationships(\n    symbol_name: str = Query(..., description=\"Symbol to find relationships for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get code relationship analysis for a symbol.\n    \"\"\"\n    try:\n        # Get comprehensive relationship data\n        usages = query_service.find_method_usages(symbol_name)\n        callers = query_service.find_callers(symbol_name)\n        \n        return {\n            \"symbol\": symbol_name,\n            \"relationships\": {\n                \"usages\": usages,\n                \"callers\": callers,\n                \"usage_count\": len(usages.get('usages', [])),\n                \"caller_count\": len(callers)\n            }\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get code relationships: {str(e)}\")\n\n\n@router.get(\"/metrics\")\nasync def get_code_metrics(\n    repo_id: str = Query(None, description=\"Repository ID for repo-specific metrics\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get code metrics and statistics.\n    \"\"\"\n    try:\n        if repo_id:\n            # Get repository-specific stats\n            stats = query_service.get_repository_stats(repo_id)\n            return {\n                \"repository_id\": repo_id,\n                \"metrics\": stats\n            }\n        else:\n            # Get global graph stats\n            stats = query_service.get_graph_stats()\n            return {\n                \"global_metrics\": stats\n            }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get code metrics: {str(e)}\")\n\n\n@router.get(\"/stats\")\nasync def get_graph_stats(\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get overall graph statistics.\n    \"\"\"\n    try:\n        stats = query_service.get_graph_stats()\n        return stats\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get graph stats: {str(e)}\")\n\n\n@router.get(\"/symbol/{qualified_name}\")\nasync def get_symbol_by_qualified_name(\n    qualified_name: str,\n    repo_id: str = Query(..., description=\"Repository ID\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get symbol information by its qualified name.\n    \"\"\"\n    try:\n        symbol = query_service.find_symbol_by_qualified_name(qualified_name, repo_id)\n        if not symbol:\n            raise HTTPException(status_code=404, detail=\"Symbol not found\")\n        return symbol\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find symbol: {str(e)}\")\n\n\n# =========================================================================\n# CodeFinder Tool Integration Endpoints\n# =========================================================================\n\n@router.get(\"/code-finder/function\")\nasync def find_function_by_name(\n    name: str = Query(..., description=\"Function name to search for\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_function_name(name, fuzzy)\n        return {\n            \"function_name\": name,\n            \"fuzzy_search\": fuzzy,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/class\")\nasync def find_class_by_name(\n    name: str = Query(..., description=\"Class name to search for\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find classes by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_class_name(name, fuzzy)\n        return {\n            \"class_name\": name,\n            \"fuzzy_search\": fuzzy,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Class search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/variable\")\nasync def find_variable_by_name(\n    name: str = Query(..., description=\"Variable name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find variables by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_variable_name(name)\n        return {\n            \"variable_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Variable search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/content\")\nasync def find_by_content(\n    query: str = Query(..., description=\"Content search term\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find code by content matching using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_content(query)\n        return {\n            \"search_query\": query,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Content search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/module\")\nasync def find_module_by_name(\n    name: str = Query(..., description=\"Module name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find modules by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_module_name(name)\n        return {\n            \"module_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Module search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/imports\")\nasync def find_imports(\n    name: str = Query(..., description=\"Import name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find import statements using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_imports(name)\n        return {\n            \"import_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Import search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/related\")\nasync def find_related_code(\n    query: str = Query(..., description=\"Search query for related code\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    edit_distance: int = Query(2, description=\"Edit distance for fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find code related to a query using multiple search strategies.\n    \"\"\"\n    try:\n        results = code_finder.find_related_code(query, fuzzy, edit_distance)\n        return {\n            \"search_query\": query,\n            \"fuzzy_search\": fuzzy,\n            \"edit_distance\": edit_distance,\n            **results\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Related code search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/function/arguments\")\nasync def find_functions_by_argument(\n    argument_name: str = Query(..., description=\"Argument name to search for\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions that take a specific argument.\n    \"\"\"\n    try:\n        results = code_finder.find_functions_by_argument(argument_name, path)\n        return {\n            \"argument_name\": argument_name,\n            \"path_filter\": path,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function argument search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/function/decorator\")\nasync def find_functions_by_decorator(\n    decorator_name: str = Query(..., description=\"Decorator name to search for\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions that have a specific decorator.\n    \"\"\"\n    try:\n        results = code_finder.find_functions_by_decorator(decorator_name, path)\n        return {\n            \"decorator_name\": decorator_name,\n            \"path_filter\": path,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function decorator search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/complexity\")\nasync def get_cyclomatic_complexity(\n    function_name: str = Query(..., description=\"Function name to analyze\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get cyclomatic complexity of a function.\n    \"\"\"\n    try:\n        result = code_finder.get_cyclomatic_complexity(function_name, path)\n        if not result:\n            raise HTTPException(status_code=404, detail=\"Function not found\")\n        return {\n            \"function_name\": function_name,\n            \"path_filter\": path,\n            \"complexity\": result\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complexity analysis failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/complexity/top\")\nasync def find_most_complex_functions(\n    limit: int = Query(10, description=\"Number of results to return\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find the most complex functions by cyclomatic complexity.\n    \"\"\"\n    try:\n        results = code_finder.find_most_complex_functions(limit)\n        return {\n            \"limit\": limit,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complex function search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/relationships\")\nasync def analyze_code_relationships(\n    query_type: str = Query(..., description=\"Type of relationship query\"),\n    target: str = Query(..., description=\"Target symbol for analysis\"),\n    context: str = Query(None, description=\"Additional context for the query\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze code relationships using the CodeFinder's relationship query system.\n    \n    Supported query types:\n    - find_callers: Find all functions that call the target function\n    - find_callees: Find all functions called by the target function\n    - find_importers: Find all files that import the target module\n    - who_modifies: Find what functions modify a target variable\n    - class_hierarchy: Find inheritance relationships for a class\n    - call_chain: Find call paths between functions (format: 'start->end')\n    - module_deps: Find module dependencies\n    - variable_scope: Find variable usage across scopes\n    \"\"\"\n    try:\n        results = code_finder.execute_relationship_query(query_type, target, context)\n        return results\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Relationship analysis failed: {str(e)}\")\n\n\n@router.get(\"/repositories/indexed\")\nasync def list_indexed_repositories(\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    List all indexed repositories using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.list_indexed_repositories()\n        return {\n            \"repositories\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to list repositories: {str(e)}\")\n\n\n\n@router.get(\"/language/{language}/symbols\")\nasync def get_language_symbols(\n    language: str,\n    symbol_type: str = Query(..., description=\"Symbol type: function, class, variable, etc.\"),\n    limit: int = Query(50, description=\"Maximum number of results\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get all symbols of a specific type for a given language.\n    \n    Supported symbol types:\n    - function: All functions\n    - class: All classes  \n    - variable: All variables\n    - module: All modules\n    - file: All files\n    \"\"\"\n    try:\n        # Use Neo4j to query symbols by type and language\n        if symbol_type.lower() == \"function\":\n            query = f\"\"\"\n                MATCH (n:Function)\n                OPTIONAL MATCH (f:File)-[:CONTAINS]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.docstring as docstring, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"class\":\n            query = f\"\"\"\n                MATCH (n:Class)\n                OPTIONAL MATCH (f:File)-[:CONTAINS]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.docstring as docstring, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"variable\":\n            query = f\"\"\"\n                MATCH (n:Variable)\n                OPTIONAL MATCH (f:File)-[:CONTAINS*]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.value as value, n.context as context, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"file\":\n            query = f\"\"\"\n                MATCH (n:File)\n                WHERE n.language = $language OR n.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.relative_path as relative_path,\n                       n.language as language, n.extension as extension,\n                       n.is_dependency as is_dependency\n                ORDER BY n.is_dependency ASC, n.path\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"module\":\n            query = f\"\"\"\n                MATCH (n:Module)\n                WHERE n.lang = $language\n                RETURN n.name as name, n.lang as language,\n                       n.full_import_name as full_import_name\n                ORDER BY n.name\n                LIMIT $limit\n            \"\"\"\n        else:\n            raise HTTPException(status_code=400, detail=f\"Unsupported symbol type: {symbol_type}\")\n        \n        records, _, _ = query_service.db.run_query(query, {\"language\": language, \"limit\": limit})\n        \n        return {\n            \"language\": language,\n            \"symbol_type\": symbol_type,\n            \"results\": [dict(record) for record in records],\n            \"total\": len(records),\n            \"limit\": limit\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Language symbol query failed: {str(e)}\")\n\n\n@router.get(\"/language/stats\")\nasync def get_language_statistics(\n    language: str = Query(None, description=\"Optional language filter\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get statistics about programming languages in the codebase.\n    \"\"\"\n    try:\n        if language:\n            # Get stats for specific language\n            query = \"\"\"\n                MATCH (f:File)\n                WHERE f.language = $language OR f.extension IN ['.{}'.format($language.lower()), '.{}'.format($language[:2].lower())]\n                OPTIONAL MATCH (f)-[:CONTAINS]->(func:Function)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(cls:Class)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(var:Variable)\n                RETURN \n                    count(DISTINCT f) as file_count,\n                    count(DISTINCT func) as function_count,\n                    count(DISTINCT cls) as class_count,\n                    count(DISTINCT var) as variable_count\n            \"\"\"\n            records, _, _ = query_service.db.run_query(query, {\"language\": language})\n            result = dict(records[0]) if records else {}\n            result[\"language\"] = language\n            return result\n        else:\n            # Get stats for all languages\n            query = \"\"\"\n                MATCH (f:File)\n                WHERE f.language IS NOT NULL\n                OPTIONAL MATCH (f)-[:CONTAINS]->(func:Function)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(cls:Class)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(var:Variable)\n                RETURN \n                    f.language as language,\n                    count(DISTINCT f) as file_count,\n                    count(DISTINCT func) as function_count,\n                    count(DISTINCT cls) as class_count,\n                    count(DISTINCT var) as variable_count\n                ORDER BY file_count DESC\n            \"\"\"\n            records, _, _ = query_service.db.run_query(query)\n            return {\n                \"languages\": [dict(record) for record in records],\n                \"total_languages\": len(records)\n            }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Language statistics query failed: {str(e)}\")\n\n\n# --- Code Review / Diff Context Endpoints ---\n\n\n@router.get(\"/symbols-at-lines\")\nasync def get_symbols_at_lines(\n    file_path: str = Query(..., description=\"Absolute file path\"),\n    start_line: int = Query(..., description=\"Start line number\"),\n    end_line: int = Query(..., description=\"End line number\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all symbols (functions, classes, variables) overlapping a line range.\n    Useful for mapping diff hunks to affected code.\n    \"\"\"\n    try:\n        results = query_service.get_symbols_at_lines(file_path, start_line, end_line)\n        return {\n            \"file_path\": file_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n            \"symbols\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol lookup failed: {str(e)}\")\n\n\n@router.get(\"/symbols-at-lines-relative\")\nasync def get_symbols_at_lines_relative(\n    repo_id: str = Query(..., description=\"Repository ID (e.g. owner/repo)\"),\n    file_path: str = Query(..., description=\"Repo-relative file path (e.g. src/main.py)\"),\n    start_line: int = Query(..., description=\"Start line number\"),\n    end_line: int = Query(..., description=\"End line number\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all symbols overlapping a line range using repo-relative path.\n    \"\"\"\n    try:\n        results = query_service.get_symbols_at_lines_by_relative_path(\n            repo_id, file_path, start_line, end_line\n        )\n        return {\n            \"repo_id\": repo_id,\n            \"file_path\": file_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n            \"symbols\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol lookup failed: {str(e)}\")\n\n\nclass FileChange(BaseModel):\n    file_path: str\n    start_line: int = 1\n    end_line: int = 999999\n\n\nclass DiffContextRequest(BaseModel):\n    repo_id: str\n    changes: List[FileChange]\n\n\n@router.post(\"/diff-context\")\nasync def get_diff_context(\n    request: DiffContextRequest,\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Build full RAG context for a code diff.\n\n    Given a repository and a list of file changes (path + line ranges),\n    returns affected symbols with source code, their callers, class hierarchy,\n    and full file sources. Designed for AI-powered code review.\n\n    Example request:\n    ```json\n    {\n        \"repo_id\": \"owner/repo\",\n        \"changes\": [\n            {\"file_path\": \"src/main.py\", \"start_line\": 10, \"end_line\": 30},\n            {\"file_path\": \"src/utils.py\", \"start_line\": 1, \"end_line\": 50}\n        ]\n    }\n    ```\n    \"\"\"\n    try:\n        changes_dicts = [c.model_dump() for c in request.changes]\n        result = query_service.get_diff_context(request.repo_id, changes_dicts)\n        return result\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Diff context failed: {str(e)}\")\n\n\n@router.get(\"/file-source\")\nasync def get_file_source(\n    repo_id: str = Query(..., description=\"Repository ID\"),\n    file_path: str = Query(..., description=\"Repo-relative file path\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get the full source code of a file from the graph.\n    \"\"\"\n    try:\n        query = \"\"\"\n        MATCH (f:File)\n        WHERE f.relative_path = $relative_path AND f.path CONTAINS $repo_id\n        RETURN f.source_code as source_code, f.relative_path as path,\n               f.language as language, f.lines_count as lines_count\n        LIMIT 1\n        \"\"\"\n        records, _, _ = query_service.db.run_query(query, {\n            \"relative_path\": file_path,\n            \"repo_id\": repo_id,\n        })\n        if not records:\n            raise HTTPException(status_code=404, detail=\"File not found\")\n        record = records[0]\n        return {\n            \"file_path\": record.get(\"path\"),\n            \"language\": record.get(\"language\"),\n            \"lines_count\": record.get(\"lines_count\"),\n            \"source_code\": record.get(\"source_code\"),\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"File source retrieval failed: {str(e)}\")\n","structuredPatch":[{"oldStart":507,"oldLines":6,"newStart":507,"newLines":53,"lines":["         raise HTTPException(status_code=500, detail=f\"Complex function search failed: {str(e)}\")"," "," ","+@router.get(\"/code-finder/line\")","+async def find_by_line(","+    query: str = Query(..., description=\"Search term to find in file content\"),","+    limit: int = Query(50, description=\"Maximum number of line matches to return\"),","+    query_service: CodeQueryService = Depends(get_query_service),","+) -> Dict[str, Any]:","+    \"\"\"","+    Search raw file content line-by-line.","+    Uses file_content_search fulltext index (falls back to CONTAINS).","+    Returns path + line_number + match_line for each hit — no source dumps.","+    Pair with /code-finder/peek to view context around a hit.","+    \"\"\"","+    try:","+        results = query_service.search_file_content(query, limit)","+        return {","+            \"query\": query,","+            \"results\": results,","+            \"total\": len(results),","+        }","+    except Exception as e:","+        raise HTTPException(status_code=500, detail=f\"Line search failed: {str(e)}\")","+","+","+@router.get(\"/code-finder/peek\")","+async def peek_file_lines(","+    path: str = Query(..., description=\"Absolute file path (as stored in graph)\"),","+    line: int = Query(..., description=\"Anchor line number (1-indexed)\"),","+    above: int = Query(10, description=\"Lines to show above the anchor\"),","+    below: int = Query(10, description=\"Lines to show below the anchor\"),","+    query_service: CodeQueryService = Depends(get_query_service),","+) -> Dict[str, Any]:","+    \"\"\"","+    Return a window of lines around a given line in a file.","+    The anchor line is flagged with is_anchor=true.","+    Use above/below to control the context window size.","+    \"\"\"","+    try:","+        result = query_service.peek_file_lines(path, line, above, below)","+        if \"error\" in result:","+            raise HTTPException(status_code=404, detail=result[\"error\"])","+        return result","+    except HTTPException:","+        raise","+    except Exception as e:","+        raise HTTPException(status_code=500, detail=f\"Peek failed: {str(e)}\")","+","+"," @router.get(\"/code-finder/relationships\")"," async def analyze_code_relationships(","     query_type: str = Query(..., description=\"Type of relationship query\"),"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"f4ed98d3-93f3-4537-b93d-1a374b141ed7"}
{"parentUuid":"cfd1c190-09a7-489a-9d85-878528bcc12a","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01ThUAUkXArWY131jEjS4Rte","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01BYLLLj3DVtYFpFBLvDnXv6","name":"TaskUpdate","input":{"taskId":"2","status":"completed"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1046,"cache_read_input_tokens":92798,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1046},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLuLZNQKigFzRq5CCgbX","type":"assistant","uuid":"e7f1893e-b77d-4f8f-bc6e-db5982a4f8d0","timestamp":"2026-02-21T08:31:50.800Z"}
{"parentUuid":"e7f1893e-b77d-4f8f-bc6e-db5982a4f8d0","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01BYLLLj3DVtYFpFBLvDnXv6","type":"tool_result","content":"Updated task #2 status"}]},"uuid":"1642f09e-faf3-42f8-9908-482f89f20237","timestamp":"2026-02-21T08:31:50.805Z","toolUseResult":{"success":true,"taskId":"2","updatedFields":["status"],"statusChange":{"from":"in_progress","to":"completed"}},"sourceToolAssistantUUID":"e7f1893e-b77d-4f8f-bc6e-db5982a4f8d0"}
{"parentUuid":"1642f09e-faf3-42f8-9908-482f89f20237","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01ThUAUkXArWY131jEjS4Rte","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013X1wjrse8WzPKUjcj4VC5z","name":"TaskUpdate","input":{"taskId":"3","status":"in_progress"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1046,"cache_read_input_tokens":92798,"output_tokens":125,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":1046,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLuLZNQKigFzRq5CCgbX","type":"assistant","uuid":"2efe8970-4a54-49af-b834-addbb048e874","timestamp":"2026-02-21T08:31:51.184Z"}
{"parentUuid":"2efe8970-4a54-49af-b834-addbb048e874","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013X1wjrse8WzPKUjcj4VC5z","type":"tool_result","content":"Updated task #3 status"}]},"uuid":"9a70bd59-ee30-4ed6-afaa-62cc559a5c0c","timestamp":"2026-02-21T08:31:51.186Z","toolUseResult":{"success":true,"taskId":"3","updatedFields":["status"],"statusChange":{"from":"pending","to":"in_progress"}},"sourceToolAssistantUUID":"2efe8970-4a54-49af-b834-addbb048e874"}
{"parentUuid":"9a70bd59-ee30-4ed6-afaa-62cc559a5c0c","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01KmtcjbHSkd7yEqiZNEBVGA","type":"message","role":"assistant","content":[{"type":"text","text":"**Step 4: Update the frontend query page with `SearchResultsView` + `PeekViewer`**"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":198,"cache_read_input_tokens":93844,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":198},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLuLj92P41Nyn2VddRou","type":"assistant","uuid":"5f6f9045-9f95-4c40-b447-b351f7ba2985","timestamp":"2026-02-21T08:31:53.331Z"}
{"parentUuid":"5f6f9045-9f95-4c40-b447-b351f7ba2985","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01KmtcjbHSkd7yEqiZNEBVGA","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Q4WDi5KhXwqG7tv22yMxwx","name":"Write","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/frontend/app/(protected)/query/page.tsx","content":"\"use client\";\n\nimport { useState } from \"react\";\nimport { Card, CardContent, CardHeader, CardTitle } from \"@/components/ui/card\";\nimport { Button } from \"@/components/ui/button\";\nimport { Input } from \"@/components/ui/input\";\nimport { Label } from \"@/components/ui/label\";\nimport { Textarea } from \"@/components/ui/textarea\";\nimport { Tabs, TabsContent, TabsList, TabsTrigger } from \"@/components/ui/tabs\";\nimport { Badge } from \"@/components/ui/badge\";\nimport { CodeBlock } from \"@/components/ui/code-block\";\nimport { toast } from \"sonner\";\nimport * as api from \"@/lib/api\";\n\n// ─── Types ────────────────────────────────────────────────────────────────────\n\ninterface SearchHit {\n  name?: string;\n  type?: string;\n  path?: string;\n  line_number?: number;\n  match_line?: string;\n  score?: number;\n}\n\ninterface PeekLine {\n  line_number: number;\n  content: string;\n  is_anchor: boolean;\n}\n\ninterface PeekResult {\n  path: string;\n  anchor_line: number;\n  window: PeekLine[];\n  total_lines: number;\n}\n\ntype QueryDef = {\n  label: string;\n  placeholder: string;\n  fn: (q: string) => Promise<unknown>;\n  needsInput: boolean;\n  isSearch?: boolean;\n};\n\n// ─── Query definitions ────────────────────────────────────────────────────────\n\nconst queryGroups: Record<string, QueryDef[]> = {\n  Search: [\n    {\n      label: \"Full-text Search\",\n      placeholder: \"Search query (e.g. LoginRequest)...\",\n      fn: api.searchCode,\n      needsInput: true,\n      isSearch: true,\n    },\n    {\n      label: \"Symbol Search\",\n      placeholder: \"Symbol name (e.g. LoginRequest)...\",\n      fn: api.searchSymbols,\n      needsInput: true,\n      isSearch: true,\n    },\n  ],\n  Analysis: [\n    { label: \"Method Usages\", placeholder: \"Method name...\", fn: api.getMethodUsages, needsInput: true },\n    { label: \"Find Callers\", placeholder: \"Symbol name...\", fn: api.findCallers, needsInput: true },\n    { label: \"Class Hierarchy\", placeholder: \"Class name...\", fn: api.getClassHierarchy, needsInput: true },\n    { label: \"Change Impact\", placeholder: \"Symbol name...\", fn: api.getChangeImpact, needsInput: true },\n  ],\n  CodeFinder: [\n    { label: \"Function\", placeholder: \"Function name...\", fn: api.findFunction, needsInput: true },\n    { label: \"Class\", placeholder: \"Class name...\", fn: api.findClass, needsInput: true },\n    { label: \"Variable\", placeholder: \"Variable name...\", fn: api.findVariable, needsInput: true },\n    { label: \"Content\", placeholder: \"Content query...\", fn: api.findContent, needsInput: true },\n    { label: \"Module\", placeholder: \"Module name...\", fn: api.findModule, needsInput: true },\n    { label: \"Imports\", placeholder: \"Import name...\", fn: api.findImports, needsInput: true },\n    {\n      label: \"Line Search\",\n      placeholder: \"Code snippet to find in files...\",\n      fn: api.findByLine,\n      needsInput: true,\n      isSearch: true,\n    },\n  ],\n  Metrics: [\n    { label: \"Graph Stats\", placeholder: \"\", fn: api.getGraphStats, needsInput: false },\n    { label: \"Language Stats\", placeholder: \"\", fn: api.getLanguageStats, needsInput: false },\n    { label: \"Top Complex Functions\", placeholder: \"\", fn: api.getTopComplexFunctions, needsInput: false },\n  ],\n};\n\n// ─── PeekViewer ───────────────────────────────────────────────────────────────\n\nfunction PeekViewer({ path, anchorLine }: { path: string; anchorLine: number }) {\n  const STEP = 20;\n  const [above, setAbove] = useState(10);\n  const [below, setBelow] = useState(10);\n  const [result, setResult] = useState<PeekResult | null>(null);\n  const [loading, setLoading] = useState(false);\n  const [opened, setOpened] = useState(false);\n\n  const load = async (newAbove: number, newBelow: number) => {\n    setLoading(true);\n    try {\n      const data = await api.peekFileLines(path, anchorLine, newAbove, newBelow);\n      setResult(data as PeekResult);\n      setAbove(newAbove);\n      setBelow(newBelow);\n    } catch {\n      toast.error(\"Failed to load context\");\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  if (!opened) {\n    return (\n      <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" onClick={() => { setOpened(true); load(above, below); }}>\n        Peek context\n      </Button>\n    );\n  }\n\n  return (\n    <div className=\"mt-2 space-y-1\">\n      <div className=\"flex gap-2 items-center\">\n        <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" disabled={loading} onClick={() => load(above + STEP, below)}>\n          ↑ Load {STEP} more above\n        </Button>\n        <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" disabled={loading} onClick={() => load(above, below + STEP)}>\n          Load {STEP} more below ↓\n        </Button>\n        <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" onClick={() => setOpened(false)}>\n          Close\n        </Button>\n        {result && (\n          <span className=\"text-xs text-muted-foreground\">\n            Lines {result.window[0]?.line_number}–{result.window[result.window.length - 1]?.line_number} / {result.total_lines}\n          </span>\n        )}\n      </div>\n\n      {result && (\n        <div className=\"font-mono text-xs rounded border border-border overflow-x-auto\">\n          {result.window.map((ln) => (\n            <div\n              key={ln.line_number}\n              className={`flex gap-2 px-2 py-0.5 ${ln.is_anchor ? \"bg-yellow-500/20 font-semibold\" : \"hover:bg-muted/30\"}`}\n            >\n              <span className=\"select-none w-10 text-right text-muted-foreground shrink-0\">\n                {ln.line_number}\n              </span>\n              <span className=\"whitespace-pre\">{ln.content}</span>\n            </div>\n          ))}\n        </div>\n      )}\n    </div>\n  );\n}\n\n// ─── SearchResultsView ────────────────────────────────────────────────────────\n\nfunction SearchResultsView({ data }: { data: unknown }) {\n  // Normalise: the API wraps results in { results: [...], total: N } or { symbols: [...] }\n  let hits: SearchHit[] = [];\n  if (Array.isArray(data)) {\n    hits = data as SearchHit[];\n  } else if (data && typeof data === \"object\") {\n    const obj = data as Record<string, unknown>;\n    const inner = obj.results ?? obj.symbols ?? obj.ranked_results ?? [];\n    if (Array.isArray(inner)) hits = inner as SearchHit[];\n  }\n\n  if (hits.length === 0) {\n    return <p className=\"text-muted-foreground text-sm\">No results found.</p>;\n  }\n\n  return (\n    <div className=\"space-y-2 max-h-[680px] overflow-y-auto\">\n      {hits.map((hit, i) => (\n        <div key={i} className=\"p-3 rounded border border-border space-y-1\">\n          <div className=\"flex flex-wrap items-center gap-2\">\n            {hit.type && (\n              <Badge variant={hit.type === \"function\" ? \"default\" : hit.type === \"class\" ? \"secondary\" : \"outline\"}>\n                {hit.type}\n              </Badge>\n            )}\n            {hit.name && <span className=\"font-mono font-medium\">{hit.name}</span>}\n            {hit.match_line && !hit.name && (\n              <span className=\"font-mono text-sm text-foreground\">{hit.match_line.trim()}</span>\n            )}\n            {hit.score != null && (\n              <span className=\"ml-auto text-xs text-muted-foreground\">score {hit.score.toFixed(3)}</span>\n            )}\n          </div>\n\n          {hit.path && (\n            <div className=\"flex items-center gap-2 text-xs text-muted-foreground\">\n              <span className=\"font-mono truncate\">{hit.path}</span>\n              {hit.line_number != null && hit.line_number > 0 && (\n                <span className=\"shrink-0\">:{hit.line_number}</span>\n              )}\n            </div>\n          )}\n\n          {hit.match_line && hit.name && (\n            <p className=\"text-xs font-mono text-muted-foreground truncate\">{hit.match_line.trim()}</p>\n          )}\n\n          {hit.path && hit.line_number != null && hit.line_number > 0 && (\n            <PeekViewer path={hit.path} anchorLine={hit.line_number} />\n          )}\n        </div>\n      ))}\n    </div>\n  );\n}\n\n// ─── Main page ────────────────────────────────────────────────────────────────\n\nexport default function QueryPage() {\n  const [input, setInput] = useState(\"\");\n  const [loading, setLoading] = useState(false);\n  const [results, setResults] = useState<unknown>(null);\n  const [activeQuery, setActiveQuery] = useState<QueryDef | null>(null);\n\n  // Diff context state\n  const [diffRepoId, setDiffRepoId] = useState(\"\");\n  const [diffChangesText, setDiffChangesText] = useState(\"\");\n  const [diffLoading, setDiffLoading] = useState(false);\n  const [diffResults, setDiffResults] = useState<unknown>(null);\n\n  const runQuery = async (qDef: QueryDef) => {\n    if (qDef.needsInput && !input.trim()) {\n      toast.error(\"Please enter a query\");\n      return;\n    }\n    setLoading(true);\n    setActiveQuery(qDef);\n    setResults(null);\n    try {\n      const data = await qDef.fn(input.trim());\n      setResults(data);\n    } catch (e) {\n      toast.error(`Query failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  const runDiffContext = async () => {\n    if (!diffRepoId.trim()) {\n      toast.error(\"Please enter a repository ID\");\n      return;\n    }\n    const lines = diffChangesText.trim().split(\"\\n\").filter(Boolean);\n    const changes = lines.map((line) => {\n      const [filePath, range] = line.split(\":\");\n      if (range) {\n        const [start, end] = range.split(\"-\").map(Number);\n        return { file_path: filePath.trim(), start_line: start || 1, end_line: end || 999999 };\n      }\n      return { file_path: filePath.trim() };\n    });\n\n    if (changes.length === 0) {\n      toast.error(\"Please enter at least one file change\");\n      return;\n    }\n\n    setDiffLoading(true);\n    setDiffResults(null);\n    try {\n      const data = await api.getDiffContext({ repo_id: diffRepoId.trim(), changes });\n      setDiffResults(data);\n    } catch (e) {\n      toast.error(`Diff context failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);\n    } finally {\n      setDiffLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"max-w-5xl mx-auto space-y-6\">\n      <h1 className=\"text-2xl font-bold\">Query</h1>\n\n      <Tabs defaultValue=\"Search\">\n        <TabsList>\n          {Object.keys(queryGroups).map((group) => (\n            <TabsTrigger key={group} value={group}>\n              {group}\n            </TabsTrigger>\n          ))}\n          <TabsTrigger value=\"DiffContext\">Code Review</TabsTrigger>\n        </TabsList>\n\n        {Object.entries(queryGroups).map(([group, queries]) => (\n          <TabsContent key={group} value={group} className=\"space-y-4 pt-4\">\n            <Input\n              placeholder=\"Enter search term or symbol name...\"\n              value={input}\n              onChange={(e) => setInput(e.target.value)}\n              className=\"text-base\"\n              onKeyDown={(e) => {\n                if (e.key === \"Enter\" && activeQuery) runQuery(activeQuery);\n              }}\n            />\n            <div className=\"flex flex-wrap gap-2\">\n              {queries.map((q) => (\n                <Button\n                  key={q.label}\n                  variant={activeQuery?.label === q.label ? \"default\" : \"secondary\"}\n                  size=\"sm\"\n                  onClick={() => runQuery(q)}\n                  disabled={loading}\n                >\n                  {q.label}\n                </Button>\n              ))}\n            </div>\n          </TabsContent>\n        ))}\n\n        <TabsContent value=\"DiffContext\" className=\"space-y-4 pt-4\">\n          <Card>\n            <CardHeader>\n              <CardTitle>Diff Context Builder</CardTitle>\n            </CardHeader>\n            <CardContent className=\"space-y-4\">\n              <p className=\"text-sm text-muted-foreground\">\n                Build RAG context for code review. Provide the repository and changed files\n                to get affected symbols, their callers, class hierarchy, and source code.\n              </p>\n              <div className=\"space-y-2\">\n                <Label>Repository ID</Label>\n                <Input\n                  placeholder=\"owner/repo_name\"\n                  value={diffRepoId}\n                  onChange={(e) => setDiffRepoId(e.target.value)}\n                />\n              </div>\n              <div className=\"space-y-2\">\n                <Label>Changed Files</Label>\n                <Textarea\n                  placeholder={\"One per line — file_path:start_line-end_line\\n\\nExamples:\\nsrc/main.py:10-30\\nsrc/utils.py:1-50\\nREADME.md\"}\n                  value={diffChangesText}\n                  onChange={(e) => setDiffChangesText(e.target.value)}\n                  rows={6}\n                  className=\"font-mono text-sm\"\n                />\n              </div>\n              <Button onClick={runDiffContext} disabled={diffLoading}>\n                {diffLoading ? \"Loading...\" : \"Get Diff Context\"}\n              </Button>\n            </CardContent>\n          </Card>\n\n          {diffResults !== null && (\n            <DiffContextResults data={diffResults as DiffContextData} />\n          )}\n        </TabsContent>\n      </Tabs>\n\n      {/* Query results */}\n      {loading && (\n        <Card>\n          <CardContent className=\"py-8 text-center text-muted-foreground\">\n            Loading...\n          </CardContent>\n        </Card>\n      )}\n\n      {!loading && results !== null && activeQuery !== null && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm text-muted-foreground\">\n              Results: {activeQuery.label}\n            </CardTitle>\n          </CardHeader>\n          <CardContent>\n            {activeQuery.isSearch ? (\n              <SearchResultsView data={results} />\n            ) : (\n              <ResultsView data={results} />\n            )}\n          </CardContent>\n        </Card>\n      )}\n    </div>\n  );\n}\n\n// ─── Diff Context Results ──────────────────────────────────────────────────────\n\ninterface DiffContextData {\n  affected_symbols: {\n    type: string;\n    name: string;\n    start_line: number;\n    end_line: number;\n    source: string | null;\n    docstring: string | null;\n    change_file: string;\n    file_path?: string;\n  }[];\n  callers: {\n    symbol: string;\n    symbol_type: string;\n    callers: { type: string; name: string; path: string; source: string | null }[];\n  }[];\n  class_hierarchy: {\n    class: string;\n    hierarchy: { name: string; path: string; source: string | null }[];\n  }[];\n  file_sources: Record<string, string>;\n  total_affected: number;\n  total_files: number;\n}\n\nfunction DiffContextResults({ data }: { data: DiffContextData }) {\n  return (\n    <div className=\"space-y-4\">\n      <div className=\"flex gap-3\">\n        <Badge variant=\"secondary\">{data.total_files} files</Badge>\n        <Badge variant=\"secondary\">{data.total_affected} affected symbols</Badge>\n        <Badge variant=\"secondary\">{data.callers.length} caller chains</Badge>\n        <Badge variant=\"secondary\">{data.class_hierarchy.length} class hierarchies</Badge>\n      </div>\n\n      {data.affected_symbols.length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">Affected Symbols</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-2 max-h-[400px] overflow-y-auto\">\n            {data.affected_symbols.map((sym, i) => (\n              <div key={i} className=\"p-3 rounded border border-border space-y-1\">\n                <div className=\"flex items-center gap-2\">\n                  <Badge variant={sym.type === \"function\" ? \"default\" : \"secondary\"}>{sym.type}</Badge>\n                  <span className=\"font-medium font-mono\">{sym.name}</span>\n                  <span className=\"text-xs text-muted-foreground\">\n                    {sym.change_file}:{sym.start_line}-{sym.end_line}\n                  </span>\n                </div>\n                {sym.docstring && (\n                  <p className=\"text-xs text-muted-foreground\">{sym.docstring}</p>\n                )}\n                {sym.source && (\n                  <CodeBlock\n                    code={sym.source}\n                    startLine={sym.start_line}\n                    maxHeight=\"max-h-48\"\n                  />\n                )}\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {data.callers.length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">Callers of Affected Symbols</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-3 max-h-[400px] overflow-y-auto\">\n            {data.callers.map((group, i) => (\n              <div key={i} className=\"space-y-1\">\n                <p className=\"text-sm font-medium\">\n                  <Badge variant=\"outline\" className=\"mr-1\">{group.symbol_type}</Badge>\n                  <span className=\"font-mono\">{group.symbol}</span>\n                  <span className=\"text-muted-foreground ml-1\">called by:</span>\n                </p>\n                {group.callers.map((caller, j) => (\n                  <div key={j} className=\"ml-4 p-2 rounded border border-border text-sm\">\n                    <span className=\"font-mono\">{caller.name}</span>\n                    <span className=\"text-xs text-muted-foreground ml-2\">{caller.path}</span>\n                    {caller.source && (\n                      <CodeBlock\n                        code={caller.source}\n                        maxHeight=\"max-h-32\"\n                        className=\"mt-1\"\n                      />\n                    )}\n                  </div>\n                ))}\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {data.class_hierarchy.length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">Class Hierarchy</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-2 max-h-[300px] overflow-y-auto\">\n            {data.class_hierarchy.map((h, i) => (\n              <div key={i} className=\"space-y-1\">\n                <p className=\"text-sm font-medium font-mono\">{h.class}</p>\n                <div className=\"ml-4 space-y-1\">\n                  {h.hierarchy.map((parent, j) => (\n                    <div key={j} className=\"flex items-center gap-2 text-sm\">\n                      <span className=\"text-muted-foreground\">{j === 0 ? \"\" : \"\\u2514\\u2500\"}</span>\n                      <span className=\"font-mono\">{parent.name}</span>\n                      <span className=\"text-xs text-muted-foreground\">{parent.path}</span>\n                    </div>\n                  ))}\n                </div>\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {Object.keys(data.file_sources).length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">File Sources</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-3 max-h-[400px] overflow-y-auto\">\n            {Object.entries(data.file_sources).map(([path, source]) => (\n              <div key={path} className=\"space-y-1\">\n                <p className=\"text-sm font-mono text-primary\">{path}</p>\n                <CodeBlock code={source} maxHeight=\"max-h-64\" />\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n    </div>\n  );\n}\n\n// ─── Generic Results ──────────────────────────────────────────────────────────\n\nfunction ResultsView({ data }: { data: unknown }) {\n  if (data === null || data === undefined) {\n    return <p className=\"text-muted-foreground\">No results</p>;\n  }\n\n  if (Array.isArray(data)) {\n    if (data.length === 0) return <p className=\"text-muted-foreground\">No results found</p>;\n    return (\n      <div className=\"space-y-2 max-h-[600px] overflow-y-auto\">\n        {data.map((item, i) => (\n          <div key={i} className=\"p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n            {typeof item === \"object\" ? <ObjectView obj={item} /> : String(item)}\n          </div>\n        ))}\n      </div>\n    );\n  }\n\n  if (typeof data === \"object\") {\n    return <ObjectView obj={data as Record<string, unknown>} />;\n  }\n\n  return <pre className=\"text-sm font-mono\">{String(data)}</pre>;\n}\n\nfunction ObjectView({ obj }: { obj: Record<string, unknown> }) {\n  return (\n    <div className=\"space-y-1\">\n      {Object.entries(obj).map(([key, value]) => {\n        if (key === \"source\" && typeof value === \"string\" && value) {\n          const startLine = (obj.line_number as number) || (obj.start_line as number) || 1;\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <CodeBlock code={value} startLine={startLine} maxHeight=\"max-h-64\" />\n            </div>\n          );\n        }\n\n        if (Array.isArray(value)) {\n          if (value.length === 0) {\n            return (\n              <div key={key} className=\"flex gap-2\">\n                <span className=\"text-primary font-medium shrink-0\">{key}:</span>\n                <span className=\"text-muted-foreground\">[]</span>\n              </div>\n            );\n          }\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <div className=\"ml-4 space-y-2\">\n                {value.map((item, i) => (\n                  <div key={i} className=\"p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n                    {typeof item === \"object\" && item !== null\n                      ? <ObjectView obj={item as Record<string, unknown>} />\n                      : String(item)}\n                  </div>\n                ))}\n              </div>\n            </div>\n          );\n        }\n\n        if (typeof value === \"object\" && value !== null) {\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <div className=\"ml-4 p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n                <ObjectView obj={value as Record<string, unknown>} />\n              </div>\n            </div>\n          );\n        }\n\n        return (\n          <div key={key} className=\"flex gap-2\">\n            <span className=\"text-primary font-medium shrink-0\">{key}:</span>\n            <span className=\"text-muted-foreground break-all\">\n              {String(value ?? \"\\u2014\")}\n            </span>\n          </div>\n        );\n      })}\n    </div>\n  );\n}\n"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":198,"cache_read_input_tokens":93844,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":198},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLuLj92P41Nyn2VddRou","type":"assistant","uuid":"8f774f1c-b68c-44c0-bd35-8e28fe5497ed","timestamp":"2026-02-21T08:33:07.839Z"}
{"type":"file-history-snapshot","messageId":"8f774f1c-b68c-44c0-bd35-8e28fe5497ed","snapshot":{"messageId":"c24e474a-29dd-4bc8-afe3-07caafdf094e","trackedFileBackups":{"db/schema.py":{"backupFileName":"283975a9ba984ffc@v1","version":1,"backupTime":"2026-02-21T08:25:31.646Z"},"db/queries.py":{"backupFileName":"3dbb7f971a633538@v1","version":1,"backupTime":"2026-02-21T08:31:28.475Z"},"api/routers/query.py":{"backupFileName":"e6ad69c83e8fb9b0@v1","version":1,"backupTime":"2026-02-21T08:31:48.989Z"},"frontend/app/(protected)/query/page.tsx":{"backupFileName":"30dea031ecc29fcb@v1","version":1,"backupTime":"2026-02-21T08:34:10.076Z"}},"timestamp":"2026-02-21T08:05:38.177Z"},"isSnapshotUpdate":true}
{"parentUuid":"8f774f1c-b68c-44c0-bd35-8e28fe5497ed","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Write","command":"callback"},"parentToolUseID":"toolu_01Q4WDi5KhXwqG7tv22yMxwx","toolUseID":"toolu_01Q4WDi5KhXwqG7tv22yMxwx","timestamp":"2026-02-21T08:34:10.086Z","uuid":"d86ba194-6454-47a7-878f-61fb32738b93"}
{"parentUuid":"8f774f1c-b68c-44c0-bd35-8e28fe5497ed","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Q4WDi5KhXwqG7tv22yMxwx","type":"tool_result","content":"The file /Users/skmabudalam/Documents/BugViper/frontend/app/(protected)/query/page.tsx has been updated successfully."}]},"uuid":"5f7bf1fb-28c9-4c24-92cd-e5aec47c013c","timestamp":"2026-02-21T08:34:10.083Z","toolUseResult":{"type":"update","filePath":"/Users/skmabudalam/Documents/BugViper/frontend/app/(protected)/query/page.tsx","content":"\"use client\";\n\nimport { useState } from \"react\";\nimport { Card, CardContent, CardHeader, CardTitle } from \"@/components/ui/card\";\nimport { Button } from \"@/components/ui/button\";\nimport { Input } from \"@/components/ui/input\";\nimport { Label } from \"@/components/ui/label\";\nimport { Textarea } from \"@/components/ui/textarea\";\nimport { Tabs, TabsContent, TabsList, TabsTrigger } from \"@/components/ui/tabs\";\nimport { Badge } from \"@/components/ui/badge\";\nimport { CodeBlock } from \"@/components/ui/code-block\";\nimport { toast } from \"sonner\";\nimport * as api from \"@/lib/api\";\n\n// ─── Types ────────────────────────────────────────────────────────────────────\n\ninterface SearchHit {\n  name?: string;\n  type?: string;\n  path?: string;\n  line_number?: number;\n  match_line?: string;\n  score?: number;\n}\n\ninterface PeekLine {\n  line_number: number;\n  content: string;\n  is_anchor: boolean;\n}\n\ninterface PeekResult {\n  path: string;\n  anchor_line: number;\n  window: PeekLine[];\n  total_lines: number;\n}\n\ntype QueryDef = {\n  label: string;\n  placeholder: string;\n  fn: (q: string) => Promise<unknown>;\n  needsInput: boolean;\n  isSearch?: boolean;\n};\n\n// ─── Query definitions ────────────────────────────────────────────────────────\n\nconst queryGroups: Record<string, QueryDef[]> = {\n  Search: [\n    {\n      label: \"Full-text Search\",\n      placeholder: \"Search query (e.g. LoginRequest)...\",\n      fn: api.searchCode,\n      needsInput: true,\n      isSearch: true,\n    },\n    {\n      label: \"Symbol Search\",\n      placeholder: \"Symbol name (e.g. LoginRequest)...\",\n      fn: api.searchSymbols,\n      needsInput: true,\n      isSearch: true,\n    },\n  ],\n  Analysis: [\n    { label: \"Method Usages\", placeholder: \"Method name...\", fn: api.getMethodUsages, needsInput: true },\n    { label: \"Find Callers\", placeholder: \"Symbol name...\", fn: api.findCallers, needsInput: true },\n    { label: \"Class Hierarchy\", placeholder: \"Class name...\", fn: api.getClassHierarchy, needsInput: true },\n    { label: \"Change Impact\", placeholder: \"Symbol name...\", fn: api.getChangeImpact, needsInput: true },\n  ],\n  CodeFinder: [\n    { label: \"Function\", placeholder: \"Function name...\", fn: api.findFunction, needsInput: true },\n    { label: \"Class\", placeholder: \"Class name...\", fn: api.findClass, needsInput: true },\n    { label: \"Variable\", placeholder: \"Variable name...\", fn: api.findVariable, needsInput: true },\n    { label: \"Content\", placeholder: \"Content query...\", fn: api.findContent, needsInput: true },\n    { label: \"Module\", placeholder: \"Module name...\", fn: api.findModule, needsInput: true },\n    { label: \"Imports\", placeholder: \"Import name...\", fn: api.findImports, needsInput: true },\n    {\n      label: \"Line Search\",\n      placeholder: \"Code snippet to find in files...\",\n      fn: api.findByLine,\n      needsInput: true,\n      isSearch: true,\n    },\n  ],\n  Metrics: [\n    { label: \"Graph Stats\", placeholder: \"\", fn: api.getGraphStats, needsInput: false },\n    { label: \"Language Stats\", placeholder: \"\", fn: api.getLanguageStats, needsInput: false },\n    { label: \"Top Complex Functions\", placeholder: \"\", fn: api.getTopComplexFunctions, needsInput: false },\n  ],\n};\n\n// ─── PeekViewer ───────────────────────────────────────────────────────────────\n\nfunction PeekViewer({ path, anchorLine }: { path: string; anchorLine: number }) {\n  const STEP = 20;\n  const [above, setAbove] = useState(10);\n  const [below, setBelow] = useState(10);\n  const [result, setResult] = useState<PeekResult | null>(null);\n  const [loading, setLoading] = useState(false);\n  const [opened, setOpened] = useState(false);\n\n  const load = async (newAbove: number, newBelow: number) => {\n    setLoading(true);\n    try {\n      const data = await api.peekFileLines(path, anchorLine, newAbove, newBelow);\n      setResult(data as PeekResult);\n      setAbove(newAbove);\n      setBelow(newBelow);\n    } catch {\n      toast.error(\"Failed to load context\");\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  if (!opened) {\n    return (\n      <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" onClick={() => { setOpened(true); load(above, below); }}>\n        Peek context\n      </Button>\n    );\n  }\n\n  return (\n    <div className=\"mt-2 space-y-1\">\n      <div className=\"flex gap-2 items-center\">\n        <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" disabled={loading} onClick={() => load(above + STEP, below)}>\n          ↑ Load {STEP} more above\n        </Button>\n        <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" disabled={loading} onClick={() => load(above, below + STEP)}>\n          Load {STEP} more below ↓\n        </Button>\n        <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" onClick={() => setOpened(false)}>\n          Close\n        </Button>\n        {result && (\n          <span className=\"text-xs text-muted-foreground\">\n            Lines {result.window[0]?.line_number}–{result.window[result.window.length - 1]?.line_number} / {result.total_lines}\n          </span>\n        )}\n      </div>\n\n      {result && (\n        <div className=\"font-mono text-xs rounded border border-border overflow-x-auto\">\n          {result.window.map((ln) => (\n            <div\n              key={ln.line_number}\n              className={`flex gap-2 px-2 py-0.5 ${ln.is_anchor ? \"bg-yellow-500/20 font-semibold\" : \"hover:bg-muted/30\"}`}\n            >\n              <span className=\"select-none w-10 text-right text-muted-foreground shrink-0\">\n                {ln.line_number}\n              </span>\n              <span className=\"whitespace-pre\">{ln.content}</span>\n            </div>\n          ))}\n        </div>\n      )}\n    </div>\n  );\n}\n\n// ─── SearchResultsView ────────────────────────────────────────────────────────\n\nfunction SearchResultsView({ data }: { data: unknown }) {\n  // Normalise: the API wraps results in { results: [...], total: N } or { symbols: [...] }\n  let hits: SearchHit[] = [];\n  if (Array.isArray(data)) {\n    hits = data as SearchHit[];\n  } else if (data && typeof data === \"object\") {\n    const obj = data as Record<string, unknown>;\n    const inner = obj.results ?? obj.symbols ?? obj.ranked_results ?? [];\n    if (Array.isArray(inner)) hits = inner as SearchHit[];\n  }\n\n  if (hits.length === 0) {\n    return <p className=\"text-muted-foreground text-sm\">No results found.</p>;\n  }\n\n  return (\n    <div className=\"space-y-2 max-h-[680px] overflow-y-auto\">\n      {hits.map((hit, i) => (\n        <div key={i} className=\"p-3 rounded border border-border space-y-1\">\n          <div className=\"flex flex-wrap items-center gap-2\">\n            {hit.type && (\n              <Badge variant={hit.type === \"function\" ? \"default\" : hit.type === \"class\" ? \"secondary\" : \"outline\"}>\n                {hit.type}\n              </Badge>\n            )}\n            {hit.name && <span className=\"font-mono font-medium\">{hit.name}</span>}\n            {hit.match_line && !hit.name && (\n              <span className=\"font-mono text-sm text-foreground\">{hit.match_line.trim()}</span>\n            )}\n            {hit.score != null && (\n              <span className=\"ml-auto text-xs text-muted-foreground\">score {hit.score.toFixed(3)}</span>\n            )}\n          </div>\n\n          {hit.path && (\n            <div className=\"flex items-center gap-2 text-xs text-muted-foreground\">\n              <span className=\"font-mono truncate\">{hit.path}</span>\n              {hit.line_number != null && hit.line_number > 0 && (\n                <span className=\"shrink-0\">:{hit.line_number}</span>\n              )}\n            </div>\n          )}\n\n          {hit.match_line && hit.name && (\n            <p className=\"text-xs font-mono text-muted-foreground truncate\">{hit.match_line.trim()}</p>\n          )}\n\n          {hit.path && hit.line_number != null && hit.line_number > 0 && (\n            <PeekViewer path={hit.path} anchorLine={hit.line_number} />\n          )}\n        </div>\n      ))}\n    </div>\n  );\n}\n\n// ─── Main page ────────────────────────────────────────────────────────────────\n\nexport default function QueryPage() {\n  const [input, setInput] = useState(\"\");\n  const [loading, setLoading] = useState(false);\n  const [results, setResults] = useState<unknown>(null);\n  const [activeQuery, setActiveQuery] = useState<QueryDef | null>(null);\n\n  // Diff context state\n  const [diffRepoId, setDiffRepoId] = useState(\"\");\n  const [diffChangesText, setDiffChangesText] = useState(\"\");\n  const [diffLoading, setDiffLoading] = useState(false);\n  const [diffResults, setDiffResults] = useState<unknown>(null);\n\n  const runQuery = async (qDef: QueryDef) => {\n    if (qDef.needsInput && !input.trim()) {\n      toast.error(\"Please enter a query\");\n      return;\n    }\n    setLoading(true);\n    setActiveQuery(qDef);\n    setResults(null);\n    try {\n      const data = await qDef.fn(input.trim());\n      setResults(data);\n    } catch (e) {\n      toast.error(`Query failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  const runDiffContext = async () => {\n    if (!diffRepoId.trim()) {\n      toast.error(\"Please enter a repository ID\");\n      return;\n    }\n    const lines = diffChangesText.trim().split(\"\\n\").filter(Boolean);\n    const changes = lines.map((line) => {\n      const [filePath, range] = line.split(\":\");\n      if (range) {\n        const [start, end] = range.split(\"-\").map(Number);\n        return { file_path: filePath.trim(), start_line: start || 1, end_line: end || 999999 };\n      }\n      return { file_path: filePath.trim() };\n    });\n\n    if (changes.length === 0) {\n      toast.error(\"Please enter at least one file change\");\n      return;\n    }\n\n    setDiffLoading(true);\n    setDiffResults(null);\n    try {\n      const data = await api.getDiffContext({ repo_id: diffRepoId.trim(), changes });\n      setDiffResults(data);\n    } catch (e) {\n      toast.error(`Diff context failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);\n    } finally {\n      setDiffLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"max-w-5xl mx-auto space-y-6\">\n      <h1 className=\"text-2xl font-bold\">Query</h1>\n\n      <Tabs defaultValue=\"Search\">\n        <TabsList>\n          {Object.keys(queryGroups).map((group) => (\n            <TabsTrigger key={group} value={group}>\n              {group}\n            </TabsTrigger>\n          ))}\n          <TabsTrigger value=\"DiffContext\">Code Review</TabsTrigger>\n        </TabsList>\n\n        {Object.entries(queryGroups).map(([group, queries]) => (\n          <TabsContent key={group} value={group} className=\"space-y-4 pt-4\">\n            <Input\n              placeholder=\"Enter search term or symbol name...\"\n              value={input}\n              onChange={(e) => setInput(e.target.value)}\n              className=\"text-base\"\n              onKeyDown={(e) => {\n                if (e.key === \"Enter\" && activeQuery) runQuery(activeQuery);\n              }}\n            />\n            <div className=\"flex flex-wrap gap-2\">\n              {queries.map((q) => (\n                <Button\n                  key={q.label}\n                  variant={activeQuery?.label === q.label ? \"default\" : \"secondary\"}\n                  size=\"sm\"\n                  onClick={() => runQuery(q)}\n                  disabled={loading}\n                >\n                  {q.label}\n                </Button>\n              ))}\n            </div>\n          </TabsContent>\n        ))}\n\n        <TabsContent value=\"DiffContext\" className=\"space-y-4 pt-4\">\n          <Card>\n            <CardHeader>\n              <CardTitle>Diff Context Builder</CardTitle>\n            </CardHeader>\n            <CardContent className=\"space-y-4\">\n              <p className=\"text-sm text-muted-foreground\">\n                Build RAG context for code review. Provide the repository and changed files\n                to get affected symbols, their callers, class hierarchy, and source code.\n              </p>\n              <div className=\"space-y-2\">\n                <Label>Repository ID</Label>\n                <Input\n                  placeholder=\"owner/repo_name\"\n                  value={diffRepoId}\n                  onChange={(e) => setDiffRepoId(e.target.value)}\n                />\n              </div>\n              <div className=\"space-y-2\">\n                <Label>Changed Files</Label>\n                <Textarea\n                  placeholder={\"One per line — file_path:start_line-end_line\\n\\nExamples:\\nsrc/main.py:10-30\\nsrc/utils.py:1-50\\nREADME.md\"}\n                  value={diffChangesText}\n                  onChange={(e) => setDiffChangesText(e.target.value)}\n                  rows={6}\n                  className=\"font-mono text-sm\"\n                />\n              </div>\n              <Button onClick={runDiffContext} disabled={diffLoading}>\n                {diffLoading ? \"Loading...\" : \"Get Diff Context\"}\n              </Button>\n            </CardContent>\n          </Card>\n\n          {diffResults !== null && (\n            <DiffContextResults data={diffResults as DiffContextData} />\n          )}\n        </TabsContent>\n      </Tabs>\n\n      {/* Query results */}\n      {loading && (\n        <Card>\n          <CardContent className=\"py-8 text-center text-muted-foreground\">\n            Loading...\n          </CardContent>\n        </Card>\n      )}\n\n      {!loading && results !== null && activeQuery !== null && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm text-muted-foreground\">\n              Results: {activeQuery.label}\n            </CardTitle>\n          </CardHeader>\n          <CardContent>\n            {activeQuery.isSearch ? (\n              <SearchResultsView data={results} />\n            ) : (\n              <ResultsView data={results} />\n            )}\n          </CardContent>\n        </Card>\n      )}\n    </div>\n  );\n}\n\n// ─── Diff Context Results ──────────────────────────────────────────────────────\n\ninterface DiffContextData {\n  affected_symbols: {\n    type: string;\n    name: string;\n    start_line: number;\n    end_line: number;\n    source: string | null;\n    docstring: string | null;\n    change_file: string;\n    file_path?: string;\n  }[];\n  callers: {\n    symbol: string;\n    symbol_type: string;\n    callers: { type: string; name: string; path: string; source: string | null }[];\n  }[];\n  class_hierarchy: {\n    class: string;\n    hierarchy: { name: string; path: string; source: string | null }[];\n  }[];\n  file_sources: Record<string, string>;\n  total_affected: number;\n  total_files: number;\n}\n\nfunction DiffContextResults({ data }: { data: DiffContextData }) {\n  return (\n    <div className=\"space-y-4\">\n      <div className=\"flex gap-3\">\n        <Badge variant=\"secondary\">{data.total_files} files</Badge>\n        <Badge variant=\"secondary\">{data.total_affected} affected symbols</Badge>\n        <Badge variant=\"secondary\">{data.callers.length} caller chains</Badge>\n        <Badge variant=\"secondary\">{data.class_hierarchy.length} class hierarchies</Badge>\n      </div>\n\n      {data.affected_symbols.length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">Affected Symbols</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-2 max-h-[400px] overflow-y-auto\">\n            {data.affected_symbols.map((sym, i) => (\n              <div key={i} className=\"p-3 rounded border border-border space-y-1\">\n                <div className=\"flex items-center gap-2\">\n                  <Badge variant={sym.type === \"function\" ? \"default\" : \"secondary\"}>{sym.type}</Badge>\n                  <span className=\"font-medium font-mono\">{sym.name}</span>\n                  <span className=\"text-xs text-muted-foreground\">\n                    {sym.change_file}:{sym.start_line}-{sym.end_line}\n                  </span>\n                </div>\n                {sym.docstring && (\n                  <p className=\"text-xs text-muted-foreground\">{sym.docstring}</p>\n                )}\n                {sym.source && (\n                  <CodeBlock\n                    code={sym.source}\n                    startLine={sym.start_line}\n                    maxHeight=\"max-h-48\"\n                  />\n                )}\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {data.callers.length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">Callers of Affected Symbols</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-3 max-h-[400px] overflow-y-auto\">\n            {data.callers.map((group, i) => (\n              <div key={i} className=\"space-y-1\">\n                <p className=\"text-sm font-medium\">\n                  <Badge variant=\"outline\" className=\"mr-1\">{group.symbol_type}</Badge>\n                  <span className=\"font-mono\">{group.symbol}</span>\n                  <span className=\"text-muted-foreground ml-1\">called by:</span>\n                </p>\n                {group.callers.map((caller, j) => (\n                  <div key={j} className=\"ml-4 p-2 rounded border border-border text-sm\">\n                    <span className=\"font-mono\">{caller.name}</span>\n                    <span className=\"text-xs text-muted-foreground ml-2\">{caller.path}</span>\n                    {caller.source && (\n                      <CodeBlock\n                        code={caller.source}\n                        maxHeight=\"max-h-32\"\n                        className=\"mt-1\"\n                      />\n                    )}\n                  </div>\n                ))}\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {data.class_hierarchy.length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">Class Hierarchy</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-2 max-h-[300px] overflow-y-auto\">\n            {data.class_hierarchy.map((h, i) => (\n              <div key={i} className=\"space-y-1\">\n                <p className=\"text-sm font-medium font-mono\">{h.class}</p>\n                <div className=\"ml-4 space-y-1\">\n                  {h.hierarchy.map((parent, j) => (\n                    <div key={j} className=\"flex items-center gap-2 text-sm\">\n                      <span className=\"text-muted-foreground\">{j === 0 ? \"\" : \"\\u2514\\u2500\"}</span>\n                      <span className=\"font-mono\">{parent.name}</span>\n                      <span className=\"text-xs text-muted-foreground\">{parent.path}</span>\n                    </div>\n                  ))}\n                </div>\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {Object.keys(data.file_sources).length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">File Sources</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-3 max-h-[400px] overflow-y-auto\">\n            {Object.entries(data.file_sources).map(([path, source]) => (\n              <div key={path} className=\"space-y-1\">\n                <p className=\"text-sm font-mono text-primary\">{path}</p>\n                <CodeBlock code={source} maxHeight=\"max-h-64\" />\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n    </div>\n  );\n}\n\n// ─── Generic Results ──────────────────────────────────────────────────────────\n\nfunction ResultsView({ data }: { data: unknown }) {\n  if (data === null || data === undefined) {\n    return <p className=\"text-muted-foreground\">No results</p>;\n  }\n\n  if (Array.isArray(data)) {\n    if (data.length === 0) return <p className=\"text-muted-foreground\">No results found</p>;\n    return (\n      <div className=\"space-y-2 max-h-[600px] overflow-y-auto\">\n        {data.map((item, i) => (\n          <div key={i} className=\"p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n            {typeof item === \"object\" ? <ObjectView obj={item} /> : String(item)}\n          </div>\n        ))}\n      </div>\n    );\n  }\n\n  if (typeof data === \"object\") {\n    return <ObjectView obj={data as Record<string, unknown>} />;\n  }\n\n  return <pre className=\"text-sm font-mono\">{String(data)}</pre>;\n}\n\nfunction ObjectView({ obj }: { obj: Record<string, unknown> }) {\n  return (\n    <div className=\"space-y-1\">\n      {Object.entries(obj).map(([key, value]) => {\n        if (key === \"source\" && typeof value === \"string\" && value) {\n          const startLine = (obj.line_number as number) || (obj.start_line as number) || 1;\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <CodeBlock code={value} startLine={startLine} maxHeight=\"max-h-64\" />\n            </div>\n          );\n        }\n\n        if (Array.isArray(value)) {\n          if (value.length === 0) {\n            return (\n              <div key={key} className=\"flex gap-2\">\n                <span className=\"text-primary font-medium shrink-0\">{key}:</span>\n                <span className=\"text-muted-foreground\">[]</span>\n              </div>\n            );\n          }\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <div className=\"ml-4 space-y-2\">\n                {value.map((item, i) => (\n                  <div key={i} className=\"p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n                    {typeof item === \"object\" && item !== null\n                      ? <ObjectView obj={item as Record<string, unknown>} />\n                      : String(item)}\n                  </div>\n                ))}\n              </div>\n            </div>\n          );\n        }\n\n        if (typeof value === \"object\" && value !== null) {\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <div className=\"ml-4 p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n                <ObjectView obj={value as Record<string, unknown>} />\n              </div>\n            </div>\n          );\n        }\n\n        return (\n          <div key={key} className=\"flex gap-2\">\n            <span className=\"text-primary font-medium shrink-0\">{key}:</span>\n            <span className=\"text-muted-foreground break-all\">\n              {String(value ?? \"\\u2014\")}\n            </span>\n          </div>\n        );\n      })}\n    </div>\n  );\n}\n","structuredPatch":[{"oldStart":12,"oldLines":17,"newStart":12,"newLines":56,"lines":[" import { toast } from \"sonner\";"," import * as api from \"@/lib/api\";"," ","+// ─── Types ────────────────────────────────────────────────────────────────────","+","+interface SearchHit {","+  name?: string;","+  type?: string;","+  path?: string;","+  line_number?: number;","+  match_line?: string;","+  score?: number;","+}","+","+interface PeekLine {","+  line_number: number;","+  content: string;","+  is_anchor: boolean;","+}","+","+interface PeekResult {","+  path: string;","+  anchor_line: number;","+  window: PeekLine[];","+  total_lines: number;","+}","+"," type QueryDef = {","   label: string;","   placeholder: string;","   fn: (q: string) => Promise<unknown>;","   needsInput: boolean;","+  isSearch?: boolean;"," };"," ","+// ─── Query definitions ────────────────────────────────────────────────────────","+"," const queryGroups: Record<string, QueryDef[]> = {","   Search: [","-    { label: \"Full-text Search\", placeholder: \"Search query...\", fn: api.searchCode, needsInput: true },","-    { label: \"Symbol Search\", placeholder: \"Symbol name...\", fn: api.searchSymbols, needsInput: true },","+    {","+      label: \"Full-text Search\",","+      placeholder: \"Search query (e.g. LoginRequest)...\",","+      fn: api.searchCode,","+      needsInput: true,","+      isSearch: true,","+    },","+    {","+      label: \"Symbol Search\",","+      placeholder: \"Symbol name (e.g. LoginRequest)...\",","+      fn: api.searchSymbols,","+      needsInput: true,","+      isSearch: true,","+    },","   ],","   Analysis: [","     { label: \"Method Usages\", placeholder: \"Method name...\", fn: api.getMethodUsages, needsInput: true },"]},{"oldStart":37,"oldLines":6,"newStart":76,"newLines":13,"lines":["     { label: \"Content\", placeholder: \"Content query...\", fn: api.findContent, needsInput: true },","     { label: \"Module\", placeholder: \"Module name...\", fn: api.findModule, needsInput: true },","     { label: \"Imports\", placeholder: \"Import name...\", fn: api.findImports, needsInput: true },","+    {","+      label: \"Line Search\",","+      placeholder: \"Code snippet to find in files...\",","+      fn: api.findByLine,","+      needsInput: true,","+      isSearch: true,","+    },","   ],","   Metrics: [","     { label: \"Graph Stats\", placeholder: \"\", fn: api.getGraphStats, needsInput: false },"]},{"oldStart":45,"oldLines":11,"newStart":91,"newLines":141,"lines":["   ],"," };"," ","+// ─── PeekViewer ───────────────────────────────────────────────────────────────","+","+function PeekViewer({ path, anchorLine }: { path: string; anchorLine: number }) {","+  const STEP = 20;","+  const [above, setAbove] = useState(10);","+  const [below, setBelow] = useState(10);","+  const [result, setResult] = useState<PeekResult | null>(null);","+  const [loading, setLoading] = useState(false);","+  const [opened, setOpened] = useState(false);","+","+  const load = async (newAbove: number, newBelow: number) => {","+    setLoading(true);","+    try {","+      const data = await api.peekFileLines(path, anchorLine, newAbove, newBelow);","+      setResult(data as PeekResult);","+      setAbove(newAbove);","+      setBelow(newBelow);","+    } catch {","+      toast.error(\"Failed to load context\");","+    } finally {","+      setLoading(false);","+    }","+  };","+","+  if (!opened) {","+    return (","+      <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" onClick={() => { setOpened(true); load(above, below); }}>","+        Peek context","+      </Button>","+    );","+  }","+","+  return (","+    <div className=\"mt-2 space-y-1\">","+      <div className=\"flex gap-2 items-center\">","+        <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" disabled={loading} onClick={() => load(above + STEP, below)}>","+          ↑ Load {STEP} more above","+        </Button>","+        <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" disabled={loading} onClick={() => load(above, below + STEP)}>","+          Load {STEP} more below ↓","+        </Button>","+        <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" onClick={() => setOpened(false)}>","+          Close","+        </Button>","+        {result && (","+          <span className=\"text-xs text-muted-foreground\">","+            Lines {result.window[0]?.line_number}–{result.window[result.window.length - 1]?.line_number} / {result.total_lines}","+          </span>","+        )}","+      </div>","+","+      {result && (","+        <div className=\"font-mono text-xs rounded border border-border overflow-x-auto\">","+          {result.window.map((ln) => (","+            <div","+              key={ln.line_number}","+              className={`flex gap-2 px-2 py-0.5 ${ln.is_anchor ? \"bg-yellow-500/20 font-semibold\" : \"hover:bg-muted/30\"}`}","+            >","+              <span className=\"select-none w-10 text-right text-muted-foreground shrink-0\">","+                {ln.line_number}","+              </span>","+              <span className=\"whitespace-pre\">{ln.content}</span>","+            </div>","+          ))}","+        </div>","+      )}","+    </div>","+  );","+}","+","+// ─── SearchResultsView ────────────────────────────────────────────────────────","+","+function SearchResultsView({ data }: { data: unknown }) {","+  // Normalise: the API wraps results in { results: [...], total: N } or { symbols: [...] }","+  let hits: SearchHit[] = [];","+  if (Array.isArray(data)) {","+    hits = data as SearchHit[];","+  } else if (data && typeof data === \"object\") {","+    const obj = data as Record<string, unknown>;","+    const inner = obj.results ?? obj.symbols ?? obj.ranked_results ?? [];","+    if (Array.isArray(inner)) hits = inner as SearchHit[];","+  }","+","+  if (hits.length === 0) {","+    return <p className=\"text-muted-foreground text-sm\">No results found.</p>;","+  }","+","+  return (","+    <div className=\"space-y-2 max-h-[680px] overflow-y-auto\">","+      {hits.map((hit, i) => (","+        <div key={i} className=\"p-3 rounded border border-border space-y-1\">","+          <div className=\"flex flex-wrap items-center gap-2\">","+            {hit.type && (","+              <Badge variant={hit.type === \"function\" ? \"default\" : hit.type === \"class\" ? \"secondary\" : \"outline\"}>","+                {hit.type}","+              </Badge>","+            )}","+            {hit.name && <span className=\"font-mono font-medium\">{hit.name}</span>}","+            {hit.match_line && !hit.name && (","+              <span className=\"font-mono text-sm text-foreground\">{hit.match_line.trim()}</span>","+            )}","+            {hit.score != null && (","+              <span className=\"ml-auto text-xs text-muted-foreground\">score {hit.score.toFixed(3)}</span>","+            )}","+          </div>","+","+          {hit.path && (","+            <div className=\"flex items-center gap-2 text-xs text-muted-foreground\">","+              <span className=\"font-mono truncate\">{hit.path}</span>","+              {hit.line_number != null && hit.line_number > 0 && (","+                <span className=\"shrink-0\">:{hit.line_number}</span>","+              )}","+            </div>","+          )}","+","+          {hit.match_line && hit.name && (","+            <p className=\"text-xs font-mono text-muted-foreground truncate\">{hit.match_line.trim()}</p>","+          )}","+","+          {hit.path && hit.line_number != null && hit.line_number > 0 && (","+            <PeekViewer path={hit.path} anchorLine={hit.line_number} />","+          )}","+        </div>","+      ))}","+    </div>","+  );","+}","+","+// ─── Main page ────────────────────────────────────────────────────────────────","+"," export default function QueryPage() {","   const [input, setInput] = useState(\"\");","   const [loading, setLoading] = useState(false);","   const [results, setResults] = useState<unknown>(null);","-  const [activeQuery, setActiveQuery] = useState<string>(\"\");","+  const [activeQuery, setActiveQuery] = useState<QueryDef | null>(null);"," ","   // Diff context state","   const [diffRepoId, setDiffRepoId] = useState(\"\");"]},{"oldStart":63,"oldLines":13,"newStart":239,"newLines":13,"lines":["       return;","     }","     setLoading(true);","-    setActiveQuery(qDef.label);","+    setActiveQuery(qDef);","+    setResults(null);","     try {","       const data = await qDef.fn(input.trim());","       setResults(data);","     } catch (e) {","       toast.error(`Query failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);","-      setResults(null);","     } finally {","       setLoading(false);","     }"]},{"oldStart":80,"oldLines":7,"newStart":256,"newLines":6,"lines":["       toast.error(\"Please enter a repository ID\");","       return;","     }","-    // Parse changes: one per line, format: file_path:start_line-end_line","     const lines = diffChangesText.trim().split(\"\\n\").filter(Boolean);","     const changes = lines.map((line) => {","       const [filePath, range] = line.split(\":\");"]},{"oldStart":130,"oldLines":18,"newStart":305,"newLines":14,"lines":["               onChange={(e) => setInput(e.target.value)}","               className=\"text-base\"","               onKeyDown={(e) => {","-                if (e.key === \"Enter\" && activeQuery) {","-                  const allQueries = Object.values(queryGroups).flat();","-                  const q = allQueries.find((q) => q.label === activeQuery);","-                  if (q) runQuery(q);","-                }","+                if (e.key === \"Enter\" && activeQuery) runQuery(activeQuery);","               }}","             />","             <div className=\"flex flex-wrap gap-2\">","               {queries.map((q) => (","                 <Button","                   key={q.label}","-                  variant={activeQuery === q.label ? \"default\" : \"secondary\"}","+                  variant={activeQuery?.label === q.label ? \"default\" : \"secondary\"}","                   size=\"sm\"","                   onClick={() => runQuery(q)}","                   disabled={loading}"]},{"oldStart":193,"oldLines":7,"newStart":364,"newLines":7,"lines":["         </TabsContent>","       </Tabs>"," ","-      {/* Standard query results */}","+      {/* Query results */}","       {loading && (","         <Card>","           <CardContent className=\"py-8 text-center text-muted-foreground\">"]},{"oldStart":202,"oldLines":15,"newStart":373,"newLines":19,"lines":["         </Card>","       )}"," ","-      {!loading && results !== null && activeQuery !== \"\" && (","+      {!loading && results !== null && activeQuery !== null && (","         <Card>","           <CardHeader>","             <CardTitle className=\"text-sm text-muted-foreground\">","-              Results: {activeQuery}","+              Results: {activeQuery.label}","             </CardTitle>","           </CardHeader>","           <CardContent>","-            <ResultsView data={results} />","+            {activeQuery.isSearch ? (","+              <SearchResultsView data={results} />","+            ) : (","+              <ResultsView data={results} />","+            )}","           </CardContent>","         </Card>","       )}"]},{"oldStart":218,"oldLines":7,"newStart":393,"newLines":7,"lines":["   );"," }"," ","-// --- Diff Context Results ---","+// ─── Diff Context Results ──────────────────────────────────────────────────────"," "," interface DiffContextData {","   affected_symbols: {"]},{"oldStart":248,"oldLines":7,"newStart":423,"newLines":6,"lines":[" function DiffContextResults({ data }: { data: DiffContextData }) {","   return (","     <div className=\"space-y-4\">","-      {/* Summary */}","       <div className=\"flex gap-3\">","         <Badge variant=\"secondary\">{data.total_files} files</Badge>","         <Badge variant=\"secondary\">{data.total_affected} affected symbols</Badge>"]},{"oldStart":256,"oldLines":7,"newStart":430,"newLines":6,"lines":["         <Badge variant=\"secondary\">{data.class_hierarchy.length} class hierarchies</Badge>","       </div>"," ","-      {/* Affected Symbols */}","       {data.affected_symbols.length > 0 && (","         <Card>","           <CardHeader>"]},{"oldStart":288,"oldLines":7,"newStart":461,"newLines":6,"lines":["         </Card>","       )}"," ","-      {/* Callers */}","       {data.callers.length > 0 && (","         <Card>","           <CardHeader>"]},{"oldStart":321,"oldLines":7,"newStart":493,"newLines":6,"lines":["         </Card>","       )}"," ","-      {/* Class Hierarchy */}","       {data.class_hierarchy.length > 0 && (","         <Card>","           <CardHeader>"]},{"oldStart":346,"oldLines":7,"newStart":517,"newLines":6,"lines":["         </Card>","       )}"," ","-      {/* File Sources */}","       {Object.keys(data.file_sources).length > 0 && (","         <Card>","           <CardHeader>"]},{"oldStart":366,"oldLines":7,"newStart":536,"newLines":7,"lines":["   );"," }"," ","-// --- Generic Results ---","+// ─── Generic Results ──────────────────────────────────────────────────────────"," "," function ResultsView({ data }: { data: unknown }) {","   if (data === null || data === undefined) {"]},{"oldStart":397,"oldLines":7,"newStart":567,"newLines":6,"lines":["   return (","     <div className=\"space-y-1\">","       {Object.entries(obj).map(([key, value]) => {","-        // Render source code fields with CodeBlock","         if (key === \"source\" && typeof value === \"string\" && value) {","           const startLine = (obj.line_number as number) || (obj.start_line as number) || 1;","           return ("]},{"oldStart":408,"oldLines":7,"newStart":577,"newLines":6,"lines":["           );","         }"," ","-        // Render nested arrays recursively","         if (Array.isArray(value)) {","           if (value.length === 0) {","             return ("]},{"oldStart":434,"oldLines":7,"newStart":602,"newLines":6,"lines":["           );","         }"," ","-        // Render nested objects recursively","         if (typeof value === \"object\" && value !== null) {","           return (","             <div key={key} className=\"space-y-1\">"]}],"originalFile":"\"use client\";\n\nimport { useState } from \"react\";\nimport { Card, CardContent, CardHeader, CardTitle } from \"@/components/ui/card\";\nimport { Button } from \"@/components/ui/button\";\nimport { Input } from \"@/components/ui/input\";\nimport { Label } from \"@/components/ui/label\";\nimport { Textarea } from \"@/components/ui/textarea\";\nimport { Tabs, TabsContent, TabsList, TabsTrigger } from \"@/components/ui/tabs\";\nimport { Badge } from \"@/components/ui/badge\";\nimport { CodeBlock } from \"@/components/ui/code-block\";\nimport { toast } from \"sonner\";\nimport * as api from \"@/lib/api\";\n\ntype QueryDef = {\n  label: string;\n  placeholder: string;\n  fn: (q: string) => Promise<unknown>;\n  needsInput: boolean;\n};\n\nconst queryGroups: Record<string, QueryDef[]> = {\n  Search: [\n    { label: \"Full-text Search\", placeholder: \"Search query...\", fn: api.searchCode, needsInput: true },\n    { label: \"Symbol Search\", placeholder: \"Symbol name...\", fn: api.searchSymbols, needsInput: true },\n  ],\n  Analysis: [\n    { label: \"Method Usages\", placeholder: \"Method name...\", fn: api.getMethodUsages, needsInput: true },\n    { label: \"Find Callers\", placeholder: \"Symbol name...\", fn: api.findCallers, needsInput: true },\n    { label: \"Class Hierarchy\", placeholder: \"Class name...\", fn: api.getClassHierarchy, needsInput: true },\n    { label: \"Change Impact\", placeholder: \"Symbol name...\", fn: api.getChangeImpact, needsInput: true },\n  ],\n  CodeFinder: [\n    { label: \"Function\", placeholder: \"Function name...\", fn: api.findFunction, needsInput: true },\n    { label: \"Class\", placeholder: \"Class name...\", fn: api.findClass, needsInput: true },\n    { label: \"Variable\", placeholder: \"Variable name...\", fn: api.findVariable, needsInput: true },\n    { label: \"Content\", placeholder: \"Content query...\", fn: api.findContent, needsInput: true },\n    { label: \"Module\", placeholder: \"Module name...\", fn: api.findModule, needsInput: true },\n    { label: \"Imports\", placeholder: \"Import name...\", fn: api.findImports, needsInput: true },\n  ],\n  Metrics: [\n    { label: \"Graph Stats\", placeholder: \"\", fn: api.getGraphStats, needsInput: false },\n    { label: \"Language Stats\", placeholder: \"\", fn: api.getLanguageStats, needsInput: false },\n    { label: \"Top Complex Functions\", placeholder: \"\", fn: api.getTopComplexFunctions, needsInput: false },\n  ],\n};\n\nexport default function QueryPage() {\n  const [input, setInput] = useState(\"\");\n  const [loading, setLoading] = useState(false);\n  const [results, setResults] = useState<unknown>(null);\n  const [activeQuery, setActiveQuery] = useState<string>(\"\");\n\n  // Diff context state\n  const [diffRepoId, setDiffRepoId] = useState(\"\");\n  const [diffChangesText, setDiffChangesText] = useState(\"\");\n  const [diffLoading, setDiffLoading] = useState(false);\n  const [diffResults, setDiffResults] = useState<unknown>(null);\n\n  const runQuery = async (qDef: QueryDef) => {\n    if (qDef.needsInput && !input.trim()) {\n      toast.error(\"Please enter a query\");\n      return;\n    }\n    setLoading(true);\n    setActiveQuery(qDef.label);\n    try {\n      const data = await qDef.fn(input.trim());\n      setResults(data);\n    } catch (e) {\n      toast.error(`Query failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);\n      setResults(null);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  const runDiffContext = async () => {\n    if (!diffRepoId.trim()) {\n      toast.error(\"Please enter a repository ID\");\n      return;\n    }\n    // Parse changes: one per line, format: file_path:start_line-end_line\n    const lines = diffChangesText.trim().split(\"\\n\").filter(Boolean);\n    const changes = lines.map((line) => {\n      const [filePath, range] = line.split(\":\");\n      if (range) {\n        const [start, end] = range.split(\"-\").map(Number);\n        return { file_path: filePath.trim(), start_line: start || 1, end_line: end || 999999 };\n      }\n      return { file_path: filePath.trim() };\n    });\n\n    if (changes.length === 0) {\n      toast.error(\"Please enter at least one file change\");\n      return;\n    }\n\n    setDiffLoading(true);\n    setDiffResults(null);\n    try {\n      const data = await api.getDiffContext({ repo_id: diffRepoId.trim(), changes });\n      setDiffResults(data);\n    } catch (e) {\n      toast.error(`Diff context failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);\n    } finally {\n      setDiffLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"max-w-5xl mx-auto space-y-6\">\n      <h1 className=\"text-2xl font-bold\">Query</h1>\n\n      <Tabs defaultValue=\"Search\">\n        <TabsList>\n          {Object.keys(queryGroups).map((group) => (\n            <TabsTrigger key={group} value={group}>\n              {group}\n            </TabsTrigger>\n          ))}\n          <TabsTrigger value=\"DiffContext\">Code Review</TabsTrigger>\n        </TabsList>\n\n        {Object.entries(queryGroups).map(([group, queries]) => (\n          <TabsContent key={group} value={group} className=\"space-y-4 pt-4\">\n            <Input\n              placeholder=\"Enter search term or symbol name...\"\n              value={input}\n              onChange={(e) => setInput(e.target.value)}\n              className=\"text-base\"\n              onKeyDown={(e) => {\n                if (e.key === \"Enter\" && activeQuery) {\n                  const allQueries = Object.values(queryGroups).flat();\n                  const q = allQueries.find((q) => q.label === activeQuery);\n                  if (q) runQuery(q);\n                }\n              }}\n            />\n            <div className=\"flex flex-wrap gap-2\">\n              {queries.map((q) => (\n                <Button\n                  key={q.label}\n                  variant={activeQuery === q.label ? \"default\" : \"secondary\"}\n                  size=\"sm\"\n                  onClick={() => runQuery(q)}\n                  disabled={loading}\n                >\n                  {q.label}\n                </Button>\n              ))}\n            </div>\n          </TabsContent>\n        ))}\n\n        <TabsContent value=\"DiffContext\" className=\"space-y-4 pt-4\">\n          <Card>\n            <CardHeader>\n              <CardTitle>Diff Context Builder</CardTitle>\n            </CardHeader>\n            <CardContent className=\"space-y-4\">\n              <p className=\"text-sm text-muted-foreground\">\n                Build RAG context for code review. Provide the repository and changed files\n                to get affected symbols, their callers, class hierarchy, and source code.\n              </p>\n              <div className=\"space-y-2\">\n                <Label>Repository ID</Label>\n                <Input\n                  placeholder=\"owner/repo_name\"\n                  value={diffRepoId}\n                  onChange={(e) => setDiffRepoId(e.target.value)}\n                />\n              </div>\n              <div className=\"space-y-2\">\n                <Label>Changed Files</Label>\n                <Textarea\n                  placeholder={\"One per line — file_path:start_line-end_line\\n\\nExamples:\\nsrc/main.py:10-30\\nsrc/utils.py:1-50\\nREADME.md\"}\n                  value={diffChangesText}\n                  onChange={(e) => setDiffChangesText(e.target.value)}\n                  rows={6}\n                  className=\"font-mono text-sm\"\n                />\n              </div>\n              <Button onClick={runDiffContext} disabled={diffLoading}>\n                {diffLoading ? \"Loading...\" : \"Get Diff Context\"}\n              </Button>\n            </CardContent>\n          </Card>\n\n          {diffResults !== null && (\n            <DiffContextResults data={diffResults as DiffContextData} />\n          )}\n        </TabsContent>\n      </Tabs>\n\n      {/* Standard query results */}\n      {loading && (\n        <Card>\n          <CardContent className=\"py-8 text-center text-muted-foreground\">\n            Loading...\n          </CardContent>\n        </Card>\n      )}\n\n      {!loading && results !== null && activeQuery !== \"\" && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm text-muted-foreground\">\n              Results: {activeQuery}\n            </CardTitle>\n          </CardHeader>\n          <CardContent>\n            <ResultsView data={results} />\n          </CardContent>\n        </Card>\n      )}\n    </div>\n  );\n}\n\n// --- Diff Context Results ---\n\ninterface DiffContextData {\n  affected_symbols: {\n    type: string;\n    name: string;\n    start_line: number;\n    end_line: number;\n    source: string | null;\n    docstring: string | null;\n    change_file: string;\n    file_path?: string;\n  }[];\n  callers: {\n    symbol: string;\n    symbol_type: string;\n    callers: { type: string; name: string; path: string; source: string | null }[];\n  }[];\n  class_hierarchy: {\n    class: string;\n    hierarchy: { name: string; path: string; source: string | null }[];\n  }[];\n  file_sources: Record<string, string>;\n  total_affected: number;\n  total_files: number;\n}\n\nfunction DiffContextResults({ data }: { data: DiffContextData }) {\n  return (\n    <div className=\"space-y-4\">\n      {/* Summary */}\n      <div className=\"flex gap-3\">\n        <Badge variant=\"secondary\">{data.total_files} files</Badge>\n        <Badge variant=\"secondary\">{data.total_affected} affected symbols</Badge>\n        <Badge variant=\"secondary\">{data.callers.length} caller chains</Badge>\n        <Badge variant=\"secondary\">{data.class_hierarchy.length} class hierarchies</Badge>\n      </div>\n\n      {/* Affected Symbols */}\n      {data.affected_symbols.length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">Affected Symbols</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-2 max-h-[400px] overflow-y-auto\">\n            {data.affected_symbols.map((sym, i) => (\n              <div key={i} className=\"p-3 rounded border border-border space-y-1\">\n                <div className=\"flex items-center gap-2\">\n                  <Badge variant={sym.type === \"function\" ? \"default\" : \"secondary\"}>{sym.type}</Badge>\n                  <span className=\"font-medium font-mono\">{sym.name}</span>\n                  <span className=\"text-xs text-muted-foreground\">\n                    {sym.change_file}:{sym.start_line}-{sym.end_line}\n                  </span>\n                </div>\n                {sym.docstring && (\n                  <p className=\"text-xs text-muted-foreground\">{sym.docstring}</p>\n                )}\n                {sym.source && (\n                  <CodeBlock\n                    code={sym.source}\n                    startLine={sym.start_line}\n                    maxHeight=\"max-h-48\"\n                  />\n                )}\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {/* Callers */}\n      {data.callers.length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">Callers of Affected Symbols</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-3 max-h-[400px] overflow-y-auto\">\n            {data.callers.map((group, i) => (\n              <div key={i} className=\"space-y-1\">\n                <p className=\"text-sm font-medium\">\n                  <Badge variant=\"outline\" className=\"mr-1\">{group.symbol_type}</Badge>\n                  <span className=\"font-mono\">{group.symbol}</span>\n                  <span className=\"text-muted-foreground ml-1\">called by:</span>\n                </p>\n                {group.callers.map((caller, j) => (\n                  <div key={j} className=\"ml-4 p-2 rounded border border-border text-sm\">\n                    <span className=\"font-mono\">{caller.name}</span>\n                    <span className=\"text-xs text-muted-foreground ml-2\">{caller.path}</span>\n                    {caller.source && (\n                      <CodeBlock\n                        code={caller.source}\n                        maxHeight=\"max-h-32\"\n                        className=\"mt-1\"\n                      />\n                    )}\n                  </div>\n                ))}\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {/* Class Hierarchy */}\n      {data.class_hierarchy.length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">Class Hierarchy</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-2 max-h-[300px] overflow-y-auto\">\n            {data.class_hierarchy.map((h, i) => (\n              <div key={i} className=\"space-y-1\">\n                <p className=\"text-sm font-medium font-mono\">{h.class}</p>\n                <div className=\"ml-4 space-y-1\">\n                  {h.hierarchy.map((parent, j) => (\n                    <div key={j} className=\"flex items-center gap-2 text-sm\">\n                      <span className=\"text-muted-foreground\">{j === 0 ? \"\" : \"\\u2514\\u2500\"}</span>\n                      <span className=\"font-mono\">{parent.name}</span>\n                      <span className=\"text-xs text-muted-foreground\">{parent.path}</span>\n                    </div>\n                  ))}\n                </div>\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {/* File Sources */}\n      {Object.keys(data.file_sources).length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">File Sources</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-3 max-h-[400px] overflow-y-auto\">\n            {Object.entries(data.file_sources).map(([path, source]) => (\n              <div key={path} className=\"space-y-1\">\n                <p className=\"text-sm font-mono text-primary\">{path}</p>\n                <CodeBlock code={source} maxHeight=\"max-h-64\" />\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n    </div>\n  );\n}\n\n// --- Generic Results ---\n\nfunction ResultsView({ data }: { data: unknown }) {\n  if (data === null || data === undefined) {\n    return <p className=\"text-muted-foreground\">No results</p>;\n  }\n\n  if (Array.isArray(data)) {\n    if (data.length === 0) return <p className=\"text-muted-foreground\">No results found</p>;\n    return (\n      <div className=\"space-y-2 max-h-[600px] overflow-y-auto\">\n        {data.map((item, i) => (\n          <div key={i} className=\"p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n            {typeof item === \"object\" ? <ObjectView obj={item} /> : String(item)}\n          </div>\n        ))}\n      </div>\n    );\n  }\n\n  if (typeof data === \"object\") {\n    return <ObjectView obj={data as Record<string, unknown>} />;\n  }\n\n  return <pre className=\"text-sm font-mono\">{String(data)}</pre>;\n}\n\nfunction ObjectView({ obj }: { obj: Record<string, unknown> }) {\n  return (\n    <div className=\"space-y-1\">\n      {Object.entries(obj).map(([key, value]) => {\n        // Render source code fields with CodeBlock\n        if (key === \"source\" && typeof value === \"string\" && value) {\n          const startLine = (obj.line_number as number) || (obj.start_line as number) || 1;\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <CodeBlock code={value} startLine={startLine} maxHeight=\"max-h-64\" />\n            </div>\n          );\n        }\n\n        // Render nested arrays recursively\n        if (Array.isArray(value)) {\n          if (value.length === 0) {\n            return (\n              <div key={key} className=\"flex gap-2\">\n                <span className=\"text-primary font-medium shrink-0\">{key}:</span>\n                <span className=\"text-muted-foreground\">[]</span>\n              </div>\n            );\n          }\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <div className=\"ml-4 space-y-2\">\n                {value.map((item, i) => (\n                  <div key={i} className=\"p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n                    {typeof item === \"object\" && item !== null\n                      ? <ObjectView obj={item as Record<string, unknown>} />\n                      : String(item)}\n                  </div>\n                ))}\n              </div>\n            </div>\n          );\n        }\n\n        // Render nested objects recursively\n        if (typeof value === \"object\" && value !== null) {\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <div className=\"ml-4 p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n                <ObjectView obj={value as Record<string, unknown>} />\n              </div>\n            </div>\n          );\n        }\n\n        return (\n          <div key={key} className=\"flex gap-2\">\n            <span className=\"text-primary font-medium shrink-0\">{key}:</span>\n            <span className=\"text-muted-foreground break-all\">\n              {String(value ?? \"\\u2014\")}\n            </span>\n          </div>\n        );\n      })}\n    </div>\n  );\n}\n"},"sourceToolAssistantUUID":"8f774f1c-b68c-44c0-bd35-8e28fe5497ed"}
{"parentUuid":"5f7bf1fb-28c9-4c24-92cd-e5aec47c013c","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_011oP6hopNy9QN24wpBLg4GU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0171L7nXC9covw7tQCe2LjQd","name":"TaskUpdate","input":{"taskId":"3","status":"completed"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":6892,"cache_read_input_tokens":94042,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":6892},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLuWxz17YCndtBMiNZxs","type":"assistant","uuid":"0042d3fe-b1d6-4316-a9e9-7f4a0ef04756","timestamp":"2026-02-21T08:34:12.115Z"}
{"parentUuid":"0042d3fe-b1d6-4316-a9e9-7f4a0ef04756","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0171L7nXC9covw7tQCe2LjQd","type":"tool_result","content":"Updated task #3 status"}]},"uuid":"8e943709-0456-4784-a9bf-95f40f5a0029","timestamp":"2026-02-21T08:34:12.119Z","toolUseResult":{"success":true,"taskId":"3","updatedFields":["status"],"statusChange":{"from":"in_progress","to":"completed"}},"sourceToolAssistantUUID":"0042d3fe-b1d6-4316-a9e9-7f4a0ef04756"}
{"parentUuid":"8e943709-0456-4784-a9bf-95f40f5a0029","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_014qzdDJuaEiBfQisqaHLZkH","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The diagnostics are just TailwindCSS v4 suggestions to use canonical class names. These are warnings, not errors, and won't affect functionality. The linter is suggesting using TailwindCSS v4's new shorthand classes, but both formats work. I'll leave them as is since they're just style suggestions and not errors.\n\nLet me verify the changes look correct by doing a quick sanity check.","signature":"EqoECkYICxgCKkAH0f3TzAW4fv7mgzgVhG/tkm2xVdHVBul+21FCT1B0VyHwRjTjJAcFllNJbtNOmblTFs+QrGSXOLFUDK+bnPWcEgygxIL10Zv865NoLPYaDFGxu2QTiOwAR5lBtSIwGIAz80xernbhMmhjhbbCvqejAz17G32c9e1LV6ouTI5uSi1r1vq7EZq8LnBJWiTJKpED9HVGgKEApzsWqq39jLk82+kQF6/iOxPOUy0+6PQk1AhukQyEaSeCK5wE2G77bV4XTIPbRZRuyIUEt3o1CRfhzLVE8pYdUSONp/WqIvmrXpabZM4cWANwcWj4lXIn5iIPheXJ06wzvE+gbxHK6x6Orx1faPDJeSELzh/YZpQa8CUqXSriG/gLoBo2pc9MNroxQWi9bgGaNsMs0PV7n9WmAAfwe8vGDJ0Ux2jGt5oQgv9Aq15AvMyfKEkWiTfelW2Wasz6b49eQcXOoenkrTvK9yIlpQvanjgCMih82ZBO2L25CdJqdxPGCp/6ztZmE7Mz+VXlf0EsRQw6G1qXOPI/OdJ3+GVYjpwBwLtGYH2FRK2u5inzN5BlJ8k+JpeEAyldlQ283q1vZrtGT2DUSAr2nI/Xkf/vKLE2R4cQuD0wX2CNUflhsAMFA7XeH7UI3tapyXqNInHjtpB8yhyEW6E2JZY75LF0pIu3aUJUVBpaLw0HbvQPu2RjRtf2eSiVKvseKS/y9eOrkcBU3R8iZZEf9lcYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":401,"cache_read_input_tokens":100934,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":401},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLuX7xzTiegrmZ8KykPv","type":"assistant","uuid":"a5a94c82-8fdb-407a-9010-1a9547c9e9c2","timestamp":"2026-02-21T08:34:15.931Z"}
{"parentUuid":"a5a94c82-8fdb-407a-9010-1a9547c9e9c2","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_014qzdDJuaEiBfQisqaHLZkH","type":"message","role":"assistant","content":[{"type":"text","text":"Those are only Tailwind v4 style suggestions (warnings), not errors — they won't affect functionality. Let me do a quick sanity check on the key backend changes."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":401,"cache_read_input_tokens":100934,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":401},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLuX7xzTiegrmZ8KykPv","type":"assistant","uuid":"c4b84447-0ea4-4939-bf86-e105efe967b2","timestamp":"2026-02-21T08:34:16.775Z"}
{"parentUuid":"c4b84447-0ea4-4939-bf86-e105efe967b2","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_014qzdDJuaEiBfQisqaHLZkH","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VednMfC2bKxiVXtD7zQX9o","name":"Grep","input":{"pattern":"def search_code|def search_symbols|def search_file_content|def peek_file_lines","path":"/Users/skmabudalam/Documents/BugViper/db/queries.py","output_mode":"content"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":401,"cache_read_input_tokens":100934,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":401},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLuX7xzTiegrmZ8KykPv","type":"assistant","uuid":"5fcc062f-98d9-4511-8020-89a072c0689e","timestamp":"2026-02-21T08:34:18.474Z"}
{"parentUuid":"5fcc062f-98d9-4511-8020-89a072c0689e","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01VednMfC2bKxiVXtD7zQX9o","toolUseID":"toolu_01VednMfC2bKxiVXtD7zQX9o","timestamp":"2026-02-21T08:34:19.206Z","uuid":"7e1afe0b-7641-4aee-ad6c-cc2226715bed"}
{"parentUuid":"5fcc062f-98d9-4511-8020-89a072c0689e","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VednMfC2bKxiVXtD7zQX9o","type":"tool_result","content":"302:    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n353:    def search_symbols(\n412:    def search_file_content(self, search_term: str, limit: int = 50) -> List[Dict[str, Any]]:\n462:    def peek_file_lines("}]},"uuid":"e61beeda-f551-4cb4-8127-435a1e053d5f","timestamp":"2026-02-21T08:34:19.204Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"302:    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n353:    def search_symbols(\n412:    def search_file_content(self, search_term: str, limit: int = 50) -> List[Dict[str, Any]]:\n462:    def peek_file_lines(","numLines":4},"sourceToolAssistantUUID":"5fcc062f-98d9-4511-8020-89a072c0689e"}
{"parentUuid":"e61beeda-f551-4cb4-8127-435a1e053d5f","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_014qzdDJuaEiBfQisqaHLZkH","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Y8aAiCxM18Eu9wrJi3n1WU","name":"Grep","input":{"pattern":"code-finder/line|code-finder/peek","path":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","output_mode":"content"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":401,"cache_read_input_tokens":100934,"output_tokens":374,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":401,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLuX7xzTiegrmZ8KykPv","type":"assistant","uuid":"c875ee51-037f-418a-8d98-42afdd4ea863","timestamp":"2026-02-21T08:34:19.469Z"}
{"parentUuid":"c875ee51-037f-418a-8d98-42afdd4ea863","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01Y8aAiCxM18Eu9wrJi3n1WU","toolUseID":"toolu_01Y8aAiCxM18Eu9wrJi3n1WU","timestamp":"2026-02-21T08:34:19.855Z","uuid":"ba6491d3-3440-4fc7-be35-c0ca0c3b1419"}
{"parentUuid":"c875ee51-037f-418a-8d98-42afdd4ea863","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Y8aAiCxM18Eu9wrJi3n1WU","type":"tool_result","content":"510:@router.get(\"/code-finder/line\")\n520:    Pair with /code-finder/peek to view context around a hit.\n533:@router.get(\"/code-finder/peek\")"}]},"uuid":"c84f2bf3-bd5f-482e-a677-93f521cc1a42","timestamp":"2026-02-21T08:34:19.854Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"510:@router.get(\"/code-finder/line\")\n520:    Pair with /code-finder/peek to view context around a hit.\n533:@router.get(\"/code-finder/peek\")","numLines":3},"sourceToolAssistantUUID":"c875ee51-037f-418a-8d98-42afdd4ea863"}
{"parentUuid":"c84f2bf3-bd5f-482e-a677-93f521cc1a42","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01VaAyEJZfxTaMdpN5ZvoVM9","type":"message","role":"assistant","content":[{"type":"text","text":"Everything is in place. Here's a summary of all changes made:\n\n---\n\n## What was fixed\n\n### Backend\n\n**`db/schema.py`** — Fixed both Cypher queries:\n- `search_code`: `[:DEFINES*1..2]` → `OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)`, returns lean fields (`type`, `name`, `path`, `line_number`, `score`) instead of raw node objects\n- `search_symbols`: Switched from `symbol_search` index (targets non-existent `Symbol` nodes) → `code_search` index (covers real `Function`/`Class`/`Variable` nodes)\n\n**`db/queries.py`** — Rewrote 2 methods, added 2 new:\n- `search_code`: Lucene escaping already existed; now fixed Cypher output format + CONTAINS fallback when fulltext returns empty\n- `search_symbols`: **Added `_escape_lucene_query()` call** — this was the root cause of the crash (`(`, `)`, `:` breaking Lucene); switched to `code_search` index; added CONTAINS fallback; returns `path`+`line_number`\n- `search_file_content` (**new**): Uses `file_content_search` fulltext index → Python line scan to find exact matching lines → returns `path`, `line_number`, `match_line`\n- `peek_file_lines` (**new**): Fetches `File.source_code` from Neo4j, slices a configurable window around the anchor line\n\n**`api/routers/query.py`** — Added 2 new endpoints:\n- `GET /code-finder/line?query=` — line search via `search_file_content`\n- `GET /code-finder/peek?path=&line=&above=10&below=10` — context window viewer\n\n### Frontend (`query/page.tsx`)\n\n- **`SearchResultsView`**: Replaces the generic JSON dump for search queries — shows type badge + name + `file/path:line` + score per result\n- **`PeekViewer`**: Inline context expander per result — \"Peek context\" opens a 20-line window (10 above + 10 below), anchor line highlighted yellow, \"Load 20 more above/below\" buttons to expand\n- **Added \"Line Search\"** button to the CodeFinder tab (mapped to `api.findByLine`)\n- Search queries (`Full-text Search`, `Symbol Search`, `Line Search`) now route to `SearchResultsView` instead of the generic JSON view"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":564,"cache_read_input_tokens":101335,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":564},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLuXgWL5GTGJvQb4jfD5","type":"assistant","uuid":"22a56328-e606-467d-b5e6-9c44e69d3cd7","timestamp":"2026-02-21T08:34:36.815Z"}
{"parentUuid":"22a56328-e606-467d-b5e6-9c44e69d3cd7","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"6959baeb-8cd1-44e4-912d-99f05e451925","toolUseID":"6959baeb-8cd1-44e4-912d-99f05e451925","timestamp":"2026-02-21T08:34:36.902Z","uuid":"6521535b-7822-456e-afc8-b3048cad4bd9"}
{"parentUuid":"6521535b-7822-456e-afc8-b3048cad4bd9","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":2274}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-21T08:34:39.177Z","uuid":"b305fff8-dba0-40e8-a82d-5cf1fdc30fb7","toolUseID":"6959baeb-8cd1-44e4-912d-99f05e451925"}
{"parentUuid":"b305fff8-dba0-40e8-a82d-5cf1fdc30fb7","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"system","subtype":"turn_duration","durationMs":344231,"timestamp":"2026-02-21T08:34:39.184Z","uuid":"29ec5dac-a02f-4e8c-a882-4e9f948d055b","isMeta":false}
{"type":"file-history-snapshot","messageId":"9073a9d1-5a4e-4c37-9dd0-2102cc848e5a","snapshot":{"messageId":"9073a9d1-5a4e-4c37-9dd0-2102cc848e5a","trackedFileBackups":{"db/schema.py":{"backupFileName":"283975a9ba984ffc@v2","version":2,"backupTime":"2026-02-21T08:34:53.260Z"},"db/queries.py":{"backupFileName":"3dbb7f971a633538@v2","version":2,"backupTime":"2026-02-21T08:34:53.261Z"},"api/routers/query.py":{"backupFileName":"e6ad69c83e8fb9b0@v2","version":2,"backupTime":"2026-02-21T08:34:53.261Z"},"frontend/app/(protected)/query/page.tsx":{"backupFileName":"30dea031ecc29fcb@v2","version":2,"backupTime":"2026-02-21T08:34:53.262Z"}},"timestamp":"2026-02-21T08:34:53.260Z"},"isSnapshotUpdate":false}
{"parentUuid":"29ec5dac-a02f-4e8c-a882-4e9f948d055b","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":"curl 'http://localhost:8000/api/v1/query/search?query=class%20GitHubRepo(BaseModel)' \\\n  -H 'Accept: */*' \\\n  -H 'Accept-Language: en-US,en;q=0.9' \\\n  -H 'Authorization: Bearer REDACTED.REDACTED.REDACTED' \\\n  -H 'Connection: keep-alive' \\\n  -H 'Content-Type: application/json' \\\n  -H 'Origin: http://localhost:3000' \\\n  -H 'Referer: http://localhost:3000/' \\\n  -H 'Sec-Fetch-Dest: empty' \\\n  -H 'Sec-Fetch-Mode: cors' \\\n  -H 'Sec-Fetch-Site: same-site' \\\n  -H 'User-Agent: Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/145.0.0.0 Mobile Safari/537.36' \\\n  -H 'sec-ch-ua: \"Chromium\";v=\"145\", \"Not:A-Brand\";v=\"99\"' \\\n  -H 'sec-ch-ua-mobile: ?1' \\\n  -H 'sec-ch-ua-platform: \"Android\"' it found nothing , it should find any lines or any word "},"uuid":"9073a9d1-5a4e-4c37-9dd0-2102cc848e5a","timestamp":"2026-02-21T08:34:50.570Z","todos":[],"permissionMode":"default"}
{"parentUuid":"9073a9d1-5a4e-4c37-9dd0-2102cc848e5a","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_013VXSXYvyjteGxZ47ALt4jJ","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The user is searching for `class GitHubRepo(BaseModel)` and getting no results. The search should be able to find:\n1. The class `GitHubRepo` in Neo4j (if it was ingested)\n2. Any file content containing that text\n\nThe issue is the search strategy. When searching for `class GitHubRepo(BaseModel)`, the `_escape_lucene_query` wraps it in quotes: `\"class GitHubRepo(BaseModel)\"`. This is a phrase search that looks for that exact sequence of words. But:\n\n1. The `code_search` index is on `Function`, `Class`, `Variable` nodes on `name`, `docstring`, `source_code`. A phrase search for `\"class GitHubRepo(BaseModel)\"` is unlikely to match the `name` field (which would just be `GitHubRepo`).\n\n\n2. The CONTAINS fallback only checks if `node.name` contains the full search term as a substring, so it won't match since the name is just `GitHubRepo`.\n\nThe real problem is that the search strategy needs to be smarter—when it detects a pattern like `class SomeName(...)`, it should extract just `SomeName` and search for that. Alternatively, the fallback should also search the `source_code` field, which the fulltext index covers but the CONTAINS fallback doesn't, and the `file_content_search` index on `File` nodes could help capture the raw source.\n\nAccording to the CLAUDE.md docs, the intended flow is to try the fulltext `code_search` index first, then fall back to `file_content_search` if that returns nothing—but the current implementation isn't properly leveraging that second index for queries like `class GitHubRepo(BaseModel)`.\n\nThe issue is that wrapping everything in quotes for a literal phrase search might cause Lucene to reject or return empty results, especially when special characters like parentheses are involved. Even though parentheses should be treated as literals within quotes, the query might still fail to match what we're looking for in the index.\n\nThe real problem is likely that either the code wasn't ingested into Neo4j at all, or the search strategy doesn't align with what the user is actually trying to do. When someone searches for `class GitHubRepo(BaseModel)`, they're looking for that exact text pattern in the codebase, but the current CONTAINS fallback only checks `node.name`, which would just be `GitHubRepo` — not the full class definition string. I need to reconsider the search approach to handle this kind of query properly.\n\nThe solution involves parsing the search term more intelligently to extract meaningful tokens like `GitHubRepo`, and then implementing a better fallback strategy that searches the actual file contents directly instead of just node names. I'm redesigning the search method to use a two-tier approach where it first tries the fulltext index on symbols, then falls back to searching raw file content when that returns nothing.\n\nRefactoring the search method... I'm returning the results, and `search_file_content` already handles what we need for fallback matching. But I'm realizing there's a potential issue with how Lucene handles special characters like parentheses in quoted strings—they might not be treated as literals depending on the parser. The real solution is making sure the escaping function properly handles these cases, so let me check what `_escape_lucene_query` actually does with quotes and special characters.\n\nThe function wraps the query in quotes after escaping any internal quotes, which should work for most cases. But the real problem might be simpler: if the search for `class GitHubRepo(BaseModel)` returns nothing, it could mean either the escaping is breaking the query somehow, or the code was never actually ingested into the graph in the first place.\n\nLooking at the fallback logic in `search_code`, I see the issue now. When the fulltext search fails, it falls back to checking if `node.name` contains the search term—but that won't work here since class names don't include the `class` keyword. The fallback should instead extract identifiers from the search term and look for those in names, plus search the file content directly as a last resort.\n\nMy improved approach is to extract identifiers like `GitHubRepo` and `BaseModel` from the query, search for those in the symbol index, and also search raw file content for the exact text the user typed.\n\nWriting identifier extraction logic... Writing the fallback search query... Refining the escape logic...\n\nI need to detect whether the query contains special characters and handle it differently—simple identifiers should use phrase search, but queries with special chars need to be broken into tokens and combined with AND logic. Then I'll update the search function to fall back to file content search when the symbol-based queries don't return results.\n\nUpdating the escape function... I'm finishing the query construction logic and then need to update the search functions to handle empty results by falling back to content-based searches. Let me implement the changes to both the query escaping and the search_code method to ensure it properly chains to search_file_content when symbol searches don't return anything. to fall back to `search_file_content` \n3. `search_symbols` uses the same `_escape_lucene_query` so it benefits too\n\nActually wait - the AND strategy might still return empty if the class source_code isn't in the index. The main issue could be that the data wasn't ingested (this seems like a possibility). But let me make the search more robust anyway.\n\nAlso: the search should work even if `code_search` fulltext results are empty - by going to file_content_search. That's the critical missing piece.\n\nLet me make the changes:\n\n1. Improve `_escape_lucene_query` to use AND-keyword strategy for complex queries\n2. Add file_content fallback to `search_code` when symbol search is empty\n3. Make `search_symbols` also benefit from these improvements\n\nFor `search_code`, when the symbol search comes back empty, I'll add a tier-3 fallback that searches file content line-by-line and reformats those results into the standard search result structure. Now I'm ready to implement all these improvements.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":1354,"cache_read_input_tokens":102509,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1354},"output_tokens":6,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLua9b4b9jz915aKxmkh","type":"assistant","uuid":"c21bad66-5461-42d9-89c8-2fba255dc6bd","timestamp":"2026-02-21T08:35:57.112Z"}
{"parentUuid":"c21bad66-5461-42d9-89c8-2fba255dc6bd","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_013VXSXYvyjteGxZ47ALt4jJ","type":"message","role":"assistant","content":[{"type":"text","text":"The root cause is the escaping strategy and missing fallback. Currently:\n1. `\"class GitHubRepo(BaseModel)\"` as a Lucene phrase can't match because the class `name` field only stores `GitHubRepo` — not the full declaration\n2. The CONTAINS fallback searches `node.name CONTAINS \"class GitHubRepo(BaseModel)\"` which will never match\n3. When symbols return nothing, it never falls through to file content search\n\nThe CLAUDE.md describes the correct strategy: **simple identifiers → phrase `\"...\"`, special-char queries → AND-keyword strategy**. Let me fix the escape function and wire up the file content fallback."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":1354,"cache_read_input_tokens":102509,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1354},"output_tokens":6,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLua9b4b9jz915aKxmkh","type":"assistant","uuid":"613a39ec-7991-4568-befa-47848c9e160e","timestamp":"2026-02-21T08:35:58.729Z"}
{"parentUuid":"613a39ec-7991-4568-befa-47848c9e160e","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_013VXSXYvyjteGxZ47ALt4jJ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HqH3NwZUQ325nRtDnw4RoE","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/db/queries.py","offset":278,"limit":130},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":1354,"cache_read_input_tokens":102509,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1354},"output_tokens":6,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLua9b4b9jz915aKxmkh","type":"assistant","uuid":"db2bdff9-ec0b-4119-a218-f89521f32296","timestamp":"2026-02-21T08:35:59.593Z"}
{"parentUuid":"db2bdff9-ec0b-4119-a218-f89521f32296","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01HqH3NwZUQ325nRtDnw4RoE","toolUseID":"toolu_01HqH3NwZUQ325nRtDnw4RoE","timestamp":"2026-02-21T08:35:59.682Z","uuid":"82f5a3ad-789e-45aa-8261-0079ffeb114c"}
{"parentUuid":"db2bdff9-ec0b-4119-a218-f89521f32296","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HqH3NwZUQ325nRtDnw4RoE","type":"tool_result","content":"   278→    def _escape_lucene_query(self, query: str) -> str:\n   279→        \"\"\"\n   280→        Escape Lucene special characters in search query.\n   281→\n   282→        Strategy: Wrap the entire query in quotes to treat it as a literal phrase search.\n   283→        This prevents Lucene from interpreting special characters.\n   284→\n   285→        For complex queries, users can use wildcards: *\n   286→        \"\"\"\n   287→        query = query.strip()\n   288→\n   289→        # If query is empty, return a wildcard\n   290→        if not query:\n   291→            return '*'\n   292→\n   293→        # If the query already has quotes, escape internal quotes\n   294→        if '\"' in query:\n   295→            # Escape any existing quotes and wrap in quotes\n   296→            query = query.replace('\"', '\\\\\"')\n   297→\n   298→        # Wrap in quotes to make it a literal phrase search\n   299→        # This treats special characters as literals\n   300→        return f'\"{query}\"'\n   301→\n   302→    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n   303→        \"\"\"Search for code by name or docstring using fulltext index with CONTAINS fallback.\"\"\"\n   304→        escaped_term = self._escape_lucene_query(search_term)\n   305→\n   306→        results: List[Dict[str, Any]] = []\n   307→        try:\n   308→            query = CYPHER_QUERIES[\"search_code\"]\n   309→            records, _, _ = self.db.run_query(query, {\"search_term\": escaped_term})\n   310→            results = [\n   311→                {\n   312→                    \"type\": record[\"type\"],\n   313→                    \"name\": record[\"name\"],\n   314→                    \"path\": record[\"path\"],\n   315→                    \"line_number\": record[\"line_number\"],\n   316→                    \"score\": record[\"score\"],\n   317→                }\n   318→                for record in records\n   319→            ]\n   320→        except Exception as e:\n   321→            logger.warning(\"Fulltext search failed, falling back to CONTAINS: %s\", e)\n   322→\n   323→        if not results:\n   324→            fallback = \"\"\"\n   325→            MATCH (node)\n   326→            WHERE (node:Function OR node:Class OR node:Variable)\n   327→              AND node.name CONTAINS $search_term\n   328→            OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n   329→            RETURN\n   330→                CASE WHEN node:Function THEN 'function'\n   331→                     WHEN node:Class THEN 'class'\n   332→                     ELSE 'variable' END as type,\n   333→                node.name as name,\n   334→                coalesce(f.path, node.path) as path,\n   335→                coalesce(node.line_number, 0) as line_number,\n   336→                1.0 as score\n   337→            LIMIT 20\n   338→            \"\"\"\n   339→            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})\n   340→            results = [\n   341→                {\n   342→                    \"type\": record[\"type\"],\n   343→                    \"name\": record[\"name\"],\n   344→                    \"path\": record[\"path\"],\n   345→                    \"line_number\": record[\"line_number\"],\n   346→                    \"score\": record[\"score\"],\n   347→                }\n   348→                for record in records\n   349→            ]\n   350→\n   351→        return results\n   352→\n   353→    def search_symbols(\n   354→        self,\n   355→        search_term: str,\n   356→        limit: int = 20\n   357→    ) -> List[Dict[str, Any]]:\n   358→        \"\"\"Search symbols (Function/Class/Variable) using fulltext index with CONTAINS fallback.\"\"\"\n   359→        escaped_term = self._escape_lucene_query(search_term)\n   360→\n   361→        results: List[Dict[str, Any]] = []\n   362→        try:\n   363→            query = CYPHER_QUERIES[\"search_symbols\"]\n   364→            records, _, _ = self.db.run_query(query, {\n   365→                \"search_term\": escaped_term,\n   366→                \"limit\": limit,\n   367→            })\n   368→            results = [\n   369→                {\n   370→                    \"name\": record[\"name\"],\n   371→                    \"type\": record[\"type\"],\n   372→                    \"path\": record[\"path\"],\n   373→                    \"line_number\": record[\"line_number\"],\n   374→                    \"score\": record[\"score\"],\n   375→                }\n   376→                for record in records\n   377→            ]\n   378→        except Exception as e:\n   379→            logger.warning(\"Symbol fulltext search failed, falling back to CONTAINS: %s\", e)\n   380→\n   381→        if not results:\n   382→            fallback = \"\"\"\n   383→            MATCH (node)\n   384→            WHERE (node:Function OR node:Class OR node:Variable)\n   385→              AND node.name CONTAINS $search_term\n   386→            OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n   387→            RETURN\n   388→                node.name as name,\n   389→                CASE WHEN node:Function THEN 'function'\n   390→                     WHEN node:Class THEN 'class'\n   391→                     ELSE 'variable' END as type,\n   392→                coalesce(f.path, node.path) as path,\n   393→                coalesce(node.line_number, 0) as line_number,\n   394→                1.0 as score\n   395→            ORDER BY node.name\n   396→            LIMIT $limit\n   397→            \"\"\"\n   398→            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term, \"limit\": limit})\n   399→            results = [\n   400→                {\n   401→                    \"name\": record[\"name\"],\n   402→                    \"type\": record[\"type\"],\n   403→                    \"path\": record[\"path\"],\n   404→                    \"line_number\": record[\"line_number\"],\n   405→                    \"score\": record[\"score\"],\n   406→                }\n   407→                for record in records\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"3219aa1b-7fb9-495c-9ec6-5d1844ad13ad","timestamp":"2026-02-21T08:35:59.681Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/db/queries.py","content":"    def _escape_lucene_query(self, query: str) -> str:\n        \"\"\"\n        Escape Lucene special characters in search query.\n\n        Strategy: Wrap the entire query in quotes to treat it as a literal phrase search.\n        This prevents Lucene from interpreting special characters.\n\n        For complex queries, users can use wildcards: *\n        \"\"\"\n        query = query.strip()\n\n        # If query is empty, return a wildcard\n        if not query:\n            return '*'\n\n        # If the query already has quotes, escape internal quotes\n        if '\"' in query:\n            # Escape any existing quotes and wrap in quotes\n            query = query.replace('\"', '\\\\\"')\n\n        # Wrap in quotes to make it a literal phrase search\n        # This treats special characters as literals\n        return f'\"{query}\"'\n\n    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n        \"\"\"Search for code by name or docstring using fulltext index with CONTAINS fallback.\"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        results: List[Dict[str, Any]] = []\n        try:\n            query = CYPHER_QUERIES[\"search_code\"]\n            records, _, _ = self.db.run_query(query, {\"search_term\": escaped_term})\n            results = [\n                {\n                    \"type\": record[\"type\"],\n                    \"name\": record[\"name\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"Fulltext search failed, falling back to CONTAINS: %s\", e)\n\n        if not results:\n            fallback = \"\"\"\n            MATCH (node)\n            WHERE (node:Function OR node:Class OR node:Variable)\n              AND node.name CONTAINS $search_term\n            OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n            RETURN\n                CASE WHEN node:Function THEN 'function'\n                     WHEN node:Class THEN 'class'\n                     ELSE 'variable' END as type,\n                node.name as name,\n                coalesce(f.path, node.path) as path,\n                coalesce(node.line_number, 0) as line_number,\n                1.0 as score\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})\n            results = [\n                {\n                    \"type\": record[\"type\"],\n                    \"name\": record[\"name\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n\n        return results\n\n    def search_symbols(\n        self,\n        search_term: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Search symbols (Function/Class/Variable) using fulltext index with CONTAINS fallback.\"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        results: List[Dict[str, Any]] = []\n        try:\n            query = CYPHER_QUERIES[\"search_symbols\"]\n            records, _, _ = self.db.run_query(query, {\n                \"search_term\": escaped_term,\n                \"limit\": limit,\n            })\n            results = [\n                {\n                    \"name\": record[\"name\"],\n                    \"type\": record[\"type\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"Symbol fulltext search failed, falling back to CONTAINS: %s\", e)\n\n        if not results:\n            fallback = \"\"\"\n            MATCH (node)\n            WHERE (node:Function OR node:Class OR node:Variable)\n              AND node.name CONTAINS $search_term\n            OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n            RETURN\n                node.name as name,\n                CASE WHEN node:Function THEN 'function'\n                     WHEN node:Class THEN 'class'\n                     ELSE 'variable' END as type,\n                coalesce(f.path, node.path) as path,\n                coalesce(node.line_number, 0) as line_number,\n                1.0 as score\n            ORDER BY node.name\n            LIMIT $limit\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term, \"limit\": limit})\n            results = [\n                {\n                    \"name\": record[\"name\"],\n                    \"type\": record[\"type\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records","numLines":130,"startLine":278,"totalLines":1783}},"sourceToolAssistantUUID":"db2bdff9-ec0b-4119-a218-f89521f32296"}
{"parentUuid":"3219aa1b-7fb9-495c-9ec6-5d1844ad13ad","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01GdGWPsRoyss28zgLViUc74","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NEYTyAa4pqaHJj5wGyTppe","name":"Edit","input":{"replace_all":false,"file_path":"/Users/skmabudalam/Documents/BugViper/db/queries.py","old_string":"    def _escape_lucene_query(self, query: str) -> str:\n        \"\"\"\n        Escape Lucene special characters in search query.\n\n        Strategy: Wrap the entire query in quotes to treat it as a literal phrase search.\n        This prevents Lucene from interpreting special characters.\n\n        For complex queries, users can use wildcards: *\n        \"\"\"\n        query = query.strip()\n\n        # If query is empty, return a wildcard\n        if not query:\n            return '*'\n\n        # If the query already has quotes, escape internal quotes\n        if '\"' in query:\n            # Escape any existing quotes and wrap in quotes\n            query = query.replace('\"', '\\\\\"')\n\n        # Wrap in quotes to make it a literal phrase search\n        # This treats special characters as literals\n        return f'\"{query}\"'\n\n    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n        \"\"\"Search for code by name or docstring using fulltext index with CONTAINS fallback.\"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        results: List[Dict[str, Any]] = []\n        try:\n            query = CYPHER_QUERIES[\"search_code\"]\n            records, _, _ = self.db.run_query(query, {\"search_term\": escaped_term})\n            results = [\n                {\n                    \"type\": record[\"type\"],\n                    \"name\": record[\"name\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"Fulltext search failed, falling back to CONTAINS: %s\", e)\n\n        if not results:\n            fallback = \"\"\"\n            MATCH (node)\n            WHERE (node:Function OR node:Class OR node:Variable)\n              AND node.name CONTAINS $search_term\n            OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n            RETURN\n                CASE WHEN node:Function THEN 'function'\n                     WHEN node:Class THEN 'class'\n                     ELSE 'variable' END as type,\n                node.name as name,\n                coalesce(f.path, node.path) as path,\n                coalesce(node.line_number, 0) as line_number,\n                1.0 as score\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})\n            results = [\n                {\n                    \"type\": record[\"type\"],\n                    \"name\": record[\"name\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n\n        return results\n\n    def search_symbols(\n        self,\n        search_term: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Search symbols (Function/Class/Variable) using fulltext index with CONTAINS fallback.\"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        results: List[Dict[str, Any]] = []\n        try:\n            query = CYPHER_QUERIES[\"search_symbols\"]\n            records, _, _ = self.db.run_query(query, {\n                \"search_term\": escaped_term,\n                \"limit\": limit,\n            })\n            results = [\n                {\n                    \"name\": record[\"name\"],\n                    \"type\": record[\"type\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"Symbol fulltext search failed, falling back to CONTAINS: %s\", e)\n\n        if not results:\n            fallback = \"\"\"\n            MATCH (node)\n            WHERE (node:Function OR node:Class OR node:Variable)\n              AND node.name CONTAINS $search_term\n            OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n            RETURN\n                node.name as name,\n                CASE WHEN node:Function THEN 'function'\n                     WHEN node:Class THEN 'class'\n                     ELSE 'variable' END as type,\n                coalesce(f.path, node.path) as path,\n                coalesce(node.line_number, 0) as line_number,\n                1.0 as score\n            ORDER BY node.name\n            LIMIT $limit\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term, \"limit\": limit})\n            results = [\n                {\n                    \"name\": record[\"name\"],\n                    \"type\": record[\"type\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]","new_string":"    # Python/JS keywords that should not be used as search identifiers\n    _CODE_KEYWORDS = frozenset({\n        'class', 'def', 'import', 'from', 'return', 'self', 'cls', 'None',\n        'True', 'False', 'and', 'or', 'not', 'in', 'is', 'if', 'else',\n        'elif', 'for', 'while', 'try', 'except', 'with', 'as', 'pass',\n        'break', 'continue', 'raise', 'yield', 'async', 'await', 'lambda',\n        'function', 'const', 'let', 'var', 'new', 'this', 'super',\n    })\n\n    def _extract_identifiers(self, query: str) -> List[str]:\n        \"\"\"Extract meaningful code identifiers from a raw query string.\"\"\"\n        tokens = re.findall(r'\\b[A-Za-z_][A-Za-z0-9_]{2,}\\b', query)\n        seen: set = set()\n        result = []\n        for t in tokens:\n            if t not in self._CODE_KEYWORDS and t not in seen:\n                seen.add(t)\n                result.append(t)\n        return result\n\n    def _escape_lucene_query(self, query: str) -> str:\n        \"\"\"\n        Build a safe Lucene query string.\n\n        Strategy:\n        - Simple identifier (word chars only) → phrase search  e.g. \"LoginRequest\"\n        - Complex query with special chars     → AND-keyword strategy\n          e.g. \"class GitHubRepo(BaseModel)\" → \"GitHubRepo\" AND \"BaseModel\"\n          This avoids Lucene parse errors while still matching meaningful tokens.\n        \"\"\"\n        query = query.strip()\n        if not query:\n            return '*'\n\n        # Simple identifier — use phrase search directly\n        if re.match(r'^[A-Za-z0-9_]+$', query):\n            return f'\"{query}\"'\n\n        # Complex query — extract identifiers and build AND search\n        identifiers = self._extract_identifiers(query)\n        if identifiers:\n            # Cap at 3 identifiers to keep the query lean\n            return ' AND '.join(f'\"{t}\"' for t in identifiers[:3])\n\n        # Pure symbols / numbers with no useful identifiers — wrap and hope for best\n        escaped = query.replace('\"', '\\\\\"')\n        return f'\"{escaped}\"'\n\n    def _name_contains_fallback(\n        self,\n        search_term: str,\n        limit: int = 20,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        CONTAINS fallback against node names.\n        Uses the primary identifier extracted from the search term so that\n        queries like 'class GitHubRepo(BaseModel)' still find 'GitHubRepo'.\n        \"\"\"\n        identifiers = self._extract_identifiers(search_term)\n        # Use the first (longest) identifier, falling back to raw term\n        name_term = max(identifiers, key=len) if identifiers else search_term\n\n        fallback = \"\"\"\n        MATCH (node)\n        WHERE (node:Function OR node:Class OR node:Variable)\n          AND node.name CONTAINS $name_term\n        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n        RETURN\n            CASE WHEN node:Function THEN 'function'\n                 WHEN node:Class THEN 'class'\n                 ELSE 'variable' END as type,\n            node.name as name,\n            coalesce(f.path, node.path) as path,\n            coalesce(node.line_number, 0) as line_number,\n            1.0 as score\n        ORDER BY node.name\n        LIMIT $limit\n        \"\"\"\n        records, _, _ = self.db.run_query(fallback, {\"name_term\": name_term, \"limit\": limit})\n        return [\n            {\n                \"type\": record[\"type\"],\n                \"name\": record[\"name\"],\n                \"path\": record[\"path\"],\n                \"line_number\": record[\"line_number\"],\n                \"score\": record[\"score\"],\n            }\n            for record in records\n        ]\n\n    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search for code using a three-tier strategy:\n        1. code_search fulltext index (symbols: name, docstring, source_code)\n        2. Name CONTAINS fallback (uses primary extracted identifier)\n        3. File content line search (file_content_search / source_code CONTAINS)\n        Returns lean results: type, name, path, line_number, score.\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        # Tier 1 — fulltext symbol search\n        results: List[Dict[str, Any]] = []\n        try:\n            records, _, _ = self.db.run_query(\n                CYPHER_QUERIES[\"search_code\"], {\"search_term\": escaped_term}\n            )\n            results = [\n                {\n                    \"type\": record[\"type\"],\n                    \"name\": record[\"name\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"code_search fulltext failed: %s\", e)\n\n        # Tier 2 — name CONTAINS (works even when fulltext index misses)\n        if not results:\n            results = self._name_contains_fallback(search_term, limit=20)\n\n        # Tier 3 — file content line search (raw code snippets, declarations, etc.)\n        if not results:\n            file_hits = self.search_file_content(search_term, limit=20)\n            results = [\n                {\n                    \"type\": \"line\",\n                    \"name\": h[\"match_line\"].strip(),\n                    \"path\": h[\"path\"],\n                    \"line_number\": h[\"line_number\"],\n                    \"score\": 0.5,\n                }\n                for h in file_hits\n            ]\n\n        return results\n\n    def search_symbols(\n        self,\n        search_term: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search symbols (Function/Class/Variable) using fulltext index.\n        Falls back to name CONTAINS using the primary extracted identifier.\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        results: List[Dict[str, Any]] = []\n        try:\n            records, _, _ = self.db.run_query(\n                CYPHER_QUERIES[\"search_symbols\"],\n                {\"search_term\": escaped_term, \"limit\": limit},\n            )\n            results = [\n                {\n                    \"name\": record[\"name\"],\n                    \"type\": record[\"type\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"symbol fulltext search failed: %s\", e)\n\n        if not results:\n            raw = self._name_contains_fallback(search_term, limit=limit)\n            # _name_contains_fallback returns same shape, just reorder keys\n            results = [\n                {\n                    \"name\": r[\"name\"],\n                    \"type\": r[\"type\"],\n                    \"path\": r[\"path\"],\n                    \"line_number\": r[\"line_number\"],\n                    \"score\": r[\"score\"],\n                }\n                for r in raw\n            ]"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":5656,"cache_read_input_tokens":103863,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":5656},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLuf3owTbxc1VQsmcX3X","type":"assistant","uuid":"762cc62e-56e1-4af5-9370-f8f7edd96c65","timestamp":"2026-02-21T08:36:37.999Z"}
{"parentUuid":"762cc62e-56e1-4af5-9370-f8f7edd96c65","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01NEYTyAa4pqaHJj5wGyTppe","toolUseID":"toolu_01NEYTyAa4pqaHJj5wGyTppe","timestamp":"2026-02-21T08:37:36.607Z","uuid":"256e78a7-cb33-4d7c-b0e7-c58573e676c9"}
{"parentUuid":"762cc62e-56e1-4af5-9370-f8f7edd96c65","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01NEYTyAa4pqaHJj5wGyTppe","type":"tool_result","content":"The file /Users/skmabudalam/Documents/BugViper/db/queries.py has been updated successfully."}]},"uuid":"deaba551-b2f5-4f9a-b6a7-4dab00f30335","timestamp":"2026-02-21T08:37:36.606Z","toolUseResult":{"filePath":"/Users/skmabudalam/Documents/BugViper/db/queries.py","oldString":"    def _escape_lucene_query(self, query: str) -> str:\n        \"\"\"\n        Escape Lucene special characters in search query.\n\n        Strategy: Wrap the entire query in quotes to treat it as a literal phrase search.\n        This prevents Lucene from interpreting special characters.\n\n        For complex queries, users can use wildcards: *\n        \"\"\"\n        query = query.strip()\n\n        # If query is empty, return a wildcard\n        if not query:\n            return '*'\n\n        # If the query already has quotes, escape internal quotes\n        if '\"' in query:\n            # Escape any existing quotes and wrap in quotes\n            query = query.replace('\"', '\\\\\"')\n\n        # Wrap in quotes to make it a literal phrase search\n        # This treats special characters as literals\n        return f'\"{query}\"'\n\n    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n        \"\"\"Search for code by name or docstring using fulltext index with CONTAINS fallback.\"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        results: List[Dict[str, Any]] = []\n        try:\n            query = CYPHER_QUERIES[\"search_code\"]\n            records, _, _ = self.db.run_query(query, {\"search_term\": escaped_term})\n            results = [\n                {\n                    \"type\": record[\"type\"],\n                    \"name\": record[\"name\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"Fulltext search failed, falling back to CONTAINS: %s\", e)\n\n        if not results:\n            fallback = \"\"\"\n            MATCH (node)\n            WHERE (node:Function OR node:Class OR node:Variable)\n              AND node.name CONTAINS $search_term\n            OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n            RETURN\n                CASE WHEN node:Function THEN 'function'\n                     WHEN node:Class THEN 'class'\n                     ELSE 'variable' END as type,\n                node.name as name,\n                coalesce(f.path, node.path) as path,\n                coalesce(node.line_number, 0) as line_number,\n                1.0 as score\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})\n            results = [\n                {\n                    \"type\": record[\"type\"],\n                    \"name\": record[\"name\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n\n        return results\n\n    def search_symbols(\n        self,\n        search_term: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Search symbols (Function/Class/Variable) using fulltext index with CONTAINS fallback.\"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        results: List[Dict[str, Any]] = []\n        try:\n            query = CYPHER_QUERIES[\"search_symbols\"]\n            records, _, _ = self.db.run_query(query, {\n                \"search_term\": escaped_term,\n                \"limit\": limit,\n            })\n            results = [\n                {\n                    \"name\": record[\"name\"],\n                    \"type\": record[\"type\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"Symbol fulltext search failed, falling back to CONTAINS: %s\", e)\n\n        if not results:\n            fallback = \"\"\"\n            MATCH (node)\n            WHERE (node:Function OR node:Class OR node:Variable)\n              AND node.name CONTAINS $search_term\n            OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n            RETURN\n                node.name as name,\n                CASE WHEN node:Function THEN 'function'\n                     WHEN node:Class THEN 'class'\n                     ELSE 'variable' END as type,\n                coalesce(f.path, node.path) as path,\n                coalesce(node.line_number, 0) as line_number,\n                1.0 as score\n            ORDER BY node.name\n            LIMIT $limit\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term, \"limit\": limit})\n            results = [\n                {\n                    \"name\": record[\"name\"],\n                    \"type\": record[\"type\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]","newString":"    # Python/JS keywords that should not be used as search identifiers\n    _CODE_KEYWORDS = frozenset({\n        'class', 'def', 'import', 'from', 'return', 'self', 'cls', 'None',\n        'True', 'False', 'and', 'or', 'not', 'in', 'is', 'if', 'else',\n        'elif', 'for', 'while', 'try', 'except', 'with', 'as', 'pass',\n        'break', 'continue', 'raise', 'yield', 'async', 'await', 'lambda',\n        'function', 'const', 'let', 'var', 'new', 'this', 'super',\n    })\n\n    def _extract_identifiers(self, query: str) -> List[str]:\n        \"\"\"Extract meaningful code identifiers from a raw query string.\"\"\"\n        tokens = re.findall(r'\\b[A-Za-z_][A-Za-z0-9_]{2,}\\b', query)\n        seen: set = set()\n        result = []\n        for t in tokens:\n            if t not in self._CODE_KEYWORDS and t not in seen:\n                seen.add(t)\n                result.append(t)\n        return result\n\n    def _escape_lucene_query(self, query: str) -> str:\n        \"\"\"\n        Build a safe Lucene query string.\n\n        Strategy:\n        - Simple identifier (word chars only) → phrase search  e.g. \"LoginRequest\"\n        - Complex query with special chars     → AND-keyword strategy\n          e.g. \"class GitHubRepo(BaseModel)\" → \"GitHubRepo\" AND \"BaseModel\"\n          This avoids Lucene parse errors while still matching meaningful tokens.\n        \"\"\"\n        query = query.strip()\n        if not query:\n            return '*'\n\n        # Simple identifier — use phrase search directly\n        if re.match(r'^[A-Za-z0-9_]+$', query):\n            return f'\"{query}\"'\n\n        # Complex query — extract identifiers and build AND search\n        identifiers = self._extract_identifiers(query)\n        if identifiers:\n            # Cap at 3 identifiers to keep the query lean\n            return ' AND '.join(f'\"{t}\"' for t in identifiers[:3])\n\n        # Pure symbols / numbers with no useful identifiers — wrap and hope for best\n        escaped = query.replace('\"', '\\\\\"')\n        return f'\"{escaped}\"'\n\n    def _name_contains_fallback(\n        self,\n        search_term: str,\n        limit: int = 20,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        CONTAINS fallback against node names.\n        Uses the primary identifier extracted from the search term so that\n        queries like 'class GitHubRepo(BaseModel)' still find 'GitHubRepo'.\n        \"\"\"\n        identifiers = self._extract_identifiers(search_term)\n        # Use the first (longest) identifier, falling back to raw term\n        name_term = max(identifiers, key=len) if identifiers else search_term\n\n        fallback = \"\"\"\n        MATCH (node)\n        WHERE (node:Function OR node:Class OR node:Variable)\n          AND node.name CONTAINS $name_term\n        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n        RETURN\n            CASE WHEN node:Function THEN 'function'\n                 WHEN node:Class THEN 'class'\n                 ELSE 'variable' END as type,\n            node.name as name,\n            coalesce(f.path, node.path) as path,\n            coalesce(node.line_number, 0) as line_number,\n            1.0 as score\n        ORDER BY node.name\n        LIMIT $limit\n        \"\"\"\n        records, _, _ = self.db.run_query(fallback, {\"name_term\": name_term, \"limit\": limit})\n        return [\n            {\n                \"type\": record[\"type\"],\n                \"name\": record[\"name\"],\n                \"path\": record[\"path\"],\n                \"line_number\": record[\"line_number\"],\n                \"score\": record[\"score\"],\n            }\n            for record in records\n        ]\n\n    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search for code using a three-tier strategy:\n        1. code_search fulltext index (symbols: name, docstring, source_code)\n        2. Name CONTAINS fallback (uses primary extracted identifier)\n        3. File content line search (file_content_search / source_code CONTAINS)\n        Returns lean results: type, name, path, line_number, score.\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        # Tier 1 — fulltext symbol search\n        results: List[Dict[str, Any]] = []\n        try:\n            records, _, _ = self.db.run_query(\n                CYPHER_QUERIES[\"search_code\"], {\"search_term\": escaped_term}\n            )\n            results = [\n                {\n                    \"type\": record[\"type\"],\n                    \"name\": record[\"name\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"code_search fulltext failed: %s\", e)\n\n        # Tier 2 — name CONTAINS (works even when fulltext index misses)\n        if not results:\n            results = self._name_contains_fallback(search_term, limit=20)\n\n        # Tier 3 — file content line search (raw code snippets, declarations, etc.)\n        if not results:\n            file_hits = self.search_file_content(search_term, limit=20)\n            results = [\n                {\n                    \"type\": \"line\",\n                    \"name\": h[\"match_line\"].strip(),\n                    \"path\": h[\"path\"],\n                    \"line_number\": h[\"line_number\"],\n                    \"score\": 0.5,\n                }\n                for h in file_hits\n            ]\n\n        return results\n\n    def search_symbols(\n        self,\n        search_term: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search symbols (Function/Class/Variable) using fulltext index.\n        Falls back to name CONTAINS using the primary extracted identifier.\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        results: List[Dict[str, Any]] = []\n        try:\n            records, _, _ = self.db.run_query(\n                CYPHER_QUERIES[\"search_symbols\"],\n                {\"search_term\": escaped_term, \"limit\": limit},\n            )\n            results = [\n                {\n                    \"name\": record[\"name\"],\n                    \"type\": record[\"type\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"symbol fulltext search failed: %s\", e)\n\n        if not results:\n            raw = self._name_contains_fallback(search_term, limit=limit)\n            # _name_contains_fallback returns same shape, just reorder keys\n            results = [\n                {\n                    \"name\": r[\"name\"],\n                    \"type\": r[\"type\"],\n                    \"path\": r[\"path\"],\n                    \"line_number\": r[\"line_number\"],\n                    \"score\": r[\"score\"],\n                }\n                for r in raw\n            ]","originalFile":"\n\nfrom typing import Dict, List, Any, Optional\nimport re\nimport logging\n\nfrom .client import Neo4jClient\nfrom .schema import CYPHER_QUERIES\n\nlogger = logging.getLogger(__name__)\n\nclass CodeQueryService:\n    \"\"\"\n    Service for querying code elements from the Neo4j graph.\n    \n    Provides methods for:\n    - Finding method/function usages and callers\n    - Analyzing class hierarchies\n    - Searching code by name or content\n    - Reconstructing files from the graph\n    \"\"\"\n    \n    def __init__(self, client: Neo4jClient):\n        self.db = client\n    \n    # =========================================================================\n    # Graph Statistics\n    # =========================================================================\n    \n    def get_graph_stats(self) -> Dict[str, int]:\n        \"\"\"Get statistics about the code graph.\"\"\"\n        query = CYPHER_QUERIES[\"get_graph_stats\"]\n        records, _, _ = self.db.run_query(query)\n        \n        if records:\n            return dict(records[0])\n        return {}\n\n    def list_repositories(self) -> List[Dict[str, Any]]:\n        \"\"\"List all repositories in the database.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        OPTIONAL MATCH (r)-[:CONTAINS*]->(f:File)\n        RETURN r.id as id, r.name as name, r.owner as owner,\n               r.url as url, r.path as local_path,\n               r.last_commit_hash as last_commit,\n               r.created_at as created_at,\n               r.updated_at as updated_at,\n               count(DISTINCT f) as file_count\n        ORDER BY r.updated_at DESC, r.name\n        \"\"\"\n        records, _, _ = self.db.run_query(query)\n        \n        def convert_datetime(value):\n            \"\"\"Convert Neo4j DateTime to ISO string format.\"\"\"\n            if value is None:\n                return None\n            # Check if it's a Neo4j DateTime object\n            if hasattr(value, 'iso_format'):\n                return value.iso_format()\n            # If it's already a string or other type, return as is\n            return str(value) if value is not None else None\n        \n        return [\n            {\n                \"id\": record.get(\"id\"),\n                \"name\": record.get(\"name\"),\n                \"owner\": record.get(\"owner\"),\n                \"url\": record.get(\"url\"),\n                \"local_path\": record.get(\"local_path\"),\n                \"last_commit\": record.get(\"last_commit\"),\n                \"created_at\": convert_datetime(record.get(\"created_at\")),\n                \"updated_at\": convert_datetime(record.get(\"updated_at\")),\n                \"file_count\": record.get(\"file_count\") or 0\n            }\n            for record in records\n        ]\n\n    def delete_repository(self, repo_id: str) -> bool:\n        \"\"\"Delete a repository and all its associated data.\"\"\"\n        try:\n            query = \"\"\"\n            MATCH (r:Repository)\n            WHERE r.id = $repo_id OR r.repo = $repo_id\n            OPTIONAL MATCH (r)-[:CONTAINS*]->(n)\n            DETACH DELETE r, n\n            RETURN count(r) as deleted_count\n            \"\"\"\n            records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n            return records and records[0][\"deleted_count\"] > 0\n        except Exception as e:\n            logger.error(\"Error deleting repository %s: %s\", repo_id, e)\n            return False\n    \n    def get_repository_stats(self, repo_id: str) -> Dict[str, Any]:\n        \"\"\"Get statistics for a specific repository.\"\"\"\n        if not self.db.connected:\n            # Return mock stats\n            return {\n                \"files\": 25,\n                \"classes\": 12,\n                \"functions\": 89,\n                \"methods\": 156,\n                \"lines\": 3420,\n                \"imports\": 67,\n                \"languages\": [\"Python\", \"TypeScript\", \"JavaScript\"]\n            }\n            \n        query = CYPHER_QUERIES[\"get_repo_stats\"]\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        \n        if records:\n            record = records[0]\n            return {\n                \"files\": record[\"file_count\"],\n                \"classes\": record[\"class_count\"],\n                \"functions\": record[\"function_count\"],\n                \"methods\": record[\"method_count\"],\n                \"lines\": record[\"line_count\"],\n                \"imports\": record[\"import_count\"],\n                \"languages\": record[\"languages\"]\n            }\n        return {}\n    \n    # =========================================================================\n    # Method and Function Queries\n    # =========================================================================\n    \n    def find_method_usages(self, method_name: str) -> Dict[str, Any]:\n        \"\"\"Find all usages of a method by name.\"\"\"\n        query = CYPHER_QUERIES[\"find_method_usages\"]\n        records, _, _ = self.db.run_query(query, {\"method_name\": method_name})\n\n        results = []\n        for record in records:\n            # Convert Neo4j Node objects to dictionaries for JSON serialization\n            callers = []\n            for caller_dict in record[\"callers\"]:\n                if caller_dict and caller_dict.get(\"caller\"):\n                    callers.append({\n                        \"caller\": dict(caller_dict[\"caller\"]) if hasattr(caller_dict[\"caller\"], \"__iter__\") and not isinstance(caller_dict[\"caller\"], str) else {\"name\": str(caller_dict[\"caller\"])},\n                        \"line\": caller_dict.get(\"line\")\n                    })\n\n            references = []\n            for ref_dict in record[\"references\"]:\n                if ref_dict and ref_dict.get(\"line\"):\n                    references.append({\n                        \"line\": dict(ref_dict[\"line\"]) if hasattr(ref_dict[\"line\"], \"__iter__\") and not isinstance(ref_dict[\"line\"], str) else {\"line\": str(ref_dict[\"line\"])},\n                        \"col_start\": ref_dict.get(\"col_start\")\n                    })\n\n            results.append({\n                \"method\": dict(record[\"m\"]) if record[\"m\"] else None,\n                \"callers\": callers,\n                \"references\": references\n            })\n        return {\"usages\": results}\n    \n    def find_method_context(self, method_id: str) -> Dict[str, Any]:\n        \"\"\"Find the full context of a method (class, file, repo, user).\"\"\"\n        query = CYPHER_QUERIES[\"find_method_context\"]\n        records, _, _ = self.db.run_query(query, {\"method_id\": method_id})\n        \n        if records:\n            record = records[0]\n            return {\n                \"user\": record[\"user\"],\n                \"repo\": record[\"repo\"],\n                \"file\": record[\"file\"],\n                \"class\": record[\"class_name\"],\n                \"method\": record[\"method\"],\n                \"lines\": f\"{record['start_line']}-{record['end_line']}\"\n            }\n        return {}\n    \n    def find_callers(self, symbol_name: str) -> List[Dict[str, Any]]:\n        \"\"\"Find all methods/functions that call a specific symbol.\"\"\"\n        query = CYPHER_QUERIES[\"find_callers\"]\n        records, _, _ = self.db.run_query(query, {\"name\": symbol_name})\n        \n        return [\n            {\n                \"caller\": record[\"caller_name\"],\n                \"type\": record[\"caller_type\"],\n                \"file\": record[\"file_path\"],\n                \"line\": record[\"call_line\"]\n            }\n            for record in records\n        ]\n    \n    # =========================================================================\n    # Class Queries\n    # =========================================================================\n    \n    def get_class_hierarchy(self, class_name: str) -> Dict[str, Any]:\n        \"\"\"Get the inheritance hierarchy of a class.\"\"\"\n        query = CYPHER_QUERIES[\"get_class_hierarchy\"]\n        records, _, _ = self.db.run_query(query, {\"class_name\": class_name})\n        \n        if records:\n            record = records[0]\n            return {\n                \"class\": dict(record[\"c\"]) if record[\"c\"] else None,\n                \"ancestors\": [dict(n) for n in record[\"ancestors\"]] if record[\"ancestors\"] else [],\n                \"descendants\": [dict(n) for n in record[\"descendants\"]] if record[\"descendants\"] else []\n            }\n        return {}\n    \n    # =========================================================================\n    # File Queries\n    # =========================================================================\n    \n    def get_file_structure(self, file_id: str) -> Dict[str, Any]:\n        \"\"\"Get the structure of a file (classes, functions, imports).\"\"\"\n        query = CYPHER_QUERIES[\"get_file_structure\"]\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n        \n        if records:\n            record = records[0]\n            return {\n                \"file\": dict(record[\"f\"]) if record[\"f\"] else None,\n                \"classes\": record[\"classes\"],\n                \"functions\": [dict(f) for f in record[\"functions\"]] if record[\"functions\"] else [],\n                \"imports\": [dict(i) for i in record[\"imports\"]] if record[\"imports\"] else []\n            }\n        return {}\n    \n    def get_repo_overview(self, repo_id: str) -> Dict[str, Any]:\n        \"\"\"Get an overview of a repository.\"\"\"\n        if not self.db.connected:\n            # Return mock overview\n            return {\n                \"repo\": {\n                    \"id\": repo_id,\n                    \"name\": repo_id.split(\"/\")[-1] if \"/\" in repo_id else repo_id,\n                    \"owner\": repo_id.split(\"/\")[0] if \"/\" in repo_id else \"unknown\"\n                },\n                \"files\": 25,\n                \"classes\": 12,\n                \"functions\": 89,\n                \"languages\": [\"Python\", \"TypeScript\", \"JavaScript\"]\n            }\n            \n        query = CYPHER_QUERIES[\"get_repo_overview\"]\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        \n        if records:\n            record = records[0]\n            return {\n                \"repo\": record[\"repo\"],\n                \"files\": record[\"file_count\"],\n                \"classes\": record[\"class_count\"],\n                \"functions\": record[\"function_count\"],\n                \"languages\": record[\"languages\"]\n            }\n        return {}\n    \n    def get_repo_files(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all files in a repository.\"\"\"\n        query = CYPHER_QUERIES[\"get_repo_files\"]\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        \n        return [\n            {\n                \"file\": dict(record[\"f\"]) if record[\"f\"] else None,\n                \"language\": record[\"language\"],\n                \"lines_count\": record[\"lines_count\"]\n                \n            }\n            for record in records\n        ]\n    \n    # =========================================================================\n    # Search Operations\n    # =========================================================================\n    \n    def _escape_lucene_query(self, query: str) -> str:\n        \"\"\"\n        Escape Lucene special characters in search query.\n\n        Strategy: Wrap the entire query in quotes to treat it as a literal phrase search.\n        This prevents Lucene from interpreting special characters.\n\n        For complex queries, users can use wildcards: *\n        \"\"\"\n        query = query.strip()\n\n        # If query is empty, return a wildcard\n        if not query:\n            return '*'\n\n        # If the query already has quotes, escape internal quotes\n        if '\"' in query:\n            # Escape any existing quotes and wrap in quotes\n            query = query.replace('\"', '\\\\\"')\n\n        # Wrap in quotes to make it a literal phrase search\n        # This treats special characters as literals\n        return f'\"{query}\"'\n\n    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n        \"\"\"Search for code by name or docstring using fulltext index with CONTAINS fallback.\"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        results: List[Dict[str, Any]] = []\n        try:\n            query = CYPHER_QUERIES[\"search_code\"]\n            records, _, _ = self.db.run_query(query, {\"search_term\": escaped_term})\n            results = [\n                {\n                    \"type\": record[\"type\"],\n                    \"name\": record[\"name\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"Fulltext search failed, falling back to CONTAINS: %s\", e)\n\n        if not results:\n            fallback = \"\"\"\n            MATCH (node)\n            WHERE (node:Function OR node:Class OR node:Variable)\n              AND node.name CONTAINS $search_term\n            OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n            RETURN\n                CASE WHEN node:Function THEN 'function'\n                     WHEN node:Class THEN 'class'\n                     ELSE 'variable' END as type,\n                node.name as name,\n                coalesce(f.path, node.path) as path,\n                coalesce(node.line_number, 0) as line_number,\n                1.0 as score\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})\n            results = [\n                {\n                    \"type\": record[\"type\"],\n                    \"name\": record[\"name\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n\n        return results\n\n    def search_symbols(\n        self,\n        search_term: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Search symbols (Function/Class/Variable) using fulltext index with CONTAINS fallback.\"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        results: List[Dict[str, Any]] = []\n        try:\n            query = CYPHER_QUERIES[\"search_symbols\"]\n            records, _, _ = self.db.run_query(query, {\n                \"search_term\": escaped_term,\n                \"limit\": limit,\n            })\n            results = [\n                {\n                    \"name\": record[\"name\"],\n                    \"type\": record[\"type\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"Symbol fulltext search failed, falling back to CONTAINS: %s\", e)\n\n        if not results:\n            fallback = \"\"\"\n            MATCH (node)\n            WHERE (node:Function OR node:Class OR node:Variable)\n              AND node.name CONTAINS $search_term\n            OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n            RETURN\n                node.name as name,\n                CASE WHEN node:Function THEN 'function'\n                     WHEN node:Class THEN 'class'\n                     ELSE 'variable' END as type,\n                coalesce(f.path, node.path) as path,\n                coalesce(node.line_number, 0) as line_number,\n                1.0 as score\n            ORDER BY node.name\n            LIMIT $limit\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term, \"limit\": limit})\n            results = [\n                {\n                    \"name\": record[\"name\"],\n                    \"type\": record[\"type\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n\n        return results\n\n    def search_file_content(self, search_term: str, limit: int = 50) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search file source code line by line.\n        Uses file_content_search fulltext index to find candidate files,\n        then scans lines in Python to find the exact matching lines.\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n        file_records: List[Dict[str, Any]] = []\n\n        try:\n            ft_query = \"\"\"\n            CALL db.index.fulltext.queryNodes('file_content_search', $search_term) YIELD node, score\n            WHERE node.source_code IS NOT NULL\n            RETURN node.path as path, node.source_code as source_code, score\n            ORDER BY score DESC\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(ft_query, {\"search_term\": escaped_term})\n            file_records = [dict(r) for r in records]\n        except Exception as e:\n            logger.warning(\"file_content_search index failed, falling back to CONTAINS: %s\", e)\n\n        if not file_records:\n            fallback = \"\"\"\n            MATCH (f:File)\n            WHERE f.source_code CONTAINS $search_term\n            RETURN f.path as path, f.source_code as source_code, 1.0 as score\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})\n            file_records = [dict(r) for r in records]\n\n        results: List[Dict[str, Any]] = []\n        term_lower = search_term.lower()\n        for rec in file_records:\n            path = rec.get(\"path\")\n            source = rec.get(\"source_code\")\n            if not path or not source:\n                continue\n            for i, line in enumerate(source.split(\"\\n\")):\n                if search_term in line or term_lower in line.lower():\n                    results.append({\n                        \"path\": path,\n                        \"line_number\": i + 1,\n                        \"match_line\": line.rstrip(),\n                    })\n                    if len(results) >= limit:\n                        return results\n        return results\n\n    def peek_file_lines(\n        self,\n        path: str,\n        line: int,\n        above: int = 10,\n        below: int = 10,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Return a window of lines around `line` in the given file.\n        Lines are 1-indexed. The anchor line is flagged with is_anchor=True.\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {path: $path})\n        RETURN f.source_code as source_code\n        LIMIT 1\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"path\": path})\n        if not records or not records[0].get(\"source_code\"):\n            return {\"error\": \"File not found\", \"path\": path}\n\n        lines = records[0][\"source_code\"].split(\"\\n\")\n        total = len(lines)\n        start = max(0, line - above - 1)   # 0-indexed inclusive\n        end = min(total, line + below)       # 0-indexed exclusive\n\n        window = [\n            {\n                \"line_number\": i + 1,\n                \"content\": lines[i],\n                \"is_anchor\": (i + 1) == line,\n            }\n            for i in range(start, end)\n        ]\n\n        return {\n            \"path\": path,\n            \"anchor_line\": line,\n            \"window\": window,\n            \"total_lines\": total,\n        }\n\n    def find_symbol_by_qualified_name(\n        self,\n        qualified_name: str,\n        repo_id: str\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a symbol by its exact qualified name.\n\n        Args:\n            qualified_name: Full qualified name (e.g., module.Class.method)\n            repo_id: Repository ID to search in\n\n        Returns:\n            Symbol information if found\n        \"\"\"\n        query = CYPHER_QUERIES[\"search_symbols_by_qualified_name\"]\n        records, _, _ = self.db.run_query(query, {\n            \"qualified_name\": qualified_name,\n            \"repo_id\": repo_id\n        })\n\n        if records:\n            record = records[0]\n            return {\n                \"id\": record[\"id\"],\n                \"name\": record[\"name\"],\n                \"qualified_name\": record[\"qualified_name\"],\n                \"type\": record[\"type\"],\n                \"file_id\": record[\"file_id\"],\n                \"line_start\": record[\"line_start\"],\n                \"line_end\": record[\"line_end\"],\n                \"scope\": record[\"scope\"],\n                \"visibility\": record[\"visibility\"],\n                \"docstring\": record[\"docstring\"]\n            }\n        return None\n\n    def autocomplete_symbols(\n        self,\n        prefix: str,\n        repo_id: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get symbol autocomplete suggestions.\n\n        Args:\n            prefix: Prefix to match (e.g., \"module.Clas\")\n            repo_id: Repository ID\n            limit: Maximum results\n\n        Returns:\n            List of matching symbol qualified names\n        \"\"\"\n        query = CYPHER_QUERIES[\"autocomplete_symbols\"]\n        records, _, _ = self.db.run_query(query, {\n            \"prefix\": prefix,\n            \"repo_id\": repo_id,\n            \"limit\": limit\n        })\n\n        return [\n            {\n                \"qualified_name\": record[\"qualified_name\"],\n                \"type\": record[\"type\"],\n                \"visibility\": record[\"visibility\"],\n                \"file_id\": record[\"file_id\"]\n            }\n            for record in records\n        ]\n\n    def find_symbols_in_scope(\n        self,\n        file_id: str,\n        scope: str = \"module\"\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Find all symbols in a specific scope.\n\n        Args:\n            file_id: File ID to search in\n            scope: Scope type (module, class, function)\n\n        Returns:\n            List of symbols in the scope\n        \"\"\"\n        query = CYPHER_QUERIES[\"find_symbols_in_scope\"]\n        records, _, _ = self.db.run_query(query, {\n            \"file_id\": file_id,\n            \"scope\": scope\n        })\n\n        return [\n            {\n                \"name\": record[\"name\"],\n                \"qualified_name\": record[\"qualified_name\"],\n                \"type\": record[\"type\"],\n                \"line_start\": record[\"line_start\"],\n                \"visibility\": record[\"visibility\"]\n            }\n            for record in records\n        ]\n    \n    def find_symbol_definition(self, symbol_name: str, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Find where a symbol (class, function, method, variable) is defined.\"\"\"\n        query = \"\"\"\n        MATCH (symbol)\n        WHERE symbol.name = $symbol_name\n          AND (symbol.file_id STARTS WITH $repo_id OR symbol.class_id STARTS WITH $repo_id)\n        MATCH (f:File)-[:DEFINES*1..2]->(symbol)\n        RETURN symbol.name as name, labels(symbol)[0] as type,\n               f.path as file, symbol.line_start as line,\n               symbol.docstring as docstring, symbol.source_code as source_code\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\n            \"symbol_name\": symbol_name,\n            \"repo_id\": repo_id\n        })\n\n        return [\n            {\n                \"name\": record[\"name\"],\n                \"type\": record[\"type\"],\n                \"file\": record[\"file\"],\n                \"line\": record[\"line\"],\n                \"docstring\": record[\"docstring\"],\n                \"source_code\": record.get(\"source_code\")\n            }\n            for record in records\n        ]\n    \n    # =========================================================================\n    # Impact Analysis\n    # =========================================================================\n    \n    def analyze_change_impact(self, target_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Analyze the impact of changing a specific code element.\"\"\"\n        query = CYPHER_QUERIES[\"analyze_change_impact\"]\n        records, _, _ = self.db.run_query(query, {\"target_id\": target_id})\n\n        return [\n            {\n                \"affected\": record[\"affected\"],\n                \"type\": record[\"type\"],\n                \"file\": record[\"file\"],\n                \"distance\": record[\"distance\"]\n            }\n            for record in records\n        ]\n\n    def analyze_change_impact_enhanced(\n        self,\n        qualified_name: str,\n        repo_id: str\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Enhanced impact analysis with multi-dimensional impact tracking.\n\n        Analyzes:\n        - Direct callers\n        - Transitive callers (up to 3 levels)\n        - Inheritance impact (for classes/methods)\n        - Import impact (files that import changed file)\n\n        Args:\n            qualified_name: Fully qualified name of the symbol\n            repo_id: Repository ID\n\n        Returns:\n            Dict with categorized impact analysis\n        \"\"\"\n        query = CYPHER_QUERIES[\"analyze_change_impact_enhanced\"]\n        records, _, _ = self.db.run_query(query, {\n            \"qualified_name\": qualified_name,\n            \"repo_id\": repo_id\n        })\n\n        if records:\n            record = records[0]\n            return {\n                \"target\": record[\"target\"],\n                \"direct_calls\": [call for call in record[\"direct_calls\"] if call.get(\"name\")],\n                \"transitive_calls\": [call for call in record[\"transitive_calls\"] if call.get(\"name\")],\n                \"inheritance_impact\": [imp for imp in record[\"inheritance_impact\"] if imp.get(\"name\")],\n                \"import_impact\": [imp for imp in record[\"import_impact\"] if imp.get(\"name\")],\n                \"total_impact\": record[\"total_impact\"]\n            }\n        return {\n            \"target\": qualified_name,\n            \"direct_calls\": [],\n            \"transitive_calls\": [],\n            \"inheritance_impact\": [],\n            \"import_impact\": [],\n            \"total_impact\": 0\n        }\n\n    def get_call_graph(\n        self,\n        qualified_name: str,\n        repo_id: str,\n        max_depth: int = 3\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get the call graph starting from a symbol.\n\n        Args:\n            qualified_name: Starting symbol\n            repo_id: Repository ID\n            max_depth: Maximum depth to traverse\n\n        Returns:\n            List of caller-callee relationships\n        \"\"\"\n        query = CYPHER_QUERIES[\"get_call_graph\"]\n        records, _, _ = self.db.run_query(query, {\n            \"qualified_name\": qualified_name,\n            \"repo_id\": repo_id,\n            \"max_depth\": max_depth\n        })\n\n        return [\n            {\n                \"caller\": record[\"caller\"],\n                \"callee\": record[\"callee\"],\n                \"caller_type\": record[\"caller_type\"],\n                \"callee_type\": record[\"callee_type\"],\n                \"line\": record[\"line\"],\n                \"depth\": record[\"depth\"]\n            }\n            for record in records\n        ]\n    \n    # =========================================================================\n    # Code Retrieval Operations\n    # =========================================================================\n\n    def get_code_at_line(self, file_id: str, line_number: int) -> Optional[str]:\n        \"\"\"\n        Get the code content at a specific line.\n\n        Note: Uses file source_code and extracts the specific line.\n        \"\"\"\n        source_code = self.reconstruct_file(file_id)\n        if not source_code:\n            return None\n\n        lines = source_code.split('\\n')\n        if 0 < line_number <= len(lines):\n            return lines[line_number - 1]\n        return None\n\n    def get_code_range(\n        self,\n        file_id: str,\n        start_line: int,\n        end_line: int\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get code content for a range of lines.\n\n        Note: Uses file source_code and extracts the range.\n        \"\"\"\n        source_code = self.reconstruct_file(file_id)\n        if not source_code:\n            return []\n\n        lines = source_code.split('\\n')\n        result = []\n\n        for i in range(start_line - 1, min(end_line, len(lines))):\n            if i >= 0:\n                line_content = lines[i]\n                result.append({\n                    \"line\": i + 1,\n                    \"content\": line_content,\n                    \"is_comment\": line_content.strip().startswith(('#', '//', '/*')),\n                    \"is_blank\": len(line_content.strip()) == 0\n                })\n\n        return result\n    \n    # =========================================================================\n    # File Reconstruction\n    # =========================================================================\n    \n    def get_repository_files(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all files in a repository.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:CONTAINS*]->(f:File)\n        RETURN f.id as id, f.path as path, f.language as language,\n               f.lines_count as lines_count\n        ORDER BY f.path\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        return [\n            {\n                \"id\": record[\"id\"],\n                \"path\": record[\"path\"],\n                \"language\": record[\"language\"],\n                \"lines_count\": record[\"lines_count\"]\n            }\n            for record in records\n        ]\n    \n    def reconstruct_file(self, file_id: str) -> Optional[str]:\n        \"\"\"\n        Reconstruct a file's complete content from source_code property.\n\n        Returns:\n            Complete file source code or None if not found\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {id: $file_id})\n        RETURN f.source_code as source_code, f.path as path\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n\n        if not records:\n            return None\n\n        source_code = records[0].get(\"source_code\")\n        if not source_code:\n            # Fallback: try to reconstruct from individual code elements\n            # This shouldn't be needed but provides a safety net\n            print(f\"⚠️  Warning: File {records[0].get('path')} has no source_code stored\")\n            return None\n\n        return source_code\n\n    def verify_reconstruction(self, file_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Verify that file reconstruction is possible and show stats.\n\n        Args:\n            file_id: File ID to verify\n\n        Returns:\n            Dict with verification results\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {id: $file_id})\n        OPTIONAL MATCH (f)-[:DEFINES]->(c:Class)\n        OPTIONAL MATCH (f)-[:DEFINES]->(fn:Function)\n        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)\n        RETURN f.path as path,\n               f.language as language,\n               f.lines_count as lines_count,\n               f.source_code IS NOT NULL as has_source_code,\n               size(f.source_code) as source_code_size,\n               count(DISTINCT c) as class_count,\n               count(DISTINCT fn) as function_count,\n               count(DISTINCT m) as method_count\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n\n        if not records:\n            return {\"error\": \"File not found\", \"file_id\": file_id}\n\n        record = records[0]\n        can_reconstruct = record[\"has_source_code\"]\n\n        return {\n            \"file_id\": file_id,\n            \"path\": record[\"path\"],\n            \"language\": record[\"language\"],\n            \"lines_count\": record[\"lines_count\"],\n            \"can_reconstruct\": can_reconstruct,\n            \"source_code_size\": record[\"source_code_size\"] or 0,\n            \"classes\": record[\"class_count\"],\n            \"functions\": record[\"function_count\"],\n            \"methods\": record[\"method_count\"],\n            \"status\": \"✅ Ready\" if can_reconstruct else \"❌ No source_code\"\n        }\n    \n    def get_symbol_source(self, qualified_name: str, repo_id: str) -> Optional[str]:\n        \"\"\"\n        Get source code for a specific symbol.\n\n        Args:\n            qualified_name: Fully qualified name of the symbol\n            repo_id: Repository ID\n\n        Returns:\n            Source code of the symbol or None\n        \"\"\"\n        query = \"\"\"\n        MATCH (s:Symbol {qualified_name: $qualified_name})\n        WHERE s.file_id STARTS WITH $repo_id\n        RETURN s.source_code as source_code\n        LIMIT 1\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\n            \"qualified_name\": qualified_name,\n            \"repo_id\": repo_id\n        })\n\n        if records and records[0][\"source_code\"]:\n            return records[0][\"source_code\"]\n\n        # Fallback: try to get from definition node\n        symbol = self.find_symbol_by_qualified_name(qualified_name, repo_id)\n        if symbol and symbol.get(\"type\"):\n            if symbol[\"type\"] == \"class\":\n                return self.get_class_source(f\"{symbol['file_id']}:class:{symbol['name']}:{symbol['line_start']}\")\n            elif symbol[\"type\"] == \"function\":\n                return self.get_function_source(f\"{symbol['file_id']}:func:{symbol['name']}:{symbol['line_start']}\")\n            elif symbol[\"type\"] == \"method\":\n                # More complex - need to find class first\n                pass\n\n        return None\n\n    def verify_repository_reconstruction(self, repo_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Verify that all files in a repository can be reconstructed.\n\n        Args:\n            repo_id: Repository ID\n\n        Returns:\n            Dict with verification stats\n        \"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:CONTAINS*]->(f:File)\n        RETURN count(f) as total_files,\n               sum(CASE WHEN f.source_code IS NOT NULL THEN 1 ELSE 0 END) as files_with_source,\n               sum(f.lines_count) as total_lines,\n               sum(size(f.source_code)) as total_source_size\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n\n        if not records:\n            return {\"error\": \"Repository not found\", \"repo_id\": repo_id}\n\n        record = records[0]\n        total_files = record[\"total_files\"] or 0\n        files_with_source = record[\"files_with_source\"] or 0\n        success_rate = (files_with_source / total_files * 100) if total_files > 0 else 0\n\n        # Get list of files without source code\n        problem_files_query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:CONTAINS*]->(f:File)\n        WHERE f.source_code IS NULL\n        RETURN f.path as path, f.id as file_id\n        LIMIT 10\n        \"\"\"\n        problem_records, _, _ = self.db.run_query(problem_files_query, {\"repo_id\": repo_id})\n\n        return {\n            \"repo_id\": repo_id,\n            \"total_files\": total_files,\n            \"files_with_source\": files_with_source,\n            \"files_without_source\": total_files - files_with_source,\n            \"success_rate\": f\"{success_rate:.1f}%\",\n            \"total_lines\": record[\"total_lines\"] or 0,\n            \"total_source_size_mb\": (record[\"total_source_size\"] or 0) / 1024 / 1024,\n            \"status\": \"✅ All files ready\" if success_rate == 100 else f\"⚠️  {total_files - files_with_source} files missing source\",\n            \"problem_files\": [r[\"path\"] for r in problem_records] if problem_records else []\n        }\n\n    def reconstruct_repository(self, repo_id: str) -> Dict[str, str]:\n        \"\"\"\n        Reconstruct all files in a repository.\n        \n        Returns:\n            Dict mapping file paths to their reconstructed content\n        \"\"\"\n        files = self.get_repository_files(repo_id)\n        reconstructed = {}\n        \n        for file_info in files:\n            content = self.reconstruct_file(file_info[\"id\"])\n            if content is not None:\n                reconstructed[file_info[\"path\"]] = content\n        \n        return reconstructed\n    \n    def get_file_metadata(self, file_id: str) -> Dict[str, Any]:\n        \"\"\"Get complete metadata for a file including all code elements.\"\"\"\n        query = \"\"\"\n        MATCH (f:File {id: $file_id})\n        OPTIONAL MATCH (f)-[:DEFINES]->(c:Class)\n        OPTIONAL MATCH (f)-[:DEFINES]->(fn:Function)\n        OPTIONAL MATCH (f)-[:HAS_IMPORT]->(i:Import)\n        RETURN f.path as path,\n               f.language as language,\n               f.lines_count as lines_count,\n               collect(DISTINCT {name: c.name, line: c.line_start, bases: c.base_classes}) as classes,\n               collect(DISTINCT {name: fn.name, line: fn.line_start, params: fn.params}) as functions,\n               collect(DISTINCT {module: i.module, names: i.imported_names}) as imports\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n\n        if records:\n            record = records[0]\n            return {\n                \"path\": record[\"path\"],\n                \"language\": record[\"language\"],\n                \"lines_count\": record[\"lines_count\"],\n                \"classes\": [c for c in record[\"classes\"] if c[\"name\"]],\n                \"functions\": [f for f in record[\"functions\"] if f[\"name\"]],\n                \"imports\": [i for i in record[\"imports\"] if i[\"module\"]]\n            }\n        return {}\n\n    def get_method_source(self, method_id: str) -> Optional[str]:\n        \"\"\"Get the source code of a specific method.\"\"\"\n        query = \"\"\"\n        MATCH (m:Method {id: $method_id})\n        RETURN m.source_code as source_code\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"method_id\": method_id})\n        return records[0][\"source_code\"] if records and records[0][\"source_code\"] else None\n\n    def get_function_source(self, function_id: str) -> Optional[str]:\n        \"\"\"Get the source code of a specific function.\"\"\"\n        query = \"\"\"\n        MATCH (f:Function {id: $function_id})\n        RETURN f.source_code as source_code\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"function_id\": function_id})\n        return records[0][\"source_code\"] if records and records[0][\"source_code\"] else None\n\n    def get_class_source(self, class_id: str) -> Optional[str]:\n        \"\"\"Get the source code of a specific class.\"\"\"\n        query = \"\"\"\n        MATCH (c:Class {id: $class_id})\n        RETURN c.source_code as source_code\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"class_id\": class_id})\n        return records[0][\"source_code\"] if records and records[0][\"source_code\"] else None\n    \n    # =========================================================================\n    # Config File Queries\n    # =========================================================================\n    \n    def get_repo_config_files(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all config files in a repository.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:HAS_CONFIG]->(cf:ConfigFile)\n        RETURN cf.id as id, cf.path as path, cf.file_type as file_type,\n               cf.project_name as project_name, cf.version as version,\n               cf.lines_count as lines_count\n        ORDER BY cf.path\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        return [\n            {\n                \"id\": record[\"id\"],\n                \"path\": record[\"path\"],\n                \"file_type\": record[\"file_type\"],\n                \"project_name\": record[\"project_name\"],\n                \"version\": record[\"version\"],\n                \"lines_count\": record[\"lines_count\"]\n            }\n            for record in records\n        ]\n    \n    def get_repo_dependencies(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all dependencies in a repository.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:HAS_CONFIG]->(cf:ConfigFile)-[:HAS_DEPENDENCY]->(d:Dependency)\n        RETURN d.name as name, d.version_spec as version, d.is_dev as is_dev,\n               d.source as source, cf.path as config_file\n        ORDER BY d.is_dev, d.name\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        return [\n            {\n                \"name\": record[\"name\"],\n                \"version\": record[\"version\"],\n                \"is_dev\": record[\"is_dev\"],\n                \"source\": record[\"source\"],\n                \"config_file\": record[\"config_file\"]\n            }\n            for record in records\n        ]\n    \n    def delete_repository(self, repo_id: str) -> bool:\n        \"\"\"Delete a repository and all its data.\"\"\"\n        if not self.db.connected:\n            # Mock success for testing\n            return True\n\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        DETACH DELETE r\n        RETURN count(r) as deleted_count\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n\n        return len(records) > 0 and records[0].get(\"deleted_count\", 0) > 0\n    \n    def get_repo_overview_extended(self, repo_id: str) -> Dict[str, Any]:\n        \"\"\"Get extended repository overview including config files and dependencies.\"\"\"\n        # Get basic stats\n        basic = self.get_repo_overview(repo_id)\n        \n        # Get config file count\n        config_query = \"\"\"\n        MATCH (r:Repository {id: $repo_id})-[:HAS_CONFIG]->(cf:ConfigFile)\n        OPTIONAL MATCH (cf)-[:HAS_DEPENDENCY]->(d:Dependency)\n        RETURN count(DISTINCT cf) as config_count, count(DISTINCT d) as dep_count\n        \"\"\"\n        records, _, _ = self.db.run_query(config_query, {\"repo_id\": repo_id})\n        \n        if records:\n            basic[\"config_files\"] = records[0][\"config_count\"]\n            basic[\"dependencies\"] = records[0][\"dep_count\"]\n        else:\n            basic[\"config_files\"] = 0\n            basic[\"dependencies\"] = 0\n        \n        return basic\n\n    def get_all_ingested_repositories(self, owner: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all ingested repositories.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository {owner: $owner})\n        RETURN r.id as repo_id, r.owner as owner, r.name as name, r.url as url\n        ORDER BY r.owner, r.name\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"owner\": owner})\n        return [\n            {\n                \"repo_id\": record[\"repo_id\"],\n                \"owner\": record[\"owner\"],\n                \"name\": record[\"name\"],\n                \"url\": record[\"url\"]\n            }\n            for record in records\n        ]\n\n    # =========================================================================\n    # Hierarchy Navigation\n    # =========================================================================\n\n    def get_module_tree(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get the complete module/directory tree for a repository.\n\n        Args:\n            repo_id: Repository ID\n\n        Returns:\n            List of modules with hierarchy information\n        \"\"\"\n        query = CYPHER_QUERIES[\"get_module_tree\"]\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n\n        return [\n            {\n                \"path\": record[\"path\"],\n                \"name\": record[\"name\"],\n                \"parent_path\": record[\"parent_path\"],\n                \"is_package\": record[\"is_package\"],\n                \"depth\": record[\"depth\"]\n            }\n            for record in records\n        ]\n\n    def get_file_hierarchy(self, file_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get the breadcrumb hierarchy for a file.\n\n        Args:\n            file_id: File ID\n\n        Returns:\n            Ordered list from repository to file\n        \"\"\"\n        query = CYPHER_QUERIES[\"get_file_hierarchy\"]\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n\n        return [\n            {\n                \"type\": record[\"type\"],\n                \"name\": record[\"name\"],\n                \"path\": record[\"path\"],\n                \"depth\": record[\"depth\"]\n            }\n            for record in records\n        ]\n\n    def get_directory_contents(\n        self,\n        repo_id: str,\n        dir_path: str\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get contents of a specific directory.\n\n        Args:\n            repo_id: Repository ID\n            dir_path: Directory path\n\n        Returns:\n            List of files and subdirectories\n        \"\"\"\n        query = CYPHER_QUERIES[\"get_directory_contents\"]\n        records, _, _ = self.db.run_query(query, {\n            \"repo_id\": repo_id,\n            \"dir_path\": dir_path\n        })\n\n        return [\n            {\n                \"type\": record[\"type\"],\n                \"name\": record[\"name\"],\n                \"path\": record[\"path\"],\n                \"is_package\": record[\"is_package\"]\n            }\n            for record in records\n        ]\n\n    def get_symbols_at_lines(self, file_path: str, start_line: int, end_line: int) -> List[Dict[str, Any]]:\n        \"\"\"\n        Find all symbols (functions, classes, variables) that overlap a line range in a file.\n        Used to map diff hunks to affected code symbols.\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {path: $file_path})-[:CONTAINS]->(n)\n        WHERE (n:Function OR n:Class OR n:Variable)\n          AND n.line_number IS NOT NULL\n          AND n.line_number <= $end_line\n          AND coalesce(n.end_line, n.line_number) >= $start_line\n        RETURN\n            CASE\n                WHEN n:Function THEN 'function'\n                WHEN n:Class THEN 'class'\n                ELSE 'variable'\n            END as type,\n            n.name as name,\n            n.line_number as start_line,\n            coalesce(n.end_line, n.line_number) as end_line,\n            n.source as source,\n            n.docstring as docstring,\n            n.path as path\n        ORDER BY n.line_number\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\n            \"file_path\": file_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n        })\n        return [dict(r) for r in records]\n\n    def get_symbols_at_lines_by_relative_path(self, repo_id: str, relative_path: str, start_line: int, end_line: int) -> List[Dict[str, Any]]:\n        \"\"\"\n        Find all symbols overlapping a line range using repo-relative file path.\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File)\n        WHERE f.relative_path = $relative_path\n          AND f.path CONTAINS $repo_id\n        WITH f\n        MATCH (f)-[:CONTAINS]->(n)\n        WHERE (n:Function OR n:Class OR n:Variable)\n          AND n.line_number IS NOT NULL\n          AND n.line_number <= $end_line\n          AND coalesce(n.end_line, n.line_number) >= $start_line\n        RETURN\n            CASE\n                WHEN n:Function THEN 'function'\n                WHEN n:Class THEN 'class'\n                ELSE 'variable'\n            END as type,\n            n.name as name,\n            n.line_number as start_line,\n            coalesce(n.end_line, n.line_number) as end_line,\n            n.source as source,\n            n.docstring as docstring,\n            f.relative_path as file_path\n        ORDER BY n.line_number\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\n            \"repo_id\": repo_id,\n            \"relative_path\": relative_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n        })\n        return [dict(r) for r in records]\n\n    def get_diff_context(self, repo_id: str, changes: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Build full RAG context for a set of file changes (diff).\n\n        Args:\n            repo_id: Repository ID (e.g. \"owner/repo\")\n            changes: List of {\"file_path\": \"relative/path.py\", \"start_line\": 10, \"end_line\": 30}\n\n        Returns:\n            Dict with affected_symbols, callers, hierarchy, and file_sources.\n        \"\"\"\n        all_affected = []\n        all_callers = []\n        all_hierarchy = []\n        file_sources = {}\n\n        for change in changes:\n            file_path = change[\"file_path\"]\n            start_line = change.get(\"start_line\", 1)\n            end_line = change.get(\"end_line\", 999999)\n\n            # 1. Find affected symbols\n            symbols = self.get_symbols_at_lines_by_relative_path(\n                repo_id, file_path, start_line, end_line\n            )\n            for s in symbols:\n                s[\"change_file\"] = file_path\n            all_affected.extend(symbols)\n\n            # 2. For each affected symbol, find callers\n            for sym in symbols:\n                caller_query = \"\"\"\n                MATCH (caller)-[:CALLS]->(target)\n                WHERE target.name = $name AND target.path CONTAINS $repo_id\n                RETURN\n                    CASE\n                        WHEN caller:Function THEN 'function'\n                        WHEN caller:Class THEN 'class'\n                        ELSE 'other'\n                    END as type,\n                    caller.name as name,\n                    caller.path as path,\n                    caller.line_number as line_number,\n                    caller.source as source\n                LIMIT 20\n                \"\"\"\n                records, _, _ = self.db.run_query(caller_query, {\n                    \"name\": sym[\"name\"],\n                    \"repo_id\": repo_id,\n                })\n                callers = [dict(r) for r in records]\n                if callers:\n                    all_callers.append({\n                        \"symbol\": sym[\"name\"],\n                        \"symbol_type\": sym[\"type\"],\n                        \"callers\": callers,\n                    })\n\n            # 3. For affected classes, get hierarchy\n            class_symbols = [s for s in symbols if s[\"type\"] == \"class\"]\n            for cls in class_symbols:\n                hier_query = \"\"\"\n                MATCH (c:Class {name: $name})-[:INHERITS*0..5]->(parent:Class)\n                WHERE c.path CONTAINS $repo_id\n                RETURN parent.name as name, parent.path as path,\n                       parent.source as source, parent.docstring as docstring\n                \"\"\"\n                records, _, _ = self.db.run_query(hier_query, {\n                    \"name\": cls[\"name\"],\n                    \"repo_id\": repo_id,\n                })\n                if records:\n                    all_hierarchy.append({\n                        \"class\": cls[\"name\"],\n                        \"hierarchy\": [dict(r) for r in records],\n                    })\n\n            # 4. Get file source\n            file_src_query = \"\"\"\n            MATCH (f:File)\n            WHERE f.relative_path = $relative_path AND f.path CONTAINS $repo_id\n            RETURN f.source_code as source_code, f.relative_path as path\n            LIMIT 1\n            \"\"\"\n            records, _, _ = self.db.run_query(file_src_query, {\n                \"relative_path\": file_path,\n                \"repo_id\": repo_id,\n            })\n            if records and records[0].get(\"source_code\"):\n                file_sources[file_path] = records[0][\"source_code\"]\n\n        return {\n            \"affected_symbols\": all_affected,\n            \"callers\": all_callers,\n            \"class_hierarchy\": all_hierarchy,\n            \"file_sources\": file_sources,\n            \"total_affected\": len(all_affected),\n            \"total_files\": len(changes),\n        }\n\n    def get_diff_context_condensed(\n        self, repo_id: str, changes: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Build lean context for a set of file changes — optimized for LLM prompts.\n\n        Compared to get_diff_context:\n        - Only returns functions/classes/methods (skips variables)\n        - Returns symbol source snippets (the changed code chunk, not the whole file)\n        - Returns caller names + file paths only (no caller source code)\n        - Returns hierarchy as name chains only (no parent source)\n        - No full file sources at all\n\n        Args:\n            repo_id: Repository ID (e.g. \"owner/repo\")\n            changes: List of {\"file_path\": \"relative/path.py\", \"start_line\": 10, \"end_line\": 30}\n\n        Returns:\n            Dict with affected_symbols, callers, hierarchy.\n        \"\"\"\n        all_affected: List[Dict[str, Any]] = []\n        all_callers: List[Dict[str, Any]] = []\n        all_hierarchy: List[Dict[str, Any]] = []\n        seen_symbols: set = set()\n\n        for change in changes:\n            file_path = change[\"file_path\"]\n            start_line = change.get(\"start_line\", 1)\n            end_line = change.get(\"end_line\", 999999)\n\n            # 1. Find affected symbols — functions and classes only\n            query = \"\"\"\n            MATCH (f:File)\n            WHERE f.relative_path = $relative_path\n              AND f.path CONTAINS $repo_id\n            WITH f\n            MATCH (f)-[:CONTAINS]->(n)\n            WHERE (n:Function OR n:Class OR n:Method)\n              AND n.line_number IS NOT NULL\n              AND n.line_number <= $end_line\n              AND coalesce(n.end_line, n.line_number) >= $start_line\n            RETURN\n                CASE\n                    WHEN n:Function THEN 'function'\n                    WHEN n:Method THEN 'method'\n                    WHEN n:Class THEN 'class'\n                END as type,\n                n.name as name,\n                n.line_number as start_line,\n                coalesce(n.end_line, n.line_number) as end_line,\n                n.source as source,\n                n.docstring as docstring,\n                f.relative_path as file_path\n            ORDER BY n.line_number\n            \"\"\"\n            records, _, _ = self.db.run_query(query, {\n                \"repo_id\": repo_id,\n                \"relative_path\": file_path,\n                \"start_line\": start_line,\n                \"end_line\": end_line,\n            })\n\n            symbols = [dict(r) for r in records]\n            for s in symbols:\n                s[\"change_file\"] = file_path\n                # Truncate source to keep prompts lean\n                if s.get(\"source\") and len(s[\"source\"]) > 500:\n                    s[\"source\"] = s[\"source\"][:500] + \"\\n... (truncated)\"\n            all_affected.extend(symbols)\n\n            # 2. For each symbol, find caller names only (no source)\n            for sym in symbols:\n                sym_key = f\"{file_path}:{sym['name']}\"\n                if sym_key in seen_symbols:\n                    continue\n                seen_symbols.add(sym_key)\n\n                caller_query = \"\"\"\n                MATCH (caller)-[:CALLS]->(target)\n                WHERE target.name = $name AND target.path CONTAINS $repo_id\n                RETURN DISTINCT\n                    caller.name as name,\n                    CASE\n                        WHEN caller:Function THEN 'function'\n                        WHEN caller:Method THEN 'method'\n                        WHEN caller:Class THEN 'class'\n                        ELSE 'other'\n                    END as type,\n                    caller.path as path\n                LIMIT 10\n                \"\"\"\n                records, _, _ = self.db.run_query(caller_query, {\n                    \"name\": sym[\"name\"],\n                    \"repo_id\": repo_id,\n                })\n                callers = [dict(r) for r in records]\n                if callers:\n                    all_callers.append({\n                        \"symbol\": sym[\"name\"],\n                        \"symbol_type\": sym[\"type\"],\n                        \"callers\": callers,\n                    })\n\n            # 3. For affected classes, get hierarchy names only\n            class_symbols = [s for s in symbols if s[\"type\"] == \"class\"]\n            for cls in class_symbols:\n                hier_query = \"\"\"\n                MATCH (c:Class {name: $name})-[:INHERITS*0..3]->(parent:Class)\n                WHERE c.path CONTAINS $repo_id\n                RETURN parent.name as name, parent.path as path\n                \"\"\"\n                records, _, _ = self.db.run_query(hier_query, {\n                    \"name\": cls[\"name\"],\n                    \"repo_id\": repo_id,\n                })\n                if records:\n                    all_hierarchy.append({\n                        \"class\": cls[\"name\"],\n                        \"hierarchy\": [{\"name\": r[\"name\"], \"path\": r[\"path\"]} for r in records],\n                    })\n\n        return {\n            \"affected_symbols\": all_affected,\n            \"callers\": all_callers,\n            \"class_hierarchy\": all_hierarchy,\n            \"total_affected\": len(all_affected),\n            \"total_files\": len(set(c[\"file_path\"] for c in changes)),\n        }\n\n    def get_diff_context_enhanced(\n        self, repo_id: str, changes: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Build full relationship context for every changed Function, Method, and Class.\n\n        For each symbol in the diff line ranges:\n          - Full source code of the symbol itself\n          - Methods belonging to each changed Class (with source)\n          - Callers: every Function/Method that calls this symbol via CALLS edges\n          - Dependencies: every Function/Method this symbol calls via CALLS edges\n          - Imports: other in-repo symbols imported by the changed file\n          - Class hierarchy: parent/child classes for any changed Class\n\n        Both Function and Method node types are handled throughout — the graph\n        stores class methods as Function nodes under the class via CONTAINS.\n        \"\"\"\n        from api.services.code_search import CodeFinder\n\n        code_finder = CodeFinder(self.db)\n\n        all_affected: List[Dict[str, Any]] = []\n        all_callers: List[Dict[str, Any]] = []\n        all_imports: List[Dict[str, Any]] = []\n        all_dependencies: List[Dict[str, Any]] = []\n        all_hierarchy: List[Dict[str, Any]] = []\n        seen_affected: set = set()\n        seen_callers: set = set()\n        seen_imports: set = set()\n\n        for change in changes:\n            file_path = change[\"file_path\"]\n            start_line = change.get(\"start_line\", 1)\n            end_line = change.get(\"end_line\", 999999)\n\n            # ── 1. Affected symbols (Function, Class, and Method) ─────────────\n            # Method nodes are stored under Class via CONTAINS — we surface them\n            # here so the agent sees both the class body and individual methods.\n            affected_query = \"\"\"\n            MATCH (f:File {repo: $repo_id, path: $file_path})\n            MATCH (f)-[:CONTAINS]->(n)\n            WHERE (n:Function OR n:Class OR n:Method)\n              AND n.line_number IS NOT NULL\n              AND n.line_number <= $end_line\n              AND coalesce(n.end_line, n.line_number) >= $start_line\n            RETURN\n                CASE\n                    WHEN n:Class    THEN 'class'\n                    WHEN n:Method   THEN 'method'\n                    ELSE                 'function'\n                END AS type,\n                n.name          AS name,\n                n.line_number   AS start_line,\n                coalesce(n.end_line, n.line_number) AS end_line,\n                n.source        AS source,\n                n.docstring     AS docstring,\n                n.args          AS args,\n                f.path          AS file_path\n            ORDER BY n.line_number\n            \"\"\"\n            records, _, _ = self.db.run_query(affected_query, {\n                \"repo_id\": repo_id,\n                \"file_path\": file_path,\n                \"start_line\": start_line,\n                \"end_line\": end_line,\n            })\n            symbols = [dict(r) for r in records]\n\n            for s in symbols:\n                s[\"change_file\"] = file_path\n                sym_key = f\"{s['file_path']}:{s['name']}:{s['start_line']}\"\n                if sym_key not in seen_affected:\n                    seen_affected.add(sym_key)\n                    all_affected.append(s)\n\n            for sym in symbols:\n                caller_key = f\"{sym['file_path']}:{sym['name']}\"\n                if caller_key in seen_callers:\n                    continue\n                seen_callers.add(caller_key)\n\n                # ── 2. Callers: who calls this symbol? ────────────────────────\n                # Match both Function and Method callers so class methods that\n                # call the changed code are not missed.\n                try:\n                    caller_query = \"\"\"\n                    MATCH (target)\n                    WHERE (target:Function OR target:Method OR target:Class)\n                      AND target.name = $name\n                      AND coalesce(target.path, '') CONTAINS $repo_id\n                    WITH target\n                    MATCH (caller)-[call:CALLS]->(target)\n                    WHERE (caller:Function OR caller:Method)\n                      AND NOT coalesce(caller.is_dependency, false)\n                    OPTIONAL MATCH (caller_file:File)-[:CONTAINS]->(caller)\n                    RETURN DISTINCT\n                        caller.name             AS caller_name,\n                        CASE WHEN caller:Method THEN 'method' ELSE 'function' END AS caller_type,\n                        coalesce(caller.path, caller_file.path) AS caller_path,\n                        caller.line_number      AS caller_line,\n                        call.line_number        AS call_line,\n                        call.args               AS call_args\n                    ORDER BY caller_path, caller.line_number\n                    LIMIT 10\n                    \"\"\"\n                    caller_records, _, _ = self.db.run_query(\n                        caller_query, {\"name\": sym[\"name\"], \"repo_id\": repo_id}\n                    )\n                    callers_list = [dict(r) for r in caller_records]\n                    if callers_list:\n                        all_callers.append({\n                            \"symbol\": sym[\"name\"],\n                            \"symbol_type\": sym[\"type\"],\n                            \"callers\": callers_list,\n                        })\n                except Exception as e:\n                    logger.warning(f\"Error finding callers for {sym['name']}: {e}\")\n\n                # ── 3. Dependencies: what does this symbol call? ──────────────\n                # Match both Function and Method targets to catch calls to methods.\n                try:\n                    dep_query = \"\"\"\n                    MATCH (caller)\n                    WHERE (caller:Function OR caller:Method)\n                      AND caller.name = $name\n                      AND caller.path = $path\n                    MATCH (caller)-[call:CALLS]->(called)\n                    WHERE (called:Function OR called:Method)\n                      AND NOT coalesce(called.is_dependency, false)\n                    RETURN DISTINCT\n                        called.name  AS called_name,\n                        CASE WHEN called:Method THEN 'method' ELSE 'function' END AS called_type,\n                        called.path  AS called_path,\n                        call.line_number AS call_line,\n                        call.args    AS call_args\n                    ORDER BY call.line_number\n                    LIMIT 15\n                    \"\"\"\n                    dep_records, _, _ = self.db.run_query(dep_query, {\n                        \"name\": sym[\"name\"],\n                        \"path\": sym[\"file_path\"],\n                    })\n                    deps_list = [dict(r) for r in dep_records]\n                    if deps_list:\n                        all_dependencies.append({\n                            \"symbol\": sym[\"name\"],\n                            \"dependencies\": deps_list,\n                        })\n                except Exception as e:\n                    logger.warning(f\"Error finding dependencies for {sym['name']}: {e}\")\n\n                # ── 4. Class methods: when a Class is affected, fetch all ──────\n                # its methods with full source so the agent sees what each\n                # method does — not just the class skeleton.\n                if sym[\"type\"] == \"class\":\n                    try:\n                        methods_query = \"\"\"\n                        MATCH (cls:Class {name: $class_name, path: $path})\n                        MATCH (cls)-[:CONTAINS]->(m:Function)\n                        RETURN\n                            m.name          AS name,\n                            m.line_number   AS line_number,\n                            coalesce(m.end_line, m.line_number) AS end_line,\n                            m.source        AS source,\n                            m.docstring     AS docstring,\n                            m.args          AS args\n                        ORDER BY m.line_number\n                        \"\"\"\n                        method_records, _, _ = self.db.run_query(methods_query, {\n                            \"class_name\": sym[\"name\"],\n                            \"path\": sym[\"file_path\"],\n                        })\n                        methods_list = [dict(r) for r in method_records]\n                        if methods_list:\n                            sym[\"methods\"] = methods_list\n                    except Exception as e:\n                        logger.warning(f\"Error fetching methods for class {sym['name']}: {e}\")\n\n            # ── 5. Imports: resolve imported names to in-repo source ──────────\n            import_query = \"\"\"\n            MATCH (f:File {repo: $repo_id, path: $file_path})\n            MATCH (f)-[r:IMPORTS]->(m)\n            RETURN\n                r.alias          AS alias,\n                r.imported_name  AS imported_name,\n                m.name           AS module_name,\n                r.line_number    AS line_number\n            ORDER BY r.line_number\n            LIMIT 20\n            \"\"\"\n            import_records, _, _ = self.db.run_query(import_query, {\n                \"repo_id\": repo_id,\n                \"file_path\": file_path,\n            })\n\n            for imp in import_records:\n                imported_name = imp.get(\"imported_name\") or imp.get(\"alias\")\n                if not imported_name or imported_name in seen_imports:\n                    continue\n                seen_imports.add(imported_name)\n\n                try:\n                    func_results = code_finder.find_by_function_name(imported_name, fuzzy_search=False)\n                    if func_results:\n                        for func in func_results[:1]:\n                            if func.get(\"path\") and repo_id in func.get(\"path\", \"\"):\n                                all_imports.append({\n                                    \"name\": imported_name,\n                                    \"type\": \"function\",\n                                    \"source\": func.get(\"source\", \"\"),\n                                    \"path\": func.get(\"path\"),\n                                    \"line\": func.get(\"line_number\"),\n                                    \"docstring\": func.get(\"docstring\"),\n                                    \"from_file\": file_path,\n                                })\n                    else:\n                        class_results = code_finder.find_by_class_name(imported_name, fuzzy_search=False)\n                        if class_results:\n                            for cls in class_results[:1]:\n                                if cls.get(\"path\") and repo_id in cls.get(\"path\", \"\"):\n                                    all_imports.append({\n                                        \"name\": imported_name,\n                                        \"type\": \"class\",\n                                        \"source\": cls.get(\"source\", \"\"),\n                                        \"path\": cls.get(\"path\"),\n                                        \"line\": cls.get(\"line_number\"),\n                                        \"docstring\": cls.get(\"docstring\"),\n                                        \"from_file\": file_path,\n                                    })\n                except Exception as e:\n                    logger.warning(f\"Error resolving import {imported_name}: {e}\")\n\n            # ── 6. Class hierarchy for affected classes ───────────────────────\n            for cls in [s for s in symbols if s[\"type\"] == \"class\"]:\n                try:\n                    hierarchy_info = code_finder.find_class_hierarchy(\n                        cls[\"name\"], cls.get(\"file_path\")\n                    )\n                    if hierarchy_info:\n                        all_hierarchy.append({\n                            \"class\": cls[\"name\"],\n                            \"parents\": hierarchy_info.get(\"parent_classes\", []),\n                            \"children\": hierarchy_info.get(\"child_classes\", []),\n                            \"methods\": hierarchy_info.get(\"methods\", []),\n                        })\n                except Exception as e:\n                    logger.warning(f\"Error finding hierarchy for {cls['name']}: {e}\")\n\n        return {\n            \"affected_symbols\": all_affected,\n            \"callers\": all_callers,\n            \"imports\": all_imports,\n            \"dependencies\": all_dependencies,\n            \"class_hierarchy\": all_hierarchy,\n            \"total_affected\": len(all_affected),\n            \"total_imports\": len(all_imports),\n            \"total_files\": len(set(c[\"file_path\"] for c in changes)),\n        }","structuredPatch":[{"oldStart":275,"oldLines":38,"newStart":275,"newLines":112,"lines":["     # Search Operations","     # =========================================================================","     ","+    # Python/JS keywords that should not be used as search identifiers","+    _CODE_KEYWORDS = frozenset({","+        'class', 'def', 'import', 'from', 'return', 'self', 'cls', 'None',","+        'True', 'False', 'and', 'or', 'not', 'in', 'is', 'if', 'else',","+        'elif', 'for', 'while', 'try', 'except', 'with', 'as', 'pass',","+        'break', 'continue', 'raise', 'yield', 'async', 'await', 'lambda',","+        'function', 'const', 'let', 'var', 'new', 'this', 'super',","+    })","+","+    def _extract_identifiers(self, query: str) -> List[str]:","+        \"\"\"Extract meaningful code identifiers from a raw query string.\"\"\"","+        tokens = re.findall(r'\\b[A-Za-z_][A-Za-z0-9_]{2,}\\b', query)","+        seen: set = set()","+        result = []","+        for t in tokens:","+            if t not in self._CODE_KEYWORDS and t not in seen:","+                seen.add(t)","+                result.append(t)","+        return result","+","     def _escape_lucene_query(self, query: str) -> str:","         \"\"\"","-        Escape Lucene special characters in search query.","+        Build a safe Lucene query string."," ","-        Strategy: Wrap the entire query in quotes to treat it as a literal phrase search.","-        This prevents Lucene from interpreting special characters.","-","-        For complex queries, users can use wildcards: *","+        Strategy:","+        - Simple identifier (word chars only) → phrase search  e.g. \"LoginRequest\"","+        - Complex query with special chars     → AND-keyword strategy","+          e.g. \"class GitHubRepo(BaseModel)\" → \"GitHubRepo\" AND \"BaseModel\"","+          This avoids Lucene parse errors while still matching meaningful tokens.","         \"\"\"","         query = query.strip()","-","-        # If query is empty, return a wildcard","         if not query:","             return '*'"," ","-        # If the query already has quotes, escape internal quotes","-        if '\"' in query:","-            # Escape any existing quotes and wrap in quotes","-            query = query.replace('\"', '\\\\\"')","+        # Simple identifier — use phrase search directly","+        if re.match(r'^[A-Za-z0-9_]+$', query):","+            return f'\"{query}\"'"," ","-        # Wrap in quotes to make it a literal phrase search","-        # This treats special characters as literals","-        return f'\"{query}\"'","+        # Complex query — extract identifiers and build AND search","+        identifiers = self._extract_identifiers(query)","+        if identifiers:","+            # Cap at 3 identifiers to keep the query lean","+            return ' AND '.join(f'\"{t}\"' for t in identifiers[:3])"," ","+        # Pure symbols / numbers with no useful identifiers — wrap and hope for best","+        escaped = query.replace('\"', '\\\\\"')","+        return f'\"{escaped}\"'","+","+    def _name_contains_fallback(","+        self,","+        search_term: str,","+        limit: int = 20,","+    ) -> List[Dict[str, Any]]:","+        \"\"\"","+        CONTAINS fallback against node names.","+        Uses the primary identifier extracted from the search term so that","+        queries like 'class GitHubRepo(BaseModel)' still find 'GitHubRepo'.","+        \"\"\"","+        identifiers = self._extract_identifiers(search_term)","+        # Use the first (longest) identifier, falling back to raw term","+        name_term = max(identifiers, key=len) if identifiers else search_term","+","+        fallback = \"\"\"","+        MATCH (node)","+        WHERE (node:Function OR node:Class OR node:Variable)","+          AND node.name CONTAINS $name_term","+        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)","+        RETURN","+            CASE WHEN node:Function THEN 'function'","+                 WHEN node:Class THEN 'class'","+                 ELSE 'variable' END as type,","+            node.name as name,","+            coalesce(f.path, node.path) as path,","+            coalesce(node.line_number, 0) as line_number,","+            1.0 as score","+        ORDER BY node.name","+        LIMIT $limit","+        \"\"\"","+        records, _, _ = self.db.run_query(fallback, {\"name_term\": name_term, \"limit\": limit})","+        return [","+            {","+                \"type\": record[\"type\"],","+                \"name\": record[\"name\"],","+                \"path\": record[\"path\"],","+                \"line_number\": record[\"line_number\"],","+                \"score\": record[\"score\"],","+            }","+            for record in records","+        ]","+","     def search_code(self, search_term: str) -> List[Dict[str, Any]]:","-        \"\"\"Search for code by name or docstring using fulltext index with CONTAINS fallback.\"\"\"","+        \"\"\"","+        Search for code using a three-tier strategy:","+        1. code_search fulltext index (symbols: name, docstring, source_code)","+        2. Name CONTAINS fallback (uses primary extracted identifier)","+        3. File content line search (file_content_search / source_code CONTAINS)","+        Returns lean results: type, name, path, line_number, score.","+        \"\"\"","         escaped_term = self._escape_lucene_query(search_term)"," ","+        # Tier 1 — fulltext symbol search","         results: List[Dict[str, Any]] = []","         try:","-            query = CYPHER_QUERIES[\"search_code\"]","-            records, _, _ = self.db.run_query(query, {\"search_term\": escaped_term})","+            records, _, _ = self.db.run_query(","+                CYPHER_QUERIES[\"search_code\"], {\"search_term\": escaped_term}","+            )","             results = [","                 {","                     \"type\": record[\"type\"],"]},{"oldStart":318,"oldLines":34,"newStart":392,"newLines":24,"lines":["                 for record in records","             ]","         except Exception as e:","-            logger.warning(\"Fulltext search failed, falling back to CONTAINS: %s\", e)","+            logger.warning(\"code_search fulltext failed: %s\", e)"," ","+        # Tier 2 — name CONTAINS (works even when fulltext index misses)","         if not results:","-            fallback = \"\"\"","-            MATCH (node)","-            WHERE (node:Function OR node:Class OR node:Variable)","-              AND node.name CONTAINS $search_term","-            OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)","-            RETURN","-                CASE WHEN node:Function THEN 'function'","-                     WHEN node:Class THEN 'class'","-                     ELSE 'variable' END as type,","-                node.name as name,","-                coalesce(f.path, node.path) as path,","-                coalesce(node.line_number, 0) as line_number,","-                1.0 as score","-            LIMIT 20","-            \"\"\"","-            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})","+            results = self._name_contains_fallback(search_term, limit=20)","+","+        # Tier 3 — file content line search (raw code snippets, declarations, etc.)","+        if not results:","+            file_hits = self.search_file_content(search_term, limit=20)","             results = [","                 {","-                    \"type\": record[\"type\"],","-                    \"name\": record[\"name\"],","-                    \"path\": record[\"path\"],","-                    \"line_number\": record[\"line_number\"],","-                    \"score\": record[\"score\"],","+                    \"type\": \"line\",","+                    \"name\": h[\"match_line\"].strip(),","+                    \"path\": h[\"path\"],","+                    \"line_number\": h[\"line_number\"],","+                    \"score\": 0.5,","                 }","-                for record in records","+                for h in file_hits","             ]"," ","         return results"]},{"oldStart":355,"oldLines":16,"newStart":419,"newLines":18,"lines":["         search_term: str,","         limit: int = 20","     ) -> List[Dict[str, Any]]:","-        \"\"\"Search symbols (Function/Class/Variable) using fulltext index with CONTAINS fallback.\"\"\"","+        \"\"\"","+        Search symbols (Function/Class/Variable) using fulltext index.","+        Falls back to name CONTAINS using the primary extracted identifier.","+        \"\"\"","         escaped_term = self._escape_lucene_query(search_term)"," ","         results: List[Dict[str, Any]] = []","         try:","-            query = CYPHER_QUERIES[\"search_symbols\"]","-            records, _, _ = self.db.run_query(query, {","-                \"search_term\": escaped_term,","-                \"limit\": limit,","-            })","+            records, _, _ = self.db.run_query(","+                CYPHER_QUERIES[\"search_symbols\"],","+                {\"search_term\": escaped_term, \"limit\": limit},","+            )","             results = [","                 {","                     \"name\": record[\"name\"],"]},{"oldStart":376,"oldLines":35,"newStart":442,"newLines":20,"lines":["                 for record in records","             ]","         except Exception as e:","-            logger.warning(\"Symbol fulltext search failed, falling back to CONTAINS: %s\", e)","+            logger.warning(\"symbol fulltext search failed: %s\", e)"," ","         if not results:","-            fallback = \"\"\"","-            MATCH (node)","-            WHERE (node:Function OR node:Class OR node:Variable)","-              AND node.name CONTAINS $search_term","-            OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)","-            RETURN","-                node.name as name,","-                CASE WHEN node:Function THEN 'function'","-                     WHEN node:Class THEN 'class'","-                     ELSE 'variable' END as type,","-                coalesce(f.path, node.path) as path,","-                coalesce(node.line_number, 0) as line_number,","-                1.0 as score","-            ORDER BY node.name","-            LIMIT $limit","-            \"\"\"","-            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term, \"limit\": limit})","+            raw = self._name_contains_fallback(search_term, limit=limit)","+            # _name_contains_fallback returns same shape, just reorder keys","             results = [","                 {","-                    \"name\": record[\"name\"],","-                    \"type\": record[\"type\"],","-                    \"path\": record[\"path\"],","-                    \"line_number\": record[\"line_number\"],","-                    \"score\": record[\"score\"],","+                    \"name\": r[\"name\"],","+                    \"type\": r[\"type\"],","+                    \"path\": r[\"path\"],","+                    \"line_number\": r[\"line_number\"],","+                    \"score\": r[\"score\"],","                 }","-                for record in records","+                for r in raw","             ]"," ","         return results"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"762cc62e-56e1-4af5-9370-f8f7edd96c65"}
{"parentUuid":"deaba551-b2f5-4f9a-b6a7-4dab00f30335","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01MJbXNycc4XPd4WbfKZVQWn","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me verify the logic looks correct end-to-end:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3316,"cache_read_input_tokens":109519,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3316},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLunBkcr4KCmWpwEbfzM","type":"assistant","uuid":"54f40299-554a-4dac-a46d-662819bd1ea8","timestamp":"2026-02-21T08:37:38.463Z"}
{"parentUuid":"54f40299-554a-4dac-a46d-662819bd1ea8","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01MJbXNycc4XPd4WbfKZVQWn","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01BZ6Pq5QqobXqEQduozog1J","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/db/queries.py","offset":278,"limit":170},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3316,"cache_read_input_tokens":109519,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3316},"output_tokens":3,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLunBkcr4KCmWpwEbfzM","type":"assistant","uuid":"e8e2d4fd-b4b5-4b66-a5e9-4e21343285ae","timestamp":"2026-02-21T08:37:39.153Z"}
{"parentUuid":"e8e2d4fd-b4b5-4b66-a5e9-4e21343285ae","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01BZ6Pq5QqobXqEQduozog1J","toolUseID":"toolu_01BZ6Pq5QqobXqEQduozog1J","timestamp":"2026-02-21T08:37:39.244Z","uuid":"fa9e3543-b1a9-4571-88d0-b952d0705496"}
{"parentUuid":"e8e2d4fd-b4b5-4b66-a5e9-4e21343285ae","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01BZ6Pq5QqobXqEQduozog1J","type":"tool_result","content":"   278→    # Python/JS keywords that should not be used as search identifiers\n   279→    _CODE_KEYWORDS = frozenset({\n   280→        'class', 'def', 'import', 'from', 'return', 'self', 'cls', 'None',\n   281→        'True', 'False', 'and', 'or', 'not', 'in', 'is', 'if', 'else',\n   282→        'elif', 'for', 'while', 'try', 'except', 'with', 'as', 'pass',\n   283→        'break', 'continue', 'raise', 'yield', 'async', 'await', 'lambda',\n   284→        'function', 'const', 'let', 'var', 'new', 'this', 'super',\n   285→    })\n   286→\n   287→    def _extract_identifiers(self, query: str) -> List[str]:\n   288→        \"\"\"Extract meaningful code identifiers from a raw query string.\"\"\"\n   289→        tokens = re.findall(r'\\b[A-Za-z_][A-Za-z0-9_]{2,}\\b', query)\n   290→        seen: set = set()\n   291→        result = []\n   292→        for t in tokens:\n   293→            if t not in self._CODE_KEYWORDS and t not in seen:\n   294→                seen.add(t)\n   295→                result.append(t)\n   296→        return result\n   297→\n   298→    def _escape_lucene_query(self, query: str) -> str:\n   299→        \"\"\"\n   300→        Build a safe Lucene query string.\n   301→\n   302→        Strategy:\n   303→        - Simple identifier (word chars only) → phrase search  e.g. \"LoginRequest\"\n   304→        - Complex query with special chars     → AND-keyword strategy\n   305→          e.g. \"class GitHubRepo(BaseModel)\" → \"GitHubRepo\" AND \"BaseModel\"\n   306→          This avoids Lucene parse errors while still matching meaningful tokens.\n   307→        \"\"\"\n   308→        query = query.strip()\n   309→        if not query:\n   310→            return '*'\n   311→\n   312→        # Simple identifier — use phrase search directly\n   313→        if re.match(r'^[A-Za-z0-9_]+$', query):\n   314→            return f'\"{query}\"'\n   315→\n   316→        # Complex query — extract identifiers and build AND search\n   317→        identifiers = self._extract_identifiers(query)\n   318→        if identifiers:\n   319→            # Cap at 3 identifiers to keep the query lean\n   320→            return ' AND '.join(f'\"{t}\"' for t in identifiers[:3])\n   321→\n   322→        # Pure symbols / numbers with no useful identifiers — wrap and hope for best\n   323→        escaped = query.replace('\"', '\\\\\"')\n   324→        return f'\"{escaped}\"'\n   325→\n   326→    def _name_contains_fallback(\n   327→        self,\n   328→        search_term: str,\n   329→        limit: int = 20,\n   330→    ) -> List[Dict[str, Any]]:\n   331→        \"\"\"\n   332→        CONTAINS fallback against node names.\n   333→        Uses the primary identifier extracted from the search term so that\n   334→        queries like 'class GitHubRepo(BaseModel)' still find 'GitHubRepo'.\n   335→        \"\"\"\n   336→        identifiers = self._extract_identifiers(search_term)\n   337→        # Use the first (longest) identifier, falling back to raw term\n   338→        name_term = max(identifiers, key=len) if identifiers else search_term\n   339→\n   340→        fallback = \"\"\"\n   341→        MATCH (node)\n   342→        WHERE (node:Function OR node:Class OR node:Variable)\n   343→          AND node.name CONTAINS $name_term\n   344→        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n   345→        RETURN\n   346→            CASE WHEN node:Function THEN 'function'\n   347→                 WHEN node:Class THEN 'class'\n   348→                 ELSE 'variable' END as type,\n   349→            node.name as name,\n   350→            coalesce(f.path, node.path) as path,\n   351→            coalesce(node.line_number, 0) as line_number,\n   352→            1.0 as score\n   353→        ORDER BY node.name\n   354→        LIMIT $limit\n   355→        \"\"\"\n   356→        records, _, _ = self.db.run_query(fallback, {\"name_term\": name_term, \"limit\": limit})\n   357→        return [\n   358→            {\n   359→                \"type\": record[\"type\"],\n   360→                \"name\": record[\"name\"],\n   361→                \"path\": record[\"path\"],\n   362→                \"line_number\": record[\"line_number\"],\n   363→                \"score\": record[\"score\"],\n   364→            }\n   365→            for record in records\n   366→        ]\n   367→\n   368→    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n   369→        \"\"\"\n   370→        Search for code using a three-tier strategy:\n   371→        1. code_search fulltext index (symbols: name, docstring, source_code)\n   372→        2. Name CONTAINS fallback (uses primary extracted identifier)\n   373→        3. File content line search (file_content_search / source_code CONTAINS)\n   374→        Returns lean results: type, name, path, line_number, score.\n   375→        \"\"\"\n   376→        escaped_term = self._escape_lucene_query(search_term)\n   377→\n   378→        # Tier 1 — fulltext symbol search\n   379→        results: List[Dict[str, Any]] = []\n   380→        try:\n   381→            records, _, _ = self.db.run_query(\n   382→                CYPHER_QUERIES[\"search_code\"], {\"search_term\": escaped_term}\n   383→            )\n   384→            results = [\n   385→                {\n   386→                    \"type\": record[\"type\"],\n   387→                    \"name\": record[\"name\"],\n   388→                    \"path\": record[\"path\"],\n   389→                    \"line_number\": record[\"line_number\"],\n   390→                    \"score\": record[\"score\"],\n   391→                }\n   392→                for record in records\n   393→            ]\n   394→        except Exception as e:\n   395→            logger.warning(\"code_search fulltext failed: %s\", e)\n   396→\n   397→        # Tier 2 — name CONTAINS (works even when fulltext index misses)\n   398→        if not results:\n   399→            results = self._name_contains_fallback(search_term, limit=20)\n   400→\n   401→        # Tier 3 — file content line search (raw code snippets, declarations, etc.)\n   402→        if not results:\n   403→            file_hits = self.search_file_content(search_term, limit=20)\n   404→            results = [\n   405→                {\n   406→                    \"type\": \"line\",\n   407→                    \"name\": h[\"match_line\"].strip(),\n   408→                    \"path\": h[\"path\"],\n   409→                    \"line_number\": h[\"line_number\"],\n   410→                    \"score\": 0.5,\n   411→                }\n   412→                for h in file_hits\n   413→            ]\n   414→\n   415→        return results\n   416→\n   417→    def search_symbols(\n   418→        self,\n   419→        search_term: str,\n   420→        limit: int = 20\n   421→    ) -> List[Dict[str, Any]]:\n   422→        \"\"\"\n   423→        Search symbols (Function/Class/Variable) using fulltext index.\n   424→        Falls back to name CONTAINS using the primary extracted identifier.\n   425→        \"\"\"\n   426→        escaped_term = self._escape_lucene_query(search_term)\n   427→\n   428→        results: List[Dict[str, Any]] = []\n   429→        try:\n   430→            records, _, _ = self.db.run_query(\n   431→                CYPHER_QUERIES[\"search_symbols\"],\n   432→                {\"search_term\": escaped_term, \"limit\": limit},\n   433→            )\n   434→            results = [\n   435→                {\n   436→                    \"name\": record[\"name\"],\n   437→                    \"type\": record[\"type\"],\n   438→                    \"path\": record[\"path\"],\n   439→                    \"line_number\": record[\"line_number\"],\n   440→                    \"score\": record[\"score\"],\n   441→                }\n   442→                for record in records\n   443→            ]\n   444→        except Exception as e:\n   445→            logger.warning(\"symbol fulltext search failed: %s\", e)\n   446→\n   447→        if not results:\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"762fb385-91a9-470c-aa3b-ad1514fbace7","timestamp":"2026-02-21T08:37:39.243Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/db/queries.py","content":"    # Python/JS keywords that should not be used as search identifiers\n    _CODE_KEYWORDS = frozenset({\n        'class', 'def', 'import', 'from', 'return', 'self', 'cls', 'None',\n        'True', 'False', 'and', 'or', 'not', 'in', 'is', 'if', 'else',\n        'elif', 'for', 'while', 'try', 'except', 'with', 'as', 'pass',\n        'break', 'continue', 'raise', 'yield', 'async', 'await', 'lambda',\n        'function', 'const', 'let', 'var', 'new', 'this', 'super',\n    })\n\n    def _extract_identifiers(self, query: str) -> List[str]:\n        \"\"\"Extract meaningful code identifiers from a raw query string.\"\"\"\n        tokens = re.findall(r'\\b[A-Za-z_][A-Za-z0-9_]{2,}\\b', query)\n        seen: set = set()\n        result = []\n        for t in tokens:\n            if t not in self._CODE_KEYWORDS and t not in seen:\n                seen.add(t)\n                result.append(t)\n        return result\n\n    def _escape_lucene_query(self, query: str) -> str:\n        \"\"\"\n        Build a safe Lucene query string.\n\n        Strategy:\n        - Simple identifier (word chars only) → phrase search  e.g. \"LoginRequest\"\n        - Complex query with special chars     → AND-keyword strategy\n          e.g. \"class GitHubRepo(BaseModel)\" → \"GitHubRepo\" AND \"BaseModel\"\n          This avoids Lucene parse errors while still matching meaningful tokens.\n        \"\"\"\n        query = query.strip()\n        if not query:\n            return '*'\n\n        # Simple identifier — use phrase search directly\n        if re.match(r'^[A-Za-z0-9_]+$', query):\n            return f'\"{query}\"'\n\n        # Complex query — extract identifiers and build AND search\n        identifiers = self._extract_identifiers(query)\n        if identifiers:\n            # Cap at 3 identifiers to keep the query lean\n            return ' AND '.join(f'\"{t}\"' for t in identifiers[:3])\n\n        # Pure symbols / numbers with no useful identifiers — wrap and hope for best\n        escaped = query.replace('\"', '\\\\\"')\n        return f'\"{escaped}\"'\n\n    def _name_contains_fallback(\n        self,\n        search_term: str,\n        limit: int = 20,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        CONTAINS fallback against node names.\n        Uses the primary identifier extracted from the search term so that\n        queries like 'class GitHubRepo(BaseModel)' still find 'GitHubRepo'.\n        \"\"\"\n        identifiers = self._extract_identifiers(search_term)\n        # Use the first (longest) identifier, falling back to raw term\n        name_term = max(identifiers, key=len) if identifiers else search_term\n\n        fallback = \"\"\"\n        MATCH (node)\n        WHERE (node:Function OR node:Class OR node:Variable)\n          AND node.name CONTAINS $name_term\n        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n        RETURN\n            CASE WHEN node:Function THEN 'function'\n                 WHEN node:Class THEN 'class'\n                 ELSE 'variable' END as type,\n            node.name as name,\n            coalesce(f.path, node.path) as path,\n            coalesce(node.line_number, 0) as line_number,\n            1.0 as score\n        ORDER BY node.name\n        LIMIT $limit\n        \"\"\"\n        records, _, _ = self.db.run_query(fallback, {\"name_term\": name_term, \"limit\": limit})\n        return [\n            {\n                \"type\": record[\"type\"],\n                \"name\": record[\"name\"],\n                \"path\": record[\"path\"],\n                \"line_number\": record[\"line_number\"],\n                \"score\": record[\"score\"],\n            }\n            for record in records\n        ]\n\n    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search for code using a three-tier strategy:\n        1. code_search fulltext index (symbols: name, docstring, source_code)\n        2. Name CONTAINS fallback (uses primary extracted identifier)\n        3. File content line search (file_content_search / source_code CONTAINS)\n        Returns lean results: type, name, path, line_number, score.\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        # Tier 1 — fulltext symbol search\n        results: List[Dict[str, Any]] = []\n        try:\n            records, _, _ = self.db.run_query(\n                CYPHER_QUERIES[\"search_code\"], {\"search_term\": escaped_term}\n            )\n            results = [\n                {\n                    \"type\": record[\"type\"],\n                    \"name\": record[\"name\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"code_search fulltext failed: %s\", e)\n\n        # Tier 2 — name CONTAINS (works even when fulltext index misses)\n        if not results:\n            results = self._name_contains_fallback(search_term, limit=20)\n\n        # Tier 3 — file content line search (raw code snippets, declarations, etc.)\n        if not results:\n            file_hits = self.search_file_content(search_term, limit=20)\n            results = [\n                {\n                    \"type\": \"line\",\n                    \"name\": h[\"match_line\"].strip(),\n                    \"path\": h[\"path\"],\n                    \"line_number\": h[\"line_number\"],\n                    \"score\": 0.5,\n                }\n                for h in file_hits\n            ]\n\n        return results\n\n    def search_symbols(\n        self,\n        search_term: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search symbols (Function/Class/Variable) using fulltext index.\n        Falls back to name CONTAINS using the primary extracted identifier.\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        results: List[Dict[str, Any]] = []\n        try:\n            records, _, _ = self.db.run_query(\n                CYPHER_QUERIES[\"search_symbols\"],\n                {\"search_term\": escaped_term, \"limit\": limit},\n            )\n            results = [\n                {\n                    \"name\": record[\"name\"],\n                    \"type\": record[\"type\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"symbol fulltext search failed: %s\", e)\n\n        if not results:","numLines":170,"startLine":278,"totalLines":1834}},"sourceToolAssistantUUID":"e8e2d4fd-b4b5-4b66-a5e9-4e21343285ae"}
{"parentUuid":"762fb385-91a9-470c-aa3b-ad1514fbace7","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_019WGGocv2o6bgNhGX2W7cMD","type":"message","role":"assistant","content":[{"type":"text","text":"Looks correct. Here's exactly what changed and why it now works:\n\n---\n\n## What was wrong and what's fixed\n\n### Root cause\n`_escape_lucene_query` always wrapped the full string in quotes: `\"class GitHubRepo(BaseModel)\"`. This is a Lucene **phrase search** — it tries to match that exact sequence of words in a single field. But:\n- `node.name` stores just `GitHubRepo`, not the full declaration\n- The CONTAINS fallback did `node.name CONTAINS \"class GitHubRepo(BaseModel)\"` — equally impossible to match\n- There was **no fallback to file content search** when both failed\n\n### What's fixed\n\n**`_escape_lucene_query`** now uses two strategies:\n- `GitHubRepo` (simple identifier) → `\"GitHubRepo\"` (phrase search, same as before)\n- `class GitHubRepo(BaseModel)` (has special chars) → `\"GitHubRepo\" AND \"BaseModel\"` (AND-keyword strategy — strips code keywords like `class`, extracts real identifiers)\n\n**`_name_contains_fallback`** now extracts the **longest identifier** from the query:\n- `class GitHubRepo(BaseModel)` → extracts `['GitHubRepo', 'BaseModel']` → uses `GitHubRepo` (longest) → `node.name CONTAINS \"GitHubRepo\"` ✓ (finds the class)\n\n**`search_code` is now 3-tier:**\n1. `code_search` fulltext index with AND-keyword Lucene query\n2. Name CONTAINS using the primary extracted identifier\n3. **File content line search** (`file_content_search` / `source_code CONTAINS`) — catches raw code snippets like `class GitHubRepo(BaseModel):` as a line match\n\nSo even if the class was never ingested into the graph as a `Class` node, Tier 3 will still find the line in the file's stored source code."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2535,"cache_read_input_tokens":112835,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2535},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLunPgxwmFkGfrrjGUj1","type":"assistant","uuid":"27943ec6-6f7e-415f-b9fa-e26af0761909","timestamp":"2026-02-21T08:37:52.115Z"}
{"parentUuid":"27943ec6-6f7e-415f-b9fa-e26af0761909","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"1b6f1bfa-92f4-4188-9c24-6b6054fbe2a3","toolUseID":"1b6f1bfa-92f4-4188-9c24-6b6054fbe2a3","timestamp":"2026-02-21T08:37:52.241Z","uuid":"c9a37c81-e631-41a9-ad2f-d828dc582899"}
{"parentUuid":"c9a37c81-e631-41a9-ad2f-d828dc582899","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":2068}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-21T08:37:54.310Z","uuid":"b37b1cd3-9da3-4f51-b579-09c4d8b40eb7","toolUseID":"1b6f1bfa-92f4-4188-9c24-6b6054fbe2a3"}
{"parentUuid":"b37b1cd3-9da3-4f51-b579-09c4d8b40eb7","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"system","subtype":"turn_duration","durationMs":122528,"timestamp":"2026-02-21T08:37:54.312Z","uuid":"37cedc72-6f79-4684-8377-0d778a326938","isMeta":false}
{"type":"file-history-snapshot","messageId":"e4d4e55a-5df6-4491-81af-9c5c363c5a2a","snapshot":{"messageId":"e4d4e55a-5df6-4491-81af-9c5c363c5a2a","trackedFileBackups":{"db/schema.py":{"backupFileName":"283975a9ba984ffc@v2","version":2,"backupTime":"2026-02-21T08:34:53.260Z"},"db/queries.py":{"backupFileName":"3dbb7f971a633538@v3","version":3,"backupTime":"2026-02-21T08:39:32.577Z"},"api/routers/query.py":{"backupFileName":"e6ad69c83e8fb9b0@v2","version":2,"backupTime":"2026-02-21T08:34:53.261Z"},"frontend/app/(protected)/query/page.tsx":{"backupFileName":"30dea031ecc29fcb@v2","version":2,"backupTime":"2026-02-21T08:34:53.262Z"}},"timestamp":"2026-02-21T08:39:32.576Z"},"isSnapshotUpdate":false}
{"parentUuid":"37cedc72-6f79-4684-8377-0d778a326938","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":"what is the difference between the symbol and full text search , can we put it in a single endpiint and delete this 2 separate apis and in the Ui as well a single Textfield for the Full text search . And Improve the UI as well if possible . "},"uuid":"e4d4e55a-5df6-4491-81af-9c5c363c5a2a","timestamp":"2026-02-21T08:39:29.933Z","todos":[],"permissionMode":"default"}
{"parentUuid":"e4d4e55a-5df6-4491-81af-9c5c363c5a2a","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_018JR48bkZ4YKGtraS3foHQ2","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The user wants to:\n1. Merge \"Full-text Search\" and \"Symbol Search\" into a single `/search` endpoint\n2. Remove the `/search-symbols` endpoint (or keep it but not expose in UI)\n3. In the UI: single text field for search, not two separate buttons\n4. Improve the UI\n\nLet me think about what the unified search should do:\n- It should try both symbol search (name/docstring fulltext) AND file content search\n- Return combined results with deduplication\n- Single endpoint: `GET /api/v1/query/search?query=...`\n\nThe current `/search` already does 3-tier search. The `/search-symbols` is a subset. So:\n\n\n- Keep `/search` as the unified endpoint (3-tier: symbol fulltext → name CONTAINS → file content)\n- `/search-symbols` can be deprecated/removed from the router (or kept for backward compat but not exposed in UI)\n\nFor the UI, I'll consolidate the search interface into a single prominent search bar, remove the separate Search/Symbol tabs, and redesign the results display with better visual grouping—maybe separating symbols from file matches with improved card layouts and clearer hierarchy.\n\nOn the backend, I need to remove the `/search-symbols` route from the router entirely since the user wants both APIs consolidated. On the frontend, I'll replace those two separate buttons with a unified search field that feeds into the single `/search` endpoint, then display results grouped by type with richer formatting—showing symbol metadata like function/class icons, file paths, and line numbers alongside a peek option. I should keep the `search_symbols` method in the backend since it might be useful internally, but remove the `/search-symbols` route since the unified `/search` endpoint now handles everything. On the frontend, I'll replace the separate \"Symbol Search\" button with a single search bar and improve how results are displayed—grouping symbols and file matches into distinct sections with badges, line numbers, and peek buttons. The other tabs (Analysis, CodeFinder, Metrics) stay as they are, though I could refine the generic ResultsView to work better across all of them. Looking at the API response structure, I see it returns objects with type, name, path, line_number, and score—where type can be function, class, variable, or line. I'll group the symbol types (function, class, variable) into a \"Symbols\" section and keep line matches separate as \"File Matches\", then design cards with type badges on the left and the name/path/line info on the right for symbols, while file match cards will emphasize the path with a line number badge. I'm sketching out the improved UI layout with a search bar, result counts broken down by type, and a peek viewer showing symbols and file matches with context. Now I need to implement this - I'll keep the changes focused and clean. For the query page structure, I'm thinking about how to handle the Search tab differently from the other tabs since it needs its own dedicated search interface rather than sharing the same input pattern. The simplest approach is to let each tab manage its own state, or I could give Search a top-level input while keeping the other tabs as they are.\n\nMy plan is to remove the Symbol Search option from the query groups, rename Full-text Search to just Search, and give the Search tab special treatment with a single input field, search button, and improved result grouping that separates symbols from file matches. On the backend I'll remove the `/search-symbols` route, and on the frontend I'll restructure the Search tab to feel more unified with auto-run on Enter and a more prominent search bar.\n\nLooking at the current code structure, the tabs share a single input state where each tab has its own buttons that trigger `qDef.fn(input)` when clicked. The simplest approach is to remove the Symbol Search button, rename Full-text Search to Search, and add an Enter key handler for auto-running the search. Then I'll improve the SearchResultsView to group results by type with better visual design.\n\nWriting the code changes now... Writing the SearchResultsView component...","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":243,"cache_read_input_tokens":115840,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":243},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLuvjmRqUx1DrpJTVFtK","type":"assistant","uuid":"4af5d828-8752-4222-9282-f3d724d8baf1","timestamp":"2026-02-21T08:40:24.361Z"}
{"parentUuid":"4af5d828-8752-4222-9282-f3d724d8baf1","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_018JR48bkZ4YKGtraS3foHQ2","type":"message","role":"assistant","content":[{"type":"text","text":"Let me look at both endpoints to understand the full scope before making changes."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":243,"cache_read_input_tokens":115840,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":243},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLuvjmRqUx1DrpJTVFtK","type":"assistant","uuid":"4d4adfba-0ac9-494f-8737-3e1f7687bf98","timestamp":"2026-02-21T08:40:24.466Z"}
{"parentUuid":"4d4adfba-0ac9-494f-8737-3e1f7687bf98","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_018JR48bkZ4YKGtraS3foHQ2","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01H1kGSdMm35MWLqbZexwHrP","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","offset":28,"limit":80},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":243,"cache_read_input_tokens":115840,"output_tokens":2619,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":243,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLuvjmRqUx1DrpJTVFtK","type":"assistant","uuid":"61172a3d-cb03-430e-8e7d-eaeed1cabbf8","timestamp":"2026-02-21T08:40:25.245Z"}
{"parentUuid":"61172a3d-cb03-430e-8e7d-eaeed1cabbf8","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01H1kGSdMm35MWLqbZexwHrP","toolUseID":"toolu_01H1kGSdMm35MWLqbZexwHrP","timestamp":"2026-02-21T08:40:25.342Z","uuid":"3a138472-d73c-49e6-bba9-d0b41771d11b"}
{"parentUuid":"61172a3d-cb03-430e-8e7d-eaeed1cabbf8","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01H1kGSdMm35MWLqbZexwHrP","type":"tool_result","content":"    28→@router.get(\"/search\")\n    29→async def search_code(\n    30→    query: str = Query(..., description=\"Search term for code\"),\n    31→    repo_id: str = Query(None, description=\"Optional repository ID to filter by\"),\n    32→    query_service: CodeQueryService = Depends(get_query_service)\n    33→) -> Dict[str, Any]:\n    34→    \"\"\"\n    35→    Search for code by content or name using fulltext search.\n    36→    \"\"\"\n    37→    try:\n    38→        results = query_service.search_code(query)\n    39→        \n    40→        # Filter by repo if provided\n    41→        if repo_id:\n    42→            filtered_results = []\n    43→            for result in results:\n    44→                if result.get('file', {}).get('repo_id') == repo_id:\n    45→                    filtered_results.append(result)\n    46→            results = filtered_results\n    47→        \n    48→        return {\n    49→            \"results\": results,\n    50→            \"total\": len(results),\n    51→            \"query\": query,\n    52→            \"repo_filter\": repo_id\n    53→        }\n    54→    except Exception as e:\n    55→        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")\n    56→\n    57→\n    58→@router.get(\"/search-symbols\")\n    59→async def search_symbols(\n    60→    query: str = Query(..., description=\"Search term for symbols\"),\n    61→    limit: int = Query(20, description=\"Maximum number of results\"),\n    62→    query_service: CodeQueryService = Depends(get_query_service)\n    63→) -> Dict[str, Any]:\n    64→    \"\"\"\n    65→    Search for symbols (functions, classes, variables) by name.\n    66→    \"\"\"\n    67→    try:\n    68→        results = query_service.search_symbols(query, limit)\n    69→        return {\n    70→            \"symbols\": results,\n    71→            \"total\": len(results),\n    72→            \"query\": query\n    73→        }\n    74→    except Exception as e:\n    75→        raise HTTPException(status_code=500, detail=f\"Symbol search failed: {str(e)}\")\n    76→\n    77→\n    78→@router.get(\"/method-usages\")\n    79→async def find_method_usages(\n    80→    method_name: str = Query(..., description=\"Name of the method to find usages for\"),\n    81→    query_service: CodeQueryService = Depends(get_query_service)\n    82→) -> Dict[str, Any]:\n    83→    \"\"\"\n    84→    Find all usages of a specific method.\n    85→    \"\"\"\n    86→    try:\n    87→        usages = query_service.find_method_usages(method_name)\n    88→        return usages\n    89→    except Exception as e:\n    90→        raise HTTPException(status_code=500, detail=f\"Failed to find method usages: {str(e)}\")\n    91→\n    92→\n    93→@router.get(\"/find_usages\")\n    94→async def find_usages(\n    95→    symbol_name: str = Query(..., description=\"Symbol name to find usages for\"),\n    96→    query_service: CodeQueryService = Depends(get_query_service)\n    97→) -> Dict[str, Any]:\n    98→    \"\"\"\n    99→    Find all usages of a specific symbol (alias for method-usages).\n   100→    \"\"\"\n   101→    try:\n   102→        usages = query_service.find_method_usages(symbol_name)\n   103→        return usages\n   104→    except Exception as e:\n   105→        raise HTTPException(status_code=500, detail=f\"Failed to find usages: {str(e)}\")\n   106→\n   107→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"f9f0c8b9-3f23-4623-91f9-900cbac7b1e0","timestamp":"2026-02-21T08:40:25.337Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","content":"@router.get(\"/search\")\nasync def search_code(\n    query: str = Query(..., description=\"Search term for code\"),\n    repo_id: str = Query(None, description=\"Optional repository ID to filter by\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Search for code by content or name using fulltext search.\n    \"\"\"\n    try:\n        results = query_service.search_code(query)\n        \n        # Filter by repo if provided\n        if repo_id:\n            filtered_results = []\n            for result in results:\n                if result.get('file', {}).get('repo_id') == repo_id:\n                    filtered_results.append(result)\n            results = filtered_results\n        \n        return {\n            \"results\": results,\n            \"total\": len(results),\n            \"query\": query,\n            \"repo_filter\": repo_id\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")\n\n\n@router.get(\"/search-symbols\")\nasync def search_symbols(\n    query: str = Query(..., description=\"Search term for symbols\"),\n    limit: int = Query(20, description=\"Maximum number of results\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Search for symbols (functions, classes, variables) by name.\n    \"\"\"\n    try:\n        results = query_service.search_symbols(query, limit)\n        return {\n            \"symbols\": results,\n            \"total\": len(results),\n            \"query\": query\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol search failed: {str(e)}\")\n\n\n@router.get(\"/method-usages\")\nasync def find_method_usages(\n    method_name: str = Query(..., description=\"Name of the method to find usages for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all usages of a specific method.\n    \"\"\"\n    try:\n        usages = query_service.find_method_usages(method_name)\n        return usages\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find method usages: {str(e)}\")\n\n\n@router.get(\"/find_usages\")\nasync def find_usages(\n    symbol_name: str = Query(..., description=\"Symbol name to find usages for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all usages of a specific symbol (alias for method-usages).\n    \"\"\"\n    try:\n        usages = query_service.find_method_usages(symbol_name)\n        return usages\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find usages: {str(e)}\")\n\n","numLines":80,"startLine":28,"totalLines":873}},"sourceToolAssistantUUID":"61172a3d-cb03-430e-8e7d-eaeed1cabbf8"}
{"parentUuid":"f9f0c8b9-3f23-4623-91f9-900cbac7b1e0","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01YDNBmcyAjDHaPv3NL6jAQT","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I understand the full picture. Let me:\n\n1. Remove `/search-symbols` from the router (but keep the method)\n2. Update `/search` to include `limit` param and remove the broken `repo_id` filter (that filter was checking `result.get('file', {}).get('repo_id')` but the new result format doesn't have a `file` key)\n3. Redesign the frontend\n\nLet me now implement all changes.","signature":"EpkECkYICxgCKkAVMlqi0yHavxdws+FHMmrPvXp3eNyLKsAGsxCjN974bHGyCf/ZbbczwAmJFvpGiSjZ+Z0LCrkPOwKF40+/NToCEgxz8i69J4HpS/xW8WMaDGFyIKebLgkPx38vhCIwTaKU3iJXAB7jPkzF9bmyHNAz15ryidw5IbDPgzm4bbolFDqlvrO3eBD09Jm60kdhKoAD0l34u9QKHYJdOavwhxa1T9fIY9bf1VEz3hlH7B9hY5iilryjqoCaPmkEH6iJhoSa7uW6xTiNqSEoM1dvCpnjTUdXdHfNkd/2vtaE3WvCAr0FagmFqewb0jqtzCzCJxO2/OAdDxAVYPsSG+L7rCR697oxWIKczJMU0uBhSL0ZtVXSofcqBJbNpeqEG6bc8H0c/lRWxhYZvFiYtcSV6B3HGxTj9BDVI7TTSHHDWPllDHiQOlvSgwYys0qxorrkAvoFlrQo3SUfAyn2BNVGkf0Oy0GtHBvOPdbwCRqet3srOa0bcCQJEyuWByOWgfCPgTzRmdoD9161JN3xHrNRrKa/yI71YQZihCKTjFUH6WBbWrqWI7dNB5etZvzgxrvZfOu+FaGeDSa6TmmOEIwaNv+WbmfzbleFQ4EJNmrXARmbRoQK3JUxxhvlTptrcL27GU34a3OhTpPChJu1DzBFVIOMWmaXdGXowuTchEr2W24WUqV14hwEnX33+EVvT18pojwZGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3658,"cache_read_input_tokens":116083,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3658},"output_tokens":12,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLuze3VwHZHNXfR4wNiF","type":"assistant","uuid":"5eb89993-be64-453c-b0d3-64d153982aa6","timestamp":"2026-02-21T08:40:29.224Z"}
{"parentUuid":"5eb89993-be64-453c-b0d3-64d153982aa6","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01YDNBmcyAjDHaPv3NL6jAQT","type":"message","role":"assistant","content":[{"type":"text","text":"Now I have a full picture. Let me make all the changes at once — backend cleanup and a proper UI redesign.\n\n**Backend: remove `/search-symbols`, clean up `/search`**"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3658,"cache_read_input_tokens":116083,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":3658},"output_tokens":12,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLuze3VwHZHNXfR4wNiF","type":"assistant","uuid":"d59a2742-a1e8-4306-9cb7-2efbf03c9c6a","timestamp":"2026-02-21T08:40:30.569Z"}
{"parentUuid":"d59a2742-a1e8-4306-9cb7-2efbf03c9c6a","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01YDNBmcyAjDHaPv3NL6jAQT","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01BhVwgkeVBCZJiUpLZq4kcp","name":"Edit","input":{"replace_all":false,"file_path":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","old_string":"@router.get(\"/search\")\nasync def search_code(\n    query: str = Query(..., description=\"Search term for code\"),\n    repo_id: str = Query(None, description=\"Optional repository ID to filter by\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Search for code by content or name using fulltext search.\n    \"\"\"\n    try:\n        results = query_service.search_code(query)\n        \n        # Filter by repo if provided\n        if repo_id:\n            filtered_results = []\n            for result in results:\n                if result.get('file', {}).get('repo_id') == repo_id:\n                    filtered_results.append(result)\n            results = filtered_results\n        \n        return {\n            \"results\": results,\n            \"total\": len(results),\n            \"query\": query,\n            \"repo_filter\": repo_id\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")\n\n\n@router.get(\"/search-symbols\")\nasync def search_symbols(\n    query: str = Query(..., description=\"Search term for symbols\"),\n    limit: int = Query(20, description=\"Maximum number of results\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Search for symbols (functions, classes, variables) by name.\n    \"\"\"\n    try:\n        results = query_service.search_symbols(query, limit)\n        return {\n            \"symbols\": results,\n            \"total\": len(results),\n            \"query\": query\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol search failed: {str(e)}\")","new_string":"@router.get(\"/search\")\nasync def search_code(\n    query: str = Query(..., description=\"Search term — any identifier, snippet, or keyword\"),\n    limit: int = Query(30, description=\"Maximum results to return\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Unified code search.\n\n    Three-tier strategy:\n    1. Fulltext index on symbols (name, docstring, source_code)\n    2. Name CONTAINS fallback (uses primary extracted identifier)\n    3. File content line search (file_content_search / source_code CONTAINS)\n\n    Results include type ('function' | 'class' | 'variable' | 'line'),\n    name, path, line_number, and score. Symbol results come first\n    (higher score), file-content line matches follow.\n    \"\"\"\n    try:\n        results = query_service.search_code(query)\n        if limit:\n            results = results[:limit]\n        return {\n            \"results\": results,\n            \"total\": len(results),\n            \"query\": query,\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3658,"cache_read_input_tokens":116083,"output_tokens":1035,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":3658,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLuze3VwHZHNXfR4wNiF","type":"assistant","uuid":"81dff5e5-13c5-400b-bba6-526dc4c8c2b1","timestamp":"2026-02-21T08:40:40.385Z"}
{"parentUuid":"81dff5e5-13c5-400b-bba6-526dc4c8c2b1","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01BhVwgkeVBCZJiUpLZq4kcp","toolUseID":"toolu_01BhVwgkeVBCZJiUpLZq4kcp","timestamp":"2026-02-21T08:40:49.515Z","uuid":"aebd7d28-fcc6-4527-8bab-bf02a40d17df"}
{"parentUuid":"81dff5e5-13c5-400b-bba6-526dc4c8c2b1","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01BhVwgkeVBCZJiUpLZq4kcp","type":"tool_result","content":"The file /Users/skmabudalam/Documents/BugViper/api/routers/query.py has been updated successfully."}]},"uuid":"a36d59c9-fa5b-4131-ac6c-bda954831864","timestamp":"2026-02-21T08:40:49.514Z","toolUseResult":{"filePath":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","oldString":"@router.get(\"/search\")\nasync def search_code(\n    query: str = Query(..., description=\"Search term for code\"),\n    repo_id: str = Query(None, description=\"Optional repository ID to filter by\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Search for code by content or name using fulltext search.\n    \"\"\"\n    try:\n        results = query_service.search_code(query)\n        \n        # Filter by repo if provided\n        if repo_id:\n            filtered_results = []\n            for result in results:\n                if result.get('file', {}).get('repo_id') == repo_id:\n                    filtered_results.append(result)\n            results = filtered_results\n        \n        return {\n            \"results\": results,\n            \"total\": len(results),\n            \"query\": query,\n            \"repo_filter\": repo_id\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")\n\n\n@router.get(\"/search-symbols\")\nasync def search_symbols(\n    query: str = Query(..., description=\"Search term for symbols\"),\n    limit: int = Query(20, description=\"Maximum number of results\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Search for symbols (functions, classes, variables) by name.\n    \"\"\"\n    try:\n        results = query_service.search_symbols(query, limit)\n        return {\n            \"symbols\": results,\n            \"total\": len(results),\n            \"query\": query\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol search failed: {str(e)}\")","newString":"@router.get(\"/search\")\nasync def search_code(\n    query: str = Query(..., description=\"Search term — any identifier, snippet, or keyword\"),\n    limit: int = Query(30, description=\"Maximum results to return\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Unified code search.\n\n    Three-tier strategy:\n    1. Fulltext index on symbols (name, docstring, source_code)\n    2. Name CONTAINS fallback (uses primary extracted identifier)\n    3. File content line search (file_content_search / source_code CONTAINS)\n\n    Results include type ('function' | 'class' | 'variable' | 'line'),\n    name, path, line_number, and score. Symbol results come first\n    (higher score), file-content line matches follow.\n    \"\"\"\n    try:\n        results = query_service.search_code(query)\n        if limit:\n            results = results[:limit]\n        return {\n            \"results\": results,\n            \"total\": len(results),\n            \"query\": query,\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")","originalFile":"\"\"\"\nCode query endpoints - Advanced implementation with Neo4j integration.\n\"\"\"\n\nfrom fastapi import APIRouter, HTTPException, Query, Depends, Body\nfrom pydantic import BaseModel\nfrom typing import Dict, Any, List, Optional\nimport os\n\nfrom db.client import Neo4jClient\nfrom db.queries import CodeQueryService\nfrom api.dependencies import get_neo4j_client\nfrom api.services.code_search import CodeFinder\n\nrouter = APIRouter()\n\n\ndef get_query_service(db: Neo4jClient = Depends(get_neo4j_client)) -> CodeQueryService:\n    \"\"\"Dependency to get query service.\"\"\"\n    return CodeQueryService(db)\n\n\ndef get_code_finder(db: Neo4jClient = Depends(get_neo4j_client)) -> CodeFinder:\n    \"\"\"Dependency to get code finder.\"\"\"\n    return CodeFinder(db)\n\n\n@router.get(\"/search\")\nasync def search_code(\n    query: str = Query(..., description=\"Search term for code\"),\n    repo_id: str = Query(None, description=\"Optional repository ID to filter by\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Search for code by content or name using fulltext search.\n    \"\"\"\n    try:\n        results = query_service.search_code(query)\n        \n        # Filter by repo if provided\n        if repo_id:\n            filtered_results = []\n            for result in results:\n                if result.get('file', {}).get('repo_id') == repo_id:\n                    filtered_results.append(result)\n            results = filtered_results\n        \n        return {\n            \"results\": results,\n            \"total\": len(results),\n            \"query\": query,\n            \"repo_filter\": repo_id\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")\n\n\n@router.get(\"/search-symbols\")\nasync def search_symbols(\n    query: str = Query(..., description=\"Search term for symbols\"),\n    limit: int = Query(20, description=\"Maximum number of results\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Search for symbols (functions, classes, variables) by name.\n    \"\"\"\n    try:\n        results = query_service.search_symbols(query, limit)\n        return {\n            \"symbols\": results,\n            \"total\": len(results),\n            \"query\": query\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol search failed: {str(e)}\")\n\n\n@router.get(\"/method-usages\")\nasync def find_method_usages(\n    method_name: str = Query(..., description=\"Name of the method to find usages for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all usages of a specific method.\n    \"\"\"\n    try:\n        usages = query_service.find_method_usages(method_name)\n        return usages\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find method usages: {str(e)}\")\n\n\n@router.get(\"/find_usages\")\nasync def find_usages(\n    symbol_name: str = Query(..., description=\"Symbol name to find usages for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all usages of a specific symbol (alias for method-usages).\n    \"\"\"\n    try:\n        usages = query_service.find_method_usages(symbol_name)\n        return usages\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find usages: {str(e)}\")\n\n\n@router.get(\"/find_callers\")\nasync def find_callers(\n    symbol_name: str = Query(..., description=\"Symbol name to find callers for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all methods/functions that call a specific symbol.\n    \"\"\"\n    try:\n        callers = query_service.find_callers(symbol_name)\n        return {\n            \"callers\": callers,\n            \"symbol\": symbol_name,\n            \"total\": len(callers)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find callers: {str(e)}\")\n\n\n@router.get(\"/class_hierarchy\")\nasync def get_class_hierarchy(\n    class_name: str = Query(..., description=\"Name of the class to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get class hierarchy (inheritance tree).\n    \"\"\"\n    try:\n        hierarchy = query_service.get_class_hierarchy(class_name)\n        return hierarchy\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get class hierarchy: {str(e)}\")\n\n\n@router.get(\"/class-hierarchy\")\nasync def get_class_hierarchy_alt(\n    class_name: str = Query(..., description=\"Name of the class to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get class hierarchy (inheritance tree) - alternative endpoint.\n    \"\"\"\n    try:\n        hierarchy = query_service.get_class_hierarchy(class_name)\n        return hierarchy\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get class hierarchy: {str(e)}\")\n\n\n@router.get(\"/file-structure\")\nasync def analyze_file_structure(\n    file_id: str = Query(..., description=\"File ID to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze the structure of a specific file.\n    \"\"\"\n    try:\n        structure = query_service.get_file_structure(file_id)\n        return structure\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to analyze file structure: {str(e)}\")\n\n\n@router.get(\"/change_impact\")\nasync def analyze_change_impact(\n    symbol_name: str = Query(..., description=\"Symbol to analyze impact for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze the impact of changing a specific symbol.\n    \"\"\"\n    try:\n        # Get all usages of the symbol to understand impact\n        usages = query_service.find_method_usages(symbol_name)\n        callers = query_service.find_callers(symbol_name)\n        \n        return {\n            \"symbol\": symbol_name,\n            \"usages\": usages,\n            \"callers\": callers,\n            \"impact_level\": \"high\" if len(callers) > 5 else \"medium\" if len(callers) > 0 else \"low\"\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to analyze change impact: {str(e)}\")\n\n\n@router.get(\"/relationships\")\nasync def get_code_relationships(\n    symbol_name: str = Query(..., description=\"Symbol to find relationships for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get code relationship analysis for a symbol.\n    \"\"\"\n    try:\n        # Get comprehensive relationship data\n        usages = query_service.find_method_usages(symbol_name)\n        callers = query_service.find_callers(symbol_name)\n        \n        return {\n            \"symbol\": symbol_name,\n            \"relationships\": {\n                \"usages\": usages,\n                \"callers\": callers,\n                \"usage_count\": len(usages.get('usages', [])),\n                \"caller_count\": len(callers)\n            }\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get code relationships: {str(e)}\")\n\n\n@router.get(\"/metrics\")\nasync def get_code_metrics(\n    repo_id: str = Query(None, description=\"Repository ID for repo-specific metrics\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get code metrics and statistics.\n    \"\"\"\n    try:\n        if repo_id:\n            # Get repository-specific stats\n            stats = query_service.get_repository_stats(repo_id)\n            return {\n                \"repository_id\": repo_id,\n                \"metrics\": stats\n            }\n        else:\n            # Get global graph stats\n            stats = query_service.get_graph_stats()\n            return {\n                \"global_metrics\": stats\n            }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get code metrics: {str(e)}\")\n\n\n@router.get(\"/stats\")\nasync def get_graph_stats(\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get overall graph statistics.\n    \"\"\"\n    try:\n        stats = query_service.get_graph_stats()\n        return stats\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get graph stats: {str(e)}\")\n\n\n@router.get(\"/symbol/{qualified_name}\")\nasync def get_symbol_by_qualified_name(\n    qualified_name: str,\n    repo_id: str = Query(..., description=\"Repository ID\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get symbol information by its qualified name.\n    \"\"\"\n    try:\n        symbol = query_service.find_symbol_by_qualified_name(qualified_name, repo_id)\n        if not symbol:\n            raise HTTPException(status_code=404, detail=\"Symbol not found\")\n        return symbol\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find symbol: {str(e)}\")\n\n\n# =========================================================================\n# CodeFinder Tool Integration Endpoints\n# =========================================================================\n\n@router.get(\"/code-finder/function\")\nasync def find_function_by_name(\n    name: str = Query(..., description=\"Function name to search for\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_function_name(name, fuzzy)\n        return {\n            \"function_name\": name,\n            \"fuzzy_search\": fuzzy,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/class\")\nasync def find_class_by_name(\n    name: str = Query(..., description=\"Class name to search for\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find classes by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_class_name(name, fuzzy)\n        return {\n            \"class_name\": name,\n            \"fuzzy_search\": fuzzy,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Class search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/variable\")\nasync def find_variable_by_name(\n    name: str = Query(..., description=\"Variable name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find variables by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_variable_name(name)\n        return {\n            \"variable_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Variable search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/content\")\nasync def find_by_content(\n    query: str = Query(..., description=\"Content search term\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find code by content matching using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_content(query)\n        return {\n            \"search_query\": query,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Content search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/module\")\nasync def find_module_by_name(\n    name: str = Query(..., description=\"Module name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find modules by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_module_name(name)\n        return {\n            \"module_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Module search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/imports\")\nasync def find_imports(\n    name: str = Query(..., description=\"Import name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find import statements using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_imports(name)\n        return {\n            \"import_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Import search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/related\")\nasync def find_related_code(\n    query: str = Query(..., description=\"Search query for related code\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    edit_distance: int = Query(2, description=\"Edit distance for fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find code related to a query using multiple search strategies.\n    \"\"\"\n    try:\n        results = code_finder.find_related_code(query, fuzzy, edit_distance)\n        return {\n            \"search_query\": query,\n            \"fuzzy_search\": fuzzy,\n            \"edit_distance\": edit_distance,\n            **results\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Related code search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/function/arguments\")\nasync def find_functions_by_argument(\n    argument_name: str = Query(..., description=\"Argument name to search for\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions that take a specific argument.\n    \"\"\"\n    try:\n        results = code_finder.find_functions_by_argument(argument_name, path)\n        return {\n            \"argument_name\": argument_name,\n            \"path_filter\": path,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function argument search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/function/decorator\")\nasync def find_functions_by_decorator(\n    decorator_name: str = Query(..., description=\"Decorator name to search for\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions that have a specific decorator.\n    \"\"\"\n    try:\n        results = code_finder.find_functions_by_decorator(decorator_name, path)\n        return {\n            \"decorator_name\": decorator_name,\n            \"path_filter\": path,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function decorator search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/complexity\")\nasync def get_cyclomatic_complexity(\n    function_name: str = Query(..., description=\"Function name to analyze\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get cyclomatic complexity of a function.\n    \"\"\"\n    try:\n        result = code_finder.get_cyclomatic_complexity(function_name, path)\n        if not result:\n            raise HTTPException(status_code=404, detail=\"Function not found\")\n        return {\n            \"function_name\": function_name,\n            \"path_filter\": path,\n            \"complexity\": result\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complexity analysis failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/complexity/top\")\nasync def find_most_complex_functions(\n    limit: int = Query(10, description=\"Number of results to return\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find the most complex functions by cyclomatic complexity.\n    \"\"\"\n    try:\n        results = code_finder.find_most_complex_functions(limit)\n        return {\n            \"limit\": limit,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complex function search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/line\")\nasync def find_by_line(\n    query: str = Query(..., description=\"Search term to find in file content\"),\n    limit: int = Query(50, description=\"Maximum number of line matches to return\"),\n    query_service: CodeQueryService = Depends(get_query_service),\n) -> Dict[str, Any]:\n    \"\"\"\n    Search raw file content line-by-line.\n    Uses file_content_search fulltext index (falls back to CONTAINS).\n    Returns path + line_number + match_line for each hit — no source dumps.\n    Pair with /code-finder/peek to view context around a hit.\n    \"\"\"\n    try:\n        results = query_service.search_file_content(query, limit)\n        return {\n            \"query\": query,\n            \"results\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Line search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/peek\")\nasync def peek_file_lines(\n    path: str = Query(..., description=\"Absolute file path (as stored in graph)\"),\n    line: int = Query(..., description=\"Anchor line number (1-indexed)\"),\n    above: int = Query(10, description=\"Lines to show above the anchor\"),\n    below: int = Query(10, description=\"Lines to show below the anchor\"),\n    query_service: CodeQueryService = Depends(get_query_service),\n) -> Dict[str, Any]:\n    \"\"\"\n    Return a window of lines around a given line in a file.\n    The anchor line is flagged with is_anchor=true.\n    Use above/below to control the context window size.\n    \"\"\"\n    try:\n        result = query_service.peek_file_lines(path, line, above, below)\n        if \"error\" in result:\n            raise HTTPException(status_code=404, detail=result[\"error\"])\n        return result\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Peek failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/relationships\")\nasync def analyze_code_relationships(\n    query_type: str = Query(..., description=\"Type of relationship query\"),\n    target: str = Query(..., description=\"Target symbol for analysis\"),\n    context: str = Query(None, description=\"Additional context for the query\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze code relationships using the CodeFinder's relationship query system.\n    \n    Supported query types:\n    - find_callers: Find all functions that call the target function\n    - find_callees: Find all functions called by the target function\n    - find_importers: Find all files that import the target module\n    - who_modifies: Find what functions modify a target variable\n    - class_hierarchy: Find inheritance relationships for a class\n    - call_chain: Find call paths between functions (format: 'start->end')\n    - module_deps: Find module dependencies\n    - variable_scope: Find variable usage across scopes\n    \"\"\"\n    try:\n        results = code_finder.execute_relationship_query(query_type, target, context)\n        return results\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Relationship analysis failed: {str(e)}\")\n\n\n@router.get(\"/repositories/indexed\")\nasync def list_indexed_repositories(\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    List all indexed repositories using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.list_indexed_repositories()\n        return {\n            \"repositories\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to list repositories: {str(e)}\")\n\n\n\n@router.get(\"/language/{language}/symbols\")\nasync def get_language_symbols(\n    language: str,\n    symbol_type: str = Query(..., description=\"Symbol type: function, class, variable, etc.\"),\n    limit: int = Query(50, description=\"Maximum number of results\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get all symbols of a specific type for a given language.\n    \n    Supported symbol types:\n    - function: All functions\n    - class: All classes  \n    - variable: All variables\n    - module: All modules\n    - file: All files\n    \"\"\"\n    try:\n        # Use Neo4j to query symbols by type and language\n        if symbol_type.lower() == \"function\":\n            query = f\"\"\"\n                MATCH (n:Function)\n                OPTIONAL MATCH (f:File)-[:CONTAINS]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.docstring as docstring, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"class\":\n            query = f\"\"\"\n                MATCH (n:Class)\n                OPTIONAL MATCH (f:File)-[:CONTAINS]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.docstring as docstring, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"variable\":\n            query = f\"\"\"\n                MATCH (n:Variable)\n                OPTIONAL MATCH (f:File)-[:CONTAINS*]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.value as value, n.context as context, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"file\":\n            query = f\"\"\"\n                MATCH (n:File)\n                WHERE n.language = $language OR n.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.relative_path as relative_path,\n                       n.language as language, n.extension as extension,\n                       n.is_dependency as is_dependency\n                ORDER BY n.is_dependency ASC, n.path\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"module\":\n            query = f\"\"\"\n                MATCH (n:Module)\n                WHERE n.lang = $language\n                RETURN n.name as name, n.lang as language,\n                       n.full_import_name as full_import_name\n                ORDER BY n.name\n                LIMIT $limit\n            \"\"\"\n        else:\n            raise HTTPException(status_code=400, detail=f\"Unsupported symbol type: {symbol_type}\")\n        \n        records, _, _ = query_service.db.run_query(query, {\"language\": language, \"limit\": limit})\n        \n        return {\n            \"language\": language,\n            \"symbol_type\": symbol_type,\n            \"results\": [dict(record) for record in records],\n            \"total\": len(records),\n            \"limit\": limit\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Language symbol query failed: {str(e)}\")\n\n\n@router.get(\"/language/stats\")\nasync def get_language_statistics(\n    language: str = Query(None, description=\"Optional language filter\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get statistics about programming languages in the codebase.\n    \"\"\"\n    try:\n        if language:\n            # Get stats for specific language\n            query = \"\"\"\n                MATCH (f:File)\n                WHERE f.language = $language OR f.extension IN ['.{}'.format($language.lower()), '.{}'.format($language[:2].lower())]\n                OPTIONAL MATCH (f)-[:CONTAINS]->(func:Function)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(cls:Class)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(var:Variable)\n                RETURN \n                    count(DISTINCT f) as file_count,\n                    count(DISTINCT func) as function_count,\n                    count(DISTINCT cls) as class_count,\n                    count(DISTINCT var) as variable_count\n            \"\"\"\n            records, _, _ = query_service.db.run_query(query, {\"language\": language})\n            result = dict(records[0]) if records else {}\n            result[\"language\"] = language\n            return result\n        else:\n            # Get stats for all languages\n            query = \"\"\"\n                MATCH (f:File)\n                WHERE f.language IS NOT NULL\n                OPTIONAL MATCH (f)-[:CONTAINS]->(func:Function)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(cls:Class)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(var:Variable)\n                RETURN \n                    f.language as language,\n                    count(DISTINCT f) as file_count,\n                    count(DISTINCT func) as function_count,\n                    count(DISTINCT cls) as class_count,\n                    count(DISTINCT var) as variable_count\n                ORDER BY file_count DESC\n            \"\"\"\n            records, _, _ = query_service.db.run_query(query)\n            return {\n                \"languages\": [dict(record) for record in records],\n                \"total_languages\": len(records)\n            }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Language statistics query failed: {str(e)}\")\n\n\n# --- Code Review / Diff Context Endpoints ---\n\n\n@router.get(\"/symbols-at-lines\")\nasync def get_symbols_at_lines(\n    file_path: str = Query(..., description=\"Absolute file path\"),\n    start_line: int = Query(..., description=\"Start line number\"),\n    end_line: int = Query(..., description=\"End line number\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all symbols (functions, classes, variables) overlapping a line range.\n    Useful for mapping diff hunks to affected code.\n    \"\"\"\n    try:\n        results = query_service.get_symbols_at_lines(file_path, start_line, end_line)\n        return {\n            \"file_path\": file_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n            \"symbols\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol lookup failed: {str(e)}\")\n\n\n@router.get(\"/symbols-at-lines-relative\")\nasync def get_symbols_at_lines_relative(\n    repo_id: str = Query(..., description=\"Repository ID (e.g. owner/repo)\"),\n    file_path: str = Query(..., description=\"Repo-relative file path (e.g. src/main.py)\"),\n    start_line: int = Query(..., description=\"Start line number\"),\n    end_line: int = Query(..., description=\"End line number\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all symbols overlapping a line range using repo-relative path.\n    \"\"\"\n    try:\n        results = query_service.get_symbols_at_lines_by_relative_path(\n            repo_id, file_path, start_line, end_line\n        )\n        return {\n            \"repo_id\": repo_id,\n            \"file_path\": file_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n            \"symbols\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol lookup failed: {str(e)}\")\n\n\nclass FileChange(BaseModel):\n    file_path: str\n    start_line: int = 1\n    end_line: int = 999999\n\n\nclass DiffContextRequest(BaseModel):\n    repo_id: str\n    changes: List[FileChange]\n\n\n@router.post(\"/diff-context\")\nasync def get_diff_context(\n    request: DiffContextRequest,\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Build full RAG context for a code diff.\n\n    Given a repository and a list of file changes (path + line ranges),\n    returns affected symbols with source code, their callers, class hierarchy,\n    and full file sources. Designed for AI-powered code review.\n\n    Example request:\n    ```json\n    {\n        \"repo_id\": \"owner/repo\",\n        \"changes\": [\n            {\"file_path\": \"src/main.py\", \"start_line\": 10, \"end_line\": 30},\n            {\"file_path\": \"src/utils.py\", \"start_line\": 1, \"end_line\": 50}\n        ]\n    }\n    ```\n    \"\"\"\n    try:\n        changes_dicts = [c.model_dump() for c in request.changes]\n        result = query_service.get_diff_context(request.repo_id, changes_dicts)\n        return result\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Diff context failed: {str(e)}\")\n\n\n@router.get(\"/file-source\")\nasync def get_file_source(\n    repo_id: str = Query(..., description=\"Repository ID\"),\n    file_path: str = Query(..., description=\"Repo-relative file path\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get the full source code of a file from the graph.\n    \"\"\"\n    try:\n        query = \"\"\"\n        MATCH (f:File)\n        WHERE f.relative_path = $relative_path AND f.path CONTAINS $repo_id\n        RETURN f.source_code as source_code, f.relative_path as path,\n               f.language as language, f.lines_count as lines_count\n        LIMIT 1\n        \"\"\"\n        records, _, _ = query_service.db.run_query(query, {\n            \"relative_path\": file_path,\n            \"repo_id\": repo_id,\n        })\n        if not records:\n            raise HTTPException(status_code=404, detail=\"File not found\")\n        record = records[0]\n        return {\n            \"file_path\": record.get(\"path\"),\n            \"language\": record.get(\"language\"),\n            \"lines_count\": record.get(\"lines_count\"),\n            \"source_code\": record.get(\"source_code\"),\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"File source retrieval failed: {str(e)}\")\n","structuredPatch":[{"oldStart":27,"oldLines":54,"newStart":27,"newLines":35,"lines":[" "," @router.get(\"/search\")"," async def search_code(","-    query: str = Query(..., description=\"Search term for code\"),","-    repo_id: str = Query(None, description=\"Optional repository ID to filter by\"),","+    query: str = Query(..., description=\"Search term — any identifier, snippet, or keyword\"),","+    limit: int = Query(30, description=\"Maximum results to return\"),","     query_service: CodeQueryService = Depends(get_query_service)"," ) -> Dict[str, Any]:","     \"\"\"","-    Search for code by content or name using fulltext search.","+    Unified code search.","+","+    Three-tier strategy:","+    1. Fulltext index on symbols (name, docstring, source_code)","+    2. Name CONTAINS fallback (uses primary extracted identifier)","+    3. File content line search (file_content_search / source_code CONTAINS)","+","+    Results include type ('function' | 'class' | 'variable' | 'line'),","+    name, path, line_number, and score. Symbol results come first","+    (higher score), file-content line matches follow.","     \"\"\"","     try:","         results = query_service.search_code(query)","-        ","-        # Filter by repo if provided","-        if repo_id:","-            filtered_results = []","-            for result in results:","-                if result.get('file', {}).get('repo_id') == repo_id:","-                    filtered_results.append(result)","-            results = filtered_results","-        ","+        if limit:","+            results = results[:limit]","         return {","             \"results\": results,","             \"total\": len(results),","             \"query\": query,","-            \"repo_filter\": repo_id","         }","     except Exception as e:","         raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")"," "," ","-@router.get(\"/search-symbols\")","-async def search_symbols(","-    query: str = Query(..., description=\"Search term for symbols\"),","-    limit: int = Query(20, description=\"Maximum number of results\"),","-    query_service: CodeQueryService = Depends(get_query_service)","-) -> Dict[str, Any]:","-    \"\"\"","-    Search for symbols (functions, classes, variables) by name.","-    \"\"\"","-    try:","-        results = query_service.search_symbols(query, limit)","-        return {","-            \"symbols\": results,","-            \"total\": len(results),","-            \"query\": query","-        }","-    except Exception as e:","-        raise HTTPException(status_code=500, detail=f\"Symbol search failed: {str(e)}\")","-","-"," @router.get(\"/method-usages\")"," async def find_method_usages(","     method_name: str = Query(..., description=\"Name of the method to find usages for\"),"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"81dff5e5-13c5-400b-bba6-526dc4c8c2b1"}
{"parentUuid":"a36d59c9-fa5b-4131-ac6c-bda954831864","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01WS7sJaQzHp1zeR4mptLEDA","type":"message","role":"assistant","content":[{"type":"text","text":"Also remove the stale `findDefinition` call that still hits `/search-symbols` in `api.ts`:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1076,"cache_read_input_tokens":119741,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1076},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLv2RuJpqgo9WoSkpwsQ","type":"assistant","uuid":"f2076b0f-8070-4e05-b786-1c78c479c546","timestamp":"2026-02-21T08:40:52.296Z"}
{"parentUuid":"f2076b0f-8070-4e05-b786-1c78c479c546","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01WS7sJaQzHp1zeR4mptLEDA","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0146dbzrwoxd7z43ABkZYwcp","name":"Edit","input":{"replace_all":false,"file_path":"/Users/skmabudalam/Documents/BugViper/frontend/lib/api.ts","old_string":"// Query - Search\nexport const searchCode = (query: string) =>\n  apiFetch(`/api/v1/query/search?query=${encodeURIComponent(query)}`);\nexport const searchSymbols = (query: string) =>\n  apiFetch(`/api/v1/query/search-symbols?query=${encodeURIComponent(query)}`);","new_string":"// Query - Search (unified)\nexport const searchCode = (query: string, limit = 30) =>\n  apiFetch(`/api/v1/query/search?query=${encodeURIComponent(query)}&limit=${limit}`);"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1076,"cache_read_input_tokens":119741,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1076},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLv2RuJpqgo9WoSkpwsQ","type":"assistant","uuid":"aa1e12c4-3dfa-410d-84b6-21fa844f3783","timestamp":"2026-02-21T08:40:54.694Z"}
{"type":"file-history-snapshot","messageId":"aa1e12c4-3dfa-410d-84b6-21fa844f3783","snapshot":{"messageId":"e4d4e55a-5df6-4491-81af-9c5c363c5a2a","trackedFileBackups":{"db/schema.py":{"backupFileName":"283975a9ba984ffc@v2","version":2,"backupTime":"2026-02-21T08:34:53.260Z"},"db/queries.py":{"backupFileName":"3dbb7f971a633538@v3","version":3,"backupTime":"2026-02-21T08:39:32.577Z"},"api/routers/query.py":{"backupFileName":"e6ad69c83e8fb9b0@v2","version":2,"backupTime":"2026-02-21T08:34:53.261Z"},"frontend/app/(protected)/query/page.tsx":{"backupFileName":"30dea031ecc29fcb@v2","version":2,"backupTime":"2026-02-21T08:34:53.262Z"},"frontend/lib/api.ts":{"backupFileName":"a3322355f2d59118@v1","version":1,"backupTime":"2026-02-21T08:40:54.703Z"}},"timestamp":"2026-02-21T08:39:32.576Z"},"isSnapshotUpdate":true}
{"parentUuid":"aa1e12c4-3dfa-410d-84b6-21fa844f3783","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_0146dbzrwoxd7z43ABkZYwcp","toolUseID":"toolu_0146dbzrwoxd7z43ABkZYwcp","timestamp":"2026-02-21T08:40:54.705Z","uuid":"fcdda251-baff-4e1d-9621-d71a95a1862a"}
{"parentUuid":"aa1e12c4-3dfa-410d-84b6-21fa844f3783","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0146dbzrwoxd7z43ABkZYwcp","type":"tool_result","content":"The file /Users/skmabudalam/Documents/BugViper/frontend/lib/api.ts has been updated successfully."}]},"uuid":"9efa0290-aef6-4ba7-bbcc-620e39c5c183","timestamp":"2026-02-21T08:40:54.705Z","toolUseResult":{"filePath":"/Users/skmabudalam/Documents/BugViper/frontend/lib/api.ts","oldString":"// Query - Search\nexport const searchCode = (query: string) =>\n  apiFetch(`/api/v1/query/search?query=${encodeURIComponent(query)}`);\nexport const searchSymbols = (query: string) =>\n  apiFetch(`/api/v1/query/search-symbols?query=${encodeURIComponent(query)}`);","newString":"// Query - Search (unified)\nexport const searchCode = (query: string, limit = 30) =>\n  apiFetch(`/api/v1/query/search?query=${encodeURIComponent(query)}&limit=${limit}`);","originalFile":"const API_BASE = process.env.NEXT_PUBLIC_API_URL || \"http://localhost:8000\";\n\n// Auth token injection\nlet tokenGetter: (() => Promise<string | null>) | null = null;\n\nexport function setTokenGetter(getter: () => Promise<string | null>) {\n  tokenGetter = getter;\n}\n\n// Type definitions for repository statistics\nexport interface RepositoryStatistics {\n  files: number;\n  classes: number;\n  functions: number;\n  methods: number;\n  lines: number;\n  imports: number;\n  languages: string[];\n}\n\nexport interface RepositoryStatsResponse {\n  repository_id: string;\n  statistics: RepositoryStatistics;\n}\n\nexport interface GitHubRepo {\n  name: string;\n  full_name: string;\n  description: string | null;\n  language: string | null;\n  stargazers_count: number;\n  private: boolean;\n  default_branch: string;\n  html_url: string;\n}\n\nasync function apiFetch(path: string, options?: RequestInit) {\n  const headers: Record<string, string> = {\n    \"Content-Type\": \"application/json\",\n    ...(options?.headers as Record<string, string>),\n  };\n\n  if (tokenGetter) {\n    const token = await tokenGetter();\n    if (token) {\n      headers[\"Authorization\"] = `Bearer ${token}`;\n    }\n  }\n\n  const res = await fetch(`${API_BASE}${path}`, {\n    ...options,\n    headers,\n  });\n  if (!res.ok) {\n    const text = await res.text();\n    throw new Error(text || `API error: ${res.status}`);\n  }\n  return res.json();\n}\n\n// Repositories\nexport const listRepositories = () => apiFetch(\"/api/v1/repos/\");\nexport const deleteRepository = (id: string) =>\n  apiFetch(`/api/v1/repos/${id}`, { method: \"DELETE\" });\nexport const getRepositoryStats = (owner: string, repoName: string) =>\n  apiFetch(`/api/v1/repos/${owner}/${repoName}/stats`);\n\n// Ingestion\nexport interface IngestionJobResponse {\n  job_id: string;\n  status: string;\n  message: string;\n  poll_url: string;\n}\n\nexport interface JobStatusResponse {\n  job_id: string;\n  owner: string;\n  repo_name: string;\n  branch: string | null;\n  status: string;\n  created_at: string;\n  updated_at: string;\n  started_at: string | null;\n  completed_at: string | null;\n  stats: {\n    files_processed: number;\n    files_skipped: number;\n    classes_found: number;\n    functions_found: number;\n    imports_found: number;\n    total_lines: number;\n    errors: string[];\n  } | null;\n  error_message: string | null;\n}\n\nexport const ingestGithub = (data: {\n  owner: string;\n  repo_name: string;\n  branch?: string;\n  clear_existing?: boolean;\n}): Promise<IngestionJobResponse> =>\n  apiFetch(\"/api/v1/ingest/github\", { method: \"POST\", body: JSON.stringify(data) });\n\nexport const getIngestionJobStatus = (jobId: string): Promise<JobStatusResponse> =>\n  apiFetch(`/api/v1/ingest/jobs/${jobId}`);\n\nexport const listIngestionJobs = (): Promise<JobStatusResponse[]> =>\n  apiFetch(\"/api/v1/ingest/jobs\");\n\nexport const ingestRepository = (data: {\n  repo_url: string;\n  username: string;\n  repo_name: string;\n  clear_existing?: boolean;\n}) => apiFetch(\"/api/v1/ingest/repository\", { method: \"POST\", body: JSON.stringify(data) });\n\n// Query - Search\nexport const searchCode = (query: string) =>\n  apiFetch(`/api/v1/query/search?query=${encodeURIComponent(query)}`);\nexport const searchSymbols = (query: string) =>\n  apiFetch(`/api/v1/query/search-symbols?query=${encodeURIComponent(query)}`);\n\n// Query - Analysis\nexport const getMethodUsages = (name: string) =>\n  apiFetch(`/api/v1/query/method-usages?method_name=${encodeURIComponent(name)}`);\nexport const findCallers = (name: string) =>\n  apiFetch(`/api/v1/query/find_callers?symbol_name=${encodeURIComponent(name)}`);\nexport const getClassHierarchy = (name: string) =>\n  apiFetch(`/api/v1/query/class_hierarchy?class_name=${encodeURIComponent(name)}`);\nexport const getChangeImpact = (name: string) =>\n  apiFetch(`/api/v1/query/change_impact?symbol_name=${encodeURIComponent(name)}`);\n\n// Query - CodeFinder\nexport const findFunction = (name: string) =>\n  apiFetch(`/api/v1/query/code-finder/function?name=${encodeURIComponent(name)}`);\nexport const findClass = (name: string) =>\n  apiFetch(`/api/v1/query/code-finder/class?name=${encodeURIComponent(name)}`);\nexport const findVariable = (name: string) =>\n  apiFetch(`/api/v1/query/code-finder/variable?name=${encodeURIComponent(name)}`);\nexport const findContent = (query: string) =>\n  apiFetch(`/api/v1/query/code-finder/content?query=${encodeURIComponent(query)}`);\nexport const findModule = (name: string) =>\n  apiFetch(`/api/v1/query/code-finder/module?name=${encodeURIComponent(name)}`);\nexport const findImports = (name: string) =>\n  apiFetch(`/api/v1/query/code-finder/imports?name=${encodeURIComponent(name)}`);\nexport const findByLine = (query: string) =>\n  apiFetch(`/api/v1/query/code-finder/line?query=${encodeURIComponent(query)}`);\nexport const peekFileLines = (path: string, line: number, above: number, below: number) =>\n  apiFetch(`/api/v1/query/code-finder/peek?path=${encodeURIComponent(path)}&line=${line}&above=${above}&below=${below}`);\n\n// Query - Metrics\nexport const getGraphStats = () => apiFetch(\"/api/v1/query/stats\");\nexport const getLanguageStats = () => apiFetch(\"/api/v1/query/language/stats\");\nexport const getTopComplexFunctions = () =>\n  apiFetch(\"/api/v1/query/code-finder/complexity/top\");\n\n// Query - Code Review / Diff Context\nexport const getSymbolsAtLines = (repoId: string, filePath: string, startLine: number, endLine: number) =>\n  apiFetch(`/api/v1/query/symbols-at-lines-relative?repo_id=${encodeURIComponent(repoId)}&file_path=${encodeURIComponent(filePath)}&start_line=${startLine}&end_line=${endLine}`);\n\nexport const getDiffContext = (data: {\n  repo_id: string;\n  changes: { file_path: string; start_line?: number; end_line?: number }[];\n}) => apiFetch(\"/api/v1/query/diff-context\", { method: \"POST\", body: JSON.stringify(data) });\n\nexport const getFileSource = (repoId: string, filePath: string) =>\n  apiFetch(`/api/v1/query/file-source?repo_id=${encodeURIComponent(repoId)}&file_path=${encodeURIComponent(filePath)}`);\n\n// Auth\nexport const loginUser = (data: { github_access_token: string }) =>\n  apiFetch(\"/api/v1/auth/login\", { method: \"POST\", body: JSON.stringify(data) });\n\nexport const ensureUser = () =>\n  apiFetch(\"/api/v1/auth/ensure\", { method: \"POST\" });\n\nexport const getCurrentUser = () => apiFetch(\"/api/v1/auth/me\");\n\nexport const getGitHubRepos = (): Promise<GitHubRepo[]> =>\n  apiFetch(\"/api/v1/auth/github/repos\");\n\n// Additional query functions\nexport const getComplexity = (functionName: string, path?: string) => {\n  const params = new URLSearchParams({ function_name: functionName });\n  if (path) params.set(\"path\", path);\n  return apiFetch(`/api/v1/query/code-finder/complexity?${params}`);\n};\n\nexport const findRelatedCode = (query: string, fuzzy = false, depth = 2) =>\n  apiFetch(\n    `/api/v1/query/code-finder/content?query=${encodeURIComponent(query)}&fuzzy=${fuzzy}&depth=${depth}`\n  );\n\nexport const getLanguageSymbols = (language: string, symbolType: string, limit = 50) =>\n  apiFetch(\n    `/api/v1/query/language/symbols?language=${encodeURIComponent(language)}&symbol_type=${encodeURIComponent(symbolType)}&limit=${limit}`\n  );\n\nexport const findDefinition = (symbolName: string, repoId: string) =>\n  apiFetch(\n    `/api/v1/query/search-symbols?query=${encodeURIComponent(symbolName)}&repo_id=${encodeURIComponent(repoId)}`\n  );\n\nexport const findMethodUsages = (methodName: string) =>\n  apiFetch(`/api/v1/query/method-usages?method_name=${encodeURIComponent(methodName)}`);\n\nexport const getFileStructure = (repoId: string, filePath: string) =>\n  apiFetch(\n    `/api/v1/query/file-source?repo_id=${encodeURIComponent(repoId)}&file_path=${encodeURIComponent(filePath)}`\n  );\n\nexport const analyzeRelationships = (queryType: string, target: string, context?: string) => {\n  const params = new URLSearchParams({ symbol_name: target });\n  if (context) params.set(\"context\", context);\n  const endpoint =\n    queryType === \"class_hierarchy\"\n      ? `/api/v1/query/class_hierarchy?class_name=${encodeURIComponent(target)}`\n      : queryType === \"change_impact\"\n      ? `/api/v1/query/change_impact?symbol_name=${encodeURIComponent(target)}`\n      : `/api/v1/query/find_callers?symbol_name=${encodeURIComponent(target)}&query_type=${encodeURIComponent(queryType)}`;\n  return apiFetch(endpoint);\n};\n\n// Default export for direct api.X() usage in components\nconst api = {\n  findMethodUsages,\n  getFileStructure,\n  analyzeRelationships,\n  findDefinition,\n  getComplexity,\n  findRelatedCode,\n  getLanguageSymbols,\n};\n\nexport default api;\n","structuredPatch":[{"oldStart":116,"oldLines":11,"newStart":116,"newLines":9,"lines":["   clear_existing?: boolean;"," }) => apiFetch(\"/api/v1/ingest/repository\", { method: \"POST\", body: JSON.stringify(data) });"," ","-// Query - Search","-export const searchCode = (query: string) =>","-  apiFetch(`/api/v1/query/search?query=${encodeURIComponent(query)}`);","-export const searchSymbols = (query: string) =>","-  apiFetch(`/api/v1/query/search-symbols?query=${encodeURIComponent(query)}`);","+// Query - Search (unified)","+export const searchCode = (query: string, limit = 30) =>","+  apiFetch(`/api/v1/query/search?query=${encodeURIComponent(query)}&limit=${limit}`);"," "," // Query - Analysis"," export const getMethodUsages = (name: string) =>"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"aa1e12c4-3dfa-410d-84b6-21fa844f3783"}
{"parentUuid":"9efa0290-aef6-4ba7-bbcc-620e39c5c183","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01YNvNA4nGUYcWfhtSFpWaMX","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01CPTnXoWK7GEJeznF1Pt95K","name":"Edit","input":{"replace_all":false,"file_path":"/Users/skmabudalam/Documents/BugViper/frontend/lib/api.ts","old_string":"export const findDefinition = (symbolName: string, repoId: string) =>\n  apiFetch(\n    `/api/v1/query/search-symbols?query=${encodeURIComponent(symbolName)}&repo_id=${encodeURIComponent(repoId)}`\n  );","new_string":"export const findDefinition = (symbolName: string, _repoId?: string) =>\n  apiFetch(`/api/v1/query/search?query=${encodeURIComponent(symbolName)}`);"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":338,"cache_read_input_tokens":120817,"output_tokens":246,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":338,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLv2oN8v5HEgzmchDPb5","type":"assistant","uuid":"55a7e81b-2bbb-44a3-b9d4-e4299262125f","timestamp":"2026-02-21T08:40:58.935Z"}
{"parentUuid":"55a7e81b-2bbb-44a3-b9d4-e4299262125f","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01CPTnXoWK7GEJeznF1Pt95K","toolUseID":"toolu_01CPTnXoWK7GEJeznF1Pt95K","timestamp":"2026-02-21T08:40:59.027Z","uuid":"dab31e4b-d42f-41a5-a469-411d3a133ed1"}
{"parentUuid":"55a7e81b-2bbb-44a3-b9d4-e4299262125f","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CPTnXoWK7GEJeznF1Pt95K","type":"tool_result","content":"The file /Users/skmabudalam/Documents/BugViper/frontend/lib/api.ts has been updated successfully."}]},"uuid":"3f35629a-6b7f-4620-a248-1a98799e1839","timestamp":"2026-02-21T08:40:59.026Z","toolUseResult":{"filePath":"/Users/skmabudalam/Documents/BugViper/frontend/lib/api.ts","oldString":"export const findDefinition = (symbolName: string, repoId: string) =>\n  apiFetch(\n    `/api/v1/query/search-symbols?query=${encodeURIComponent(symbolName)}&repo_id=${encodeURIComponent(repoId)}`\n  );","newString":"export const findDefinition = (symbolName: string, _repoId?: string) =>\n  apiFetch(`/api/v1/query/search?query=${encodeURIComponent(symbolName)}`);","originalFile":"const API_BASE = process.env.NEXT_PUBLIC_API_URL || \"http://localhost:8000\";\n\n// Auth token injection\nlet tokenGetter: (() => Promise<string | null>) | null = null;\n\nexport function setTokenGetter(getter: () => Promise<string | null>) {\n  tokenGetter = getter;\n}\n\n// Type definitions for repository statistics\nexport interface RepositoryStatistics {\n  files: number;\n  classes: number;\n  functions: number;\n  methods: number;\n  lines: number;\n  imports: number;\n  languages: string[];\n}\n\nexport interface RepositoryStatsResponse {\n  repository_id: string;\n  statistics: RepositoryStatistics;\n}\n\nexport interface GitHubRepo {\n  name: string;\n  full_name: string;\n  description: string | null;\n  language: string | null;\n  stargazers_count: number;\n  private: boolean;\n  default_branch: string;\n  html_url: string;\n}\n\nasync function apiFetch(path: string, options?: RequestInit) {\n  const headers: Record<string, string> = {\n    \"Content-Type\": \"application/json\",\n    ...(options?.headers as Record<string, string>),\n  };\n\n  if (tokenGetter) {\n    const token = await tokenGetter();\n    if (token) {\n      headers[\"Authorization\"] = `Bearer ${token}`;\n    }\n  }\n\n  const res = await fetch(`${API_BASE}${path}`, {\n    ...options,\n    headers,\n  });\n  if (!res.ok) {\n    const text = await res.text();\n    throw new Error(text || `API error: ${res.status}`);\n  }\n  return res.json();\n}\n\n// Repositories\nexport const listRepositories = () => apiFetch(\"/api/v1/repos/\");\nexport const deleteRepository = (id: string) =>\n  apiFetch(`/api/v1/repos/${id}`, { method: \"DELETE\" });\nexport const getRepositoryStats = (owner: string, repoName: string) =>\n  apiFetch(`/api/v1/repos/${owner}/${repoName}/stats`);\n\n// Ingestion\nexport interface IngestionJobResponse {\n  job_id: string;\n  status: string;\n  message: string;\n  poll_url: string;\n}\n\nexport interface JobStatusResponse {\n  job_id: string;\n  owner: string;\n  repo_name: string;\n  branch: string | null;\n  status: string;\n  created_at: string;\n  updated_at: string;\n  started_at: string | null;\n  completed_at: string | null;\n  stats: {\n    files_processed: number;\n    files_skipped: number;\n    classes_found: number;\n    functions_found: number;\n    imports_found: number;\n    total_lines: number;\n    errors: string[];\n  } | null;\n  error_message: string | null;\n}\n\nexport const ingestGithub = (data: {\n  owner: string;\n  repo_name: string;\n  branch?: string;\n  clear_existing?: boolean;\n}): Promise<IngestionJobResponse> =>\n  apiFetch(\"/api/v1/ingest/github\", { method: \"POST\", body: JSON.stringify(data) });\n\nexport const getIngestionJobStatus = (jobId: string): Promise<JobStatusResponse> =>\n  apiFetch(`/api/v1/ingest/jobs/${jobId}`);\n\nexport const listIngestionJobs = (): Promise<JobStatusResponse[]> =>\n  apiFetch(\"/api/v1/ingest/jobs\");\n\nexport const ingestRepository = (data: {\n  repo_url: string;\n  username: string;\n  repo_name: string;\n  clear_existing?: boolean;\n}) => apiFetch(\"/api/v1/ingest/repository\", { method: \"POST\", body: JSON.stringify(data) });\n\n// Query - Search (unified)\nexport const searchCode = (query: string, limit = 30) =>\n  apiFetch(`/api/v1/query/search?query=${encodeURIComponent(query)}&limit=${limit}`);\n\n// Query - Analysis\nexport const getMethodUsages = (name: string) =>\n  apiFetch(`/api/v1/query/method-usages?method_name=${encodeURIComponent(name)}`);\nexport const findCallers = (name: string) =>\n  apiFetch(`/api/v1/query/find_callers?symbol_name=${encodeURIComponent(name)}`);\nexport const getClassHierarchy = (name: string) =>\n  apiFetch(`/api/v1/query/class_hierarchy?class_name=${encodeURIComponent(name)}`);\nexport const getChangeImpact = (name: string) =>\n  apiFetch(`/api/v1/query/change_impact?symbol_name=${encodeURIComponent(name)}`);\n\n// Query - CodeFinder\nexport const findFunction = (name: string) =>\n  apiFetch(`/api/v1/query/code-finder/function?name=${encodeURIComponent(name)}`);\nexport const findClass = (name: string) =>\n  apiFetch(`/api/v1/query/code-finder/class?name=${encodeURIComponent(name)}`);\nexport const findVariable = (name: string) =>\n  apiFetch(`/api/v1/query/code-finder/variable?name=${encodeURIComponent(name)}`);\nexport const findContent = (query: string) =>\n  apiFetch(`/api/v1/query/code-finder/content?query=${encodeURIComponent(query)}`);\nexport const findModule = (name: string) =>\n  apiFetch(`/api/v1/query/code-finder/module?name=${encodeURIComponent(name)}`);\nexport const findImports = (name: string) =>\n  apiFetch(`/api/v1/query/code-finder/imports?name=${encodeURIComponent(name)}`);\nexport const findByLine = (query: string) =>\n  apiFetch(`/api/v1/query/code-finder/line?query=${encodeURIComponent(query)}`);\nexport const peekFileLines = (path: string, line: number, above: number, below: number) =>\n  apiFetch(`/api/v1/query/code-finder/peek?path=${encodeURIComponent(path)}&line=${line}&above=${above}&below=${below}`);\n\n// Query - Metrics\nexport const getGraphStats = () => apiFetch(\"/api/v1/query/stats\");\nexport const getLanguageStats = () => apiFetch(\"/api/v1/query/language/stats\");\nexport const getTopComplexFunctions = () =>\n  apiFetch(\"/api/v1/query/code-finder/complexity/top\");\n\n// Query - Code Review / Diff Context\nexport const getSymbolsAtLines = (repoId: string, filePath: string, startLine: number, endLine: number) =>\n  apiFetch(`/api/v1/query/symbols-at-lines-relative?repo_id=${encodeURIComponent(repoId)}&file_path=${encodeURIComponent(filePath)}&start_line=${startLine}&end_line=${endLine}`);\n\nexport const getDiffContext = (data: {\n  repo_id: string;\n  changes: { file_path: string; start_line?: number; end_line?: number }[];\n}) => apiFetch(\"/api/v1/query/diff-context\", { method: \"POST\", body: JSON.stringify(data) });\n\nexport const getFileSource = (repoId: string, filePath: string) =>\n  apiFetch(`/api/v1/query/file-source?repo_id=${encodeURIComponent(repoId)}&file_path=${encodeURIComponent(filePath)}`);\n\n// Auth\nexport const loginUser = (data: { github_access_token: string }) =>\n  apiFetch(\"/api/v1/auth/login\", { method: \"POST\", body: JSON.stringify(data) });\n\nexport const ensureUser = () =>\n  apiFetch(\"/api/v1/auth/ensure\", { method: \"POST\" });\n\nexport const getCurrentUser = () => apiFetch(\"/api/v1/auth/me\");\n\nexport const getGitHubRepos = (): Promise<GitHubRepo[]> =>\n  apiFetch(\"/api/v1/auth/github/repos\");\n\n// Additional query functions\nexport const getComplexity = (functionName: string, path?: string) => {\n  const params = new URLSearchParams({ function_name: functionName });\n  if (path) params.set(\"path\", path);\n  return apiFetch(`/api/v1/query/code-finder/complexity?${params}`);\n};\n\nexport const findRelatedCode = (query: string, fuzzy = false, depth = 2) =>\n  apiFetch(\n    `/api/v1/query/code-finder/content?query=${encodeURIComponent(query)}&fuzzy=${fuzzy}&depth=${depth}`\n  );\n\nexport const getLanguageSymbols = (language: string, symbolType: string, limit = 50) =>\n  apiFetch(\n    `/api/v1/query/language/symbols?language=${encodeURIComponent(language)}&symbol_type=${encodeURIComponent(symbolType)}&limit=${limit}`\n  );\n\nexport const findDefinition = (symbolName: string, repoId: string) =>\n  apiFetch(\n    `/api/v1/query/search-symbols?query=${encodeURIComponent(symbolName)}&repo_id=${encodeURIComponent(repoId)}`\n  );\n\nexport const findMethodUsages = (methodName: string) =>\n  apiFetch(`/api/v1/query/method-usages?method_name=${encodeURIComponent(methodName)}`);\n\nexport const getFileStructure = (repoId: string, filePath: string) =>\n  apiFetch(\n    `/api/v1/query/file-source?repo_id=${encodeURIComponent(repoId)}&file_path=${encodeURIComponent(filePath)}`\n  );\n\nexport const analyzeRelationships = (queryType: string, target: string, context?: string) => {\n  const params = new URLSearchParams({ symbol_name: target });\n  if (context) params.set(\"context\", context);\n  const endpoint =\n    queryType === \"class_hierarchy\"\n      ? `/api/v1/query/class_hierarchy?class_name=${encodeURIComponent(target)}`\n      : queryType === \"change_impact\"\n      ? `/api/v1/query/change_impact?symbol_name=${encodeURIComponent(target)}`\n      : `/api/v1/query/find_callers?symbol_name=${encodeURIComponent(target)}&query_type=${encodeURIComponent(queryType)}`;\n  return apiFetch(endpoint);\n};\n\n// Default export for direct api.X() usage in components\nconst api = {\n  findMethodUsages,\n  getFileStructure,\n  analyzeRelationships,\n  findDefinition,\n  getComplexity,\n  findRelatedCode,\n  getLanguageSymbols,\n};\n\nexport default api;\n","structuredPatch":[{"oldStart":195,"oldLines":10,"newStart":195,"newLines":8,"lines":["     `/api/v1/query/language/symbols?language=${encodeURIComponent(language)}&symbol_type=${encodeURIComponent(symbolType)}&limit=${limit}`","   );"," ","-export const findDefinition = (symbolName: string, repoId: string) =>","-  apiFetch(","-    `/api/v1/query/search-symbols?query=${encodeURIComponent(symbolName)}&repo_id=${encodeURIComponent(repoId)}`","-  );","+export const findDefinition = (symbolName: string, _repoId?: string) =>","+  apiFetch(`/api/v1/query/search?query=${encodeURIComponent(symbolName)}`);"," "," export const findMethodUsages = (methodName: string) =>","   apiFetch(`/api/v1/query/method-usages?method_name=${encodeURIComponent(methodName)}`);"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"55a7e81b-2bbb-44a3-b9d4-e4299262125f"}
{"parentUuid":"3f35629a-6b7f-4620-a248-1a98799e1839","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_016rQFZarq2FqfbjbMcAWQeW","type":"message","role":"assistant","content":[{"type":"text","text":"Now rewrite the query page with a proper unified search UI:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":286,"cache_read_input_tokens":121155,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":286},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLv37xaqxFcZsdqbwEc1","type":"assistant","uuid":"273ede0a-e9de-4e37-93ae-6f9647e03fed","timestamp":"2026-02-21T08:41:01.094Z"}
{"parentUuid":"273ede0a-e9de-4e37-93ae-6f9647e03fed","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_016rQFZarq2FqfbjbMcAWQeW","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013Y8pUY7QND9kN7Bif4mznu","name":"Write","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/frontend/app/(protected)/query/page.tsx","content":"\"use client\";\n\nimport { useState, useRef, useCallback } from \"react\";\nimport { Card, CardContent, CardHeader, CardTitle } from \"@/components/ui/card\";\nimport { Button } from \"@/components/ui/button\";\nimport { Input } from \"@/components/ui/input\";\nimport { Label } from \"@/components/ui/label\";\nimport { Textarea } from \"@/components/ui/textarea\";\nimport { Tabs, TabsContent, TabsList, TabsTrigger } from \"@/components/ui/tabs\";\nimport { Badge } from \"@/components/ui/badge\";\nimport { CodeBlock } from \"@/components/ui/code-block\";\nimport { toast } from \"sonner\";\nimport * as api from \"@/lib/api\";\n\n// ─── Types ────────────────────────────────────────────────────────────────────\n\ninterface SearchHit {\n  name?: string;\n  type?: string;\n  path?: string;\n  line_number?: number;\n  match_line?: string;\n  score?: number;\n}\n\ninterface PeekLine {\n  line_number: number;\n  content: string;\n  is_anchor: boolean;\n}\n\ninterface PeekResult {\n  path: string;\n  anchor_line: number;\n  window: PeekLine[];\n  total_lines: number;\n}\n\n// ─── PeekViewer ───────────────────────────────────────────────────────────────\n\nfunction PeekViewer({ path, anchorLine }: { path: string; anchorLine: number }) {\n  const STEP = 20;\n  const [above, setAbove] = useState(10);\n  const [below, setBelow] = useState(10);\n  const [result, setResult] = useState<PeekResult | null>(null);\n  const [loading, setLoading] = useState(false);\n  const [opened, setOpened] = useState(false);\n\n  const load = useCallback(async (a: number, b: number) => {\n    setLoading(true);\n    try {\n      const data = await api.peekFileLines(path, anchorLine, a, b);\n      setResult(data as PeekResult);\n      setAbove(a);\n      setBelow(b);\n    } catch {\n      toast.error(\"Failed to load context\");\n    } finally {\n      setLoading(false);\n    }\n  }, [path, anchorLine]);\n\n  if (!opened) {\n    return (\n      <button\n        className=\"text-xs text-primary underline-offset-2 hover:underline mt-1\"\n        onClick={() => { setOpened(true); load(above, below); }}\n      >\n        Show context\n      </button>\n    );\n  }\n\n  return (\n    <div className=\"mt-2 space-y-1.5\">\n      <div className=\"flex flex-wrap gap-2 items-center text-xs text-muted-foreground\">\n        <button\n          className=\"hover:text-foreground disabled:opacity-40\"\n          disabled={loading}\n          onClick={() => load(above + STEP, below)}\n        >\n          ↑ {STEP} more above\n        </button>\n        <span>·</span>\n        <button\n          className=\"hover:text-foreground disabled:opacity-40\"\n          disabled={loading}\n          onClick={() => load(above, below + STEP)}\n        >\n          {STEP} more below ↓\n        </button>\n        <span>·</span>\n        <button className=\"hover:text-foreground\" onClick={() => setOpened(false)}>\n          collapse\n        </button>\n        {result && (\n          <span className=\"ml-auto\">\n            lines {result.window[0]?.line_number}–{result.window[result.window.length - 1]?.line_number}\n            {\" \"}/ {result.total_lines}\n          </span>\n        )}\n      </div>\n\n      {result && (\n        <div className=\"rounded border border-border overflow-x-auto text-xs font-mono\">\n          {result.window.map((ln) => (\n            <div\n              key={ln.line_number}\n              className={`flex ${ln.is_anchor\n                ? \"bg-yellow-400/15 dark:bg-yellow-500/15 border-l-2 border-yellow-500\"\n                : \"hover:bg-muted/40\"\n              }`}\n            >\n              <span className=\"select-none w-12 text-right px-2 py-0.5 text-muted-foreground/60 shrink-0 border-r border-border\">\n                {ln.line_number}\n              </span>\n              <span className=\"px-3 py-0.5 whitespace-pre\">{ln.content}</span>\n            </div>\n          ))}\n        </div>\n      )}\n    </div>\n  );\n}\n\n// ─── Type badge colours ───────────────────────────────────────────────────────\n\nconst TYPE_STYLES: Record<string, string> = {\n  function: \"bg-blue-500/10 text-blue-600 dark:text-blue-400 border-blue-500/20\",\n  class:    \"bg-purple-500/10 text-purple-600 dark:text-purple-400 border-purple-500/20\",\n  variable: \"bg-green-500/10 text-green-600 dark:text-green-400 border-green-500/20\",\n  line:     \"bg-orange-500/10 text-orange-600 dark:text-orange-400 border-orange-500/20\",\n};\n\nfunction TypeBadge({ type }: { type: string }) {\n  return (\n    <span className={`inline-flex items-center px-1.5 py-0.5 rounded text-xs font-medium border ${TYPE_STYLES[type] ?? \"bg-muted text-muted-foreground border-border\"}`}>\n      {type}\n    </span>\n  );\n}\n\n// ─── Search Result Card ───────────────────────────────────────────────────────\n\nfunction SearchHitCard({ hit }: { hit: SearchHit }) {\n  const filename = hit.path ? hit.path.split(\"/\").pop() : null;\n  const dirPath  = hit.path && filename ? hit.path.slice(0, hit.path.length - filename.length - 1) : null;\n  const hasLine  = hit.line_number != null && hit.line_number > 0;\n\n  return (\n    <div className=\"group rounded-lg border border-border bg-card px-4 py-3 space-y-1.5 hover:border-primary/40 transition-colors\">\n      {/* Header */}\n      <div className=\"flex items-start gap-2\">\n        {hit.type && <TypeBadge type={hit.type} />}\n        <span className=\"font-mono font-semibold text-sm leading-tight break-all\">\n          {hit.name ?? hit.match_line?.trim()}\n        </span>\n        {hit.score != null && (\n          <span className=\"ml-auto shrink-0 text-xs text-muted-foreground/50\">\n            {hit.score.toFixed(2)}\n          </span>\n        )}\n      </div>\n\n      {/* Path */}\n      {hit.path && (\n        <div className=\"flex items-center gap-1 text-xs text-muted-foreground font-mono\">\n          {dirPath && <span className=\"opacity-60 truncate\">{dirPath}/</span>}\n          {filename && <span className=\"text-foreground/80 font-medium\">{filename}</span>}\n          {hasLine && (\n            <span className=\"shrink-0 px-1 rounded bg-muted text-foreground/70\">:{hit.line_number}</span>\n          )}\n        </div>\n      )}\n\n      {/* Match snippet (for line-type results where name IS the code line) */}\n      {hit.type === \"line\" && hit.name && (\n        <pre className=\"text-xs text-muted-foreground bg-muted/50 rounded px-2 py-1 overflow-x-auto\">{hit.name}</pre>\n      )}\n\n      {/* Peek */}\n      {hit.path && hasLine && (\n        <PeekViewer path={hit.path} anchorLine={hit.line_number!} />\n      )}\n    </div>\n  );\n}\n\n// ─── Unified Search Results ───────────────────────────────────────────────────\n\nfunction SearchResultsView({ data }: { data: unknown }) {\n  let hits: SearchHit[] = [];\n  if (Array.isArray(data)) {\n    hits = data as SearchHit[];\n  } else if (data && typeof data === \"object\") {\n    const obj = data as Record<string, unknown>;\n    const inner = obj.results ?? obj.symbols ?? obj.ranked_results ?? [];\n    if (Array.isArray(inner)) hits = inner as SearchHit[];\n  }\n\n  if (hits.length === 0) {\n    return (\n      <div className=\"py-12 text-center text-muted-foreground text-sm\">\n        No results found.\n      </div>\n    );\n  }\n\n  const symbols = hits.filter((h) => h.type !== \"line\");\n  const lines   = hits.filter((h) => h.type === \"line\");\n\n  return (\n    <div className=\"space-y-4\">\n      {/* Summary row */}\n      <div className=\"flex gap-2 text-xs text-muted-foreground\">\n        <span>{hits.length} results</span>\n        {symbols.length > 0 && <span>· {symbols.length} symbols</span>}\n        {lines.length > 0   && <span>· {lines.length} file matches</span>}\n      </div>\n\n      {symbols.length > 0 && (\n        <section className=\"space-y-2\">\n          {symbols.length > 0 && lines.length > 0 && (\n            <h3 className=\"text-xs font-semibold uppercase tracking-wider text-muted-foreground\">Symbols</h3>\n          )}\n          {symbols.map((hit, i) => <SearchHitCard key={i} hit={hit} />)}\n        </section>\n      )}\n\n      {lines.length > 0 && (\n        <section className=\"space-y-2\">\n          {symbols.length > 0 && lines.length > 0 && (\n            <h3 className=\"text-xs font-semibold uppercase tracking-wider text-muted-foreground\">File matches</h3>\n          )}\n          {lines.map((hit, i) => <SearchHitCard key={i} hit={hit} />)}\n        </section>\n      )}\n    </div>\n  );\n}\n\n// ─── Unified Search Tab ───────────────────────────────────────────────────────\n\nfunction SearchTab() {\n  const [query, setQuery] = useState(\"\");\n  const [loading, setLoading] = useState(false);\n  const [results, setResults] = useState<unknown>(null);\n  const inputRef = useRef<HTMLInputElement>(null);\n\n  const runSearch = async (q = query) => {\n    const term = q.trim();\n    if (!term) { inputRef.current?.focus(); return; }\n    setLoading(true);\n    setResults(null);\n    try {\n      const data = await api.searchCode(term);\n      setResults(data);\n    } catch (e) {\n      toast.error(`Search failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"space-y-4 pt-4\">\n      {/* Search bar */}\n      <div className=\"flex gap-2\">\n        <Input\n          ref={inputRef}\n          placeholder=\"Search by name, snippet, or code pattern — e.g. GitHubRepo or class LoginRequest(BaseModel)\"\n          value={query}\n          onChange={(e) => setQuery(e.target.value)}\n          onKeyDown={(e) => { if (e.key === \"Enter\") runSearch(); }}\n          className=\"text-sm\"\n          autoFocus\n        />\n        <Button onClick={() => runSearch()} disabled={loading} className=\"shrink-0\">\n          {loading ? \"Searching…\" : \"Search\"}\n        </Button>\n      </div>\n\n      {/* Hint */}\n      {results === null && !loading && (\n        <p className=\"text-xs text-muted-foreground\">\n          Searches symbols (functions, classes, variables) and file content. Supports identifiers, code snippets, and keywords.\n        </p>\n      )}\n\n      {/* Loading */}\n      {loading && (\n        <div className=\"py-10 text-center text-muted-foreground text-sm animate-pulse\">Searching…</div>\n      )}\n\n      {/* Results */}\n      {!loading && results !== null && <SearchResultsView data={results} />}\n    </div>\n  );\n}\n\n// ─── Analysis / CodeFinder / Metrics shared pattern ──────────────────────────\n\ntype QueryDef = {\n  label: string;\n  placeholder: string;\n  fn: (q: string) => Promise<unknown>;\n  needsInput: boolean;\n};\n\nconst queryGroups: Record<string, QueryDef[]> = {\n  Analysis: [\n    { label: \"Method Usages\",  placeholder: \"Method name…\",  fn: api.getMethodUsages,  needsInput: true },\n    { label: \"Find Callers\",   placeholder: \"Symbol name…\",  fn: api.findCallers,       needsInput: true },\n    { label: \"Class Hierarchy\",placeholder: \"Class name…\",   fn: api.getClassHierarchy, needsInput: true },\n    { label: \"Change Impact\",  placeholder: \"Symbol name…\",  fn: api.getChangeImpact,   needsInput: true },\n  ],\n  CodeFinder: [\n    { label: \"Function\",    placeholder: \"Function name…\",   fn: api.findFunction,  needsInput: true },\n    { label: \"Class\",       placeholder: \"Class name…\",      fn: api.findClass,     needsInput: true },\n    { label: \"Variable\",    placeholder: \"Variable name…\",   fn: api.findVariable,  needsInput: true },\n    { label: \"Content\",     placeholder: \"Content query…\",   fn: api.findContent,   needsInput: true },\n    { label: \"Module\",      placeholder: \"Module name…\",     fn: api.findModule,    needsInput: true },\n    { label: \"Imports\",     placeholder: \"Import name…\",     fn: api.findImports,   needsInput: true },\n    { label: \"Line Search\", placeholder: \"Code line to find…\", fn: api.findByLine, needsInput: true },\n  ],\n  Metrics: [\n    { label: \"Graph Stats\",           placeholder: \"\", fn: api.getGraphStats,          needsInput: false },\n    { label: \"Language Stats\",        placeholder: \"\", fn: api.getLanguageStats,        needsInput: false },\n    { label: \"Top Complex Functions\", placeholder: \"\", fn: api.getTopComplexFunctions,  needsInput: false },\n  ],\n};\n\nfunction GenericQueryTab({ queries }: { queries: QueryDef[] }) {\n  const [input, setInput]           = useState(\"\");\n  const [loading, setLoading]       = useState(false);\n  const [results, setResults]       = useState<unknown>(null);\n  const [activeLabel, setActiveLabel] = useState<string>(\"\");\n\n  const run = async (q: QueryDef) => {\n    if (q.needsInput && !input.trim()) { toast.error(\"Enter a query first\"); return; }\n    setLoading(true);\n    setActiveLabel(q.label);\n    setResults(null);\n    try {\n      setResults(await q.fn(input.trim()));\n    } catch (e) {\n      toast.error(`Failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"space-y-4 pt-4\">\n      <Input\n        placeholder=\"Enter name or query…\"\n        value={input}\n        onChange={(e) => setInput(e.target.value)}\n        onKeyDown={(e) => {\n          if (e.key === \"Enter\" && activeLabel) {\n            const q = queries.find((q) => q.label === activeLabel);\n            if (q) run(q);\n          }\n        }}\n        className=\"text-sm\"\n      />\n      <div className=\"flex flex-wrap gap-2\">\n        {queries.map((q) => (\n          <Button\n            key={q.label}\n            variant={activeLabel === q.label ? \"default\" : \"secondary\"}\n            size=\"sm\"\n            onClick={() => run(q)}\n            disabled={loading}\n          >\n            {q.label}\n          </Button>\n        ))}\n      </div>\n\n      {loading && (\n        <Card>\n          <CardContent className=\"py-8 text-center text-muted-foreground animate-pulse\">Loading…</CardContent>\n        </Card>\n      )}\n\n      {!loading && results !== null && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm text-muted-foreground\">{activeLabel}</CardTitle>\n          </CardHeader>\n          <CardContent>\n            <ResultsView data={results} />\n          </CardContent>\n        </Card>\n      )}\n    </div>\n  );\n}\n\n// ─── Main page ────────────────────────────────────────────────────────────────\n\nexport default function QueryPage() {\n  const [diffRepoId, setDiffRepoId]       = useState(\"\");\n  const [diffChangesText, setDiffChangesText] = useState(\"\");\n  const [diffLoading, setDiffLoading]     = useState(false);\n  const [diffResults, setDiffResults]     = useState<unknown>(null);\n\n  const runDiffContext = async () => {\n    if (!diffRepoId.trim()) { toast.error(\"Enter a repository ID\"); return; }\n    const lines = diffChangesText.trim().split(\"\\n\").filter(Boolean);\n    const changes = lines.map((line) => {\n      const [filePath, range] = line.split(\":\");\n      if (range) {\n        const [start, end] = range.split(\"-\").map(Number);\n        return { file_path: filePath.trim(), start_line: start || 1, end_line: end || 999999 };\n      }\n      return { file_path: filePath.trim() };\n    });\n    if (changes.length === 0) { toast.error(\"Enter at least one file change\"); return; }\n    setDiffLoading(true);\n    setDiffResults(null);\n    try {\n      setDiffResults(await api.getDiffContext({ repo_id: diffRepoId.trim(), changes }));\n    } catch (e) {\n      toast.error(`Diff context failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);\n    } finally {\n      setDiffLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"max-w-5xl mx-auto space-y-6\">\n      <h1 className=\"text-2xl font-bold\">Query</h1>\n\n      <Tabs defaultValue=\"Search\">\n        <TabsList>\n          <TabsTrigger value=\"Search\">Search</TabsTrigger>\n          <TabsTrigger value=\"Analysis\">Analysis</TabsTrigger>\n          <TabsTrigger value=\"CodeFinder\">CodeFinder</TabsTrigger>\n          <TabsTrigger value=\"Metrics\">Metrics</TabsTrigger>\n          <TabsTrigger value=\"DiffContext\">Code Review</TabsTrigger>\n        </TabsList>\n\n        <TabsContent value=\"Search\">\n          <SearchTab />\n        </TabsContent>\n\n        {Object.entries(queryGroups).map(([group, queries]) => (\n          <TabsContent key={group} value={group}>\n            <GenericQueryTab queries={queries} />\n          </TabsContent>\n        ))}\n\n        <TabsContent value=\"DiffContext\" className=\"space-y-4 pt-4\">\n          <Card>\n            <CardHeader><CardTitle>Diff Context Builder</CardTitle></CardHeader>\n            <CardContent className=\"space-y-4\">\n              <p className=\"text-sm text-muted-foreground\">\n                Build RAG context for code review. Provide the repository and changed files\n                to get affected symbols, callers, class hierarchy, and source.\n              </p>\n              <div className=\"space-y-2\">\n                <Label>Repository ID</Label>\n                <Input\n                  placeholder=\"owner/repo_name\"\n                  value={diffRepoId}\n                  onChange={(e) => setDiffRepoId(e.target.value)}\n                />\n              </div>\n              <div className=\"space-y-2\">\n                <Label>Changed Files</Label>\n                <Textarea\n                  placeholder={\"One per line — file_path:start_line-end_line\\n\\nExamples:\\nsrc/main.py:10-30\\nsrc/utils.py:1-50\"}\n                  value={diffChangesText}\n                  onChange={(e) => setDiffChangesText(e.target.value)}\n                  rows={6}\n                  className=\"font-mono text-sm\"\n                />\n              </div>\n              <Button onClick={runDiffContext} disabled={diffLoading}>\n                {diffLoading ? \"Loading…\" : \"Get Diff Context\"}\n              </Button>\n            </CardContent>\n          </Card>\n          {diffResults !== null && <DiffContextResults data={diffResults as DiffContextData} />}\n        </TabsContent>\n      </Tabs>\n    </div>\n  );\n}\n\n// ─── Diff Context Results ──────────────────────────────────────────────────────\n\ninterface DiffContextData {\n  affected_symbols: {\n    type: string; name: string; start_line: number; end_line: number;\n    source: string | null; docstring: string | null; change_file: string;\n  }[];\n  callers: {\n    symbol: string; symbol_type: string;\n    callers: { type: string; name: string; path: string; source: string | null }[];\n  }[];\n  class_hierarchy: { class: string; hierarchy: { name: string; path: string }[] }[];\n  file_sources: Record<string, string>;\n  total_affected: number;\n  total_files: number;\n}\n\nfunction DiffContextResults({ data }: { data: DiffContextData }) {\n  return (\n    <div className=\"space-y-4\">\n      <div className=\"flex gap-3\">\n        <Badge variant=\"secondary\">{data.total_files} files</Badge>\n        <Badge variant=\"secondary\">{data.total_affected} affected symbols</Badge>\n        <Badge variant=\"secondary\">{data.callers.length} caller chains</Badge>\n        <Badge variant=\"secondary\">{data.class_hierarchy.length} class hierarchies</Badge>\n      </div>\n\n      {data.affected_symbols.length > 0 && (\n        <Card>\n          <CardHeader><CardTitle className=\"text-sm\">Affected Symbols</CardTitle></CardHeader>\n          <CardContent className=\"space-y-2 max-h-96 overflow-y-auto\">\n            {data.affected_symbols.map((sym, i) => (\n              <div key={i} className=\"p-3 rounded border border-border space-y-1\">\n                <div className=\"flex items-center gap-2\">\n                  <Badge variant={sym.type === \"function\" ? \"default\" : \"secondary\"}>{sym.type}</Badge>\n                  <span className=\"font-medium font-mono\">{sym.name}</span>\n                  <span className=\"text-xs text-muted-foreground\">{sym.change_file}:{sym.start_line}-{sym.end_line}</span>\n                </div>\n                {sym.docstring && <p className=\"text-xs text-muted-foreground\">{sym.docstring}</p>}\n                {sym.source && <CodeBlock code={sym.source} startLine={sym.start_line} maxHeight=\"max-h-48\" />}\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {data.callers.length > 0 && (\n        <Card>\n          <CardHeader><CardTitle className=\"text-sm\">Callers</CardTitle></CardHeader>\n          <CardContent className=\"space-y-3 max-h-96 overflow-y-auto\">\n            {data.callers.map((group, i) => (\n              <div key={i} className=\"space-y-1\">\n                <p className=\"text-sm font-medium\">\n                  <Badge variant=\"outline\" className=\"mr-1\">{group.symbol_type}</Badge>\n                  <span className=\"font-mono\">{group.symbol}</span>\n                  <span className=\"text-muted-foreground ml-1\">called by:</span>\n                </p>\n                {group.callers.map((caller, j) => (\n                  <div key={j} className=\"ml-4 p-2 rounded border border-border text-sm\">\n                    <span className=\"font-mono\">{caller.name}</span>\n                    <span className=\"text-xs text-muted-foreground ml-2\">{caller.path}</span>\n                    {caller.source && <CodeBlock code={caller.source} maxHeight=\"max-h-32\" className=\"mt-1\" />}\n                  </div>\n                ))}\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {data.class_hierarchy.length > 0 && (\n        <Card>\n          <CardHeader><CardTitle className=\"text-sm\">Class Hierarchy</CardTitle></CardHeader>\n          <CardContent className=\"space-y-2 max-h-72 overflow-y-auto\">\n            {data.class_hierarchy.map((h, i) => (\n              <div key={i} className=\"space-y-1\">\n                <p className=\"text-sm font-medium font-mono\">{h.class}</p>\n                <div className=\"ml-4 space-y-1\">\n                  {h.hierarchy.map((parent, j) => (\n                    <div key={j} className=\"flex items-center gap-2 text-sm\">\n                      <span className=\"text-muted-foreground\">{j === 0 ? \"\" : \"└─\"}</span>\n                      <span className=\"font-mono\">{parent.name}</span>\n                      <span className=\"text-xs text-muted-foreground\">{parent.path}</span>\n                    </div>\n                  ))}\n                </div>\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {Object.keys(data.file_sources).length > 0 && (\n        <Card>\n          <CardHeader><CardTitle className=\"text-sm\">File Sources</CardTitle></CardHeader>\n          <CardContent className=\"space-y-3 max-h-96 overflow-y-auto\">\n            {Object.entries(data.file_sources).map(([path, source]) => (\n              <div key={path} className=\"space-y-1\">\n                <p className=\"text-sm font-mono text-primary\">{path}</p>\n                <CodeBlock code={source} maxHeight=\"max-h-64\" />\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n    </div>\n  );\n}\n\n// ─── Generic JSON Results ─────────────────────────────────────────────────────\n\nfunction ResultsView({ data }: { data: unknown }) {\n  if (!data) return <p className=\"text-muted-foreground text-sm\">No results</p>;\n\n  if (Array.isArray(data)) {\n    if (data.length === 0) return <p className=\"text-muted-foreground text-sm\">No results found</p>;\n    return (\n      <div className=\"space-y-2 max-h-[600px] overflow-y-auto\">\n        {data.map((item, i) => (\n          <div key={i} className=\"p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n            {typeof item === \"object\" ? <ObjectView obj={item} /> : String(item)}\n          </div>\n        ))}\n      </div>\n    );\n  }\n\n  if (typeof data === \"object\") return <ObjectView obj={data as Record<string, unknown>} />;\n  return <pre className=\"text-sm font-mono\">{String(data)}</pre>;\n}\n\nfunction ObjectView({ obj }: { obj: Record<string, unknown> }) {\n  return (\n    <div className=\"space-y-1\">\n      {Object.entries(obj).map(([key, value]) => {\n        if (key === \"source\" && typeof value === \"string\" && value) {\n          const startLine = (obj.line_number as number) || (obj.start_line as number) || 1;\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <CodeBlock code={value} startLine={startLine} maxHeight=\"max-h-64\" />\n            </div>\n          );\n        }\n        if (Array.isArray(value)) {\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              {value.length === 0\n                ? <span className=\"text-muted-foreground ml-2\">[]</span>\n                : (\n                  <div className=\"ml-4 space-y-2\">\n                    {value.map((item, i) => (\n                      <div key={i} className=\"p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n                        {typeof item === \"object\" && item !== null ? <ObjectView obj={item as Record<string, unknown>} /> : String(item)}\n                      </div>\n                    ))}\n                  </div>\n                )}\n            </div>\n          );\n        }\n        if (typeof value === \"object\" && value !== null) {\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <div className=\"ml-4 p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n                <ObjectView obj={value as Record<string, unknown>} />\n              </div>\n            </div>\n          );\n        }\n        return (\n          <div key={key} className=\"flex gap-2\">\n            <span className=\"text-primary font-medium shrink-0\">{key}:</span>\n            <span className=\"text-muted-foreground break-all\">{String(value ?? \"—\")}</span>\n          </div>\n        );\n      })}\n    </div>\n  );\n}\n"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":286,"cache_read_input_tokens":121155,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":286},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLv37xaqxFcZsdqbwEc1","type":"assistant","uuid":"739335d0-b2b8-4e08-bb86-53441d0fcb5e","timestamp":"2026-02-21T08:42:31.146Z"}
{"parentUuid":"739335d0-b2b8-4e08-bb86-53441d0fcb5e","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Write","command":"callback"},"parentToolUseID":"toolu_013Y8pUY7QND9kN7Bif4mznu","toolUseID":"toolu_013Y8pUY7QND9kN7Bif4mznu","timestamp":"2026-02-21T08:42:31.304Z","uuid":"e065cf09-66c4-46f2-bb94-6f719bf1c515"}
{"parentUuid":"739335d0-b2b8-4e08-bb86-53441d0fcb5e","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013Y8pUY7QND9kN7Bif4mznu","type":"tool_result","content":"The file /Users/skmabudalam/Documents/BugViper/frontend/app/(protected)/query/page.tsx has been updated successfully."}]},"uuid":"d27848a1-49c7-4ca9-9768-e60ba387958a","timestamp":"2026-02-21T08:42:31.302Z","toolUseResult":{"type":"update","filePath":"/Users/skmabudalam/Documents/BugViper/frontend/app/(protected)/query/page.tsx","content":"\"use client\";\n\nimport { useState, useRef, useCallback } from \"react\";\nimport { Card, CardContent, CardHeader, CardTitle } from \"@/components/ui/card\";\nimport { Button } from \"@/components/ui/button\";\nimport { Input } from \"@/components/ui/input\";\nimport { Label } from \"@/components/ui/label\";\nimport { Textarea } from \"@/components/ui/textarea\";\nimport { Tabs, TabsContent, TabsList, TabsTrigger } from \"@/components/ui/tabs\";\nimport { Badge } from \"@/components/ui/badge\";\nimport { CodeBlock } from \"@/components/ui/code-block\";\nimport { toast } from \"sonner\";\nimport * as api from \"@/lib/api\";\n\n// ─── Types ────────────────────────────────────────────────────────────────────\n\ninterface SearchHit {\n  name?: string;\n  type?: string;\n  path?: string;\n  line_number?: number;\n  match_line?: string;\n  score?: number;\n}\n\ninterface PeekLine {\n  line_number: number;\n  content: string;\n  is_anchor: boolean;\n}\n\ninterface PeekResult {\n  path: string;\n  anchor_line: number;\n  window: PeekLine[];\n  total_lines: number;\n}\n\n// ─── PeekViewer ───────────────────────────────────────────────────────────────\n\nfunction PeekViewer({ path, anchorLine }: { path: string; anchorLine: number }) {\n  const STEP = 20;\n  const [above, setAbove] = useState(10);\n  const [below, setBelow] = useState(10);\n  const [result, setResult] = useState<PeekResult | null>(null);\n  const [loading, setLoading] = useState(false);\n  const [opened, setOpened] = useState(false);\n\n  const load = useCallback(async (a: number, b: number) => {\n    setLoading(true);\n    try {\n      const data = await api.peekFileLines(path, anchorLine, a, b);\n      setResult(data as PeekResult);\n      setAbove(a);\n      setBelow(b);\n    } catch {\n      toast.error(\"Failed to load context\");\n    } finally {\n      setLoading(false);\n    }\n  }, [path, anchorLine]);\n\n  if (!opened) {\n    return (\n      <button\n        className=\"text-xs text-primary underline-offset-2 hover:underline mt-1\"\n        onClick={() => { setOpened(true); load(above, below); }}\n      >\n        Show context\n      </button>\n    );\n  }\n\n  return (\n    <div className=\"mt-2 space-y-1.5\">\n      <div className=\"flex flex-wrap gap-2 items-center text-xs text-muted-foreground\">\n        <button\n          className=\"hover:text-foreground disabled:opacity-40\"\n          disabled={loading}\n          onClick={() => load(above + STEP, below)}\n        >\n          ↑ {STEP} more above\n        </button>\n        <span>·</span>\n        <button\n          className=\"hover:text-foreground disabled:opacity-40\"\n          disabled={loading}\n          onClick={() => load(above, below + STEP)}\n        >\n          {STEP} more below ↓\n        </button>\n        <span>·</span>\n        <button className=\"hover:text-foreground\" onClick={() => setOpened(false)}>\n          collapse\n        </button>\n        {result && (\n          <span className=\"ml-auto\">\n            lines {result.window[0]?.line_number}–{result.window[result.window.length - 1]?.line_number}\n            {\" \"}/ {result.total_lines}\n          </span>\n        )}\n      </div>\n\n      {result && (\n        <div className=\"rounded border border-border overflow-x-auto text-xs font-mono\">\n          {result.window.map((ln) => (\n            <div\n              key={ln.line_number}\n              className={`flex ${ln.is_anchor\n                ? \"bg-yellow-400/15 dark:bg-yellow-500/15 border-l-2 border-yellow-500\"\n                : \"hover:bg-muted/40\"\n              }`}\n            >\n              <span className=\"select-none w-12 text-right px-2 py-0.5 text-muted-foreground/60 shrink-0 border-r border-border\">\n                {ln.line_number}\n              </span>\n              <span className=\"px-3 py-0.5 whitespace-pre\">{ln.content}</span>\n            </div>\n          ))}\n        </div>\n      )}\n    </div>\n  );\n}\n\n// ─── Type badge colours ───────────────────────────────────────────────────────\n\nconst TYPE_STYLES: Record<string, string> = {\n  function: \"bg-blue-500/10 text-blue-600 dark:text-blue-400 border-blue-500/20\",\n  class:    \"bg-purple-500/10 text-purple-600 dark:text-purple-400 border-purple-500/20\",\n  variable: \"bg-green-500/10 text-green-600 dark:text-green-400 border-green-500/20\",\n  line:     \"bg-orange-500/10 text-orange-600 dark:text-orange-400 border-orange-500/20\",\n};\n\nfunction TypeBadge({ type }: { type: string }) {\n  return (\n    <span className={`inline-flex items-center px-1.5 py-0.5 rounded text-xs font-medium border ${TYPE_STYLES[type] ?? \"bg-muted text-muted-foreground border-border\"}`}>\n      {type}\n    </span>\n  );\n}\n\n// ─── Search Result Card ───────────────────────────────────────────────────────\n\nfunction SearchHitCard({ hit }: { hit: SearchHit }) {\n  const filename = hit.path ? hit.path.split(\"/\").pop() : null;\n  const dirPath  = hit.path && filename ? hit.path.slice(0, hit.path.length - filename.length - 1) : null;\n  const hasLine  = hit.line_number != null && hit.line_number > 0;\n\n  return (\n    <div className=\"group rounded-lg border border-border bg-card px-4 py-3 space-y-1.5 hover:border-primary/40 transition-colors\">\n      {/* Header */}\n      <div className=\"flex items-start gap-2\">\n        {hit.type && <TypeBadge type={hit.type} />}\n        <span className=\"font-mono font-semibold text-sm leading-tight break-all\">\n          {hit.name ?? hit.match_line?.trim()}\n        </span>\n        {hit.score != null && (\n          <span className=\"ml-auto shrink-0 text-xs text-muted-foreground/50\">\n            {hit.score.toFixed(2)}\n          </span>\n        )}\n      </div>\n\n      {/* Path */}\n      {hit.path && (\n        <div className=\"flex items-center gap-1 text-xs text-muted-foreground font-mono\">\n          {dirPath && <span className=\"opacity-60 truncate\">{dirPath}/</span>}\n          {filename && <span className=\"text-foreground/80 font-medium\">{filename}</span>}\n          {hasLine && (\n            <span className=\"shrink-0 px-1 rounded bg-muted text-foreground/70\">:{hit.line_number}</span>\n          )}\n        </div>\n      )}\n\n      {/* Match snippet (for line-type results where name IS the code line) */}\n      {hit.type === \"line\" && hit.name && (\n        <pre className=\"text-xs text-muted-foreground bg-muted/50 rounded px-2 py-1 overflow-x-auto\">{hit.name}</pre>\n      )}\n\n      {/* Peek */}\n      {hit.path && hasLine && (\n        <PeekViewer path={hit.path} anchorLine={hit.line_number!} />\n      )}\n    </div>\n  );\n}\n\n// ─── Unified Search Results ───────────────────────────────────────────────────\n\nfunction SearchResultsView({ data }: { data: unknown }) {\n  let hits: SearchHit[] = [];\n  if (Array.isArray(data)) {\n    hits = data as SearchHit[];\n  } else if (data && typeof data === \"object\") {\n    const obj = data as Record<string, unknown>;\n    const inner = obj.results ?? obj.symbols ?? obj.ranked_results ?? [];\n    if (Array.isArray(inner)) hits = inner as SearchHit[];\n  }\n\n  if (hits.length === 0) {\n    return (\n      <div className=\"py-12 text-center text-muted-foreground text-sm\">\n        No results found.\n      </div>\n    );\n  }\n\n  const symbols = hits.filter((h) => h.type !== \"line\");\n  const lines   = hits.filter((h) => h.type === \"line\");\n\n  return (\n    <div className=\"space-y-4\">\n      {/* Summary row */}\n      <div className=\"flex gap-2 text-xs text-muted-foreground\">\n        <span>{hits.length} results</span>\n        {symbols.length > 0 && <span>· {symbols.length} symbols</span>}\n        {lines.length > 0   && <span>· {lines.length} file matches</span>}\n      </div>\n\n      {symbols.length > 0 && (\n        <section className=\"space-y-2\">\n          {symbols.length > 0 && lines.length > 0 && (\n            <h3 className=\"text-xs font-semibold uppercase tracking-wider text-muted-foreground\">Symbols</h3>\n          )}\n          {symbols.map((hit, i) => <SearchHitCard key={i} hit={hit} />)}\n        </section>\n      )}\n\n      {lines.length > 0 && (\n        <section className=\"space-y-2\">\n          {symbols.length > 0 && lines.length > 0 && (\n            <h3 className=\"text-xs font-semibold uppercase tracking-wider text-muted-foreground\">File matches</h3>\n          )}\n          {lines.map((hit, i) => <SearchHitCard key={i} hit={hit} />)}\n        </section>\n      )}\n    </div>\n  );\n}\n\n// ─── Unified Search Tab ───────────────────────────────────────────────────────\n\nfunction SearchTab() {\n  const [query, setQuery] = useState(\"\");\n  const [loading, setLoading] = useState(false);\n  const [results, setResults] = useState<unknown>(null);\n  const inputRef = useRef<HTMLInputElement>(null);\n\n  const runSearch = async (q = query) => {\n    const term = q.trim();\n    if (!term) { inputRef.current?.focus(); return; }\n    setLoading(true);\n    setResults(null);\n    try {\n      const data = await api.searchCode(term);\n      setResults(data);\n    } catch (e) {\n      toast.error(`Search failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"space-y-4 pt-4\">\n      {/* Search bar */}\n      <div className=\"flex gap-2\">\n        <Input\n          ref={inputRef}\n          placeholder=\"Search by name, snippet, or code pattern — e.g. GitHubRepo or class LoginRequest(BaseModel)\"\n          value={query}\n          onChange={(e) => setQuery(e.target.value)}\n          onKeyDown={(e) => { if (e.key === \"Enter\") runSearch(); }}\n          className=\"text-sm\"\n          autoFocus\n        />\n        <Button onClick={() => runSearch()} disabled={loading} className=\"shrink-0\">\n          {loading ? \"Searching…\" : \"Search\"}\n        </Button>\n      </div>\n\n      {/* Hint */}\n      {results === null && !loading && (\n        <p className=\"text-xs text-muted-foreground\">\n          Searches symbols (functions, classes, variables) and file content. Supports identifiers, code snippets, and keywords.\n        </p>\n      )}\n\n      {/* Loading */}\n      {loading && (\n        <div className=\"py-10 text-center text-muted-foreground text-sm animate-pulse\">Searching…</div>\n      )}\n\n      {/* Results */}\n      {!loading && results !== null && <SearchResultsView data={results} />}\n    </div>\n  );\n}\n\n// ─── Analysis / CodeFinder / Metrics shared pattern ──────────────────────────\n\ntype QueryDef = {\n  label: string;\n  placeholder: string;\n  fn: (q: string) => Promise<unknown>;\n  needsInput: boolean;\n};\n\nconst queryGroups: Record<string, QueryDef[]> = {\n  Analysis: [\n    { label: \"Method Usages\",  placeholder: \"Method name…\",  fn: api.getMethodUsages,  needsInput: true },\n    { label: \"Find Callers\",   placeholder: \"Symbol name…\",  fn: api.findCallers,       needsInput: true },\n    { label: \"Class Hierarchy\",placeholder: \"Class name…\",   fn: api.getClassHierarchy, needsInput: true },\n    { label: \"Change Impact\",  placeholder: \"Symbol name…\",  fn: api.getChangeImpact,   needsInput: true },\n  ],\n  CodeFinder: [\n    { label: \"Function\",    placeholder: \"Function name…\",   fn: api.findFunction,  needsInput: true },\n    { label: \"Class\",       placeholder: \"Class name…\",      fn: api.findClass,     needsInput: true },\n    { label: \"Variable\",    placeholder: \"Variable name…\",   fn: api.findVariable,  needsInput: true },\n    { label: \"Content\",     placeholder: \"Content query…\",   fn: api.findContent,   needsInput: true },\n    { label: \"Module\",      placeholder: \"Module name…\",     fn: api.findModule,    needsInput: true },\n    { label: \"Imports\",     placeholder: \"Import name…\",     fn: api.findImports,   needsInput: true },\n    { label: \"Line Search\", placeholder: \"Code line to find…\", fn: api.findByLine, needsInput: true },\n  ],\n  Metrics: [\n    { label: \"Graph Stats\",           placeholder: \"\", fn: api.getGraphStats,          needsInput: false },\n    { label: \"Language Stats\",        placeholder: \"\", fn: api.getLanguageStats,        needsInput: false },\n    { label: \"Top Complex Functions\", placeholder: \"\", fn: api.getTopComplexFunctions,  needsInput: false },\n  ],\n};\n\nfunction GenericQueryTab({ queries }: { queries: QueryDef[] }) {\n  const [input, setInput]           = useState(\"\");\n  const [loading, setLoading]       = useState(false);\n  const [results, setResults]       = useState<unknown>(null);\n  const [activeLabel, setActiveLabel] = useState<string>(\"\");\n\n  const run = async (q: QueryDef) => {\n    if (q.needsInput && !input.trim()) { toast.error(\"Enter a query first\"); return; }\n    setLoading(true);\n    setActiveLabel(q.label);\n    setResults(null);\n    try {\n      setResults(await q.fn(input.trim()));\n    } catch (e) {\n      toast.error(`Failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"space-y-4 pt-4\">\n      <Input\n        placeholder=\"Enter name or query…\"\n        value={input}\n        onChange={(e) => setInput(e.target.value)}\n        onKeyDown={(e) => {\n          if (e.key === \"Enter\" && activeLabel) {\n            const q = queries.find((q) => q.label === activeLabel);\n            if (q) run(q);\n          }\n        }}\n        className=\"text-sm\"\n      />\n      <div className=\"flex flex-wrap gap-2\">\n        {queries.map((q) => (\n          <Button\n            key={q.label}\n            variant={activeLabel === q.label ? \"default\" : \"secondary\"}\n            size=\"sm\"\n            onClick={() => run(q)}\n            disabled={loading}\n          >\n            {q.label}\n          </Button>\n        ))}\n      </div>\n\n      {loading && (\n        <Card>\n          <CardContent className=\"py-8 text-center text-muted-foreground animate-pulse\">Loading…</CardContent>\n        </Card>\n      )}\n\n      {!loading && results !== null && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm text-muted-foreground\">{activeLabel}</CardTitle>\n          </CardHeader>\n          <CardContent>\n            <ResultsView data={results} />\n          </CardContent>\n        </Card>\n      )}\n    </div>\n  );\n}\n\n// ─── Main page ────────────────────────────────────────────────────────────────\n\nexport default function QueryPage() {\n  const [diffRepoId, setDiffRepoId]       = useState(\"\");\n  const [diffChangesText, setDiffChangesText] = useState(\"\");\n  const [diffLoading, setDiffLoading]     = useState(false);\n  const [diffResults, setDiffResults]     = useState<unknown>(null);\n\n  const runDiffContext = async () => {\n    if (!diffRepoId.trim()) { toast.error(\"Enter a repository ID\"); return; }\n    const lines = diffChangesText.trim().split(\"\\n\").filter(Boolean);\n    const changes = lines.map((line) => {\n      const [filePath, range] = line.split(\":\");\n      if (range) {\n        const [start, end] = range.split(\"-\").map(Number);\n        return { file_path: filePath.trim(), start_line: start || 1, end_line: end || 999999 };\n      }\n      return { file_path: filePath.trim() };\n    });\n    if (changes.length === 0) { toast.error(\"Enter at least one file change\"); return; }\n    setDiffLoading(true);\n    setDiffResults(null);\n    try {\n      setDiffResults(await api.getDiffContext({ repo_id: diffRepoId.trim(), changes }));\n    } catch (e) {\n      toast.error(`Diff context failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);\n    } finally {\n      setDiffLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"max-w-5xl mx-auto space-y-6\">\n      <h1 className=\"text-2xl font-bold\">Query</h1>\n\n      <Tabs defaultValue=\"Search\">\n        <TabsList>\n          <TabsTrigger value=\"Search\">Search</TabsTrigger>\n          <TabsTrigger value=\"Analysis\">Analysis</TabsTrigger>\n          <TabsTrigger value=\"CodeFinder\">CodeFinder</TabsTrigger>\n          <TabsTrigger value=\"Metrics\">Metrics</TabsTrigger>\n          <TabsTrigger value=\"DiffContext\">Code Review</TabsTrigger>\n        </TabsList>\n\n        <TabsContent value=\"Search\">\n          <SearchTab />\n        </TabsContent>\n\n        {Object.entries(queryGroups).map(([group, queries]) => (\n          <TabsContent key={group} value={group}>\n            <GenericQueryTab queries={queries} />\n          </TabsContent>\n        ))}\n\n        <TabsContent value=\"DiffContext\" className=\"space-y-4 pt-4\">\n          <Card>\n            <CardHeader><CardTitle>Diff Context Builder</CardTitle></CardHeader>\n            <CardContent className=\"space-y-4\">\n              <p className=\"text-sm text-muted-foreground\">\n                Build RAG context for code review. Provide the repository and changed files\n                to get affected symbols, callers, class hierarchy, and source.\n              </p>\n              <div className=\"space-y-2\">\n                <Label>Repository ID</Label>\n                <Input\n                  placeholder=\"owner/repo_name\"\n                  value={diffRepoId}\n                  onChange={(e) => setDiffRepoId(e.target.value)}\n                />\n              </div>\n              <div className=\"space-y-2\">\n                <Label>Changed Files</Label>\n                <Textarea\n                  placeholder={\"One per line — file_path:start_line-end_line\\n\\nExamples:\\nsrc/main.py:10-30\\nsrc/utils.py:1-50\"}\n                  value={diffChangesText}\n                  onChange={(e) => setDiffChangesText(e.target.value)}\n                  rows={6}\n                  className=\"font-mono text-sm\"\n                />\n              </div>\n              <Button onClick={runDiffContext} disabled={diffLoading}>\n                {diffLoading ? \"Loading…\" : \"Get Diff Context\"}\n              </Button>\n            </CardContent>\n          </Card>\n          {diffResults !== null && <DiffContextResults data={diffResults as DiffContextData} />}\n        </TabsContent>\n      </Tabs>\n    </div>\n  );\n}\n\n// ─── Diff Context Results ──────────────────────────────────────────────────────\n\ninterface DiffContextData {\n  affected_symbols: {\n    type: string; name: string; start_line: number; end_line: number;\n    source: string | null; docstring: string | null; change_file: string;\n  }[];\n  callers: {\n    symbol: string; symbol_type: string;\n    callers: { type: string; name: string; path: string; source: string | null }[];\n  }[];\n  class_hierarchy: { class: string; hierarchy: { name: string; path: string }[] }[];\n  file_sources: Record<string, string>;\n  total_affected: number;\n  total_files: number;\n}\n\nfunction DiffContextResults({ data }: { data: DiffContextData }) {\n  return (\n    <div className=\"space-y-4\">\n      <div className=\"flex gap-3\">\n        <Badge variant=\"secondary\">{data.total_files} files</Badge>\n        <Badge variant=\"secondary\">{data.total_affected} affected symbols</Badge>\n        <Badge variant=\"secondary\">{data.callers.length} caller chains</Badge>\n        <Badge variant=\"secondary\">{data.class_hierarchy.length} class hierarchies</Badge>\n      </div>\n\n      {data.affected_symbols.length > 0 && (\n        <Card>\n          <CardHeader><CardTitle className=\"text-sm\">Affected Symbols</CardTitle></CardHeader>\n          <CardContent className=\"space-y-2 max-h-96 overflow-y-auto\">\n            {data.affected_symbols.map((sym, i) => (\n              <div key={i} className=\"p-3 rounded border border-border space-y-1\">\n                <div className=\"flex items-center gap-2\">\n                  <Badge variant={sym.type === \"function\" ? \"default\" : \"secondary\"}>{sym.type}</Badge>\n                  <span className=\"font-medium font-mono\">{sym.name}</span>\n                  <span className=\"text-xs text-muted-foreground\">{sym.change_file}:{sym.start_line}-{sym.end_line}</span>\n                </div>\n                {sym.docstring && <p className=\"text-xs text-muted-foreground\">{sym.docstring}</p>}\n                {sym.source && <CodeBlock code={sym.source} startLine={sym.start_line} maxHeight=\"max-h-48\" />}\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {data.callers.length > 0 && (\n        <Card>\n          <CardHeader><CardTitle className=\"text-sm\">Callers</CardTitle></CardHeader>\n          <CardContent className=\"space-y-3 max-h-96 overflow-y-auto\">\n            {data.callers.map((group, i) => (\n              <div key={i} className=\"space-y-1\">\n                <p className=\"text-sm font-medium\">\n                  <Badge variant=\"outline\" className=\"mr-1\">{group.symbol_type}</Badge>\n                  <span className=\"font-mono\">{group.symbol}</span>\n                  <span className=\"text-muted-foreground ml-1\">called by:</span>\n                </p>\n                {group.callers.map((caller, j) => (\n                  <div key={j} className=\"ml-4 p-2 rounded border border-border text-sm\">\n                    <span className=\"font-mono\">{caller.name}</span>\n                    <span className=\"text-xs text-muted-foreground ml-2\">{caller.path}</span>\n                    {caller.source && <CodeBlock code={caller.source} maxHeight=\"max-h-32\" className=\"mt-1\" />}\n                  </div>\n                ))}\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {data.class_hierarchy.length > 0 && (\n        <Card>\n          <CardHeader><CardTitle className=\"text-sm\">Class Hierarchy</CardTitle></CardHeader>\n          <CardContent className=\"space-y-2 max-h-72 overflow-y-auto\">\n            {data.class_hierarchy.map((h, i) => (\n              <div key={i} className=\"space-y-1\">\n                <p className=\"text-sm font-medium font-mono\">{h.class}</p>\n                <div className=\"ml-4 space-y-1\">\n                  {h.hierarchy.map((parent, j) => (\n                    <div key={j} className=\"flex items-center gap-2 text-sm\">\n                      <span className=\"text-muted-foreground\">{j === 0 ? \"\" : \"└─\"}</span>\n                      <span className=\"font-mono\">{parent.name}</span>\n                      <span className=\"text-xs text-muted-foreground\">{parent.path}</span>\n                    </div>\n                  ))}\n                </div>\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {Object.keys(data.file_sources).length > 0 && (\n        <Card>\n          <CardHeader><CardTitle className=\"text-sm\">File Sources</CardTitle></CardHeader>\n          <CardContent className=\"space-y-3 max-h-96 overflow-y-auto\">\n            {Object.entries(data.file_sources).map(([path, source]) => (\n              <div key={path} className=\"space-y-1\">\n                <p className=\"text-sm font-mono text-primary\">{path}</p>\n                <CodeBlock code={source} maxHeight=\"max-h-64\" />\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n    </div>\n  );\n}\n\n// ─── Generic JSON Results ─────────────────────────────────────────────────────\n\nfunction ResultsView({ data }: { data: unknown }) {\n  if (!data) return <p className=\"text-muted-foreground text-sm\">No results</p>;\n\n  if (Array.isArray(data)) {\n    if (data.length === 0) return <p className=\"text-muted-foreground text-sm\">No results found</p>;\n    return (\n      <div className=\"space-y-2 max-h-[600px] overflow-y-auto\">\n        {data.map((item, i) => (\n          <div key={i} className=\"p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n            {typeof item === \"object\" ? <ObjectView obj={item} /> : String(item)}\n          </div>\n        ))}\n      </div>\n    );\n  }\n\n  if (typeof data === \"object\") return <ObjectView obj={data as Record<string, unknown>} />;\n  return <pre className=\"text-sm font-mono\">{String(data)}</pre>;\n}\n\nfunction ObjectView({ obj }: { obj: Record<string, unknown> }) {\n  return (\n    <div className=\"space-y-1\">\n      {Object.entries(obj).map(([key, value]) => {\n        if (key === \"source\" && typeof value === \"string\" && value) {\n          const startLine = (obj.line_number as number) || (obj.start_line as number) || 1;\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <CodeBlock code={value} startLine={startLine} maxHeight=\"max-h-64\" />\n            </div>\n          );\n        }\n        if (Array.isArray(value)) {\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              {value.length === 0\n                ? <span className=\"text-muted-foreground ml-2\">[]</span>\n                : (\n                  <div className=\"ml-4 space-y-2\">\n                    {value.map((item, i) => (\n                      <div key={i} className=\"p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n                        {typeof item === \"object\" && item !== null ? <ObjectView obj={item as Record<string, unknown>} /> : String(item)}\n                      </div>\n                    ))}\n                  </div>\n                )}\n            </div>\n          );\n        }\n        if (typeof value === \"object\" && value !== null) {\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <div className=\"ml-4 p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n                <ObjectView obj={value as Record<string, unknown>} />\n              </div>\n            </div>\n          );\n        }\n        return (\n          <div key={key} className=\"flex gap-2\">\n            <span className=\"text-primary font-medium shrink-0\">{key}:</span>\n            <span className=\"text-muted-foreground break-all\">{String(value ?? \"—\")}</span>\n          </div>\n        );\n      })}\n    </div>\n  );\n}\n","structuredPatch":[{"oldStart":1,"oldLines":6,"newStart":1,"newLines":6,"lines":[" \"use client\";"," ","-import { useState } from \"react\";","+import { useState, useRef, useCallback } from \"react\";"," import { Card, CardContent, CardHeader, CardTitle } from \"@/components/ui/card\";"," import { Button } from \"@/components/ui/button\";"," import { Input } from \"@/components/ui/input\";"]},{"oldStart":36,"oldLines":61,"newStart":36,"newLines":6,"lines":["   total_lines: number;"," }"," ","-type QueryDef = {","-  label: string;","-  placeholder: string;","-  fn: (q: string) => Promise<unknown>;","-  needsInput: boolean;","-  isSearch?: boolean;","-};","-","-// ─── Query definitions ────────────────────────────────────────────────────────","-","-const queryGroups: Record<string, QueryDef[]> = {","-  Search: [","-    {","-      label: \"Full-text Search\",","-      placeholder: \"Search query (e.g. LoginRequest)...\",","-      fn: api.searchCode,","-      needsInput: true,","-      isSearch: true,","-    },","-    {","-      label: \"Symbol Search\",","-      placeholder: \"Symbol name (e.g. LoginRequest)...\",","-      fn: api.searchSymbols,","-      needsInput: true,","-      isSearch: true,","-    },","-  ],","-  Analysis: [","-    { label: \"Method Usages\", placeholder: \"Method name...\", fn: api.getMethodUsages, needsInput: true },","-    { label: \"Find Callers\", placeholder: \"Symbol name...\", fn: api.findCallers, needsInput: true },","-    { label: \"Class Hierarchy\", placeholder: \"Class name...\", fn: api.getClassHierarchy, needsInput: true },","-    { label: \"Change Impact\", placeholder: \"Symbol name...\", fn: api.getChangeImpact, needsInput: true },","-  ],","-  CodeFinder: [","-    { label: \"Function\", placeholder: \"Function name...\", fn: api.findFunction, needsInput: true },","-    { label: \"Class\", placeholder: \"Class name...\", fn: api.findClass, needsInput: true },","-    { label: \"Variable\", placeholder: \"Variable name...\", fn: api.findVariable, needsInput: true },","-    { label: \"Content\", placeholder: \"Content query...\", fn: api.findContent, needsInput: true },","-    { label: \"Module\", placeholder: \"Module name...\", fn: api.findModule, needsInput: true },","-    { label: \"Imports\", placeholder: \"Import name...\", fn: api.findImports, needsInput: true },","-    {","-      label: \"Line Search\",","-      placeholder: \"Code snippet to find in files...\",","-      fn: api.findByLine,","-      needsInput: true,","-      isSearch: true,","-    },","-  ],","-  Metrics: [","-    { label: \"Graph Stats\", placeholder: \"\", fn: api.getGraphStats, needsInput: false },","-    { label: \"Language Stats\", placeholder: \"\", fn: api.getLanguageStats, needsInput: false },","-    { label: \"Top Complex Functions\", placeholder: \"\", fn: api.getTopComplexFunctions, needsInput: false },","-  ],","-};","-"," // ─── PeekViewer ───────────────────────────────────────────────────────────────"," "," function PeekViewer({ path, anchorLine }: { path: string; anchorLine: number }) {"]},{"oldStart":101,"oldLines":58,"newStart":46,"newLines":75,"lines":["   const [loading, setLoading] = useState(false);","   const [opened, setOpened] = useState(false);"," ","-  const load = async (newAbove: number, newBelow: number) => {","+  const load = useCallback(async (a: number, b: number) => {","     setLoading(true);","     try {","-      const data = await api.peekFileLines(path, anchorLine, newAbove, newBelow);","+      const data = await api.peekFileLines(path, anchorLine, a, b);","       setResult(data as PeekResult);","-      setAbove(newAbove);","-      setBelow(newBelow);","+      setAbove(a);","+      setBelow(b);","     } catch {","       toast.error(\"Failed to load context\");","     } finally {","       setLoading(false);","     }","-  };","+  }, [path, anchorLine]);"," ","   if (!opened) {","     return (","-      <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" onClick={() => { setOpened(true); load(above, below); }}>","-        Peek context","-      </Button>","+      <button","+        className=\"text-xs text-primary underline-offset-2 hover:underline mt-1\"","+        onClick={() => { setOpened(true); load(above, below); }}","+      >","+        Show context","+      </button>","     );","   }"," ","   return (","-    <div className=\"mt-2 space-y-1\">","-      <div className=\"flex gap-2 items-center\">","-        <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" disabled={loading} onClick={() => load(above + STEP, below)}>","-          ↑ Load {STEP} more above","-        </Button>","-        <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" disabled={loading} onClick={() => load(above, below + STEP)}>","-          Load {STEP} more below ↓","-        </Button>","-        <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" onClick={() => setOpened(false)}>","-          Close","-        </Button>","+    <div className=\"mt-2 space-y-1.5\">","+      <div className=\"flex flex-wrap gap-2 items-center text-xs text-muted-foreground\">","+        <button","+          className=\"hover:text-foreground disabled:opacity-40\"","+          disabled={loading}","+          onClick={() => load(above + STEP, below)}","+        >","+          ↑ {STEP} more above","+        </button>","+        <span>·</span>","+        <button","+          className=\"hover:text-foreground disabled:opacity-40\"","+          disabled={loading}","+          onClick={() => load(above, below + STEP)}","+        >","+          {STEP} more below ↓","+        </button>","+        <span>·</span>","+        <button className=\"hover:text-foreground\" onClick={() => setOpened(false)}>","+          collapse","+        </button>","         {result && (","-          <span className=\"text-xs text-muted-foreground\">","-            Lines {result.window[0]?.line_number}–{result.window[result.window.length - 1]?.line_number} / {result.total_lines}","+          <span className=\"ml-auto\">","+            lines {result.window[0]?.line_number}–{result.window[result.window.length - 1]?.line_number}","+            {\" \"}/ {result.total_lines}","           </span>","         )}","       </div>"," ","       {result && (","-        <div className=\"font-mono text-xs rounded border border-border overflow-x-auto\">","+        <div className=\"rounded border border-border overflow-x-auto text-xs font-mono\">","           {result.window.map((ln) => (","             <div","               key={ln.line_number}","-              className={`flex gap-2 px-2 py-0.5 ${ln.is_anchor ? \"bg-yellow-500/20 font-semibold\" : \"hover:bg-muted/30\"}`}","+              className={`flex ${ln.is_anchor","+                ? \"bg-yellow-400/15 dark:bg-yellow-500/15 border-l-2 border-yellow-500\"","+                : \"hover:bg-muted/40\"","+              }`}","             >","-              <span className=\"select-none w-10 text-right text-muted-foreground shrink-0\">","+              <span className=\"select-none w-12 text-right px-2 py-0.5 text-muted-foreground/60 shrink-0 border-r border-border\">","                 {ln.line_number}","               </span>","-              <span className=\"whitespace-pre\">{ln.content}</span>","+              <span className=\"px-3 py-0.5 whitespace-pre\">{ln.content}</span>","             </div>","           ))}","         </div>"]},{"oldStart":161,"oldLines":10,"newStart":123,"newLines":72,"lines":["   );"," }"," ","-// ─── SearchResultsView ────────────────────────────────────────────────────────","+// ─── Type badge colours ───────────────────────────────────────────────────────"," ","+const TYPE_STYLES: Record<string, string> = {","+  function: \"bg-blue-500/10 text-blue-600 dark:text-blue-400 border-blue-500/20\",","+  class:    \"bg-purple-500/10 text-purple-600 dark:text-purple-400 border-purple-500/20\",","+  variable: \"bg-green-500/10 text-green-600 dark:text-green-400 border-green-500/20\",","+  line:     \"bg-orange-500/10 text-orange-600 dark:text-orange-400 border-orange-500/20\",","+};","+","+function TypeBadge({ type }: { type: string }) {","+  return (","+    <span className={`inline-flex items-center px-1.5 py-0.5 rounded text-xs font-medium border ${TYPE_STYLES[type] ?? \"bg-muted text-muted-foreground border-border\"}`}>","+      {type}","+    </span>","+  );","+}","+","+// ─── Search Result Card ───────────────────────────────────────────────────────","+","+function SearchHitCard({ hit }: { hit: SearchHit }) {","+  const filename = hit.path ? hit.path.split(\"/\").pop() : null;","+  const dirPath  = hit.path && filename ? hit.path.slice(0, hit.path.length - filename.length - 1) : null;","+  const hasLine  = hit.line_number != null && hit.line_number > 0;","+","+  return (","+    <div className=\"group rounded-lg border border-border bg-card px-4 py-3 space-y-1.5 hover:border-primary/40 transition-colors\">","+      {/* Header */}","+      <div className=\"flex items-start gap-2\">","+        {hit.type && <TypeBadge type={hit.type} />}","+        <span className=\"font-mono font-semibold text-sm leading-tight break-all\">","+          {hit.name ?? hit.match_line?.trim()}","+        </span>","+        {hit.score != null && (","+          <span className=\"ml-auto shrink-0 text-xs text-muted-foreground/50\">","+            {hit.score.toFixed(2)}","+          </span>","+        )}","+      </div>","+","+      {/* Path */}","+      {hit.path && (","+        <div className=\"flex items-center gap-1 text-xs text-muted-foreground font-mono\">","+          {dirPath && <span className=\"opacity-60 truncate\">{dirPath}/</span>}","+          {filename && <span className=\"text-foreground/80 font-medium\">{filename}</span>}","+          {hasLine && (","+            <span className=\"shrink-0 px-1 rounded bg-muted text-foreground/70\">:{hit.line_number}</span>","+          )}","+        </div>","+      )}","+","+      {/* Match snippet (for line-type results where name IS the code line) */}","+      {hit.type === \"line\" && hit.name && (","+        <pre className=\"text-xs text-muted-foreground bg-muted/50 rounded px-2 py-1 overflow-x-auto\">{hit.name}</pre>","+      )}","+","+      {/* Peek */}","+      {hit.path && hasLine && (","+        <PeekViewer path={hit.path} anchorLine={hit.line_number!} />","+      )}","+    </div>","+  );","+}","+","+// ─── Unified Search Results ───────────────────────────────────────────────────","+"," function SearchResultsView({ data }: { data: unknown }) {","-  // Normalise: the API wraps results in { results: [...], total: N } or { symbols: [...] }","   let hits: SearchHit[] = [];","   if (Array.isArray(data)) {","     hits = data as SearchHit[];"]},{"oldStart":175,"oldLines":87,"newStart":199,"newLines":215,"lines":["   }"," ","   if (hits.length === 0) {","-    return <p className=\"text-muted-foreground text-sm\">No results found.</p>;","+    return (","+      <div className=\"py-12 text-center text-muted-foreground text-sm\">","+        No results found.","+      </div>","+    );","   }"," ","+  const symbols = hits.filter((h) => h.type !== \"line\");","+  const lines   = hits.filter((h) => h.type === \"line\");","+","   return (","-    <div className=\"space-y-2 max-h-[680px] overflow-y-auto\">","-      {hits.map((hit, i) => (","-        <div key={i} className=\"p-3 rounded border border-border space-y-1\">","-          <div className=\"flex flex-wrap items-center gap-2\">","-            {hit.type && (","-              <Badge variant={hit.type === \"function\" ? \"default\" : hit.type === \"class\" ? \"secondary\" : \"outline\"}>","-                {hit.type}","-              </Badge>","-            )}","-            {hit.name && <span className=\"font-mono font-medium\">{hit.name}</span>}","-            {hit.match_line && !hit.name && (","-              <span className=\"font-mono text-sm text-foreground\">{hit.match_line.trim()}</span>","-            )}","-            {hit.score != null && (","-              <span className=\"ml-auto text-xs text-muted-foreground\">score {hit.score.toFixed(3)}</span>","-            )}","-          </div>","+    <div className=\"space-y-4\">","+      {/* Summary row */}","+      <div className=\"flex gap-2 text-xs text-muted-foreground\">","+        <span>{hits.length} results</span>","+        {symbols.length > 0 && <span>· {symbols.length} symbols</span>}","+        {lines.length > 0   && <span>· {lines.length} file matches</span>}","+      </div>"," ","-          {hit.path && (","-            <div className=\"flex items-center gap-2 text-xs text-muted-foreground\">","-              <span className=\"font-mono truncate\">{hit.path}</span>","-              {hit.line_number != null && hit.line_number > 0 && (","-                <span className=\"shrink-0\">:{hit.line_number}</span>","-              )}","-            </div>","+      {symbols.length > 0 && (","+        <section className=\"space-y-2\">","+          {symbols.length > 0 && lines.length > 0 && (","+            <h3 className=\"text-xs font-semibold uppercase tracking-wider text-muted-foreground\">Symbols</h3>","           )}","+          {symbols.map((hit, i) => <SearchHitCard key={i} hit={hit} />)}","+        </section>","+      )}"," ","-          {hit.match_line && hit.name && (","-            <p className=\"text-xs font-mono text-muted-foreground truncate\">{hit.match_line.trim()}</p>","+      {lines.length > 0 && (","+        <section className=\"space-y-2\">","+          {symbols.length > 0 && lines.length > 0 && (","+            <h3 className=\"text-xs font-semibold uppercase tracking-wider text-muted-foreground\">File matches</h3>","           )}","-","-          {hit.path && hit.line_number != null && hit.line_number > 0 && (","-            <PeekViewer path={hit.path} anchorLine={hit.line_number} />","-          )}","-        </div>","-      ))}","+          {lines.map((hit, i) => <SearchHitCard key={i} hit={hit} />)}","+        </section>","+      )}","     </div>","   );"," }"," ","-// ─── Main page ────────────────────────────────────────────────────────────────","+// ─── Unified Search Tab ───────────────────────────────────────────────────────"," ","-export default function QueryPage() {","-  const [input, setInput] = useState(\"\");","+function SearchTab() {","+  const [query, setQuery] = useState(\"\");","   const [loading, setLoading] = useState(false);","   const [results, setResults] = useState<unknown>(null);","-  const [activeQuery, setActiveQuery] = useState<QueryDef | null>(null);","+  const inputRef = useRef<HTMLInputElement>(null);"," ","-  // Diff context state","-  const [diffRepoId, setDiffRepoId] = useState(\"\");","-  const [diffChangesText, setDiffChangesText] = useState(\"\");","-  const [diffLoading, setDiffLoading] = useState(false);","-  const [diffResults, setDiffResults] = useState<unknown>(null);","-","-  const runQuery = async (qDef: QueryDef) => {","-    if (qDef.needsInput && !input.trim()) {","-      toast.error(\"Please enter a query\");","-      return;","-    }","+  const runSearch = async (q = query) => {","+    const term = q.trim();","+    if (!term) { inputRef.current?.focus(); return; }","     setLoading(true);","-    setActiveQuery(qDef);","     setResults(null);","     try {","-      const data = await qDef.fn(input.trim());","+      const data = await api.searchCode(term);","       setResults(data);","     } catch (e) {","-      toast.error(`Query failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);","+      toast.error(`Search failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);","     } finally {","       setLoading(false);","     }","   };"," ","-  const runDiffContext = async () => {","-    if (!diffRepoId.trim()) {","-      toast.error(\"Please enter a repository ID\");","-      return;","+  return (","+    <div className=\"space-y-4 pt-4\">","+      {/* Search bar */}","+      <div className=\"flex gap-2\">","+        <Input","+          ref={inputRef}","+          placeholder=\"Search by name, snippet, or code pattern — e.g. GitHubRepo or class LoginRequest(BaseModel)\"","+          value={query}","+          onChange={(e) => setQuery(e.target.value)}","+          onKeyDown={(e) => { if (e.key === \"Enter\") runSearch(); }}","+          className=\"text-sm\"","+          autoFocus","+        />","+        <Button onClick={() => runSearch()} disabled={loading} className=\"shrink-0\">","+          {loading ? \"Searching…\" : \"Search\"}","+        </Button>","+      </div>","+","+      {/* Hint */}","+      {results === null && !loading && (","+        <p className=\"text-xs text-muted-foreground\">","+          Searches symbols (functions, classes, variables) and file content. Supports identifiers, code snippets, and keywords.","+        </p>","+      )}","+","+      {/* Loading */}","+      {loading && (","+        <div className=\"py-10 text-center text-muted-foreground text-sm animate-pulse\">Searching…</div>","+      )}","+","+      {/* Results */}","+      {!loading && results !== null && <SearchResultsView data={results} />}","+    </div>","+  );","+}","+","+// ─── Analysis / CodeFinder / Metrics shared pattern ──────────────────────────","+","+type QueryDef = {","+  label: string;","+  placeholder: string;","+  fn: (q: string) => Promise<unknown>;","+  needsInput: boolean;","+};","+","+const queryGroups: Record<string, QueryDef[]> = {","+  Analysis: [","+    { label: \"Method Usages\",  placeholder: \"Method name…\",  fn: api.getMethodUsages,  needsInput: true },","+    { label: \"Find Callers\",   placeholder: \"Symbol name…\",  fn: api.findCallers,       needsInput: true },","+    { label: \"Class Hierarchy\",placeholder: \"Class name…\",   fn: api.getClassHierarchy, needsInput: true },","+    { label: \"Change Impact\",  placeholder: \"Symbol name…\",  fn: api.getChangeImpact,   needsInput: true },","+  ],","+  CodeFinder: [","+    { label: \"Function\",    placeholder: \"Function name…\",   fn: api.findFunction,  needsInput: true },","+    { label: \"Class\",       placeholder: \"Class name…\",      fn: api.findClass,     needsInput: true },","+    { label: \"Variable\",    placeholder: \"Variable name…\",   fn: api.findVariable,  needsInput: true },","+    { label: \"Content\",     placeholder: \"Content query…\",   fn: api.findContent,   needsInput: true },","+    { label: \"Module\",      placeholder: \"Module name…\",     fn: api.findModule,    needsInput: true },","+    { label: \"Imports\",     placeholder: \"Import name…\",     fn: api.findImports,   needsInput: true },","+    { label: \"Line Search\", placeholder: \"Code line to find…\", fn: api.findByLine, needsInput: true },","+  ],","+  Metrics: [","+    { label: \"Graph Stats\",           placeholder: \"\", fn: api.getGraphStats,          needsInput: false },","+    { label: \"Language Stats\",        placeholder: \"\", fn: api.getLanguageStats,        needsInput: false },","+    { label: \"Top Complex Functions\", placeholder: \"\", fn: api.getTopComplexFunctions,  needsInput: false },","+  ],","+};","+","+function GenericQueryTab({ queries }: { queries: QueryDef[] }) {","+  const [input, setInput]           = useState(\"\");","+  const [loading, setLoading]       = useState(false);","+  const [results, setResults]       = useState<unknown>(null);","+  const [activeLabel, setActiveLabel] = useState<string>(\"\");","+","+  const run = async (q: QueryDef) => {","+    if (q.needsInput && !input.trim()) { toast.error(\"Enter a query first\"); return; }","+    setLoading(true);","+    setActiveLabel(q.label);","+    setResults(null);","+    try {","+      setResults(await q.fn(input.trim()));","+    } catch (e) {","+      toast.error(`Failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);","+    } finally {","+      setLoading(false);","     }","+  };","+","+  return (","+    <div className=\"space-y-4 pt-4\">","+      <Input","+        placeholder=\"Enter name or query…\"","+        value={input}","+        onChange={(e) => setInput(e.target.value)}","+        onKeyDown={(e) => {","+          if (e.key === \"Enter\" && activeLabel) {","+            const q = queries.find((q) => q.label === activeLabel);","+            if (q) run(q);","+          }","+        }}","+        className=\"text-sm\"","+      />","+      <div className=\"flex flex-wrap gap-2\">","+        {queries.map((q) => (","+          <Button","+            key={q.label}","+            variant={activeLabel === q.label ? \"default\" : \"secondary\"}","+            size=\"sm\"","+            onClick={() => run(q)}","+            disabled={loading}","+          >","+            {q.label}","+          </Button>","+        ))}","+      </div>","+","+      {loading && (","+        <Card>","+          <CardContent className=\"py-8 text-center text-muted-foreground animate-pulse\">Loading…</CardContent>","+        </Card>","+      )}","+","+      {!loading && results !== null && (","+        <Card>","+          <CardHeader>","+            <CardTitle className=\"text-sm text-muted-foreground\">{activeLabel}</CardTitle>","+          </CardHeader>","+          <CardContent>","+            <ResultsView data={results} />","+          </CardContent>","+        </Card>","+      )}","+    </div>","+  );","+}","+","+// ─── Main page ────────────────────────────────────────────────────────────────","+","+export default function QueryPage() {","+  const [diffRepoId, setDiffRepoId]       = useState(\"\");","+  const [diffChangesText, setDiffChangesText] = useState(\"\");","+  const [diffLoading, setDiffLoading]     = useState(false);","+  const [diffResults, setDiffResults]     = useState<unknown>(null);","+","+  const runDiffContext = async () => {","+    if (!diffRepoId.trim()) { toast.error(\"Enter a repository ID\"); return; }","     const lines = diffChangesText.trim().split(\"\\n\").filter(Boolean);","     const changes = lines.map((line) => {","       const [filePath, range] = line.split(\":\");"]},{"oldStart":265,"oldLines":17,"newStart":417,"newLines":11,"lines":["       }","       return { file_path: filePath.trim() };","     });","-","-    if (changes.length === 0) {","-      toast.error(\"Please enter at least one file change\");","-      return;","-    }","-","+    if (changes.length === 0) { toast.error(\"Enter at least one file change\"); return; }","     setDiffLoading(true);","     setDiffResults(null);","     try {","-      const data = await api.getDiffContext({ repo_id: diffRepoId.trim(), changes });","-      setDiffResults(data);","+      setDiffResults(await api.getDiffContext({ repo_id: diffRepoId.trim(), changes }));","     } catch (e) {","       toast.error(`Diff context failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);","     } finally {"]},{"oldStart":289,"oldLines":50,"newStart":435,"newLines":30,"lines":[" ","       <Tabs defaultValue=\"Search\">","         <TabsList>","-          {Object.keys(queryGroups).map((group) => (","-            <TabsTrigger key={group} value={group}>","-              {group}","-            </TabsTrigger>","-          ))}","+          <TabsTrigger value=\"Search\">Search</TabsTrigger>","+          <TabsTrigger value=\"Analysis\">Analysis</TabsTrigger>","+          <TabsTrigger value=\"CodeFinder\">CodeFinder</TabsTrigger>","+          <TabsTrigger value=\"Metrics\">Metrics</TabsTrigger>","           <TabsTrigger value=\"DiffContext\">Code Review</TabsTrigger>","         </TabsList>"," ","+        <TabsContent value=\"Search\">","+          <SearchTab />","+        </TabsContent>","+","         {Object.entries(queryGroups).map(([group, queries]) => (","-          <TabsContent key={group} value={group} className=\"space-y-4 pt-4\">","-            <Input","-              placeholder=\"Enter search term or symbol name...\"","-              value={input}","-              onChange={(e) => setInput(e.target.value)}","-              className=\"text-base\"","-              onKeyDown={(e) => {","-                if (e.key === \"Enter\" && activeQuery) runQuery(activeQuery);","-              }}","-            />","-            <div className=\"flex flex-wrap gap-2\">","-              {queries.map((q) => (","-                <Button","-                  key={q.label}","-                  variant={activeQuery?.label === q.label ? \"default\" : \"secondary\"}","-                  size=\"sm\"","-                  onClick={() => runQuery(q)}","-                  disabled={loading}","-                >","-                  {q.label}","-                </Button>","-              ))}","-            </div>","+          <TabsContent key={group} value={group}>","+            <GenericQueryTab queries={queries} />","           </TabsContent>","         ))}"," ","         <TabsContent value=\"DiffContext\" className=\"space-y-4 pt-4\">","           <Card>","-            <CardHeader>","-              <CardTitle>Diff Context Builder</CardTitle>","-            </CardHeader>","+            <CardHeader><CardTitle>Diff Context Builder</CardTitle></CardHeader>","             <CardContent className=\"space-y-4\">","               <p className=\"text-sm text-muted-foreground\">","                 Build RAG context for code review. Provide the repository and changed files","-                to get affected symbols, their callers, class hierarchy, and source code.","+                to get affected symbols, callers, class hierarchy, and source.","               </p>","               <div className=\"space-y-2\">","                 <Label>Repository ID</Label>"]},{"oldStart":345,"oldLines":7,"newStart":471,"newLines":7,"lines":["               <div className=\"space-y-2\">","                 <Label>Changed Files</Label>","                 <Textarea","-                  placeholder={\"One per line — file_path:start_line-end_line\\n\\nExamples:\\nsrc/main.py:10-30\\nsrc/utils.py:1-50\\nREADME.md\"}","+                  placeholder={\"One per line — file_path:start_line-end_line\\n\\nExamples:\\nsrc/main.py:10-30\\nsrc/utils.py:1-50\"}","                   value={diffChangesText}","                   onChange={(e) => setDiffChangesText(e.target.value)}","                   rows={6}"]},{"oldStart":353,"oldLines":42,"newStart":479,"newLines":13,"lines":["                 />","               </div>","               <Button onClick={runDiffContext} disabled={diffLoading}>","-                {diffLoading ? \"Loading...\" : \"Get Diff Context\"}","+                {diffLoading ? \"Loading…\" : \"Get Diff Context\"}","               </Button>","             </CardContent>","           </Card>","-","-          {diffResults !== null && (","-            <DiffContextResults data={diffResults as DiffContextData} />","-          )}","+          {diffResults !== null && <DiffContextResults data={diffResults as DiffContextData} />}","         </TabsContent>","       </Tabs>","-","-      {/* Query results */}","-      {loading && (","-        <Card>","-          <CardContent className=\"py-8 text-center text-muted-foreground\">","-            Loading...","-          </CardContent>","-        </Card>","-      )}","-","-      {!loading && results !== null && activeQuery !== null && (","-        <Card>","-          <CardHeader>","-            <CardTitle className=\"text-sm text-muted-foreground\">","-              Results: {activeQuery.label}","-            </CardTitle>","-          </CardHeader>","-          <CardContent>","-            {activeQuery.isSearch ? (","-              <SearchResultsView data={results} />","-            ) : (","-              <ResultsView data={results} />","-            )}","-          </CardContent>","-        </Card>","-      )}","     </div>","   );"," }"]},{"oldStart":397,"oldLines":24,"newStart":494,"newLines":14,"lines":[" "," interface DiffContextData {","   affected_symbols: {","-    type: string;","-    name: string;","-    start_line: number;","-    end_line: number;","-    source: string | null;","-    docstring: string | null;","-    change_file: string;","-    file_path?: string;","+    type: string; name: string; start_line: number; end_line: number;","+    source: string | null; docstring: string | null; change_file: string;","   }[];","   callers: {","-    symbol: string;","-    symbol_type: string;","+    symbol: string; symbol_type: string;","     callers: { type: string; name: string; path: string; source: string | null }[];","   }[];","-  class_hierarchy: {","-    class: string;","-    hierarchy: { name: string; path: string; source: string | null }[];","-  }[];","+  class_hierarchy: { class: string; hierarchy: { name: string; path: string }[] }[];","   file_sources: Record<string, string>;","   total_affected: number;","   total_files: number;"]},{"oldStart":432,"oldLines":29,"newStart":519,"newLines":17,"lines":[" ","       {data.affected_symbols.length > 0 && (","         <Card>","-          <CardHeader>","-            <CardTitle className=\"text-sm\">Affected Symbols</CardTitle>","-          </CardHeader>","-          <CardContent className=\"space-y-2 max-h-[400px] overflow-y-auto\">","+          <CardHeader><CardTitle className=\"text-sm\">Affected Symbols</CardTitle></CardHeader>","+          <CardContent className=\"space-y-2 max-h-96 overflow-y-auto\">","             {data.affected_symbols.map((sym, i) => (","               <div key={i} className=\"p-3 rounded border border-border space-y-1\">","                 <div className=\"flex items-center gap-2\">","                   <Badge variant={sym.type === \"function\" ? \"default\" : \"secondary\"}>{sym.type}</Badge>","                   <span className=\"font-medium font-mono\">{sym.name}</span>","-                  <span className=\"text-xs text-muted-foreground\">","-                    {sym.change_file}:{sym.start_line}-{sym.end_line}","-                  </span>","+                  <span className=\"text-xs text-muted-foreground\">{sym.change_file}:{sym.start_line}-{sym.end_line}</span>","                 </div>","-                {sym.docstring && (","-                  <p className=\"text-xs text-muted-foreground\">{sym.docstring}</p>","-                )}","-                {sym.source && (","-                  <CodeBlock","-                    code={sym.source}","-                    startLine={sym.start_line}","-                    maxHeight=\"max-h-48\"","-                  />","-                )}","+                {sym.docstring && <p className=\"text-xs text-muted-foreground\">{sym.docstring}</p>}","+                {sym.source && <CodeBlock code={sym.source} startLine={sym.start_line} maxHeight=\"max-h-48\" />}","               </div>","             ))}","           </CardContent>"]},{"oldStart":463,"oldLines":10,"newStart":538,"newLines":8,"lines":[" ","       {data.callers.length > 0 && (","         <Card>","-          <CardHeader>","-            <CardTitle className=\"text-sm\">Callers of Affected Symbols</CardTitle>","-          </CardHeader>","-          <CardContent className=\"space-y-3 max-h-[400px] overflow-y-auto\">","+          <CardHeader><CardTitle className=\"text-sm\">Callers</CardTitle></CardHeader>","+          <CardContent className=\"space-y-3 max-h-96 overflow-y-auto\">","             {data.callers.map((group, i) => (","               <div key={i} className=\"space-y-1\">","                 <p className=\"text-sm font-medium\">"]},{"oldStart":478,"oldLines":13,"newStart":551,"newLines":7,"lines":["                   <div key={j} className=\"ml-4 p-2 rounded border border-border text-sm\">","                     <span className=\"font-mono\">{caller.name}</span>","                     <span className=\"text-xs text-muted-foreground ml-2\">{caller.path}</span>","-                    {caller.source && (","-                      <CodeBlock","-                        code={caller.source}","-                        maxHeight=\"max-h-32\"","-                        className=\"mt-1\"","-                      />","-                    )}","+                    {caller.source && <CodeBlock code={caller.source} maxHeight=\"max-h-32\" className=\"mt-1\" />}","                   </div>","                 ))}","               </div>"]},{"oldStart":495,"oldLines":17,"newStart":562,"newLines":15,"lines":[" ","       {data.class_hierarchy.length > 0 && (","         <Card>","-          <CardHeader>","-            <CardTitle className=\"text-sm\">Class Hierarchy</CardTitle>","-          </CardHeader>","-          <CardContent className=\"space-y-2 max-h-[300px] overflow-y-auto\">","+          <CardHeader><CardTitle className=\"text-sm\">Class Hierarchy</CardTitle></CardHeader>","+          <CardContent className=\"space-y-2 max-h-72 overflow-y-auto\">","             {data.class_hierarchy.map((h, i) => (","               <div key={i} className=\"space-y-1\">","                 <p className=\"text-sm font-medium font-mono\">{h.class}</p>","                 <div className=\"ml-4 space-y-1\">","                   {h.hierarchy.map((parent, j) => (","                     <div key={j} className=\"flex items-center gap-2 text-sm\">","-                      <span className=\"text-muted-foreground\">{j === 0 ? \"\" : \"\\u2514\\u2500\"}</span>","+                      <span className=\"text-muted-foreground\">{j === 0 ? \"\" : \"└─\"}</span>","                       <span className=\"font-mono\">{parent.name}</span>","                       <span className=\"text-xs text-muted-foreground\">{parent.path}</span>","                     </div>"]},{"oldStart":519,"oldLines":10,"newStart":584,"newLines":8,"lines":[" ","       {Object.keys(data.file_sources).length > 0 && (","         <Card>","-          <CardHeader>","-            <CardTitle className=\"text-sm\">File Sources</CardTitle>","-          </CardHeader>","-          <CardContent className=\"space-y-3 max-h-[400px] overflow-y-auto\">","+          <CardHeader><CardTitle className=\"text-sm\">File Sources</CardTitle></CardHeader>","+          <CardContent className=\"space-y-3 max-h-96 overflow-y-auto\">","             {Object.entries(data.file_sources).map(([path, source]) => (","               <div key={path} className=\"space-y-1\">","                 <p className=\"text-sm font-mono text-primary\">{path}</p>"]},{"oldStart":536,"oldLines":15,"newStart":599,"newLines":13,"lines":["   );"," }"," ","-// ─── Generic Results ──────────────────────────────────────────────────────────","+// ─── Generic JSON Results ─────────────────────────────────────────────────────"," "," function ResultsView({ data }: { data: unknown }) {","-  if (data === null || data === undefined) {","-    return <p className=\"text-muted-foreground\">No results</p>;","-  }","+  if (!data) return <p className=\"text-muted-foreground text-sm\">No results</p>;"," ","   if (Array.isArray(data)) {","-    if (data.length === 0) return <p className=\"text-muted-foreground\">No results found</p>;","+    if (data.length === 0) return <p className=\"text-muted-foreground text-sm\">No results found</p>;","     return (","       <div className=\"space-y-2 max-h-[600px] overflow-y-auto\">","         {data.map((item, i) => ("]},{"oldStart":556,"oldLines":10,"newStart":617,"newLines":7,"lines":["     );","   }"," ","-  if (typeof data === \"object\") {","-    return <ObjectView obj={data as Record<string, unknown>} />;","-  }","-","+  if (typeof data === \"object\") return <ObjectView obj={data as Record<string, unknown>} />;","   return <pre className=\"text-sm font-mono\">{String(data)}</pre>;"," }"," "]},{"oldStart":576,"oldLines":32,"newStart":634,"newLines":24,"lines":["             </div>","           );","         }","-","         if (Array.isArray(value)) {","-          if (value.length === 0) {","-            return (","-              <div key={key} className=\"flex gap-2\">","-                <span className=\"text-primary font-medium shrink-0\">{key}:</span>","-                <span className=\"text-muted-foreground\">[]</span>","-              </div>","-            );","-          }","           return (","             <div key={key} className=\"space-y-1\">","               <span className=\"text-primary font-medium\">{key}:</span>","-              <div className=\"ml-4 space-y-2\">","-                {value.map((item, i) => (","-                  <div key={i} className=\"p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">","-                    {typeof item === \"object\" && item !== null","-                      ? <ObjectView obj={item as Record<string, unknown>} />","-                      : String(item)}","+              {value.length === 0","+                ? <span className=\"text-muted-foreground ml-2\">[]</span>","+                : (","+                  <div className=\"ml-4 space-y-2\">","+                    {value.map((item, i) => (","+                      <div key={i} className=\"p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">","+                        {typeof item === \"object\" && item !== null ? <ObjectView obj={item as Record<string, unknown>} /> : String(item)}","+                      </div>","+                    ))}","                   </div>","-                ))}","-              </div>","+                )}","             </div>","           );","         }","-","         if (typeof value === \"object\" && value !== null) {","           return (","             <div key={key} className=\"space-y-1\">"]},{"oldStart":612,"oldLines":13,"newStart":662,"newLines":10,"lines":["             </div>","           );","         }","-","         return (","           <div key={key} className=\"flex gap-2\">","             <span className=\"text-primary font-medium shrink-0\">{key}:</span>","-            <span className=\"text-muted-foreground break-all\">","-              {String(value ?? \"\\u2014\")}","-            </span>","+            <span className=\"text-muted-foreground break-all\">{String(value ?? \"—\")}</span>","           </div>","         );","       })}"]}],"originalFile":"\"use client\";\n\nimport { useState } from \"react\";\nimport { Card, CardContent, CardHeader, CardTitle } from \"@/components/ui/card\";\nimport { Button } from \"@/components/ui/button\";\nimport { Input } from \"@/components/ui/input\";\nimport { Label } from \"@/components/ui/label\";\nimport { Textarea } from \"@/components/ui/textarea\";\nimport { Tabs, TabsContent, TabsList, TabsTrigger } from \"@/components/ui/tabs\";\nimport { Badge } from \"@/components/ui/badge\";\nimport { CodeBlock } from \"@/components/ui/code-block\";\nimport { toast } from \"sonner\";\nimport * as api from \"@/lib/api\";\n\n// ─── Types ────────────────────────────────────────────────────────────────────\n\ninterface SearchHit {\n  name?: string;\n  type?: string;\n  path?: string;\n  line_number?: number;\n  match_line?: string;\n  score?: number;\n}\n\ninterface PeekLine {\n  line_number: number;\n  content: string;\n  is_anchor: boolean;\n}\n\ninterface PeekResult {\n  path: string;\n  anchor_line: number;\n  window: PeekLine[];\n  total_lines: number;\n}\n\ntype QueryDef = {\n  label: string;\n  placeholder: string;\n  fn: (q: string) => Promise<unknown>;\n  needsInput: boolean;\n  isSearch?: boolean;\n};\n\n// ─── Query definitions ────────────────────────────────────────────────────────\n\nconst queryGroups: Record<string, QueryDef[]> = {\n  Search: [\n    {\n      label: \"Full-text Search\",\n      placeholder: \"Search query (e.g. LoginRequest)...\",\n      fn: api.searchCode,\n      needsInput: true,\n      isSearch: true,\n    },\n    {\n      label: \"Symbol Search\",\n      placeholder: \"Symbol name (e.g. LoginRequest)...\",\n      fn: api.searchSymbols,\n      needsInput: true,\n      isSearch: true,\n    },\n  ],\n  Analysis: [\n    { label: \"Method Usages\", placeholder: \"Method name...\", fn: api.getMethodUsages, needsInput: true },\n    { label: \"Find Callers\", placeholder: \"Symbol name...\", fn: api.findCallers, needsInput: true },\n    { label: \"Class Hierarchy\", placeholder: \"Class name...\", fn: api.getClassHierarchy, needsInput: true },\n    { label: \"Change Impact\", placeholder: \"Symbol name...\", fn: api.getChangeImpact, needsInput: true },\n  ],\n  CodeFinder: [\n    { label: \"Function\", placeholder: \"Function name...\", fn: api.findFunction, needsInput: true },\n    { label: \"Class\", placeholder: \"Class name...\", fn: api.findClass, needsInput: true },\n    { label: \"Variable\", placeholder: \"Variable name...\", fn: api.findVariable, needsInput: true },\n    { label: \"Content\", placeholder: \"Content query...\", fn: api.findContent, needsInput: true },\n    { label: \"Module\", placeholder: \"Module name...\", fn: api.findModule, needsInput: true },\n    { label: \"Imports\", placeholder: \"Import name...\", fn: api.findImports, needsInput: true },\n    {\n      label: \"Line Search\",\n      placeholder: \"Code snippet to find in files...\",\n      fn: api.findByLine,\n      needsInput: true,\n      isSearch: true,\n    },\n  ],\n  Metrics: [\n    { label: \"Graph Stats\", placeholder: \"\", fn: api.getGraphStats, needsInput: false },\n    { label: \"Language Stats\", placeholder: \"\", fn: api.getLanguageStats, needsInput: false },\n    { label: \"Top Complex Functions\", placeholder: \"\", fn: api.getTopComplexFunctions, needsInput: false },\n  ],\n};\n\n// ─── PeekViewer ───────────────────────────────────────────────────────────────\n\nfunction PeekViewer({ path, anchorLine }: { path: string; anchorLine: number }) {\n  const STEP = 20;\n  const [above, setAbove] = useState(10);\n  const [below, setBelow] = useState(10);\n  const [result, setResult] = useState<PeekResult | null>(null);\n  const [loading, setLoading] = useState(false);\n  const [opened, setOpened] = useState(false);\n\n  const load = async (newAbove: number, newBelow: number) => {\n    setLoading(true);\n    try {\n      const data = await api.peekFileLines(path, anchorLine, newAbove, newBelow);\n      setResult(data as PeekResult);\n      setAbove(newAbove);\n      setBelow(newBelow);\n    } catch {\n      toast.error(\"Failed to load context\");\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  if (!opened) {\n    return (\n      <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" onClick={() => { setOpened(true); load(above, below); }}>\n        Peek context\n      </Button>\n    );\n  }\n\n  return (\n    <div className=\"mt-2 space-y-1\">\n      <div className=\"flex gap-2 items-center\">\n        <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" disabled={loading} onClick={() => load(above + STEP, below)}>\n          ↑ Load {STEP} more above\n        </Button>\n        <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" disabled={loading} onClick={() => load(above, below + STEP)}>\n          Load {STEP} more below ↓\n        </Button>\n        <Button variant=\"ghost\" size=\"sm\" className=\"text-xs h-6 px-2\" onClick={() => setOpened(false)}>\n          Close\n        </Button>\n        {result && (\n          <span className=\"text-xs text-muted-foreground\">\n            Lines {result.window[0]?.line_number}–{result.window[result.window.length - 1]?.line_number} / {result.total_lines}\n          </span>\n        )}\n      </div>\n\n      {result && (\n        <div className=\"font-mono text-xs rounded border border-border overflow-x-auto\">\n          {result.window.map((ln) => (\n            <div\n              key={ln.line_number}\n              className={`flex gap-2 px-2 py-0.5 ${ln.is_anchor ? \"bg-yellow-500/20 font-semibold\" : \"hover:bg-muted/30\"}`}\n            >\n              <span className=\"select-none w-10 text-right text-muted-foreground shrink-0\">\n                {ln.line_number}\n              </span>\n              <span className=\"whitespace-pre\">{ln.content}</span>\n            </div>\n          ))}\n        </div>\n      )}\n    </div>\n  );\n}\n\n// ─── SearchResultsView ────────────────────────────────────────────────────────\n\nfunction SearchResultsView({ data }: { data: unknown }) {\n  // Normalise: the API wraps results in { results: [...], total: N } or { symbols: [...] }\n  let hits: SearchHit[] = [];\n  if (Array.isArray(data)) {\n    hits = data as SearchHit[];\n  } else if (data && typeof data === \"object\") {\n    const obj = data as Record<string, unknown>;\n    const inner = obj.results ?? obj.symbols ?? obj.ranked_results ?? [];\n    if (Array.isArray(inner)) hits = inner as SearchHit[];\n  }\n\n  if (hits.length === 0) {\n    return <p className=\"text-muted-foreground text-sm\">No results found.</p>;\n  }\n\n  return (\n    <div className=\"space-y-2 max-h-[680px] overflow-y-auto\">\n      {hits.map((hit, i) => (\n        <div key={i} className=\"p-3 rounded border border-border space-y-1\">\n          <div className=\"flex flex-wrap items-center gap-2\">\n            {hit.type && (\n              <Badge variant={hit.type === \"function\" ? \"default\" : hit.type === \"class\" ? \"secondary\" : \"outline\"}>\n                {hit.type}\n              </Badge>\n            )}\n            {hit.name && <span className=\"font-mono font-medium\">{hit.name}</span>}\n            {hit.match_line && !hit.name && (\n              <span className=\"font-mono text-sm text-foreground\">{hit.match_line.trim()}</span>\n            )}\n            {hit.score != null && (\n              <span className=\"ml-auto text-xs text-muted-foreground\">score {hit.score.toFixed(3)}</span>\n            )}\n          </div>\n\n          {hit.path && (\n            <div className=\"flex items-center gap-2 text-xs text-muted-foreground\">\n              <span className=\"font-mono truncate\">{hit.path}</span>\n              {hit.line_number != null && hit.line_number > 0 && (\n                <span className=\"shrink-0\">:{hit.line_number}</span>\n              )}\n            </div>\n          )}\n\n          {hit.match_line && hit.name && (\n            <p className=\"text-xs font-mono text-muted-foreground truncate\">{hit.match_line.trim()}</p>\n          )}\n\n          {hit.path && hit.line_number != null && hit.line_number > 0 && (\n            <PeekViewer path={hit.path} anchorLine={hit.line_number} />\n          )}\n        </div>\n      ))}\n    </div>\n  );\n}\n\n// ─── Main page ────────────────────────────────────────────────────────────────\n\nexport default function QueryPage() {\n  const [input, setInput] = useState(\"\");\n  const [loading, setLoading] = useState(false);\n  const [results, setResults] = useState<unknown>(null);\n  const [activeQuery, setActiveQuery] = useState<QueryDef | null>(null);\n\n  // Diff context state\n  const [diffRepoId, setDiffRepoId] = useState(\"\");\n  const [diffChangesText, setDiffChangesText] = useState(\"\");\n  const [diffLoading, setDiffLoading] = useState(false);\n  const [diffResults, setDiffResults] = useState<unknown>(null);\n\n  const runQuery = async (qDef: QueryDef) => {\n    if (qDef.needsInput && !input.trim()) {\n      toast.error(\"Please enter a query\");\n      return;\n    }\n    setLoading(true);\n    setActiveQuery(qDef);\n    setResults(null);\n    try {\n      const data = await qDef.fn(input.trim());\n      setResults(data);\n    } catch (e) {\n      toast.error(`Query failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  const runDiffContext = async () => {\n    if (!diffRepoId.trim()) {\n      toast.error(\"Please enter a repository ID\");\n      return;\n    }\n    const lines = diffChangesText.trim().split(\"\\n\").filter(Boolean);\n    const changes = lines.map((line) => {\n      const [filePath, range] = line.split(\":\");\n      if (range) {\n        const [start, end] = range.split(\"-\").map(Number);\n        return { file_path: filePath.trim(), start_line: start || 1, end_line: end || 999999 };\n      }\n      return { file_path: filePath.trim() };\n    });\n\n    if (changes.length === 0) {\n      toast.error(\"Please enter at least one file change\");\n      return;\n    }\n\n    setDiffLoading(true);\n    setDiffResults(null);\n    try {\n      const data = await api.getDiffContext({ repo_id: diffRepoId.trim(), changes });\n      setDiffResults(data);\n    } catch (e) {\n      toast.error(`Diff context failed: ${e instanceof Error ? e.message : \"Unknown error\"}`);\n    } finally {\n      setDiffLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"max-w-5xl mx-auto space-y-6\">\n      <h1 className=\"text-2xl font-bold\">Query</h1>\n\n      <Tabs defaultValue=\"Search\">\n        <TabsList>\n          {Object.keys(queryGroups).map((group) => (\n            <TabsTrigger key={group} value={group}>\n              {group}\n            </TabsTrigger>\n          ))}\n          <TabsTrigger value=\"DiffContext\">Code Review</TabsTrigger>\n        </TabsList>\n\n        {Object.entries(queryGroups).map(([group, queries]) => (\n          <TabsContent key={group} value={group} className=\"space-y-4 pt-4\">\n            <Input\n              placeholder=\"Enter search term or symbol name...\"\n              value={input}\n              onChange={(e) => setInput(e.target.value)}\n              className=\"text-base\"\n              onKeyDown={(e) => {\n                if (e.key === \"Enter\" && activeQuery) runQuery(activeQuery);\n              }}\n            />\n            <div className=\"flex flex-wrap gap-2\">\n              {queries.map((q) => (\n                <Button\n                  key={q.label}\n                  variant={activeQuery?.label === q.label ? \"default\" : \"secondary\"}\n                  size=\"sm\"\n                  onClick={() => runQuery(q)}\n                  disabled={loading}\n                >\n                  {q.label}\n                </Button>\n              ))}\n            </div>\n          </TabsContent>\n        ))}\n\n        <TabsContent value=\"DiffContext\" className=\"space-y-4 pt-4\">\n          <Card>\n            <CardHeader>\n              <CardTitle>Diff Context Builder</CardTitle>\n            </CardHeader>\n            <CardContent className=\"space-y-4\">\n              <p className=\"text-sm text-muted-foreground\">\n                Build RAG context for code review. Provide the repository and changed files\n                to get affected symbols, their callers, class hierarchy, and source code.\n              </p>\n              <div className=\"space-y-2\">\n                <Label>Repository ID</Label>\n                <Input\n                  placeholder=\"owner/repo_name\"\n                  value={diffRepoId}\n                  onChange={(e) => setDiffRepoId(e.target.value)}\n                />\n              </div>\n              <div className=\"space-y-2\">\n                <Label>Changed Files</Label>\n                <Textarea\n                  placeholder={\"One per line — file_path:start_line-end_line\\n\\nExamples:\\nsrc/main.py:10-30\\nsrc/utils.py:1-50\\nREADME.md\"}\n                  value={diffChangesText}\n                  onChange={(e) => setDiffChangesText(e.target.value)}\n                  rows={6}\n                  className=\"font-mono text-sm\"\n                />\n              </div>\n              <Button onClick={runDiffContext} disabled={diffLoading}>\n                {diffLoading ? \"Loading...\" : \"Get Diff Context\"}\n              </Button>\n            </CardContent>\n          </Card>\n\n          {diffResults !== null && (\n            <DiffContextResults data={diffResults as DiffContextData} />\n          )}\n        </TabsContent>\n      </Tabs>\n\n      {/* Query results */}\n      {loading && (\n        <Card>\n          <CardContent className=\"py-8 text-center text-muted-foreground\">\n            Loading...\n          </CardContent>\n        </Card>\n      )}\n\n      {!loading && results !== null && activeQuery !== null && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm text-muted-foreground\">\n              Results: {activeQuery.label}\n            </CardTitle>\n          </CardHeader>\n          <CardContent>\n            {activeQuery.isSearch ? (\n              <SearchResultsView data={results} />\n            ) : (\n              <ResultsView data={results} />\n            )}\n          </CardContent>\n        </Card>\n      )}\n    </div>\n  );\n}\n\n// ─── Diff Context Results ──────────────────────────────────────────────────────\n\ninterface DiffContextData {\n  affected_symbols: {\n    type: string;\n    name: string;\n    start_line: number;\n    end_line: number;\n    source: string | null;\n    docstring: string | null;\n    change_file: string;\n    file_path?: string;\n  }[];\n  callers: {\n    symbol: string;\n    symbol_type: string;\n    callers: { type: string; name: string; path: string; source: string | null }[];\n  }[];\n  class_hierarchy: {\n    class: string;\n    hierarchy: { name: string; path: string; source: string | null }[];\n  }[];\n  file_sources: Record<string, string>;\n  total_affected: number;\n  total_files: number;\n}\n\nfunction DiffContextResults({ data }: { data: DiffContextData }) {\n  return (\n    <div className=\"space-y-4\">\n      <div className=\"flex gap-3\">\n        <Badge variant=\"secondary\">{data.total_files} files</Badge>\n        <Badge variant=\"secondary\">{data.total_affected} affected symbols</Badge>\n        <Badge variant=\"secondary\">{data.callers.length} caller chains</Badge>\n        <Badge variant=\"secondary\">{data.class_hierarchy.length} class hierarchies</Badge>\n      </div>\n\n      {data.affected_symbols.length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">Affected Symbols</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-2 max-h-[400px] overflow-y-auto\">\n            {data.affected_symbols.map((sym, i) => (\n              <div key={i} className=\"p-3 rounded border border-border space-y-1\">\n                <div className=\"flex items-center gap-2\">\n                  <Badge variant={sym.type === \"function\" ? \"default\" : \"secondary\"}>{sym.type}</Badge>\n                  <span className=\"font-medium font-mono\">{sym.name}</span>\n                  <span className=\"text-xs text-muted-foreground\">\n                    {sym.change_file}:{sym.start_line}-{sym.end_line}\n                  </span>\n                </div>\n                {sym.docstring && (\n                  <p className=\"text-xs text-muted-foreground\">{sym.docstring}</p>\n                )}\n                {sym.source && (\n                  <CodeBlock\n                    code={sym.source}\n                    startLine={sym.start_line}\n                    maxHeight=\"max-h-48\"\n                  />\n                )}\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {data.callers.length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">Callers of Affected Symbols</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-3 max-h-[400px] overflow-y-auto\">\n            {data.callers.map((group, i) => (\n              <div key={i} className=\"space-y-1\">\n                <p className=\"text-sm font-medium\">\n                  <Badge variant=\"outline\" className=\"mr-1\">{group.symbol_type}</Badge>\n                  <span className=\"font-mono\">{group.symbol}</span>\n                  <span className=\"text-muted-foreground ml-1\">called by:</span>\n                </p>\n                {group.callers.map((caller, j) => (\n                  <div key={j} className=\"ml-4 p-2 rounded border border-border text-sm\">\n                    <span className=\"font-mono\">{caller.name}</span>\n                    <span className=\"text-xs text-muted-foreground ml-2\">{caller.path}</span>\n                    {caller.source && (\n                      <CodeBlock\n                        code={caller.source}\n                        maxHeight=\"max-h-32\"\n                        className=\"mt-1\"\n                      />\n                    )}\n                  </div>\n                ))}\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {data.class_hierarchy.length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">Class Hierarchy</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-2 max-h-[300px] overflow-y-auto\">\n            {data.class_hierarchy.map((h, i) => (\n              <div key={i} className=\"space-y-1\">\n                <p className=\"text-sm font-medium font-mono\">{h.class}</p>\n                <div className=\"ml-4 space-y-1\">\n                  {h.hierarchy.map((parent, j) => (\n                    <div key={j} className=\"flex items-center gap-2 text-sm\">\n                      <span className=\"text-muted-foreground\">{j === 0 ? \"\" : \"\\u2514\\u2500\"}</span>\n                      <span className=\"font-mono\">{parent.name}</span>\n                      <span className=\"text-xs text-muted-foreground\">{parent.path}</span>\n                    </div>\n                  ))}\n                </div>\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n\n      {Object.keys(data.file_sources).length > 0 && (\n        <Card>\n          <CardHeader>\n            <CardTitle className=\"text-sm\">File Sources</CardTitle>\n          </CardHeader>\n          <CardContent className=\"space-y-3 max-h-[400px] overflow-y-auto\">\n            {Object.entries(data.file_sources).map(([path, source]) => (\n              <div key={path} className=\"space-y-1\">\n                <p className=\"text-sm font-mono text-primary\">{path}</p>\n                <CodeBlock code={source} maxHeight=\"max-h-64\" />\n              </div>\n            ))}\n          </CardContent>\n        </Card>\n      )}\n    </div>\n  );\n}\n\n// ─── Generic Results ──────────────────────────────────────────────────────────\n\nfunction ResultsView({ data }: { data: unknown }) {\n  if (data === null || data === undefined) {\n    return <p className=\"text-muted-foreground\">No results</p>;\n  }\n\n  if (Array.isArray(data)) {\n    if (data.length === 0) return <p className=\"text-muted-foreground\">No results found</p>;\n    return (\n      <div className=\"space-y-2 max-h-[600px] overflow-y-auto\">\n        {data.map((item, i) => (\n          <div key={i} className=\"p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n            {typeof item === \"object\" ? <ObjectView obj={item} /> : String(item)}\n          </div>\n        ))}\n      </div>\n    );\n  }\n\n  if (typeof data === \"object\") {\n    return <ObjectView obj={data as Record<string, unknown>} />;\n  }\n\n  return <pre className=\"text-sm font-mono\">{String(data)}</pre>;\n}\n\nfunction ObjectView({ obj }: { obj: Record<string, unknown> }) {\n  return (\n    <div className=\"space-y-1\">\n      {Object.entries(obj).map(([key, value]) => {\n        if (key === \"source\" && typeof value === \"string\" && value) {\n          const startLine = (obj.line_number as number) || (obj.start_line as number) || 1;\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <CodeBlock code={value} startLine={startLine} maxHeight=\"max-h-64\" />\n            </div>\n          );\n        }\n\n        if (Array.isArray(value)) {\n          if (value.length === 0) {\n            return (\n              <div key={key} className=\"flex gap-2\">\n                <span className=\"text-primary font-medium shrink-0\">{key}:</span>\n                <span className=\"text-muted-foreground\">[]</span>\n              </div>\n            );\n          }\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <div className=\"ml-4 space-y-2\">\n                {value.map((item, i) => (\n                  <div key={i} className=\"p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n                    {typeof item === \"object\" && item !== null\n                      ? <ObjectView obj={item as Record<string, unknown>} />\n                      : String(item)}\n                  </div>\n                ))}\n              </div>\n            </div>\n          );\n        }\n\n        if (typeof value === \"object\" && value !== null) {\n          return (\n            <div key={key} className=\"space-y-1\">\n              <span className=\"text-primary font-medium\">{key}:</span>\n              <div className=\"ml-4 p-3 rounded border border-border text-sm font-mono whitespace-pre-wrap break-all\">\n                <ObjectView obj={value as Record<string, unknown>} />\n              </div>\n            </div>\n          );\n        }\n\n        return (\n          <div key={key} className=\"flex gap-2\">\n            <span className=\"text-primary font-medium shrink-0\">{key}:</span>\n            <span className=\"text-muted-foreground break-all\">\n              {String(value ?? \"\\u2014\")}\n            </span>\n          </div>\n        );\n      })}\n    </div>\n  );\n}\n"},"sourceToolAssistantUUID":"739335d0-b2b8-4e08-bb86-53441d0fcb5e"}
{"parentUuid":"d27848a1-49c7-4ca9-9768-e60ba387958a","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01Kur528UcRVagTaQqCyCVMA","type":"message","role":"assistant","content":[{"type":"text","text":"Let me verify the backend and API client are clean:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":7980,"cache_read_input_tokens":121441,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":7980},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLv9v4fPPGyCY3enAznb","type":"assistant","uuid":"e78d5425-b367-4dec-b7e7-9ad6e5811ffc","timestamp":"2026-02-21T08:42:33.766Z"}
{"parentUuid":"e78d5425-b367-4dec-b7e7-9ad6e5811ffc","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01Kur528UcRVagTaQqCyCVMA","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01QKKfcgSkQe6n2wi8KB8Z9S","name":"Grep","input":{"pattern":"search-symbols|searchSymbols","path":"/Users/skmabudalam/Documents/BugViper","output_mode":"content"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":7980,"cache_read_input_tokens":121441,"output_tokens":120,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":7980,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLv9v4fPPGyCY3enAznb","type":"assistant","uuid":"d0f32d60-e5b0-42a8-bb56-bbf9a1bfdd79","timestamp":"2026-02-21T08:42:34.754Z"}
{"parentUuid":"d0f32d60-e5b0-42a8-bb56-bbf9a1bfdd79","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01QKKfcgSkQe6n2wi8KB8Z9S","toolUseID":"toolu_01QKKfcgSkQe6n2wi8KB8Z9S","timestamp":"2026-02-21T08:42:35.449Z","uuid":"a6e358f5-be41-49c7-a940-d0757d7a7f79"}
{"parentUuid":"d0f32d60-e5b0-42a8-bb56-bbf9a1bfdd79","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01QKKfcgSkQe6n2wi8KB8Z9S","type":"tool_result","content":"Claude.md:229:| GET | `/api/v1/query/search-symbols` | Symbol-only search |"}]},"uuid":"88117e06-6615-4eb9-a0dc-697307b0e7c6","timestamp":"2026-02-21T08:42:35.447Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"Claude.md:229:| GET | `/api/v1/query/search-symbols` | Symbol-only search |","numLines":1},"sourceToolAssistantUUID":"d0f32d60-e5b0-42a8-bb56-bbf9a1bfdd79"}
{"parentUuid":"88117e06-6615-4eb9-a0dc-697307b0e7c6","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_015RrucB9k7GfCH8Y7hLEQPu","type":"message","role":"assistant","content":[{"type":"text","text":"Good — only a stale mention in Claude.md (documentation), no live code references. Let me update that too:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":269,"cache_read_input_tokens":129421,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":269},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvAEyhb4Qx3X8MZaJ7x","type":"assistant","uuid":"23d739af-b95a-4453-94fc-766d50d0d282","timestamp":"2026-02-21T08:42:38.227Z"}
{"parentUuid":"23d739af-b95a-4453-94fc-766d50d0d282","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_015RrucB9k7GfCH8Y7hLEQPu","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012gp8qsAD5GY5Lbpvvtca2R","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/Claude.md","offset":220,"limit":20},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":269,"cache_read_input_tokens":129421,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":269},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvAEyhb4Qx3X8MZaJ7x","type":"assistant","uuid":"4d923a28-7d31-4a55-8a0e-4874ee8c8a56","timestamp":"2026-02-21T08:42:38.961Z"}
{"parentUuid":"4d923a28-7d31-4a55-8a0e-4874ee8c8a56","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_012gp8qsAD5GY5Lbpvvtca2R","toolUseID":"toolu_012gp8qsAD5GY5Lbpvvtca2R","timestamp":"2026-02-21T08:42:39.126Z","uuid":"a894748d-fb69-4a35-8197-f69eafcde90c"}
{"parentUuid":"4d923a28-7d31-4a55-8a0e-4874ee8c8a56","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012gp8qsAD5GY5Lbpvvtca2R","type":"tool_result","content":"   220→Peek API (`/code-finder/peek`): language-agnostic line-window fetcher. Takes `path`, `line`, `above`, `below`. Used for interactive code navigation in the frontend.\n   221→\n   222→## Key Endpoints\n   223→\n   224→| Method | Path | Description |\n   225→|--------|------|-------------|\n   226→| POST | `/api/v1/ingest/repository` | Ingest a repository |\n   227→| POST | `/api/v1/ingest/setup` | Initialize DB schema |\n   228→| GET | `/api/v1/query/search` | Full-text code search (auto-fallback symbol→file content) |\n   229→| GET | `/api/v1/query/search-symbols` | Symbol-only search |\n   230→| GET | `/api/v1/query/stats` | Total node counts (functions, classes, files, etc.) |\n   231→| GET | `/api/v1/query/metrics` | Same as stats, supports `?repo_id=` scoping |\n   232→| GET | `/api/v1/query/language/stats` | Per-language file/function/class counts |\n   233→| GET | `/api/v1/query/method-usages` | Find all callers of a function |\n   234→| GET | `/api/v1/query/find_callers` | Find callers of a symbol |\n   235→| GET | `/api/v1/query/class_hierarchy` | Class inheritance hierarchy |\n   236→| GET | `/api/v1/query/change_impact` | Change impact analysis |\n   237→| GET | `/api/v1/query/code-finder/line` | Search file content (raw line search) |\n   238→| GET | `/api/v1/query/code-finder/peek` | Peek lines around a file location |\n   239→| GET | `/api/v1/query/code-finder/complexity` | Cyclomatic complexity for one function |\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"d1f6ae5a-6044-413d-bb31-09f7f62c91e5","timestamp":"2026-02-21T08:42:39.125Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/Claude.md","content":"Peek API (`/code-finder/peek`): language-agnostic line-window fetcher. Takes `path`, `line`, `above`, `below`. Used for interactive code navigation in the frontend.\n\n## Key Endpoints\n\n| Method | Path | Description |\n|--------|------|-------------|\n| POST | `/api/v1/ingest/repository` | Ingest a repository |\n| POST | `/api/v1/ingest/setup` | Initialize DB schema |\n| GET | `/api/v1/query/search` | Full-text code search (auto-fallback symbol→file content) |\n| GET | `/api/v1/query/search-symbols` | Symbol-only search |\n| GET | `/api/v1/query/stats` | Total node counts (functions, classes, files, etc.) |\n| GET | `/api/v1/query/metrics` | Same as stats, supports `?repo_id=` scoping |\n| GET | `/api/v1/query/language/stats` | Per-language file/function/class counts |\n| GET | `/api/v1/query/method-usages` | Find all callers of a function |\n| GET | `/api/v1/query/find_callers` | Find callers of a symbol |\n| GET | `/api/v1/query/class_hierarchy` | Class inheritance hierarchy |\n| GET | `/api/v1/query/change_impact` | Change impact analysis |\n| GET | `/api/v1/query/code-finder/line` | Search file content (raw line search) |\n| GET | `/api/v1/query/code-finder/peek` | Peek lines around a file location |\n| GET | `/api/v1/query/code-finder/complexity` | Cyclomatic complexity for one function |","numLines":20,"startLine":220,"totalLines":250}},"sourceToolAssistantUUID":"4d923a28-7d31-4a55-8a0e-4874ee8c8a56"}
{"parentUuid":"d1f6ae5a-6044-413d-bb31-09f7f62c91e5","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01BZdcirySoS3nExGvNpNHQb","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011wFoThX54eKfCgvXaeT7Pp","name":"Edit","input":{"replace_all":false,"file_path":"/Users/skmabudalam/Documents/BugViper/Claude.md","old_string":"| GET | `/api/v1/query/search` | Full-text code search (auto-fallback symbol→file content) |\n| GET | `/api/v1/query/search-symbols` | Symbol-only search |","new_string":"| GET | `/api/v1/query/search` | Unified search: symbols → name CONTAINS → file content line search |"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":706,"cache_read_input_tokens":129690,"output_tokens":206,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":706,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLvAVnh7pZdjDeS2rbB3","type":"assistant","uuid":"d55a5c13-92dd-40ea-932a-cfbc4f23cc5d","timestamp":"2026-02-21T08:42:42.739Z"}
{"type":"file-history-snapshot","messageId":"d55a5c13-92dd-40ea-932a-cfbc4f23cc5d","snapshot":{"messageId":"e4d4e55a-5df6-4491-81af-9c5c363c5a2a","trackedFileBackups":{"db/schema.py":{"backupFileName":"283975a9ba984ffc@v2","version":2,"backupTime":"2026-02-21T08:34:53.260Z"},"db/queries.py":{"backupFileName":"3dbb7f971a633538@v3","version":3,"backupTime":"2026-02-21T08:39:32.577Z"},"api/routers/query.py":{"backupFileName":"e6ad69c83e8fb9b0@v2","version":2,"backupTime":"2026-02-21T08:34:53.261Z"},"frontend/app/(protected)/query/page.tsx":{"backupFileName":"30dea031ecc29fcb@v2","version":2,"backupTime":"2026-02-21T08:34:53.262Z"},"frontend/lib/api.ts":{"backupFileName":"a3322355f2d59118@v1","version":1,"backupTime":"2026-02-21T08:40:54.703Z"},"Claude.md":{"backupFileName":"8ee2a4b8e81d0daa@v1","version":1,"backupTime":"2026-02-21T08:42:42.905Z"}},"timestamp":"2026-02-21T08:39:32.576Z"},"isSnapshotUpdate":true}
{"parentUuid":"d55a5c13-92dd-40ea-932a-cfbc4f23cc5d","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_011wFoThX54eKfCgvXaeT7Pp","toolUseID":"toolu_011wFoThX54eKfCgvXaeT7Pp","timestamp":"2026-02-21T08:42:42.910Z","uuid":"a9cfecd1-8239-429a-abfe-226d01f18622"}
{"parentUuid":"d55a5c13-92dd-40ea-932a-cfbc4f23cc5d","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011wFoThX54eKfCgvXaeT7Pp","type":"tool_result","content":"The file /Users/skmabudalam/Documents/BugViper/Claude.md has been updated successfully."}]},"uuid":"44b3ec6f-7eb9-46ab-b4c3-5c0e9fb2ea69","timestamp":"2026-02-21T08:42:42.907Z","toolUseResult":{"filePath":"/Users/skmabudalam/Documents/BugViper/Claude.md","oldString":"| GET | `/api/v1/query/search` | Full-text code search (auto-fallback symbol→file content) |\n| GET | `/api/v1/query/search-symbols` | Symbol-only search |","newString":"| GET | `/api/v1/query/search` | Unified search: symbols → name CONTAINS → file content line search |","originalFile":"# CLAUDE.md - BugViper\n\n## Project Overview\n\nBugViper is a full-stack AI-powered code review and repository intelligence platform. It ingests repositories into a Neo4j graph database via Tree-sitter AST parsing (17 languages), then uses multi-agent LLM pipelines to perform automated PR reviews (bug detection + security auditing). The frontend is a Next.js dashboard for repository management, code search, and graph exploration.\n\n**Status**: Work In Progress (Alpha)\n\n## Tech Stack\n\n### Backend (Python 3.13+)\n- **Framework**: FastAPI + Uvicorn\n- **Package Manager**: uv (lockfile: `uv.lock`)\n- **Database**: Neo4j (graph database)\n- **Code Parsing**: Tree-sitter (17 language parsers)\n- **AI/LLM**: Pydantic AI + OpenRouter\n- **GitHub**: PyGithub + GitHub App webhooks\n- **Firebase**: firebase-admin SDK\n- **Observability**: Logfire\n\n### Frontend (Node.js)\n- **Framework**: Next.js 16 (App Router) + React 19\n- **Language**: TypeScript (strict mode)\n- **Styling**: TailwindCSS 4 + shadcn/ui (Radix primitives)\n- **Icons**: Lucide React\n\n## Project Structure\n\n```\napi/                    # FastAPI backend\n├── app.py              # Entry point, CORS, router registration\n├── dependencies.py     # DI (Neo4j client injection)\n├── models/schemas.py   # Pydantic request/response models\n├── routers/            # REST endpoints\n│   ├── ingestion.py    #   POST /repository, /setup\n│   ├── query.py        #   GET /search, /stats, /code-finder/*\n│   ├── repository.py   #   GET/DELETE repositories\n│   └── webhook.py      #   POST /onPush, /onComment, /github\n├── services/           # Business logic\n│   ├── review_service.py   # PR review pipeline orchestration\n│   └── push_service.py     # Incremental push handling\n└── utils/              # Helpers (comment_formatter, graph_context)\n\ndb/                     # Neo4j database layer\n├── client.py           # Connection management + retry logic\n├── ingestion.py        # Graph ingestion service\n├── queries.py          # CodeQueryService (search, stats, CRUD)\n└── schema.py           # Constraints, indexes, schema init\n\ndeepagent/              # AI agent system\n├── config.py           # Agent config (models, temperature)\n├── prompts.py          # System prompts (bug-hunter, security-auditor)\n└── agent/\n    └── review_pipeline.py  # Multi-agent parallel execution + dedup\n\ningestion/              # Code parsing & ingestion engine\n├── repo_ingestion_engine.py  # Main orchestrator (AdvancedIngestionEngine)\n├── graph_builder.py          # Graph construction from parsed ASTs\n├── github_client.py          # GitHub API interactions\n├── code_search.py            # Code search functionality\n├── language_query.py         # Language-specific queries\n├── languages/                # Per-language Tree-sitter parsers (17 files)\n├── handlers/                 # Indexing, analysis, management handlers\n├── core/                     # Database helpers, job management\n└── utils/                    # tree_sitter_manager, debug_log\n\ncommon/                 # Shared utilities\n├── diff_parser.py      # Unified diff parsing\n└── bugviper_firebase_service.py  # Firebase integration\n\nfrontend/               # Next.js 16 frontend\n├── app/                # App Router pages\n│   ├── layout.tsx      #   Root layout + sidebar\n│   ├── page.tsx        #   Dashboard (repo stats)\n│   ├── query/page.tsx  #   Code search interface\n│   └── repositories/page.tsx  # Repo management + ingestion\n├── components/         # React components\n│   ├── sidebar.tsx     #   Navigation\n│   └── ui/             #   shadcn/ui components (15+)\n└── lib/\n    ├── api.ts          # API client\n    └── utils.ts        # Utilities\n```\n\n## Commands\n\n### Run Everything\n```bash\n./start.sh              # Starts API + Frontend + Ngrok\n```\n\n### Backend\n```bash\nuvicorn api.app:app --host 0.0.0.0 --port 8000 --reload\n```\n\n### Frontend\n```bash\ncd frontend && npm run dev     # Dev server on :3000\ncd frontend && npm run build   # Production build\ncd frontend && npm run lint    # ESLint\n```\n\n### Python Quality\n```bash\npytest                  # Run tests\npytest --cov            # With coverage\nblack .                 # Format code\nruff check .            # Lint\nmypy .                  # Type check\n```\n\n## Coding Conventions\n\n### Python\n- Line length: 100 (Black + Ruff)\n- Full type annotations (Pydantic models everywhere)\n- Classes: PascalCase, functions: snake_case, constants: UPPER_SNAKE_CASE\n- Linting rules: E, F, I, W (Ruff)\n- Async/await for API handlers\n\n### TypeScript/React\n- Strict mode enabled\n- `\"use client\"` directive on client components\n- Import alias: `@/*` maps to project root\n- Components: PascalCase filenames\n\n### API Design\n- RESTful routes under `/api/v1/{resource}/{action}`\n- API version: v0.2.0\n- Auto-docs at `/docs` (Swagger) and `/redoc`\n\n## Environment Variables\n\nKey variables (see `.env.example` for full list):\n- `NEO4J_URI`, `NEO4J_USER`, `NEO4J_PASSWORD` - Database\n- `OPENROUTER_API_KEY` - LLM provider\n- `CONTEXT_MODEL`, `REVIEW_MODEL` - Model selection\n- `GITHUB_APP_ID`, `GITHUB_PRIVATE_KEY_PATH`, `GITHUB_WEBHOOK_SECRET` - GitHub App\n- `ENABLE_LOGFIRE`, `LOGFIRE_TOKEN` - Observability\n\n## Architecture Notes\n\n- **Layered backend**: Routers → Services → Queries → Neo4j Client\n- **Multi-agent reviews**: Bug-hunter + Security-auditor run in parallel, results deduplicated\n- **Incremental ingestion**: Push webhooks trigger partial graph updates (not full re-ingestion)\n- **Graph model**: 14+ node types with constraints and full-text indexes\n- **17 language parsers**: Each in `ingestion/languages/` with Tree-sitter queries\n\n## Graph Schema (Actual — as created by ingestion)\n\nNode types: `Function`, `Class`, `File`, `Variable`, `Module`, `Repository`\n\nKey relationships:\n- `(File)-[:CONTAINS]->(Function|Class|Variable)` — NOT `[:DEFINES]`\n- `(Class)-[:CONTAINS]->(Function)` — class methods are `Function` nodes, NOT `Method` nodes\n- `(Function)-[:CALLS]->(Function)` — call edges with optional `line_number` property\n- `(Class)-[:INHERITS]->(Class)` — inheritance\n- `(Repository)-[:CONTAINS]->(File)` — repo scoping\n- `(File)-[:IMPORTS]->(Module)` — import edges with `alias`, `imported_name`, `line_number` properties on the relationship\n- `(Class)-[:INCLUDES]->(Module)` — Ruby mixin includes\n\nModule nodes represent either directory paths OR external package names (e.g. `fastapi`, `react`). Properties: `name` (unique), `lang`.\n\n**Does NOT exist**: `Method` nodes, `CodeLine` nodes, `[:DEFINES]`, `[:REFERENCES]`, `[:HAS_IMPORT]`, dedicated `Import` nodes.\n\n## CodeFinder APIs (`/api/v1/query/code-finder/*`)\n\nAll endpoints live in `api/routers/query.py` and delegate to `api/services/code_search.py` (`CodeFinder` class).\n\n| Endpoint | Query strategy | Notes |\n|---|---|---|\n| `/function?name=` | `MATCH (Function {name:$name})` | Exact match. Add `&fuzzy=true` for fulltext. |\n| `/class?name=` | `MATCH (Class {name:$name})` | Same as above. |\n| `/variable?name=` | `Variable.name CONTAINS $term` | Substring scan, no fulltext index. |\n| `/content?query=` | `code_search` fulltext → CONTAINS fallback | Searches name + docstring + source_code of Function/Class/Variable. |\n| `/line?query=` | `file_content_search` fulltext → File CONTAINS fallback | Arbitrary code line search across File.source_code. Returns path + line_number + match_line only (no source dump). |\n| `/peek?path=&line=&above=&below=` | Fetches File.source_code, slices window | Language-agnostic. Pair with `/line` or `/search` for inline browsing. |\n| `/module?name=` | `Module.name CONTAINS $term` | Returns module + files that import it. Module nodes = directory paths OR package names. |\n| `/imports?name=` | `(File)-[:IMPORTS]->(Module)` CONTAINS on module name, imported_name, alias | Substring match on all three fields. Returns module_name + imported_name + alias + file path + line. |\n| `/complexity?function_name=` | `MATCH (Function {name:$name})` + optional `&path=` filter | Returns score for one function. Use `&path=` when name exists in multiple files. |\n| `/complexity/top?limit=` | ORDER BY cyclomatic_complexity DESC, is_dependency=false | Default limit 10. Only your code, not dependencies. |\n\n## Metrics APIs (`/api/v1/query/stats`, `/metrics`, `/language/stats`)\n\n| Endpoint | What it returns |\n|---|---|\n| `GET /query/stats` | Total node counts across entire graph: functions, classes, files, variables, imports, repositories |\n| `GET /query/metrics` | Same as stats. Add `?repo_id=owner/repo` to scope to one repository. |\n| `GET /query/language/stats` | Per-language breakdown: file_count, function_count, class_count. Add `?language=Python` to filter. |\n\n## Cyclomatic Complexity\n\nCalculated at **ingestion time** by Tree-sitter parsers. Stored as `Function.cyclomatic_complexity` (integer).\n\n**Formula**: starts at 1, +1 for each: `if`, `for`, `while`, `except`, `with`, `boolean_operator` (`and`/`or`), list comprehension, `case` clause.\n\n**Language support**:\n- Full calculation: Python, TypeScript, C\n- Defaults to `1`: all other languages (C++, Java, Go, Rust, etc.)\n\n**Score interpretation**:\n- 1–5: Simple, easy to test\n- 6–10: Moderate, worth reviewing\n- 11–20: Complex, refactor candidate\n- 20+: Very high risk — bugs likely here\n\n## Full-Text Search Architecture (Two-Tier)\n\nNeo4j fulltext indexes:\n- `code_search` — covers `Function`, `Class`, `Method`, `Variable` nodes on `name`, `docstring`, `source_code`\n- `file_content_search` — covers `File` nodes on `source_code`\n\nSearch strategy in `db/queries.py` `search_code()`:\n1. Query `code_search` index first (symbol names, docstrings)\n2. If empty, fall back to `file_content_search` (arbitrary code lines)\n3. Lucene escaping: simple identifiers → phrase search `\"...\"`, special-char queries → AND-keyword strategy `token1 AND token2`\n4. Returns lean results: `path`, `line_number`, `match_line` — no full source_code dump\n\nPeek API (`/code-finder/peek`): language-agnostic line-window fetcher. Takes `path`, `line`, `above`, `below`. Used for interactive code navigation in the frontend.\n\n## Key Endpoints\n\n| Method | Path | Description |\n|--------|------|-------------|\n| POST | `/api/v1/ingest/repository` | Ingest a repository |\n| POST | `/api/v1/ingest/setup` | Initialize DB schema |\n| GET | `/api/v1/query/search` | Full-text code search (auto-fallback symbol→file content) |\n| GET | `/api/v1/query/search-symbols` | Symbol-only search |\n| GET | `/api/v1/query/stats` | Total node counts (functions, classes, files, etc.) |\n| GET | `/api/v1/query/metrics` | Same as stats, supports `?repo_id=` scoping |\n| GET | `/api/v1/query/language/stats` | Per-language file/function/class counts |\n| GET | `/api/v1/query/method-usages` | Find all callers of a function |\n| GET | `/api/v1/query/find_callers` | Find callers of a symbol |\n| GET | `/api/v1/query/class_hierarchy` | Class inheritance hierarchy |\n| GET | `/api/v1/query/change_impact` | Change impact analysis |\n| GET | `/api/v1/query/code-finder/line` | Search file content (raw line search) |\n| GET | `/api/v1/query/code-finder/peek` | Peek lines around a file location |\n| GET | `/api/v1/query/code-finder/complexity` | Cyclomatic complexity for one function |\n| GET | `/api/v1/query/code-finder/complexity/top` | Top N most complex functions (your code only) |\n| GET | `/api/v1/repositories/` | List repositories |\n| POST | `/api/v1/webhook/onPush` | GitHub push webhook |\n| POST | `/api/v1/webhook/onComment` | GitHub PR comment webhook |\n\n## Cost & Token Pitfalls\n\n- NEVER use a polling/orchestrator LLM for fixed workflows — use `asyncio.gather` + direct agent calls\n- `pydantic_deep` pattern burned $6.33/review (700K tokens) — `check_task` returned full diff on every poll\n- Correct pattern: `deepagent/agent/review_pipeline.py` — 2 direct `Agent.run()` calls via `asyncio.gather`\n","structuredPatch":[{"oldStart":225,"oldLines":8,"newStart":225,"newLines":7,"lines":[" |--------|------|-------------|"," | POST | `/api/v1/ingest/repository` | Ingest a repository |"," | POST | `/api/v1/ingest/setup` | Initialize DB schema |","-| GET | `/api/v1/query/search` | Full-text code search (auto-fallback symbol→file content) |","-| GET | `/api/v1/query/search-symbols` | Symbol-only search |","+| GET | `/api/v1/query/search` | Unified search: symbols → name CONTAINS → file content line search |"," | GET | `/api/v1/query/stats` | Total node counts (functions, classes, files, etc.) |"," | GET | `/api/v1/query/metrics` | Same as stats, supports `?repo_id=` scoping |"," | GET | `/api/v1/query/language/stats` | Per-language file/function/class counts |"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"d55a5c13-92dd-40ea-932a-cfbc4f23cc5d"}
{"parentUuid":"44b3ec6f-7eb9-46ab-b4c3-5c0e9fb2ea69","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01G2aTuBejYj33vDrrHQnKVY","type":"message","role":"assistant","content":[{"type":"text","text":"Done. Here's a summary of everything changed:\n\n---\n\n## What changed\n\n### Backend\n**`api/routers/query.py`** — Removed `GET /search-symbols` entirely. The `/search` endpoint is now the single entry point, with a `limit` param (default 30).\n\n**`frontend/lib/api.ts`** — Removed `searchSymbols`. Updated `searchCode` to accept a `limit` parameter. Updated `findDefinition` to call `/search` instead of the removed endpoint.\n\n### Frontend (`query/page.tsx`)\n**Complete redesign of the Search tab** — it's now a standalone `SearchTab` component (not part of the shared button group):\n- Single wide search bar, autofocused, runs on Enter or the Search button\n- Results grouped into two sections: **Symbols** (function/class/variable) and **File matches** (raw code lines)\n- Each result card shows: colour-coded type badge, name in monospace, pretty path (directory dimmed, filename bold, line number in a pill)\n- **PeekViewer** now has a cleaner inline design — line numbers in a gutter column, anchor line highlighted yellow with a left border, `↑ 20 more above` / `20 more below ↓` expand links\n\n**Analysis/CodeFinder/Metrics tabs** — refactored into a shared `GenericQueryTab` component (same functionality, slightly cleaner code). Each tab now manages its own input independently so switching tabs doesn't reset your query.\n\n**The difference between \"full-text\" and \"symbol\" search is gone** — there was no real user-visible difference. The unified search now handles both in one call."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":743,"cache_read_input_tokens":130396,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":743},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvAn1G6TibhubeiWujW","type":"assistant","uuid":"c83e1794-153c-49e2-b74c-6ca78cc16189","timestamp":"2026-02-21T08:42:56.357Z"}
{"parentUuid":"c83e1794-153c-49e2-b74c-6ca78cc16189","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"6610765c-2aa6-4acb-896a-6639ec319ff2","toolUseID":"6610765c-2aa6-4acb-896a-6639ec319ff2","timestamp":"2026-02-21T08:42:56.533Z","uuid":"aca780c7-18d6-464e-aa0e-9feeae71ece8"}
{"parentUuid":"aca780c7-18d6-464e-aa0e-9feeae71ece8","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":2250}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-21T08:42:58.784Z","uuid":"cb8d6c72-d00b-4b23-9333-9b74234ab95c","toolUseID":"6610765c-2aa6-4acb-896a-6639ec319ff2"}
{"parentUuid":"cb8d6c72-d00b-4b23-9333-9b74234ab95c","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"system","subtype":"turn_duration","durationMs":197211,"timestamp":"2026-02-21T08:42:58.789Z","uuid":"8a1eeca7-afd5-49e2-81fb-6385228aa742","isMeta":false}
{"type":"file-history-snapshot","messageId":"4fb8faa7-bcb8-4341-8490-db48e24b14e0","snapshot":{"messageId":"4fb8faa7-bcb8-4341-8490-db48e24b14e0","trackedFileBackups":{"db/schema.py":{"backupFileName":"283975a9ba984ffc@v2","version":2,"backupTime":"2026-02-21T08:34:53.260Z"},"db/queries.py":{"backupFileName":"3dbb7f971a633538@v3","version":3,"backupTime":"2026-02-21T08:39:32.577Z"},"api/routers/query.py":{"backupFileName":"e6ad69c83e8fb9b0@v3","version":3,"backupTime":"2026-02-21T08:47:02.990Z"},"frontend/app/(protected)/query/page.tsx":{"backupFileName":"30dea031ecc29fcb@v3","version":3,"backupTime":"2026-02-21T08:47:02.991Z"},"frontend/lib/api.ts":{"backupFileName":"a3322355f2d59118@v2","version":2,"backupTime":"2026-02-21T08:47:02.991Z"},"Claude.md":{"backupFileName":"8ee2a4b8e81d0daa@v2","version":2,"backupTime":"2026-02-21T08:47:02.992Z"}},"timestamp":"2026-02-21T08:47:02.990Z"},"isSnapshotUpdate":false}
{"parentUuid":"8a1eeca7-afd5-49e2-81fb-6385228aa742","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":"is this fast and most optimized and secure ?"},"uuid":"4fb8faa7-bcb8-4341-8490-db48e24b14e0","timestamp":"2026-02-21T08:46:59.931Z","todos":[],"permissionMode":"acceptEdits"}
{"parentUuid":"4fb8faa7-bcb8-4341-8490-db48e24b14e0","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01BpjmbqDWkaPbxKesJzci7p","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The user is asking if the current search implementation is fast, optimized, and secure. Let me analyze the code thoroughly.\n\nLet me look at the key files:\n1. `db/queries.py` - the search methods\n2. `api/routers/query.py` - the endpoints\n3. `db/schema.py` - the Cypher queries\n\nLet me think about the issues:\n\n### Performance Issues:\n1. **`search_file_content`** - This is the biggest performance problem. It:\n   - Fetches up to 20 entire files' `source_code` from Neo4j\n   - Then does Python-side line scanning\n   - Files can be large (thousands of lines), returning huge payloads from Neo4j just to scan them in Python\n   - The CONTAINS fallback loads ALL matching files' full source code into memory\n\n2. **`_name_contains_fallback`** - Does a CONTAINS scan on all Function/Class/Variable nodes. With a large graph this is a full table scan.\n\n3. **`search_code` tier 3** - Calls `search_file_content` which as noted above is expensive.\n\n4. **`peek_file_lines`** - Fetches the entire file's source_code just to slice a small window. This is wasteful for large files.\n\n5. **Missing indexes** - CONTAINS queries on `node.name` may not use Neo4j's property indexes efficiently. Neo4j does have property indexes but CONTAINS requires a full scan unless there's a text index.\n\nOn the security side, there are a few concerns: unused imports are just cleanup, but there's no input validation or length limits on search terms, and the Lucene query escaping could potentially be bypassed. The search results expose internal file paths, and there's no rate limiting on the endpoints.\n\nThe full-text search on `file_content_search` should be fast, but the Python-side line scanning after fetching the full source code defeats that efficiency. The AND keyword strategy could create false positives when terms just happen to appear together, and picking the longest identifier in `_name_contains_fallback` doesn't always give the most relevant result. That said, the 3-tier fallback strategy is solid for resilience, and the Lucene escaping approach is generally sound.\n\nFor improvements, I should optimize `search_file_content` by using Cypher string operations to filter results directly rather than pulling the entire source code into Python. I can leverage the fulltext index on `file_content_search` and then use Cypher to split the source code and find matching lines...\n\nWriting Cypher query...\n\nThe issue is that even with Cypher handling the line splitting, large source files still create massive payloads. The pragmatic solution is to truncate the source_code field in the query itself to avoid sending unnecessary data. I should also add input validation to cap query length and sanitize dangerous characters before processing.\n\nThe real performance bottleneck is the `search_file_content` function—its CONTAINS fallback triggers full table scans across all files since Neo4j can't efficiently index that operation. I need to either move the line scanning logic into Cypher or at least limit how many files get scanned. The priority fixes are adding input validation with length limits and null byte stripping, then optimizing the file content search to avoid these expensive full scans. of files and truncate source\n3. **Performance - `_name_contains_fallback`**: This is fine for reasonably sized graphs since Function/Class/Variable nodes are indexed, but CONTAINS still requires a scan\n4. **Cleanup - unused imports**: Remove `Body`, `Optional`, `os` from query.py\n5. **Security - Path traversal**: The peek endpoint takes a `path` parameter and queries Neo4j with it. This could be used to probe for files if Neo4j has sensitive data. But since it's just querying the graph database (not the filesystem), it's relatively safe. Still, we could add basic path validation.\n\nThe Lucene injection risk is minimal since the regex only captures word characters and wraps them in quotes, Cypher injection isn't possible with parameterized queries, and path traversal on the peek endpoint doesn't apply because it's querying the graph rather than the filesystem. The main concern is DoS from expensive CONTAINS queries on large graphs without rate limiting or search term length restrictions. So I should focus on the practical improvements: removing those unused imports and adding query validation. length validation** in the `/search` endpoint\n3. **Optimize `search_file_content`**:\n   - Keep the fulltext approach\n   - For the Python-side line scan: limit source_code size fetched (add `LEFT(f.source_code, 500000)` or similar)\n   - Or better: do the line matching in Cypher with `apoc.text.split` if APOC is available, otherwise keep Python-side but limit\n4. **Add `is not None` check** in the CONTAINS queries to avoid null handling issues\n\nActually, let me be more practical. The user asks \"is this fast and most optimized and secure?\" - I should give an honest assessment and make targeted improvements.\n\n**Current performance analysis:**\n- Tier 1 (fulltext): Fast - Neo4j fulltext indexes are B-tree based, O(log n) lookup\n- Tier 2 (CONTAINS on names): Medium - property indexes help but CONTAINS still requires scanning, though acceptable for typical codebases with tens of thousands of nodes\n- Tier 3 (file content search): The bottleneck - fulltext is fast, but the CONTAINS fallback scans entire source files which can be megabytes each, and the Python line scan scales poorly with repository size\n\nSo I'll focus on removing that problematic CONTAINS fallback on file content entirely, clean up the unused imports, add input validation to the endpoint, and cap the source code size we fetch for the Python-side matching.\n\nI'm realizing the main security gap is the lack of input length limits—a very long search query could cause memory issues. The injection prevention is solid, but I should add that safeguard. For correctness, I need to make sure the fallback behavior doesn't silently fail or return incomplete results.\n\nMy approach is to add a 500-character limit on search queries in the router, then optimize the database layer by filtering out oversized source files and adding null checks to prevent expensive full table scans.\n\nFor the `search_file_content` function specifically, I need to address the Python line scanning that pulls entire source files from Neo4j—for large repositories this could mean fetching hundreds of megabytes. The fix is to truncate the source code within the Cypher query itself using string operations and line splitting, rather than pulling everything into memory and filtering client-side.\n\nRefining the Cypher approach...\n\nI realize the CONTAINS check on the full source code is still inefficient without a fulltext index, since it scans entire file contents. The best practical approach is to add a file size constraint to skip massive files, keep the line-by-line scanning in Cypher to avoid transferring huge strings back to Python, and cap the results.\n\nNow I'm identifying the security issues to fix: the search term needs a length limit of 500 characters, rate limiting would require middleware so I'll note that as a future improvement, and I should remove the unused imports. I'm going to update the query router to validate input length and refactor the search query to handle the file size constraint and result limiting.\n\nWriting the code changes...","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":173,"cache_read_input_tokens":131526,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":173},"output_tokens":6,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvVyAFjvWdsqTqeqouA","type":"assistant","uuid":"bc479eae-59ce-47d6-821b-b03dfe668812","timestamp":"2026-02-21T08:48:15.322Z"}
{"parentUuid":"bc479eae-59ce-47d6-821b-b03dfe668812","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01BpjmbqDWkaPbxKesJzci7p","type":"message","role":"assistant","content":[{"type":"text","text":"Let me audit all three layers systematically."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":173,"cache_read_input_tokens":131526,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":173},"output_tokens":6,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvVyAFjvWdsqTqeqouA","type":"assistant","uuid":"1aad3529-834d-44c0-856c-891b9e24c1af","timestamp":"2026-02-21T08:48:15.546Z"}
{"parentUuid":"1aad3529-834d-44c0-856c-891b9e24c1af","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01BpjmbqDWkaPbxKesJzci7p","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01UfJK8CtUTauTTGgF2uRhdT","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/db/queries.py","offset":278,"limit":220},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":173,"cache_read_input_tokens":131526,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":173},"output_tokens":6,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvVyAFjvWdsqTqeqouA","type":"assistant","uuid":"095dd472-104d-4253-99ce-937dadea0dc5","timestamp":"2026-02-21T08:48:16.459Z"}
{"parentUuid":"095dd472-104d-4253-99ce-937dadea0dc5","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01UfJK8CtUTauTTGgF2uRhdT","toolUseID":"toolu_01UfJK8CtUTauTTGgF2uRhdT","timestamp":"2026-02-21T08:48:16.647Z","uuid":"6c2f0d43-96c9-4215-aa2e-b8520e2c5983"}
{"parentUuid":"095dd472-104d-4253-99ce-937dadea0dc5","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01UfJK8CtUTauTTGgF2uRhdT","type":"tool_result","content":"   278→    # Python/JS keywords that should not be used as search identifiers\n   279→    _CODE_KEYWORDS = frozenset({\n   280→        'class', 'def', 'import', 'from', 'return', 'self', 'cls', 'None',\n   281→        'True', 'False', 'and', 'or', 'not', 'in', 'is', 'if', 'else',\n   282→        'elif', 'for', 'while', 'try', 'except', 'with', 'as', 'pass',\n   283→        'break', 'continue', 'raise', 'yield', 'async', 'await', 'lambda',\n   284→        'function', 'const', 'let', 'var', 'new', 'this', 'super',\n   285→    })\n   286→\n   287→    def _extract_identifiers(self, query: str) -> List[str]:\n   288→        \"\"\"Extract meaningful code identifiers from a raw query string.\"\"\"\n   289→        tokens = re.findall(r'\\b[A-Za-z_][A-Za-z0-9_]{2,}\\b', query)\n   290→        seen: set = set()\n   291→        result = []\n   292→        for t in tokens:\n   293→            if t not in self._CODE_KEYWORDS and t not in seen:\n   294→                seen.add(t)\n   295→                result.append(t)\n   296→        return result\n   297→\n   298→    def _escape_lucene_query(self, query: str) -> str:\n   299→        \"\"\"\n   300→        Build a safe Lucene query string.\n   301→\n   302→        Strategy:\n   303→        - Simple identifier (word chars only) → phrase search  e.g. \"LoginRequest\"\n   304→        - Complex query with special chars     → AND-keyword strategy\n   305→          e.g. \"class GitHubRepo(BaseModel)\" → \"GitHubRepo\" AND \"BaseModel\"\n   306→          This avoids Lucene parse errors while still matching meaningful tokens.\n   307→        \"\"\"\n   308→        query = query.strip()\n   309→        if not query:\n   310→            return '*'\n   311→\n   312→        # Simple identifier — use phrase search directly\n   313→        if re.match(r'^[A-Za-z0-9_]+$', query):\n   314→            return f'\"{query}\"'\n   315→\n   316→        # Complex query — extract identifiers and build AND search\n   317→        identifiers = self._extract_identifiers(query)\n   318→        if identifiers:\n   319→            # Cap at 3 identifiers to keep the query lean\n   320→            return ' AND '.join(f'\"{t}\"' for t in identifiers[:3])\n   321→\n   322→        # Pure symbols / numbers with no useful identifiers — wrap and hope for best\n   323→        escaped = query.replace('\"', '\\\\\"')\n   324→        return f'\"{escaped}\"'\n   325→\n   326→    def _name_contains_fallback(\n   327→        self,\n   328→        search_term: str,\n   329→        limit: int = 20,\n   330→    ) -> List[Dict[str, Any]]:\n   331→        \"\"\"\n   332→        CONTAINS fallback against node names.\n   333→        Uses the primary identifier extracted from the search term so that\n   334→        queries like 'class GitHubRepo(BaseModel)' still find 'GitHubRepo'.\n   335→        \"\"\"\n   336→        identifiers = self._extract_identifiers(search_term)\n   337→        # Use the first (longest) identifier, falling back to raw term\n   338→        name_term = max(identifiers, key=len) if identifiers else search_term\n   339→\n   340→        fallback = \"\"\"\n   341→        MATCH (node)\n   342→        WHERE (node:Function OR node:Class OR node:Variable)\n   343→          AND node.name CONTAINS $name_term\n   344→        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n   345→        RETURN\n   346→            CASE WHEN node:Function THEN 'function'\n   347→                 WHEN node:Class THEN 'class'\n   348→                 ELSE 'variable' END as type,\n   349→            node.name as name,\n   350→            coalesce(f.path, node.path) as path,\n   351→            coalesce(node.line_number, 0) as line_number,\n   352→            1.0 as score\n   353→        ORDER BY node.name\n   354→        LIMIT $limit\n   355→        \"\"\"\n   356→        records, _, _ = self.db.run_query(fallback, {\"name_term\": name_term, \"limit\": limit})\n   357→        return [\n   358→            {\n   359→                \"type\": record[\"type\"],\n   360→                \"name\": record[\"name\"],\n   361→                \"path\": record[\"path\"],\n   362→                \"line_number\": record[\"line_number\"],\n   363→                \"score\": record[\"score\"],\n   364→            }\n   365→            for record in records\n   366→        ]\n   367→\n   368→    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n   369→        \"\"\"\n   370→        Search for code using a three-tier strategy:\n   371→        1. code_search fulltext index (symbols: name, docstring, source_code)\n   372→        2. Name CONTAINS fallback (uses primary extracted identifier)\n   373→        3. File content line search (file_content_search / source_code CONTAINS)\n   374→        Returns lean results: type, name, path, line_number, score.\n   375→        \"\"\"\n   376→        escaped_term = self._escape_lucene_query(search_term)\n   377→\n   378→        # Tier 1 — fulltext symbol search\n   379→        results: List[Dict[str, Any]] = []\n   380→        try:\n   381→            records, _, _ = self.db.run_query(\n   382→                CYPHER_QUERIES[\"search_code\"], {\"search_term\": escaped_term}\n   383→            )\n   384→            results = [\n   385→                {\n   386→                    \"type\": record[\"type\"],\n   387→                    \"name\": record[\"name\"],\n   388→                    \"path\": record[\"path\"],\n   389→                    \"line_number\": record[\"line_number\"],\n   390→                    \"score\": record[\"score\"],\n   391→                }\n   392→                for record in records\n   393→            ]\n   394→        except Exception as e:\n   395→            logger.warning(\"code_search fulltext failed: %s\", e)\n   396→\n   397→        # Tier 2 — name CONTAINS (works even when fulltext index misses)\n   398→        if not results:\n   399→            results = self._name_contains_fallback(search_term, limit=20)\n   400→\n   401→        # Tier 3 — file content line search (raw code snippets, declarations, etc.)\n   402→        if not results:\n   403→            file_hits = self.search_file_content(search_term, limit=20)\n   404→            results = [\n   405→                {\n   406→                    \"type\": \"line\",\n   407→                    \"name\": h[\"match_line\"].strip(),\n   408→                    \"path\": h[\"path\"],\n   409→                    \"line_number\": h[\"line_number\"],\n   410→                    \"score\": 0.5,\n   411→                }\n   412→                for h in file_hits\n   413→            ]\n   414→\n   415→        return results\n   416→\n   417→    def search_symbols(\n   418→        self,\n   419→        search_term: str,\n   420→        limit: int = 20\n   421→    ) -> List[Dict[str, Any]]:\n   422→        \"\"\"\n   423→        Search symbols (Function/Class/Variable) using fulltext index.\n   424→        Falls back to name CONTAINS using the primary extracted identifier.\n   425→        \"\"\"\n   426→        escaped_term = self._escape_lucene_query(search_term)\n   427→\n   428→        results: List[Dict[str, Any]] = []\n   429→        try:\n   430→            records, _, _ = self.db.run_query(\n   431→                CYPHER_QUERIES[\"search_symbols\"],\n   432→                {\"search_term\": escaped_term, \"limit\": limit},\n   433→            )\n   434→            results = [\n   435→                {\n   436→                    \"name\": record[\"name\"],\n   437→                    \"type\": record[\"type\"],\n   438→                    \"path\": record[\"path\"],\n   439→                    \"line_number\": record[\"line_number\"],\n   440→                    \"score\": record[\"score\"],\n   441→                }\n   442→                for record in records\n   443→            ]\n   444→        except Exception as e:\n   445→            logger.warning(\"symbol fulltext search failed: %s\", e)\n   446→\n   447→        if not results:\n   448→            raw = self._name_contains_fallback(search_term, limit=limit)\n   449→            # _name_contains_fallback returns same shape, just reorder keys\n   450→            results = [\n   451→                {\n   452→                    \"name\": r[\"name\"],\n   453→                    \"type\": r[\"type\"],\n   454→                    \"path\": r[\"path\"],\n   455→                    \"line_number\": r[\"line_number\"],\n   456→                    \"score\": r[\"score\"],\n   457→                }\n   458→                for r in raw\n   459→            ]\n   460→\n   461→        return results\n   462→\n   463→    def search_file_content(self, search_term: str, limit: int = 50) -> List[Dict[str, Any]]:\n   464→        \"\"\"\n   465→        Search file source code line by line.\n   466→        Uses file_content_search fulltext index to find candidate files,\n   467→        then scans lines in Python to find the exact matching lines.\n   468→        \"\"\"\n   469→        escaped_term = self._escape_lucene_query(search_term)\n   470→        file_records: List[Dict[str, Any]] = []\n   471→\n   472→        try:\n   473→            ft_query = \"\"\"\n   474→            CALL db.index.fulltext.queryNodes('file_content_search', $search_term) YIELD node, score\n   475→            WHERE node.source_code IS NOT NULL\n   476→            RETURN node.path as path, node.source_code as source_code, score\n   477→            ORDER BY score DESC\n   478→            LIMIT 20\n   479→            \"\"\"\n   480→            records, _, _ = self.db.run_query(ft_query, {\"search_term\": escaped_term})\n   481→            file_records = [dict(r) for r in records]\n   482→        except Exception as e:\n   483→            logger.warning(\"file_content_search index failed, falling back to CONTAINS: %s\", e)\n   484→\n   485→        if not file_records:\n   486→            fallback = \"\"\"\n   487→            MATCH (f:File)\n   488→            WHERE f.source_code CONTAINS $search_term\n   489→            RETURN f.path as path, f.source_code as source_code, 1.0 as score\n   490→            LIMIT 20\n   491→            \"\"\"\n   492→            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})\n   493→            file_records = [dict(r) for r in records]\n   494→\n   495→        results: List[Dict[str, Any]] = []\n   496→        term_lower = search_term.lower()\n   497→        for rec in file_records:\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"8549c81c-4f4e-4da0-8b61-0bd65f799ce6","timestamp":"2026-02-21T08:48:16.646Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/db/queries.py","content":"    # Python/JS keywords that should not be used as search identifiers\n    _CODE_KEYWORDS = frozenset({\n        'class', 'def', 'import', 'from', 'return', 'self', 'cls', 'None',\n        'True', 'False', 'and', 'or', 'not', 'in', 'is', 'if', 'else',\n        'elif', 'for', 'while', 'try', 'except', 'with', 'as', 'pass',\n        'break', 'continue', 'raise', 'yield', 'async', 'await', 'lambda',\n        'function', 'const', 'let', 'var', 'new', 'this', 'super',\n    })\n\n    def _extract_identifiers(self, query: str) -> List[str]:\n        \"\"\"Extract meaningful code identifiers from a raw query string.\"\"\"\n        tokens = re.findall(r'\\b[A-Za-z_][A-Za-z0-9_]{2,}\\b', query)\n        seen: set = set()\n        result = []\n        for t in tokens:\n            if t not in self._CODE_KEYWORDS and t not in seen:\n                seen.add(t)\n                result.append(t)\n        return result\n\n    def _escape_lucene_query(self, query: str) -> str:\n        \"\"\"\n        Build a safe Lucene query string.\n\n        Strategy:\n        - Simple identifier (word chars only) → phrase search  e.g. \"LoginRequest\"\n        - Complex query with special chars     → AND-keyword strategy\n          e.g. \"class GitHubRepo(BaseModel)\" → \"GitHubRepo\" AND \"BaseModel\"\n          This avoids Lucene parse errors while still matching meaningful tokens.\n        \"\"\"\n        query = query.strip()\n        if not query:\n            return '*'\n\n        # Simple identifier — use phrase search directly\n        if re.match(r'^[A-Za-z0-9_]+$', query):\n            return f'\"{query}\"'\n\n        # Complex query — extract identifiers and build AND search\n        identifiers = self._extract_identifiers(query)\n        if identifiers:\n            # Cap at 3 identifiers to keep the query lean\n            return ' AND '.join(f'\"{t}\"' for t in identifiers[:3])\n\n        # Pure symbols / numbers with no useful identifiers — wrap and hope for best\n        escaped = query.replace('\"', '\\\\\"')\n        return f'\"{escaped}\"'\n\n    def _name_contains_fallback(\n        self,\n        search_term: str,\n        limit: int = 20,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        CONTAINS fallback against node names.\n        Uses the primary identifier extracted from the search term so that\n        queries like 'class GitHubRepo(BaseModel)' still find 'GitHubRepo'.\n        \"\"\"\n        identifiers = self._extract_identifiers(search_term)\n        # Use the first (longest) identifier, falling back to raw term\n        name_term = max(identifiers, key=len) if identifiers else search_term\n\n        fallback = \"\"\"\n        MATCH (node)\n        WHERE (node:Function OR node:Class OR node:Variable)\n          AND node.name CONTAINS $name_term\n        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n        RETURN\n            CASE WHEN node:Function THEN 'function'\n                 WHEN node:Class THEN 'class'\n                 ELSE 'variable' END as type,\n            node.name as name,\n            coalesce(f.path, node.path) as path,\n            coalesce(node.line_number, 0) as line_number,\n            1.0 as score\n        ORDER BY node.name\n        LIMIT $limit\n        \"\"\"\n        records, _, _ = self.db.run_query(fallback, {\"name_term\": name_term, \"limit\": limit})\n        return [\n            {\n                \"type\": record[\"type\"],\n                \"name\": record[\"name\"],\n                \"path\": record[\"path\"],\n                \"line_number\": record[\"line_number\"],\n                \"score\": record[\"score\"],\n            }\n            for record in records\n        ]\n\n    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search for code using a three-tier strategy:\n        1. code_search fulltext index (symbols: name, docstring, source_code)\n        2. Name CONTAINS fallback (uses primary extracted identifier)\n        3. File content line search (file_content_search / source_code CONTAINS)\n        Returns lean results: type, name, path, line_number, score.\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        # Tier 1 — fulltext symbol search\n        results: List[Dict[str, Any]] = []\n        try:\n            records, _, _ = self.db.run_query(\n                CYPHER_QUERIES[\"search_code\"], {\"search_term\": escaped_term}\n            )\n            results = [\n                {\n                    \"type\": record[\"type\"],\n                    \"name\": record[\"name\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"code_search fulltext failed: %s\", e)\n\n        # Tier 2 — name CONTAINS (works even when fulltext index misses)\n        if not results:\n            results = self._name_contains_fallback(search_term, limit=20)\n\n        # Tier 3 — file content line search (raw code snippets, declarations, etc.)\n        if not results:\n            file_hits = self.search_file_content(search_term, limit=20)\n            results = [\n                {\n                    \"type\": \"line\",\n                    \"name\": h[\"match_line\"].strip(),\n                    \"path\": h[\"path\"],\n                    \"line_number\": h[\"line_number\"],\n                    \"score\": 0.5,\n                }\n                for h in file_hits\n            ]\n\n        return results\n\n    def search_symbols(\n        self,\n        search_term: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search symbols (Function/Class/Variable) using fulltext index.\n        Falls back to name CONTAINS using the primary extracted identifier.\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        results: List[Dict[str, Any]] = []\n        try:\n            records, _, _ = self.db.run_query(\n                CYPHER_QUERIES[\"search_symbols\"],\n                {\"search_term\": escaped_term, \"limit\": limit},\n            )\n            results = [\n                {\n                    \"name\": record[\"name\"],\n                    \"type\": record[\"type\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"symbol fulltext search failed: %s\", e)\n\n        if not results:\n            raw = self._name_contains_fallback(search_term, limit=limit)\n            # _name_contains_fallback returns same shape, just reorder keys\n            results = [\n                {\n                    \"name\": r[\"name\"],\n                    \"type\": r[\"type\"],\n                    \"path\": r[\"path\"],\n                    \"line_number\": r[\"line_number\"],\n                    \"score\": r[\"score\"],\n                }\n                for r in raw\n            ]\n\n        return results\n\n    def search_file_content(self, search_term: str, limit: int = 50) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search file source code line by line.\n        Uses file_content_search fulltext index to find candidate files,\n        then scans lines in Python to find the exact matching lines.\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n        file_records: List[Dict[str, Any]] = []\n\n        try:\n            ft_query = \"\"\"\n            CALL db.index.fulltext.queryNodes('file_content_search', $search_term) YIELD node, score\n            WHERE node.source_code IS NOT NULL\n            RETURN node.path as path, node.source_code as source_code, score\n            ORDER BY score DESC\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(ft_query, {\"search_term\": escaped_term})\n            file_records = [dict(r) for r in records]\n        except Exception as e:\n            logger.warning(\"file_content_search index failed, falling back to CONTAINS: %s\", e)\n\n        if not file_records:\n            fallback = \"\"\"\n            MATCH (f:File)\n            WHERE f.source_code CONTAINS $search_term\n            RETURN f.path as path, f.source_code as source_code, 1.0 as score\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})\n            file_records = [dict(r) for r in records]\n\n        results: List[Dict[str, Any]] = []\n        term_lower = search_term.lower()\n        for rec in file_records:","numLines":220,"startLine":278,"totalLines":1834}},"sourceToolAssistantUUID":"095dd472-104d-4253-99ce-937dadea0dc5"}
{"parentUuid":"8549c81c-4f4e-4da0-8b61-0bd65f799ce6","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01BpjmbqDWkaPbxKesJzci7p","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012mjRfJctBc2qCBDh5tJ9dq","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","offset":1,"limit":20},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":173,"cache_read_input_tokens":131526,"output_tokens":3621,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":173,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLvVyAFjvWdsqTqeqouA","type":"assistant","uuid":"0b207f9c-f0d5-4fa7-a8ed-b8a638da0ca0","timestamp":"2026-02-21T08:48:17.193Z"}
{"parentUuid":"0b207f9c-f0d5-4fa7-a8ed-b8a638da0ca0","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_012mjRfJctBc2qCBDh5tJ9dq","toolUseID":"toolu_012mjRfJctBc2qCBDh5tJ9dq","timestamp":"2026-02-21T08:48:17.361Z","uuid":"a82ce41b-6524-4b76-a288-067d389c80cc"}
{"parentUuid":"0b207f9c-f0d5-4fa7-a8ed-b8a638da0ca0","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012mjRfJctBc2qCBDh5tJ9dq","type":"tool_result","content":"     1→\"\"\"\n     2→Code query endpoints - Advanced implementation with Neo4j integration.\n     3→\"\"\"\n     4→\n     5→from fastapi import APIRouter, HTTPException, Query, Depends, Body\n     6→from pydantic import BaseModel\n     7→from typing import Dict, Any, List, Optional\n     8→import os\n     9→\n    10→from db.client import Neo4jClient\n    11→from db.queries import CodeQueryService\n    12→from api.dependencies import get_neo4j_client\n    13→from api.services.code_search import CodeFinder\n    14→\n    15→router = APIRouter()\n    16→\n    17→\n    18→def get_query_service(db: Neo4jClient = Depends(get_neo4j_client)) -> CodeQueryService:\n    19→    \"\"\"Dependency to get query service.\"\"\"\n    20→    return CodeQueryService(db)\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"e3c101a0-601e-41fb-bd2b-a23e72a66a7b","timestamp":"2026-02-21T08:48:17.359Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","content":"\"\"\"\nCode query endpoints - Advanced implementation with Neo4j integration.\n\"\"\"\n\nfrom fastapi import APIRouter, HTTPException, Query, Depends, Body\nfrom pydantic import BaseModel\nfrom typing import Dict, Any, List, Optional\nimport os\n\nfrom db.client import Neo4jClient\nfrom db.queries import CodeQueryService\nfrom api.dependencies import get_neo4j_client\nfrom api.services.code_search import CodeFinder\n\nrouter = APIRouter()\n\n\ndef get_query_service(db: Neo4jClient = Depends(get_neo4j_client)) -> CodeQueryService:\n    \"\"\"Dependency to get query service.\"\"\"\n    return CodeQueryService(db)","numLines":20,"startLine":1,"totalLines":854}},"sourceToolAssistantUUID":"0b207f9c-f0d5-4fa7-a8ed-b8a638da0ca0"}
{"parentUuid":"e3c101a0-601e-41fb-bd2b-a23e72a66a7b","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_016aPoEWzP7G1hyM2fa9GY7r","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"Now I have a clear picture of all the issues. Let me list them:\n\n### Issues found:\n\n**Speed/Performance:**\n1. `search_file_content` - the Python-side line scanning loads ENTIRE `source_code` fields from Neo4j, potentially hundreds of MB for large repos. The fulltext YIELDS the file, then returns `source_code` which could be 100KB+ per file × 20 files = 2MB+ transferred to Python just for line scanning.\n2. `search_file_content` CONTAINS fallback does a FULL TABLE SCAN on all `File.source_code` (potentially GBs). \n3. `_name_contains_fallback` also scans all Function/Class/Variable nodes with CONTAINS. While these nodes are smaller, without a text index it still scans.\n4. `peek_file_lines` fetches the entire file source_code just to slice a few lines. Better to do it server-side.\n\n**Security:**\n1. No query length limit - a 10MB search term could cause issues\n\nThe CONTAINS fallbacks are particularly problematic for large repositories since they force full table scans across potentially gigabytes of data, and there are also some security concerns around unbounded input sizes.\n\nI need to remove the unused imports from `query.py`, add query length validation across the search endpoints, and move the line scanning logic into Cypher itself so we're not pulling massive source files into Python just to extract a few lines.\n\nRefactoring the Cypher query...\n\nThe split happens server-side in Neo4j, so we only send back the matching lines instead of entire files—much more efficient. Though I'm realizing that UNWIND on huge line counts could still create bloated intermediate result sets, so I'll need to cap file sizes to keep this performant.\n\nNow I'm refining the fallback search to handle cases where the full-text index doesn't work. I'll move the entire line-matching logic into Cypher itself, filtering out files larger than 500KB and limiting to just the first 5 matching files to avoid overwhelming the database with processing.\n\nRefining the Cypher query... I'm realizing the Cypher approach for line slicing gets complicated, so I'll stick with Python-side slicing for the peek operation since it's only reading one file at a time—though I should add a guard to reject source code larger than 2MB to avoid memory issues. For the `_name_contains_fallback` search, there's not much optimization possible without property indexes, but a full-text scan across 100K nodes should still complete in acceptable time, so I'll move forward with implementing these fixes.\n\nNow I'm rewriting the `search_file_content` function to use server-side line scanning in Cypher with a fulltext index query...\n\nWriting Cypher query... Writing the query optimization... I'm realizing the Cypher query is getting unwieldy with all the WITH clauses, and Neo4j might struggle with large list comprehensions anyway. Since the peek operation only fetches one file and Python handles the slicing on the client side, I just need to add a file size guard in the WHERE clause to prevent pulling massive files into memory—that's the real bottleneck here.","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":7030,"cache_read_input_tokens":131699,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":7030},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvbSSij3qb9P8BU9FDd","type":"assistant","uuid":"7bd2c529-9a64-403c-bf0e-be80e2a473f2","timestamp":"2026-02-21T08:48:58.975Z"}
{"parentUuid":"7bd2c529-9a64-403c-bf0e-be80e2a473f2","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_016aPoEWzP7G1hyM2fa9GY7r","type":"message","role":"assistant","content":[{"type":"text","text":"Found the issues. Here's the full audit:\n\n**Performance:**\n1. `search_file_content` — fetches entire `source_code` (can be 100KB+ per file × 20 files = MB of transfer) then scans in Python. Needs to run server-side in Cypher\n2. `search_file_content` CONTAINS fallback — full table scan across all `File.source_code` with no size guard, worst-case scans GBs\n3. `peek_file_lines` — no guard against fetching a 10MB minified file\n\n**Security:**\n1. No query length limit — a huge string can spike memory\n2. Three unused imports in `query.py` (`Body`, `Optional`, `os`)\n\n**Fixes — backend first:**"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":7030,"cache_read_input_tokens":131699,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":7030},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvbSSij3qb9P8BU9FDd","type":"assistant","uuid":"5e3a03fb-45e5-4e0e-b962-e84ec48efa7d","timestamp":"2026-02-21T08:49:01.433Z"}
{"parentUuid":"5e3a03fb-45e5-4e0e-b962-e84ec48efa7d","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_016aPoEWzP7G1hyM2fa9GY7r","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01TPvXbiWRzaEEYEhPw8Bjfp","name":"Edit","input":{"replace_all":false,"file_path":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","old_string":"from fastapi import APIRouter, HTTPException, Query, Depends, Body\nfrom pydantic import BaseModel\nfrom typing import Dict, Any, List, Optional\nimport os","new_string":"from fastapi import APIRouter, HTTPException, Query, Depends\nfrom pydantic import BaseModel\nfrom typing import Dict, Any, List"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":7030,"cache_read_input_tokens":131699,"output_tokens":2679,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":7030,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLvbSSij3qb9P8BU9FDd","type":"assistant","uuid":"b3d2f01b-3661-4e2c-97ad-3d65c913d3dd","timestamp":"2026-02-21T08:49:03.483Z"}
{"parentUuid":"b3d2f01b-3661-4e2c-97ad-3d65c913d3dd","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01TPvXbiWRzaEEYEhPw8Bjfp","toolUseID":"toolu_01TPvXbiWRzaEEYEhPw8Bjfp","timestamp":"2026-02-21T08:49:03.496Z","uuid":"92dfb91c-8fda-4132-8127-f03e35c7d60c"}
{"parentUuid":"b3d2f01b-3661-4e2c-97ad-3d65c913d3dd","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01TPvXbiWRzaEEYEhPw8Bjfp","type":"tool_result","content":"The file /Users/skmabudalam/Documents/BugViper/api/routers/query.py has been updated successfully."}]},"uuid":"1fd95b8e-b537-40a6-815e-b0ba65daed74","timestamp":"2026-02-21T08:49:03.495Z","toolUseResult":{"filePath":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","oldString":"from fastapi import APIRouter, HTTPException, Query, Depends, Body\nfrom pydantic import BaseModel\nfrom typing import Dict, Any, List, Optional\nimport os","newString":"from fastapi import APIRouter, HTTPException, Query, Depends\nfrom pydantic import BaseModel\nfrom typing import Dict, Any, List","originalFile":"\"\"\"\nCode query endpoints - Advanced implementation with Neo4j integration.\n\"\"\"\n\nfrom fastapi import APIRouter, HTTPException, Query, Depends, Body\nfrom pydantic import BaseModel\nfrom typing import Dict, Any, List, Optional\nimport os\n\nfrom db.client import Neo4jClient\nfrom db.queries import CodeQueryService\nfrom api.dependencies import get_neo4j_client\nfrom api.services.code_search import CodeFinder\n\nrouter = APIRouter()\n\n\ndef get_query_service(db: Neo4jClient = Depends(get_neo4j_client)) -> CodeQueryService:\n    \"\"\"Dependency to get query service.\"\"\"\n    return CodeQueryService(db)\n\n\ndef get_code_finder(db: Neo4jClient = Depends(get_neo4j_client)) -> CodeFinder:\n    \"\"\"Dependency to get code finder.\"\"\"\n    return CodeFinder(db)\n\n\n@router.get(\"/search\")\nasync def search_code(\n    query: str = Query(..., description=\"Search term — any identifier, snippet, or keyword\"),\n    limit: int = Query(30, description=\"Maximum results to return\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Unified code search.\n\n    Three-tier strategy:\n    1. Fulltext index on symbols (name, docstring, source_code)\n    2. Name CONTAINS fallback (uses primary extracted identifier)\n    3. File content line search (file_content_search / source_code CONTAINS)\n\n    Results include type ('function' | 'class' | 'variable' | 'line'),\n    name, path, line_number, and score. Symbol results come first\n    (higher score), file-content line matches follow.\n    \"\"\"\n    try:\n        results = query_service.search_code(query)\n        if limit:\n            results = results[:limit]\n        return {\n            \"results\": results,\n            \"total\": len(results),\n            \"query\": query,\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")\n\n\n@router.get(\"/method-usages\")\nasync def find_method_usages(\n    method_name: str = Query(..., description=\"Name of the method to find usages for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all usages of a specific method.\n    \"\"\"\n    try:\n        usages = query_service.find_method_usages(method_name)\n        return usages\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find method usages: {str(e)}\")\n\n\n@router.get(\"/find_usages\")\nasync def find_usages(\n    symbol_name: str = Query(..., description=\"Symbol name to find usages for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all usages of a specific symbol (alias for method-usages).\n    \"\"\"\n    try:\n        usages = query_service.find_method_usages(symbol_name)\n        return usages\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find usages: {str(e)}\")\n\n\n@router.get(\"/find_callers\")\nasync def find_callers(\n    symbol_name: str = Query(..., description=\"Symbol name to find callers for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all methods/functions that call a specific symbol.\n    \"\"\"\n    try:\n        callers = query_service.find_callers(symbol_name)\n        return {\n            \"callers\": callers,\n            \"symbol\": symbol_name,\n            \"total\": len(callers)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find callers: {str(e)}\")\n\n\n@router.get(\"/class_hierarchy\")\nasync def get_class_hierarchy(\n    class_name: str = Query(..., description=\"Name of the class to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get class hierarchy (inheritance tree).\n    \"\"\"\n    try:\n        hierarchy = query_service.get_class_hierarchy(class_name)\n        return hierarchy\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get class hierarchy: {str(e)}\")\n\n\n@router.get(\"/class-hierarchy\")\nasync def get_class_hierarchy_alt(\n    class_name: str = Query(..., description=\"Name of the class to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get class hierarchy (inheritance tree) - alternative endpoint.\n    \"\"\"\n    try:\n        hierarchy = query_service.get_class_hierarchy(class_name)\n        return hierarchy\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get class hierarchy: {str(e)}\")\n\n\n@router.get(\"/file-structure\")\nasync def analyze_file_structure(\n    file_id: str = Query(..., description=\"File ID to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze the structure of a specific file.\n    \"\"\"\n    try:\n        structure = query_service.get_file_structure(file_id)\n        return structure\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to analyze file structure: {str(e)}\")\n\n\n@router.get(\"/change_impact\")\nasync def analyze_change_impact(\n    symbol_name: str = Query(..., description=\"Symbol to analyze impact for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze the impact of changing a specific symbol.\n    \"\"\"\n    try:\n        # Get all usages of the symbol to understand impact\n        usages = query_service.find_method_usages(symbol_name)\n        callers = query_service.find_callers(symbol_name)\n        \n        return {\n            \"symbol\": symbol_name,\n            \"usages\": usages,\n            \"callers\": callers,\n            \"impact_level\": \"high\" if len(callers) > 5 else \"medium\" if len(callers) > 0 else \"low\"\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to analyze change impact: {str(e)}\")\n\n\n@router.get(\"/relationships\")\nasync def get_code_relationships(\n    symbol_name: str = Query(..., description=\"Symbol to find relationships for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get code relationship analysis for a symbol.\n    \"\"\"\n    try:\n        # Get comprehensive relationship data\n        usages = query_service.find_method_usages(symbol_name)\n        callers = query_service.find_callers(symbol_name)\n        \n        return {\n            \"symbol\": symbol_name,\n            \"relationships\": {\n                \"usages\": usages,\n                \"callers\": callers,\n                \"usage_count\": len(usages.get('usages', [])),\n                \"caller_count\": len(callers)\n            }\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get code relationships: {str(e)}\")\n\n\n@router.get(\"/metrics\")\nasync def get_code_metrics(\n    repo_id: str = Query(None, description=\"Repository ID for repo-specific metrics\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get code metrics and statistics.\n    \"\"\"\n    try:\n        if repo_id:\n            # Get repository-specific stats\n            stats = query_service.get_repository_stats(repo_id)\n            return {\n                \"repository_id\": repo_id,\n                \"metrics\": stats\n            }\n        else:\n            # Get global graph stats\n            stats = query_service.get_graph_stats()\n            return {\n                \"global_metrics\": stats\n            }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get code metrics: {str(e)}\")\n\n\n@router.get(\"/stats\")\nasync def get_graph_stats(\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get overall graph statistics.\n    \"\"\"\n    try:\n        stats = query_service.get_graph_stats()\n        return stats\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get graph stats: {str(e)}\")\n\n\n@router.get(\"/symbol/{qualified_name}\")\nasync def get_symbol_by_qualified_name(\n    qualified_name: str,\n    repo_id: str = Query(..., description=\"Repository ID\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get symbol information by its qualified name.\n    \"\"\"\n    try:\n        symbol = query_service.find_symbol_by_qualified_name(qualified_name, repo_id)\n        if not symbol:\n            raise HTTPException(status_code=404, detail=\"Symbol not found\")\n        return symbol\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find symbol: {str(e)}\")\n\n\n# =========================================================================\n# CodeFinder Tool Integration Endpoints\n# =========================================================================\n\n@router.get(\"/code-finder/function\")\nasync def find_function_by_name(\n    name: str = Query(..., description=\"Function name to search for\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_function_name(name, fuzzy)\n        return {\n            \"function_name\": name,\n            \"fuzzy_search\": fuzzy,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/class\")\nasync def find_class_by_name(\n    name: str = Query(..., description=\"Class name to search for\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find classes by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_class_name(name, fuzzy)\n        return {\n            \"class_name\": name,\n            \"fuzzy_search\": fuzzy,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Class search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/variable\")\nasync def find_variable_by_name(\n    name: str = Query(..., description=\"Variable name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find variables by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_variable_name(name)\n        return {\n            \"variable_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Variable search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/content\")\nasync def find_by_content(\n    query: str = Query(..., description=\"Content search term\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find code by content matching using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_content(query)\n        return {\n            \"search_query\": query,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Content search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/module\")\nasync def find_module_by_name(\n    name: str = Query(..., description=\"Module name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find modules by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_module_name(name)\n        return {\n            \"module_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Module search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/imports\")\nasync def find_imports(\n    name: str = Query(..., description=\"Import name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find import statements using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_imports(name)\n        return {\n            \"import_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Import search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/related\")\nasync def find_related_code(\n    query: str = Query(..., description=\"Search query for related code\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    edit_distance: int = Query(2, description=\"Edit distance for fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find code related to a query using multiple search strategies.\n    \"\"\"\n    try:\n        results = code_finder.find_related_code(query, fuzzy, edit_distance)\n        return {\n            \"search_query\": query,\n            \"fuzzy_search\": fuzzy,\n            \"edit_distance\": edit_distance,\n            **results\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Related code search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/function/arguments\")\nasync def find_functions_by_argument(\n    argument_name: str = Query(..., description=\"Argument name to search for\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions that take a specific argument.\n    \"\"\"\n    try:\n        results = code_finder.find_functions_by_argument(argument_name, path)\n        return {\n            \"argument_name\": argument_name,\n            \"path_filter\": path,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function argument search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/function/decorator\")\nasync def find_functions_by_decorator(\n    decorator_name: str = Query(..., description=\"Decorator name to search for\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions that have a specific decorator.\n    \"\"\"\n    try:\n        results = code_finder.find_functions_by_decorator(decorator_name, path)\n        return {\n            \"decorator_name\": decorator_name,\n            \"path_filter\": path,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function decorator search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/complexity\")\nasync def get_cyclomatic_complexity(\n    function_name: str = Query(..., description=\"Function name to analyze\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get cyclomatic complexity of a function.\n    \"\"\"\n    try:\n        result = code_finder.get_cyclomatic_complexity(function_name, path)\n        if not result:\n            raise HTTPException(status_code=404, detail=\"Function not found\")\n        return {\n            \"function_name\": function_name,\n            \"path_filter\": path,\n            \"complexity\": result\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complexity analysis failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/complexity/top\")\nasync def find_most_complex_functions(\n    limit: int = Query(10, description=\"Number of results to return\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find the most complex functions by cyclomatic complexity.\n    \"\"\"\n    try:\n        results = code_finder.find_most_complex_functions(limit)\n        return {\n            \"limit\": limit,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complex function search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/line\")\nasync def find_by_line(\n    query: str = Query(..., description=\"Search term to find in file content\"),\n    limit: int = Query(50, description=\"Maximum number of line matches to return\"),\n    query_service: CodeQueryService = Depends(get_query_service),\n) -> Dict[str, Any]:\n    \"\"\"\n    Search raw file content line-by-line.\n    Uses file_content_search fulltext index (falls back to CONTAINS).\n    Returns path + line_number + match_line for each hit — no source dumps.\n    Pair with /code-finder/peek to view context around a hit.\n    \"\"\"\n    try:\n        results = query_service.search_file_content(query, limit)\n        return {\n            \"query\": query,\n            \"results\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Line search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/peek\")\nasync def peek_file_lines(\n    path: str = Query(..., description=\"Absolute file path (as stored in graph)\"),\n    line: int = Query(..., description=\"Anchor line number (1-indexed)\"),\n    above: int = Query(10, description=\"Lines to show above the anchor\"),\n    below: int = Query(10, description=\"Lines to show below the anchor\"),\n    query_service: CodeQueryService = Depends(get_query_service),\n) -> Dict[str, Any]:\n    \"\"\"\n    Return a window of lines around a given line in a file.\n    The anchor line is flagged with is_anchor=true.\n    Use above/below to control the context window size.\n    \"\"\"\n    try:\n        result = query_service.peek_file_lines(path, line, above, below)\n        if \"error\" in result:\n            raise HTTPException(status_code=404, detail=result[\"error\"])\n        return result\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Peek failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/relationships\")\nasync def analyze_code_relationships(\n    query_type: str = Query(..., description=\"Type of relationship query\"),\n    target: str = Query(..., description=\"Target symbol for analysis\"),\n    context: str = Query(None, description=\"Additional context for the query\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze code relationships using the CodeFinder's relationship query system.\n    \n    Supported query types:\n    - find_callers: Find all functions that call the target function\n    - find_callees: Find all functions called by the target function\n    - find_importers: Find all files that import the target module\n    - who_modifies: Find what functions modify a target variable\n    - class_hierarchy: Find inheritance relationships for a class\n    - call_chain: Find call paths between functions (format: 'start->end')\n    - module_deps: Find module dependencies\n    - variable_scope: Find variable usage across scopes\n    \"\"\"\n    try:\n        results = code_finder.execute_relationship_query(query_type, target, context)\n        return results\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Relationship analysis failed: {str(e)}\")\n\n\n@router.get(\"/repositories/indexed\")\nasync def list_indexed_repositories(\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    List all indexed repositories using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.list_indexed_repositories()\n        return {\n            \"repositories\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to list repositories: {str(e)}\")\n\n\n\n@router.get(\"/language/{language}/symbols\")\nasync def get_language_symbols(\n    language: str,\n    symbol_type: str = Query(..., description=\"Symbol type: function, class, variable, etc.\"),\n    limit: int = Query(50, description=\"Maximum number of results\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get all symbols of a specific type for a given language.\n    \n    Supported symbol types:\n    - function: All functions\n    - class: All classes  \n    - variable: All variables\n    - module: All modules\n    - file: All files\n    \"\"\"\n    try:\n        # Use Neo4j to query symbols by type and language\n        if symbol_type.lower() == \"function\":\n            query = f\"\"\"\n                MATCH (n:Function)\n                OPTIONAL MATCH (f:File)-[:CONTAINS]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.docstring as docstring, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"class\":\n            query = f\"\"\"\n                MATCH (n:Class)\n                OPTIONAL MATCH (f:File)-[:CONTAINS]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.docstring as docstring, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"variable\":\n            query = f\"\"\"\n                MATCH (n:Variable)\n                OPTIONAL MATCH (f:File)-[:CONTAINS*]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.value as value, n.context as context, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"file\":\n            query = f\"\"\"\n                MATCH (n:File)\n                WHERE n.language = $language OR n.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.relative_path as relative_path,\n                       n.language as language, n.extension as extension,\n                       n.is_dependency as is_dependency\n                ORDER BY n.is_dependency ASC, n.path\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"module\":\n            query = f\"\"\"\n                MATCH (n:Module)\n                WHERE n.lang = $language\n                RETURN n.name as name, n.lang as language,\n                       n.full_import_name as full_import_name\n                ORDER BY n.name\n                LIMIT $limit\n            \"\"\"\n        else:\n            raise HTTPException(status_code=400, detail=f\"Unsupported symbol type: {symbol_type}\")\n        \n        records, _, _ = query_service.db.run_query(query, {\"language\": language, \"limit\": limit})\n        \n        return {\n            \"language\": language,\n            \"symbol_type\": symbol_type,\n            \"results\": [dict(record) for record in records],\n            \"total\": len(records),\n            \"limit\": limit\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Language symbol query failed: {str(e)}\")\n\n\n@router.get(\"/language/stats\")\nasync def get_language_statistics(\n    language: str = Query(None, description=\"Optional language filter\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get statistics about programming languages in the codebase.\n    \"\"\"\n    try:\n        if language:\n            # Get stats for specific language\n            query = \"\"\"\n                MATCH (f:File)\n                WHERE f.language = $language OR f.extension IN ['.{}'.format($language.lower()), '.{}'.format($language[:2].lower())]\n                OPTIONAL MATCH (f)-[:CONTAINS]->(func:Function)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(cls:Class)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(var:Variable)\n                RETURN \n                    count(DISTINCT f) as file_count,\n                    count(DISTINCT func) as function_count,\n                    count(DISTINCT cls) as class_count,\n                    count(DISTINCT var) as variable_count\n            \"\"\"\n            records, _, _ = query_service.db.run_query(query, {\"language\": language})\n            result = dict(records[0]) if records else {}\n            result[\"language\"] = language\n            return result\n        else:\n            # Get stats for all languages\n            query = \"\"\"\n                MATCH (f:File)\n                WHERE f.language IS NOT NULL\n                OPTIONAL MATCH (f)-[:CONTAINS]->(func:Function)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(cls:Class)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(var:Variable)\n                RETURN \n                    f.language as language,\n                    count(DISTINCT f) as file_count,\n                    count(DISTINCT func) as function_count,\n                    count(DISTINCT cls) as class_count,\n                    count(DISTINCT var) as variable_count\n                ORDER BY file_count DESC\n            \"\"\"\n            records, _, _ = query_service.db.run_query(query)\n            return {\n                \"languages\": [dict(record) for record in records],\n                \"total_languages\": len(records)\n            }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Language statistics query failed: {str(e)}\")\n\n\n# --- Code Review / Diff Context Endpoints ---\n\n\n@router.get(\"/symbols-at-lines\")\nasync def get_symbols_at_lines(\n    file_path: str = Query(..., description=\"Absolute file path\"),\n    start_line: int = Query(..., description=\"Start line number\"),\n    end_line: int = Query(..., description=\"End line number\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all symbols (functions, classes, variables) overlapping a line range.\n    Useful for mapping diff hunks to affected code.\n    \"\"\"\n    try:\n        results = query_service.get_symbols_at_lines(file_path, start_line, end_line)\n        return {\n            \"file_path\": file_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n            \"symbols\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol lookup failed: {str(e)}\")\n\n\n@router.get(\"/symbols-at-lines-relative\")\nasync def get_symbols_at_lines_relative(\n    repo_id: str = Query(..., description=\"Repository ID (e.g. owner/repo)\"),\n    file_path: str = Query(..., description=\"Repo-relative file path (e.g. src/main.py)\"),\n    start_line: int = Query(..., description=\"Start line number\"),\n    end_line: int = Query(..., description=\"End line number\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all symbols overlapping a line range using repo-relative path.\n    \"\"\"\n    try:\n        results = query_service.get_symbols_at_lines_by_relative_path(\n            repo_id, file_path, start_line, end_line\n        )\n        return {\n            \"repo_id\": repo_id,\n            \"file_path\": file_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n            \"symbols\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol lookup failed: {str(e)}\")\n\n\nclass FileChange(BaseModel):\n    file_path: str\n    start_line: int = 1\n    end_line: int = 999999\n\n\nclass DiffContextRequest(BaseModel):\n    repo_id: str\n    changes: List[FileChange]\n\n\n@router.post(\"/diff-context\")\nasync def get_diff_context(\n    request: DiffContextRequest,\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Build full RAG context for a code diff.\n\n    Given a repository and a list of file changes (path + line ranges),\n    returns affected symbols with source code, their callers, class hierarchy,\n    and full file sources. Designed for AI-powered code review.\n\n    Example request:\n    ```json\n    {\n        \"repo_id\": \"owner/repo\",\n        \"changes\": [\n            {\"file_path\": \"src/main.py\", \"start_line\": 10, \"end_line\": 30},\n            {\"file_path\": \"src/utils.py\", \"start_line\": 1, \"end_line\": 50}\n        ]\n    }\n    ```\n    \"\"\"\n    try:\n        changes_dicts = [c.model_dump() for c in request.changes]\n        result = query_service.get_diff_context(request.repo_id, changes_dicts)\n        return result\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Diff context failed: {str(e)}\")\n\n\n@router.get(\"/file-source\")\nasync def get_file_source(\n    repo_id: str = Query(..., description=\"Repository ID\"),\n    file_path: str = Query(..., description=\"Repo-relative file path\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get the full source code of a file from the graph.\n    \"\"\"\n    try:\n        query = \"\"\"\n        MATCH (f:File)\n        WHERE f.relative_path = $relative_path AND f.path CONTAINS $repo_id\n        RETURN f.source_code as source_code, f.relative_path as path,\n               f.language as language, f.lines_count as lines_count\n        LIMIT 1\n        \"\"\"\n        records, _, _ = query_service.db.run_query(query, {\n            \"relative_path\": file_path,\n            \"repo_id\": repo_id,\n        })\n        if not records:\n            raise HTTPException(status_code=404, detail=\"File not found\")\n        record = records[0]\n        return {\n            \"file_path\": record.get(\"path\"),\n            \"language\": record.get(\"language\"),\n            \"lines_count\": record.get(\"lines_count\"),\n            \"source_code\": record.get(\"source_code\"),\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"File source retrieval failed: {str(e)}\")\n","structuredPatch":[{"oldStart":2,"oldLines":10,"newStart":2,"newLines":9,"lines":[" Code query endpoints - Advanced implementation with Neo4j integration."," \"\"\""," ","-from fastapi import APIRouter, HTTPException, Query, Depends, Body","+from fastapi import APIRouter, HTTPException, Query, Depends"," from pydantic import BaseModel","-from typing import Dict, Any, List, Optional","-import os","+from typing import Dict, Any, List"," "," from db.client import Neo4jClient"," from db.queries import CodeQueryService"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"b3d2f01b-3661-4e2c-97ad-3d65c913d3dd"}
{"parentUuid":"1fd95b8e-b537-40a6-815e-b0ba65daed74","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_019JUC27b6h4E61mNJ3NSB2Q","type":"message","role":"assistant","content":[{"type":"text","text":"Now add query length validation to the three endpoints that accept user text:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2683,"cache_read_input_tokens":138729,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2683},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLverYPm1bRvLvabzX5U","type":"assistant","uuid":"822da8b3-24b9-426d-a9bc-822aee2a1d86","timestamp":"2026-02-21T08:49:06.070Z"}
{"parentUuid":"822da8b3-24b9-426d-a9bc-822aee2a1d86","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_019JUC27b6h4E61mNJ3NSB2Q","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011GF1LUAA9fmj7c5ncfsRS4","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","offset":26,"limit":55},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2683,"cache_read_input_tokens":138729,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2683},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLverYPm1bRvLvabzX5U","type":"assistant","uuid":"238c2cd5-0624-4526-944d-e8a9127e096b","timestamp":"2026-02-21T08:49:06.825Z"}
{"parentUuid":"238c2cd5-0624-4526-944d-e8a9127e096b","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_011GF1LUAA9fmj7c5ncfsRS4","toolUseID":"toolu_011GF1LUAA9fmj7c5ncfsRS4","timestamp":"2026-02-21T08:49:07.005Z","uuid":"7c513abd-47ab-4693-be1d-54e75bae8961"}
{"parentUuid":"238c2cd5-0624-4526-944d-e8a9127e096b","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011GF1LUAA9fmj7c5ncfsRS4","type":"tool_result","content":"    26→\n    27→@router.get(\"/search\")\n    28→async def search_code(\n    29→    query: str = Query(..., description=\"Search term — any identifier, snippet, or keyword\"),\n    30→    limit: int = Query(30, description=\"Maximum results to return\"),\n    31→    query_service: CodeQueryService = Depends(get_query_service)\n    32→) -> Dict[str, Any]:\n    33→    \"\"\"\n    34→    Unified code search.\n    35→\n    36→    Three-tier strategy:\n    37→    1. Fulltext index on symbols (name, docstring, source_code)\n    38→    2. Name CONTAINS fallback (uses primary extracted identifier)\n    39→    3. File content line search (file_content_search / source_code CONTAINS)\n    40→\n    41→    Results include type ('function' | 'class' | 'variable' | 'line'),\n    42→    name, path, line_number, and score. Symbol results come first\n    43→    (higher score), file-content line matches follow.\n    44→    \"\"\"\n    45→    try:\n    46→        results = query_service.search_code(query)\n    47→        if limit:\n    48→            results = results[:limit]\n    49→        return {\n    50→            \"results\": results,\n    51→            \"total\": len(results),\n    52→            \"query\": query,\n    53→        }\n    54→    except Exception as e:\n    55→        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")\n    56→\n    57→\n    58→@router.get(\"/method-usages\")\n    59→async def find_method_usages(\n    60→    method_name: str = Query(..., description=\"Name of the method to find usages for\"),\n    61→    query_service: CodeQueryService = Depends(get_query_service)\n    62→) -> Dict[str, Any]:\n    63→    \"\"\"\n    64→    Find all usages of a specific method.\n    65→    \"\"\"\n    66→    try:\n    67→        usages = query_service.find_method_usages(method_name)\n    68→        return usages\n    69→    except Exception as e:\n    70→        raise HTTPException(status_code=500, detail=f\"Failed to find method usages: {str(e)}\")\n    71→\n    72→\n    73→@router.get(\"/find_usages\")\n    74→async def find_usages(\n    75→    symbol_name: str = Query(..., description=\"Symbol name to find usages for\"),\n    76→    query_service: CodeQueryService = Depends(get_query_service)\n    77→) -> Dict[str, Any]:\n    78→    \"\"\"\n    79→    Find all usages of a specific symbol (alias for method-usages).\n    80→    \"\"\"\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"2ec01ed2-1946-435b-af7b-b38a3126e977","timestamp":"2026-02-21T08:49:07.004Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","content":"\n@router.get(\"/search\")\nasync def search_code(\n    query: str = Query(..., description=\"Search term — any identifier, snippet, or keyword\"),\n    limit: int = Query(30, description=\"Maximum results to return\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Unified code search.\n\n    Three-tier strategy:\n    1. Fulltext index on symbols (name, docstring, source_code)\n    2. Name CONTAINS fallback (uses primary extracted identifier)\n    3. File content line search (file_content_search / source_code CONTAINS)\n\n    Results include type ('function' | 'class' | 'variable' | 'line'),\n    name, path, line_number, and score. Symbol results come first\n    (higher score), file-content line matches follow.\n    \"\"\"\n    try:\n        results = query_service.search_code(query)\n        if limit:\n            results = results[:limit]\n        return {\n            \"results\": results,\n            \"total\": len(results),\n            \"query\": query,\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")\n\n\n@router.get(\"/method-usages\")\nasync def find_method_usages(\n    method_name: str = Query(..., description=\"Name of the method to find usages for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all usages of a specific method.\n    \"\"\"\n    try:\n        usages = query_service.find_method_usages(method_name)\n        return usages\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find method usages: {str(e)}\")\n\n\n@router.get(\"/find_usages\")\nasync def find_usages(\n    symbol_name: str = Query(..., description=\"Symbol name to find usages for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all usages of a specific symbol (alias for method-usages).\n    \"\"\"","numLines":55,"startLine":26,"totalLines":853}},"sourceToolAssistantUUID":"238c2cd5-0624-4526-944d-e8a9127e096b"}
{"parentUuid":"2ec01ed2-1946-435b-af7b-b38a3126e977","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01WTFSMgkaob14C5cGsZoPW6","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01AXJ2DPiQcckY8okNUW5ogp","name":"Edit","input":{"replace_all":false,"file_path":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","old_string":"    try:\n        results = query_service.search_code(query)\n        if limit:\n            results = results[:limit]\n        return {\n            \"results\": results,\n            \"total\": len(results),\n            \"query\": query,\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")","new_string":"    if len(query) > 500:\n        raise HTTPException(status_code=400, detail=\"Query too long (max 500 characters)\")\n    try:\n        results = query_service.search_code(query)\n        if limit:\n            results = results[:limit]\n        return {\n            \"results\": results,\n            \"total\": len(results),\n            \"query\": query,\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1045,"cache_read_input_tokens":141412,"output_tokens":349,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":1045,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLvf61GNH8367wUNGhGx","type":"assistant","uuid":"4cb8b630-6432-4a36-a4c3-f651041d7334","timestamp":"2026-02-21T08:49:11.456Z"}
{"parentUuid":"4cb8b630-6432-4a36-a4c3-f651041d7334","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01AXJ2DPiQcckY8okNUW5ogp","toolUseID":"toolu_01AXJ2DPiQcckY8okNUW5ogp","timestamp":"2026-02-21T08:49:11.635Z","uuid":"45e1d5cf-0b13-457e-b87f-d35a10e9f429"}
{"parentUuid":"4cb8b630-6432-4a36-a4c3-f651041d7334","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01AXJ2DPiQcckY8okNUW5ogp","type":"tool_result","content":"The file /Users/skmabudalam/Documents/BugViper/api/routers/query.py has been updated successfully."}]},"uuid":"10182115-fc79-4e47-83d9-435ed54fd8b4","timestamp":"2026-02-21T08:49:11.634Z","toolUseResult":{"filePath":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","oldString":"    try:\n        results = query_service.search_code(query)\n        if limit:\n            results = results[:limit]\n        return {\n            \"results\": results,\n            \"total\": len(results),\n            \"query\": query,\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")","newString":"    if len(query) > 500:\n        raise HTTPException(status_code=400, detail=\"Query too long (max 500 characters)\")\n    try:\n        results = query_service.search_code(query)\n        if limit:\n            results = results[:limit]\n        return {\n            \"results\": results,\n            \"total\": len(results),\n            \"query\": query,\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")","originalFile":"\"\"\"\nCode query endpoints - Advanced implementation with Neo4j integration.\n\"\"\"\n\nfrom fastapi import APIRouter, HTTPException, Query, Depends\nfrom pydantic import BaseModel\nfrom typing import Dict, Any, List\n\nfrom db.client import Neo4jClient\nfrom db.queries import CodeQueryService\nfrom api.dependencies import get_neo4j_client\nfrom api.services.code_search import CodeFinder\n\nrouter = APIRouter()\n\n\ndef get_query_service(db: Neo4jClient = Depends(get_neo4j_client)) -> CodeQueryService:\n    \"\"\"Dependency to get query service.\"\"\"\n    return CodeQueryService(db)\n\n\ndef get_code_finder(db: Neo4jClient = Depends(get_neo4j_client)) -> CodeFinder:\n    \"\"\"Dependency to get code finder.\"\"\"\n    return CodeFinder(db)\n\n\n@router.get(\"/search\")\nasync def search_code(\n    query: str = Query(..., description=\"Search term — any identifier, snippet, or keyword\"),\n    limit: int = Query(30, description=\"Maximum results to return\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Unified code search.\n\n    Three-tier strategy:\n    1. Fulltext index on symbols (name, docstring, source_code)\n    2. Name CONTAINS fallback (uses primary extracted identifier)\n    3. File content line search (file_content_search / source_code CONTAINS)\n\n    Results include type ('function' | 'class' | 'variable' | 'line'),\n    name, path, line_number, and score. Symbol results come first\n    (higher score), file-content line matches follow.\n    \"\"\"\n    try:\n        results = query_service.search_code(query)\n        if limit:\n            results = results[:limit]\n        return {\n            \"results\": results,\n            \"total\": len(results),\n            \"query\": query,\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")\n\n\n@router.get(\"/method-usages\")\nasync def find_method_usages(\n    method_name: str = Query(..., description=\"Name of the method to find usages for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all usages of a specific method.\n    \"\"\"\n    try:\n        usages = query_service.find_method_usages(method_name)\n        return usages\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find method usages: {str(e)}\")\n\n\n@router.get(\"/find_usages\")\nasync def find_usages(\n    symbol_name: str = Query(..., description=\"Symbol name to find usages for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all usages of a specific symbol (alias for method-usages).\n    \"\"\"\n    try:\n        usages = query_service.find_method_usages(symbol_name)\n        return usages\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find usages: {str(e)}\")\n\n\n@router.get(\"/find_callers\")\nasync def find_callers(\n    symbol_name: str = Query(..., description=\"Symbol name to find callers for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all methods/functions that call a specific symbol.\n    \"\"\"\n    try:\n        callers = query_service.find_callers(symbol_name)\n        return {\n            \"callers\": callers,\n            \"symbol\": symbol_name,\n            \"total\": len(callers)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find callers: {str(e)}\")\n\n\n@router.get(\"/class_hierarchy\")\nasync def get_class_hierarchy(\n    class_name: str = Query(..., description=\"Name of the class to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get class hierarchy (inheritance tree).\n    \"\"\"\n    try:\n        hierarchy = query_service.get_class_hierarchy(class_name)\n        return hierarchy\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get class hierarchy: {str(e)}\")\n\n\n@router.get(\"/class-hierarchy\")\nasync def get_class_hierarchy_alt(\n    class_name: str = Query(..., description=\"Name of the class to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get class hierarchy (inheritance tree) - alternative endpoint.\n    \"\"\"\n    try:\n        hierarchy = query_service.get_class_hierarchy(class_name)\n        return hierarchy\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get class hierarchy: {str(e)}\")\n\n\n@router.get(\"/file-structure\")\nasync def analyze_file_structure(\n    file_id: str = Query(..., description=\"File ID to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze the structure of a specific file.\n    \"\"\"\n    try:\n        structure = query_service.get_file_structure(file_id)\n        return structure\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to analyze file structure: {str(e)}\")\n\n\n@router.get(\"/change_impact\")\nasync def analyze_change_impact(\n    symbol_name: str = Query(..., description=\"Symbol to analyze impact for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze the impact of changing a specific symbol.\n    \"\"\"\n    try:\n        # Get all usages of the symbol to understand impact\n        usages = query_service.find_method_usages(symbol_name)\n        callers = query_service.find_callers(symbol_name)\n        \n        return {\n            \"symbol\": symbol_name,\n            \"usages\": usages,\n            \"callers\": callers,\n            \"impact_level\": \"high\" if len(callers) > 5 else \"medium\" if len(callers) > 0 else \"low\"\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to analyze change impact: {str(e)}\")\n\n\n@router.get(\"/relationships\")\nasync def get_code_relationships(\n    symbol_name: str = Query(..., description=\"Symbol to find relationships for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get code relationship analysis for a symbol.\n    \"\"\"\n    try:\n        # Get comprehensive relationship data\n        usages = query_service.find_method_usages(symbol_name)\n        callers = query_service.find_callers(symbol_name)\n        \n        return {\n            \"symbol\": symbol_name,\n            \"relationships\": {\n                \"usages\": usages,\n                \"callers\": callers,\n                \"usage_count\": len(usages.get('usages', [])),\n                \"caller_count\": len(callers)\n            }\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get code relationships: {str(e)}\")\n\n\n@router.get(\"/metrics\")\nasync def get_code_metrics(\n    repo_id: str = Query(None, description=\"Repository ID for repo-specific metrics\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get code metrics and statistics.\n    \"\"\"\n    try:\n        if repo_id:\n            # Get repository-specific stats\n            stats = query_service.get_repository_stats(repo_id)\n            return {\n                \"repository_id\": repo_id,\n                \"metrics\": stats\n            }\n        else:\n            # Get global graph stats\n            stats = query_service.get_graph_stats()\n            return {\n                \"global_metrics\": stats\n            }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get code metrics: {str(e)}\")\n\n\n@router.get(\"/stats\")\nasync def get_graph_stats(\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get overall graph statistics.\n    \"\"\"\n    try:\n        stats = query_service.get_graph_stats()\n        return stats\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get graph stats: {str(e)}\")\n\n\n@router.get(\"/symbol/{qualified_name}\")\nasync def get_symbol_by_qualified_name(\n    qualified_name: str,\n    repo_id: str = Query(..., description=\"Repository ID\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get symbol information by its qualified name.\n    \"\"\"\n    try:\n        symbol = query_service.find_symbol_by_qualified_name(qualified_name, repo_id)\n        if not symbol:\n            raise HTTPException(status_code=404, detail=\"Symbol not found\")\n        return symbol\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find symbol: {str(e)}\")\n\n\n# =========================================================================\n# CodeFinder Tool Integration Endpoints\n# =========================================================================\n\n@router.get(\"/code-finder/function\")\nasync def find_function_by_name(\n    name: str = Query(..., description=\"Function name to search for\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_function_name(name, fuzzy)\n        return {\n            \"function_name\": name,\n            \"fuzzy_search\": fuzzy,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/class\")\nasync def find_class_by_name(\n    name: str = Query(..., description=\"Class name to search for\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find classes by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_class_name(name, fuzzy)\n        return {\n            \"class_name\": name,\n            \"fuzzy_search\": fuzzy,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Class search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/variable\")\nasync def find_variable_by_name(\n    name: str = Query(..., description=\"Variable name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find variables by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_variable_name(name)\n        return {\n            \"variable_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Variable search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/content\")\nasync def find_by_content(\n    query: str = Query(..., description=\"Content search term\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find code by content matching using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_content(query)\n        return {\n            \"search_query\": query,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Content search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/module\")\nasync def find_module_by_name(\n    name: str = Query(..., description=\"Module name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find modules by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_module_name(name)\n        return {\n            \"module_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Module search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/imports\")\nasync def find_imports(\n    name: str = Query(..., description=\"Import name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find import statements using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_imports(name)\n        return {\n            \"import_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Import search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/related\")\nasync def find_related_code(\n    query: str = Query(..., description=\"Search query for related code\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    edit_distance: int = Query(2, description=\"Edit distance for fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find code related to a query using multiple search strategies.\n    \"\"\"\n    try:\n        results = code_finder.find_related_code(query, fuzzy, edit_distance)\n        return {\n            \"search_query\": query,\n            \"fuzzy_search\": fuzzy,\n            \"edit_distance\": edit_distance,\n            **results\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Related code search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/function/arguments\")\nasync def find_functions_by_argument(\n    argument_name: str = Query(..., description=\"Argument name to search for\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions that take a specific argument.\n    \"\"\"\n    try:\n        results = code_finder.find_functions_by_argument(argument_name, path)\n        return {\n            \"argument_name\": argument_name,\n            \"path_filter\": path,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function argument search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/function/decorator\")\nasync def find_functions_by_decorator(\n    decorator_name: str = Query(..., description=\"Decorator name to search for\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions that have a specific decorator.\n    \"\"\"\n    try:\n        results = code_finder.find_functions_by_decorator(decorator_name, path)\n        return {\n            \"decorator_name\": decorator_name,\n            \"path_filter\": path,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function decorator search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/complexity\")\nasync def get_cyclomatic_complexity(\n    function_name: str = Query(..., description=\"Function name to analyze\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get cyclomatic complexity of a function.\n    \"\"\"\n    try:\n        result = code_finder.get_cyclomatic_complexity(function_name, path)\n        if not result:\n            raise HTTPException(status_code=404, detail=\"Function not found\")\n        return {\n            \"function_name\": function_name,\n            \"path_filter\": path,\n            \"complexity\": result\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complexity analysis failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/complexity/top\")\nasync def find_most_complex_functions(\n    limit: int = Query(10, description=\"Number of results to return\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find the most complex functions by cyclomatic complexity.\n    \"\"\"\n    try:\n        results = code_finder.find_most_complex_functions(limit)\n        return {\n            \"limit\": limit,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complex function search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/line\")\nasync def find_by_line(\n    query: str = Query(..., description=\"Search term to find in file content\"),\n    limit: int = Query(50, description=\"Maximum number of line matches to return\"),\n    query_service: CodeQueryService = Depends(get_query_service),\n) -> Dict[str, Any]:\n    \"\"\"\n    Search raw file content line-by-line.\n    Uses file_content_search fulltext index (falls back to CONTAINS).\n    Returns path + line_number + match_line for each hit — no source dumps.\n    Pair with /code-finder/peek to view context around a hit.\n    \"\"\"\n    try:\n        results = query_service.search_file_content(query, limit)\n        return {\n            \"query\": query,\n            \"results\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Line search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/peek\")\nasync def peek_file_lines(\n    path: str = Query(..., description=\"Absolute file path (as stored in graph)\"),\n    line: int = Query(..., description=\"Anchor line number (1-indexed)\"),\n    above: int = Query(10, description=\"Lines to show above the anchor\"),\n    below: int = Query(10, description=\"Lines to show below the anchor\"),\n    query_service: CodeQueryService = Depends(get_query_service),\n) -> Dict[str, Any]:\n    \"\"\"\n    Return a window of lines around a given line in a file.\n    The anchor line is flagged with is_anchor=true.\n    Use above/below to control the context window size.\n    \"\"\"\n    try:\n        result = query_service.peek_file_lines(path, line, above, below)\n        if \"error\" in result:\n            raise HTTPException(status_code=404, detail=result[\"error\"])\n        return result\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Peek failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/relationships\")\nasync def analyze_code_relationships(\n    query_type: str = Query(..., description=\"Type of relationship query\"),\n    target: str = Query(..., description=\"Target symbol for analysis\"),\n    context: str = Query(None, description=\"Additional context for the query\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze code relationships using the CodeFinder's relationship query system.\n    \n    Supported query types:\n    - find_callers: Find all functions that call the target function\n    - find_callees: Find all functions called by the target function\n    - find_importers: Find all files that import the target module\n    - who_modifies: Find what functions modify a target variable\n    - class_hierarchy: Find inheritance relationships for a class\n    - call_chain: Find call paths between functions (format: 'start->end')\n    - module_deps: Find module dependencies\n    - variable_scope: Find variable usage across scopes\n    \"\"\"\n    try:\n        results = code_finder.execute_relationship_query(query_type, target, context)\n        return results\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Relationship analysis failed: {str(e)}\")\n\n\n@router.get(\"/repositories/indexed\")\nasync def list_indexed_repositories(\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    List all indexed repositories using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.list_indexed_repositories()\n        return {\n            \"repositories\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to list repositories: {str(e)}\")\n\n\n\n@router.get(\"/language/{language}/symbols\")\nasync def get_language_symbols(\n    language: str,\n    symbol_type: str = Query(..., description=\"Symbol type: function, class, variable, etc.\"),\n    limit: int = Query(50, description=\"Maximum number of results\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get all symbols of a specific type for a given language.\n    \n    Supported symbol types:\n    - function: All functions\n    - class: All classes  \n    - variable: All variables\n    - module: All modules\n    - file: All files\n    \"\"\"\n    try:\n        # Use Neo4j to query symbols by type and language\n        if symbol_type.lower() == \"function\":\n            query = f\"\"\"\n                MATCH (n:Function)\n                OPTIONAL MATCH (f:File)-[:CONTAINS]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.docstring as docstring, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"class\":\n            query = f\"\"\"\n                MATCH (n:Class)\n                OPTIONAL MATCH (f:File)-[:CONTAINS]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.docstring as docstring, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"variable\":\n            query = f\"\"\"\n                MATCH (n:Variable)\n                OPTIONAL MATCH (f:File)-[:CONTAINS*]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.value as value, n.context as context, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"file\":\n            query = f\"\"\"\n                MATCH (n:File)\n                WHERE n.language = $language OR n.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.relative_path as relative_path,\n                       n.language as language, n.extension as extension,\n                       n.is_dependency as is_dependency\n                ORDER BY n.is_dependency ASC, n.path\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"module\":\n            query = f\"\"\"\n                MATCH (n:Module)\n                WHERE n.lang = $language\n                RETURN n.name as name, n.lang as language,\n                       n.full_import_name as full_import_name\n                ORDER BY n.name\n                LIMIT $limit\n            \"\"\"\n        else:\n            raise HTTPException(status_code=400, detail=f\"Unsupported symbol type: {symbol_type}\")\n        \n        records, _, _ = query_service.db.run_query(query, {\"language\": language, \"limit\": limit})\n        \n        return {\n            \"language\": language,\n            \"symbol_type\": symbol_type,\n            \"results\": [dict(record) for record in records],\n            \"total\": len(records),\n            \"limit\": limit\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Language symbol query failed: {str(e)}\")\n\n\n@router.get(\"/language/stats\")\nasync def get_language_statistics(\n    language: str = Query(None, description=\"Optional language filter\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get statistics about programming languages in the codebase.\n    \"\"\"\n    try:\n        if language:\n            # Get stats for specific language\n            query = \"\"\"\n                MATCH (f:File)\n                WHERE f.language = $language OR f.extension IN ['.{}'.format($language.lower()), '.{}'.format($language[:2].lower())]\n                OPTIONAL MATCH (f)-[:CONTAINS]->(func:Function)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(cls:Class)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(var:Variable)\n                RETURN \n                    count(DISTINCT f) as file_count,\n                    count(DISTINCT func) as function_count,\n                    count(DISTINCT cls) as class_count,\n                    count(DISTINCT var) as variable_count\n            \"\"\"\n            records, _, _ = query_service.db.run_query(query, {\"language\": language})\n            result = dict(records[0]) if records else {}\n            result[\"language\"] = language\n            return result\n        else:\n            # Get stats for all languages\n            query = \"\"\"\n                MATCH (f:File)\n                WHERE f.language IS NOT NULL\n                OPTIONAL MATCH (f)-[:CONTAINS]->(func:Function)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(cls:Class)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(var:Variable)\n                RETURN \n                    f.language as language,\n                    count(DISTINCT f) as file_count,\n                    count(DISTINCT func) as function_count,\n                    count(DISTINCT cls) as class_count,\n                    count(DISTINCT var) as variable_count\n                ORDER BY file_count DESC\n            \"\"\"\n            records, _, _ = query_service.db.run_query(query)\n            return {\n                \"languages\": [dict(record) for record in records],\n                \"total_languages\": len(records)\n            }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Language statistics query failed: {str(e)}\")\n\n\n# --- Code Review / Diff Context Endpoints ---\n\n\n@router.get(\"/symbols-at-lines\")\nasync def get_symbols_at_lines(\n    file_path: str = Query(..., description=\"Absolute file path\"),\n    start_line: int = Query(..., description=\"Start line number\"),\n    end_line: int = Query(..., description=\"End line number\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all symbols (functions, classes, variables) overlapping a line range.\n    Useful for mapping diff hunks to affected code.\n    \"\"\"\n    try:\n        results = query_service.get_symbols_at_lines(file_path, start_line, end_line)\n        return {\n            \"file_path\": file_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n            \"symbols\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol lookup failed: {str(e)}\")\n\n\n@router.get(\"/symbols-at-lines-relative\")\nasync def get_symbols_at_lines_relative(\n    repo_id: str = Query(..., description=\"Repository ID (e.g. owner/repo)\"),\n    file_path: str = Query(..., description=\"Repo-relative file path (e.g. src/main.py)\"),\n    start_line: int = Query(..., description=\"Start line number\"),\n    end_line: int = Query(..., description=\"End line number\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all symbols overlapping a line range using repo-relative path.\n    \"\"\"\n    try:\n        results = query_service.get_symbols_at_lines_by_relative_path(\n            repo_id, file_path, start_line, end_line\n        )\n        return {\n            \"repo_id\": repo_id,\n            \"file_path\": file_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n            \"symbols\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol lookup failed: {str(e)}\")\n\n\nclass FileChange(BaseModel):\n    file_path: str\n    start_line: int = 1\n    end_line: int = 999999\n\n\nclass DiffContextRequest(BaseModel):\n    repo_id: str\n    changes: List[FileChange]\n\n\n@router.post(\"/diff-context\")\nasync def get_diff_context(\n    request: DiffContextRequest,\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Build full RAG context for a code diff.\n\n    Given a repository and a list of file changes (path + line ranges),\n    returns affected symbols with source code, their callers, class hierarchy,\n    and full file sources. Designed for AI-powered code review.\n\n    Example request:\n    ```json\n    {\n        \"repo_id\": \"owner/repo\",\n        \"changes\": [\n            {\"file_path\": \"src/main.py\", \"start_line\": 10, \"end_line\": 30},\n            {\"file_path\": \"src/utils.py\", \"start_line\": 1, \"end_line\": 50}\n        ]\n    }\n    ```\n    \"\"\"\n    try:\n        changes_dicts = [c.model_dump() for c in request.changes]\n        result = query_service.get_diff_context(request.repo_id, changes_dicts)\n        return result\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Diff context failed: {str(e)}\")\n\n\n@router.get(\"/file-source\")\nasync def get_file_source(\n    repo_id: str = Query(..., description=\"Repository ID\"),\n    file_path: str = Query(..., description=\"Repo-relative file path\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get the full source code of a file from the graph.\n    \"\"\"\n    try:\n        query = \"\"\"\n        MATCH (f:File)\n        WHERE f.relative_path = $relative_path AND f.path CONTAINS $repo_id\n        RETURN f.source_code as source_code, f.relative_path as path,\n               f.language as language, f.lines_count as lines_count\n        LIMIT 1\n        \"\"\"\n        records, _, _ = query_service.db.run_query(query, {\n            \"relative_path\": file_path,\n            \"repo_id\": repo_id,\n        })\n        if not records:\n            raise HTTPException(status_code=404, detail=\"File not found\")\n        record = records[0]\n        return {\n            \"file_path\": record.get(\"path\"),\n            \"language\": record.get(\"language\"),\n            \"lines_count\": record.get(\"lines_count\"),\n            \"source_code\": record.get(\"source_code\"),\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"File source retrieval failed: {str(e)}\")\n","structuredPatch":[{"oldStart":42,"oldLines":6,"newStart":42,"newLines":8,"lines":["     name, path, line_number, and score. Symbol results come first","     (higher score), file-content line matches follow.","     \"\"\"","+    if len(query) > 500:","+        raise HTTPException(status_code=400, detail=\"Query too long (max 500 characters)\")","     try:","         results = query_service.search_code(query)","         if limit:"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"4cb8b630-6432-4a36-a4c3-f651041d7334"}
{"parentUuid":"10182115-fc79-4e47-83d9-435ed54fd8b4","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01HUMVVcak4jsaVfWRYu1dDb","type":"message","role":"assistant","content":[{"type":"text","text":"Now find and patch the line and peek endpoints:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":390,"cache_read_input_tokens":142457,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":390},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvfRntToyxT1VdVUios","type":"assistant","uuid":"72b3b2e4-ec4d-4965-abf5-3e38cac8078d","timestamp":"2026-02-21T08:49:13.705Z"}
{"parentUuid":"72b3b2e4-ec4d-4965-abf5-3e38cac8078d","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01HUMVVcak4jsaVfWRYu1dDb","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Ad6uWuohgyZ2qg53n3GVvB","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","offset":507,"limit":65},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":390,"cache_read_input_tokens":142457,"output_tokens":120,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":390,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLvfRntToyxT1VdVUios","type":"assistant","uuid":"b3162410-8e05-4e50-a6a7-41582d6593af","timestamp":"2026-02-21T08:49:14.454Z"}
{"parentUuid":"b3162410-8e05-4e50-a6a7-41582d6593af","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01Ad6uWuohgyZ2qg53n3GVvB","toolUseID":"toolu_01Ad6uWuohgyZ2qg53n3GVvB","timestamp":"2026-02-21T08:49:14.632Z","uuid":"428a6856-ec0f-40ee-8367-2d45a483af19"}
{"parentUuid":"b3162410-8e05-4e50-a6a7-41582d6593af","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Ad6uWuohgyZ2qg53n3GVvB","type":"tool_result","content":"   507→            \"query\": query,\n   508→            \"results\": results,\n   509→            \"total\": len(results),\n   510→        }\n   511→    except Exception as e:\n   512→        raise HTTPException(status_code=500, detail=f\"Line search failed: {str(e)}\")\n   513→\n   514→\n   515→@router.get(\"/code-finder/peek\")\n   516→async def peek_file_lines(\n   517→    path: str = Query(..., description=\"Absolute file path (as stored in graph)\"),\n   518→    line: int = Query(..., description=\"Anchor line number (1-indexed)\"),\n   519→    above: int = Query(10, description=\"Lines to show above the anchor\"),\n   520→    below: int = Query(10, description=\"Lines to show below the anchor\"),\n   521→    query_service: CodeQueryService = Depends(get_query_service),\n   522→) -> Dict[str, Any]:\n   523→    \"\"\"\n   524→    Return a window of lines around a given line in a file.\n   525→    The anchor line is flagged with is_anchor=true.\n   526→    Use above/below to control the context window size.\n   527→    \"\"\"\n   528→    try:\n   529→        result = query_service.peek_file_lines(path, line, above, below)\n   530→        if \"error\" in result:\n   531→            raise HTTPException(status_code=404, detail=result[\"error\"])\n   532→        return result\n   533→    except HTTPException:\n   534→        raise\n   535→    except Exception as e:\n   536→        raise HTTPException(status_code=500, detail=f\"Peek failed: {str(e)}\")\n   537→\n   538→\n   539→@router.get(\"/code-finder/relationships\")\n   540→async def analyze_code_relationships(\n   541→    query_type: str = Query(..., description=\"Type of relationship query\"),\n   542→    target: str = Query(..., description=\"Target symbol for analysis\"),\n   543→    context: str = Query(None, description=\"Additional context for the query\"),\n   544→    code_finder: CodeFinder = Depends(get_code_finder)\n   545→) -> Dict[str, Any]:\n   546→    \"\"\"\n   547→    Analyze code relationships using the CodeFinder's relationship query system.\n   548→    \n   549→    Supported query types:\n   550→    - find_callers: Find all functions that call the target function\n   551→    - find_callees: Find all functions called by the target function\n   552→    - find_importers: Find all files that import the target module\n   553→    - who_modifies: Find what functions modify a target variable\n   554→    - class_hierarchy: Find inheritance relationships for a class\n   555→    - call_chain: Find call paths between functions (format: 'start->end')\n   556→    - module_deps: Find module dependencies\n   557→    - variable_scope: Find variable usage across scopes\n   558→    \"\"\"\n   559→    try:\n   560→        results = code_finder.execute_relationship_query(query_type, target, context)\n   561→        return results\n   562→    except Exception as e:\n   563→        raise HTTPException(status_code=500, detail=f\"Relationship analysis failed: {str(e)}\")\n   564→\n   565→\n   566→@router.get(\"/repositories/indexed\")\n   567→async def list_indexed_repositories(\n   568→    code_finder: CodeFinder = Depends(get_code_finder)\n   569→) -> Dict[str, Any]:\n   570→    \"\"\"\n   571→    List all indexed repositories using the CodeFinder tool.\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"5afcfbf8-9122-4161-9ea5-c49db2b67b85","timestamp":"2026-02-21T08:49:14.631Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","content":"            \"query\": query,\n            \"results\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Line search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/peek\")\nasync def peek_file_lines(\n    path: str = Query(..., description=\"Absolute file path (as stored in graph)\"),\n    line: int = Query(..., description=\"Anchor line number (1-indexed)\"),\n    above: int = Query(10, description=\"Lines to show above the anchor\"),\n    below: int = Query(10, description=\"Lines to show below the anchor\"),\n    query_service: CodeQueryService = Depends(get_query_service),\n) -> Dict[str, Any]:\n    \"\"\"\n    Return a window of lines around a given line in a file.\n    The anchor line is flagged with is_anchor=true.\n    Use above/below to control the context window size.\n    \"\"\"\n    try:\n        result = query_service.peek_file_lines(path, line, above, below)\n        if \"error\" in result:\n            raise HTTPException(status_code=404, detail=result[\"error\"])\n        return result\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Peek failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/relationships\")\nasync def analyze_code_relationships(\n    query_type: str = Query(..., description=\"Type of relationship query\"),\n    target: str = Query(..., description=\"Target symbol for analysis\"),\n    context: str = Query(None, description=\"Additional context for the query\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze code relationships using the CodeFinder's relationship query system.\n    \n    Supported query types:\n    - find_callers: Find all functions that call the target function\n    - find_callees: Find all functions called by the target function\n    - find_importers: Find all files that import the target module\n    - who_modifies: Find what functions modify a target variable\n    - class_hierarchy: Find inheritance relationships for a class\n    - call_chain: Find call paths between functions (format: 'start->end')\n    - module_deps: Find module dependencies\n    - variable_scope: Find variable usage across scopes\n    \"\"\"\n    try:\n        results = code_finder.execute_relationship_query(query_type, target, context)\n        return results\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Relationship analysis failed: {str(e)}\")\n\n\n@router.get(\"/repositories/indexed\")\nasync def list_indexed_repositories(\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    List all indexed repositories using the CodeFinder tool.","numLines":65,"startLine":507,"totalLines":855}},"sourceToolAssistantUUID":"b3162410-8e05-4e50-a6a7-41582d6593af"}
{"parentUuid":"5afcfbf8-9122-4161-9ea5-c49db2b67b85","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01XbCSGBWECzm8fbJ4JxAxmM","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JRHZVGeu5kQge6FBAYxMZC","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","offset":490,"limit":25},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1128,"cache_read_input_tokens":142847,"output_tokens":109,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":1128,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLvfeca3eQHZphoEt2fM","type":"assistant","uuid":"9b98c95b-9d9d-44c7-b74d-c88217c86410","timestamp":"2026-02-21T08:49:17.395Z"}
{"parentUuid":"9b98c95b-9d9d-44c7-b74d-c88217c86410","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01JRHZVGeu5kQge6FBAYxMZC","toolUseID":"toolu_01JRHZVGeu5kQge6FBAYxMZC","timestamp":"2026-02-21T08:49:17.572Z","uuid":"eb84c895-abe9-4cfc-a4e7-f0a970589a4e"}
{"parentUuid":"9b98c95b-9d9d-44c7-b74d-c88217c86410","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JRHZVGeu5kQge6FBAYxMZC","type":"tool_result","content":"   490→\n   491→\n   492→@router.get(\"/code-finder/line\")\n   493→async def find_by_line(\n   494→    query: str = Query(..., description=\"Search term to find in file content\"),\n   495→    limit: int = Query(50, description=\"Maximum number of line matches to return\"),\n   496→    query_service: CodeQueryService = Depends(get_query_service),\n   497→) -> Dict[str, Any]:\n   498→    \"\"\"\n   499→    Search raw file content line-by-line.\n   500→    Uses file_content_search fulltext index (falls back to CONTAINS).\n   501→    Returns path + line_number + match_line for each hit — no source dumps.\n   502→    Pair with /code-finder/peek to view context around a hit.\n   503→    \"\"\"\n   504→    try:\n   505→        results = query_service.search_file_content(query, limit)\n   506→        return {\n   507→            \"query\": query,\n   508→            \"results\": results,\n   509→            \"total\": len(results),\n   510→        }\n   511→    except Exception as e:\n   512→        raise HTTPException(status_code=500, detail=f\"Line search failed: {str(e)}\")\n   513→\n   514→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"e953f78b-c71f-480e-bec0-2c453ce03ddc","timestamp":"2026-02-21T08:49:17.571Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","content":"\n\n@router.get(\"/code-finder/line\")\nasync def find_by_line(\n    query: str = Query(..., description=\"Search term to find in file content\"),\n    limit: int = Query(50, description=\"Maximum number of line matches to return\"),\n    query_service: CodeQueryService = Depends(get_query_service),\n) -> Dict[str, Any]:\n    \"\"\"\n    Search raw file content line-by-line.\n    Uses file_content_search fulltext index (falls back to CONTAINS).\n    Returns path + line_number + match_line for each hit — no source dumps.\n    Pair with /code-finder/peek to view context around a hit.\n    \"\"\"\n    try:\n        results = query_service.search_file_content(query, limit)\n        return {\n            \"query\": query,\n            \"results\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Line search failed: {str(e)}\")\n\n","numLines":25,"startLine":490,"totalLines":855}},"sourceToolAssistantUUID":"9b98c95b-9d9d-44c7-b74d-c88217c86410"}
{"parentUuid":"e953f78b-c71f-480e-bec0-2c453ce03ddc","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01SAge2UjxqVd1df4EYVQty9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01T88sD1WXziSXL2LtL8b3uH","name":"Edit","input":{"replace_all":false,"file_path":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","old_string":"    try:\n        results = query_service.search_file_content(query, limit)\n        return {\n            \"query\": query,\n            \"results\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Line search failed: {str(e)}\")","new_string":"    if len(query) > 500:\n        raise HTTPException(status_code=400, detail=\"Query too long (max 500 characters)\")\n    limit = min(limit, 100)  # hard cap\n    try:\n        results = query_service.search_file_content(query, limit)\n        return {\n            \"query\": query,\n            \"results\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Line search failed: {str(e)}\")"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":526,"cache_read_input_tokens":143975,"output_tokens":348,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":526,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLvfsA8FmVyus9eCKjfc","type":"assistant","uuid":"aae4aa24-fa3e-489d-82e1-252e7a71fbee","timestamp":"2026-02-21T08:49:21.813Z"}
{"parentUuid":"aae4aa24-fa3e-489d-82e1-252e7a71fbee","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_01T88sD1WXziSXL2LtL8b3uH","toolUseID":"toolu_01T88sD1WXziSXL2LtL8b3uH","timestamp":"2026-02-21T08:49:21.992Z","uuid":"0bbc822b-7add-4dbd-ac2b-0cd8ed0481c0"}
{"parentUuid":"aae4aa24-fa3e-489d-82e1-252e7a71fbee","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01T88sD1WXziSXL2LtL8b3uH","type":"tool_result","content":"The file /Users/skmabudalam/Documents/BugViper/api/routers/query.py has been updated successfully."}]},"uuid":"318035b6-b291-48a4-a63d-18a2ab64c4dd","timestamp":"2026-02-21T08:49:21.992Z","toolUseResult":{"filePath":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","oldString":"    try:\n        results = query_service.search_file_content(query, limit)\n        return {\n            \"query\": query,\n            \"results\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Line search failed: {str(e)}\")","newString":"    if len(query) > 500:\n        raise HTTPException(status_code=400, detail=\"Query too long (max 500 characters)\")\n    limit = min(limit, 100)  # hard cap\n    try:\n        results = query_service.search_file_content(query, limit)\n        return {\n            \"query\": query,\n            \"results\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Line search failed: {str(e)}\")","originalFile":"\"\"\"\nCode query endpoints - Advanced implementation with Neo4j integration.\n\"\"\"\n\nfrom fastapi import APIRouter, HTTPException, Query, Depends\nfrom pydantic import BaseModel\nfrom typing import Dict, Any, List\n\nfrom db.client import Neo4jClient\nfrom db.queries import CodeQueryService\nfrom api.dependencies import get_neo4j_client\nfrom api.services.code_search import CodeFinder\n\nrouter = APIRouter()\n\n\ndef get_query_service(db: Neo4jClient = Depends(get_neo4j_client)) -> CodeQueryService:\n    \"\"\"Dependency to get query service.\"\"\"\n    return CodeQueryService(db)\n\n\ndef get_code_finder(db: Neo4jClient = Depends(get_neo4j_client)) -> CodeFinder:\n    \"\"\"Dependency to get code finder.\"\"\"\n    return CodeFinder(db)\n\n\n@router.get(\"/search\")\nasync def search_code(\n    query: str = Query(..., description=\"Search term — any identifier, snippet, or keyword\"),\n    limit: int = Query(30, description=\"Maximum results to return\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Unified code search.\n\n    Three-tier strategy:\n    1. Fulltext index on symbols (name, docstring, source_code)\n    2. Name CONTAINS fallback (uses primary extracted identifier)\n    3. File content line search (file_content_search / source_code CONTAINS)\n\n    Results include type ('function' | 'class' | 'variable' | 'line'),\n    name, path, line_number, and score. Symbol results come first\n    (higher score), file-content line matches follow.\n    \"\"\"\n    if len(query) > 500:\n        raise HTTPException(status_code=400, detail=\"Query too long (max 500 characters)\")\n    try:\n        results = query_service.search_code(query)\n        if limit:\n            results = results[:limit]\n        return {\n            \"results\": results,\n            \"total\": len(results),\n            \"query\": query,\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")\n\n\n@router.get(\"/method-usages\")\nasync def find_method_usages(\n    method_name: str = Query(..., description=\"Name of the method to find usages for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all usages of a specific method.\n    \"\"\"\n    try:\n        usages = query_service.find_method_usages(method_name)\n        return usages\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find method usages: {str(e)}\")\n\n\n@router.get(\"/find_usages\")\nasync def find_usages(\n    symbol_name: str = Query(..., description=\"Symbol name to find usages for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all usages of a specific symbol (alias for method-usages).\n    \"\"\"\n    try:\n        usages = query_service.find_method_usages(symbol_name)\n        return usages\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find usages: {str(e)}\")\n\n\n@router.get(\"/find_callers\")\nasync def find_callers(\n    symbol_name: str = Query(..., description=\"Symbol name to find callers for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all methods/functions that call a specific symbol.\n    \"\"\"\n    try:\n        callers = query_service.find_callers(symbol_name)\n        return {\n            \"callers\": callers,\n            \"symbol\": symbol_name,\n            \"total\": len(callers)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find callers: {str(e)}\")\n\n\n@router.get(\"/class_hierarchy\")\nasync def get_class_hierarchy(\n    class_name: str = Query(..., description=\"Name of the class to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get class hierarchy (inheritance tree).\n    \"\"\"\n    try:\n        hierarchy = query_service.get_class_hierarchy(class_name)\n        return hierarchy\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get class hierarchy: {str(e)}\")\n\n\n@router.get(\"/class-hierarchy\")\nasync def get_class_hierarchy_alt(\n    class_name: str = Query(..., description=\"Name of the class to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get class hierarchy (inheritance tree) - alternative endpoint.\n    \"\"\"\n    try:\n        hierarchy = query_service.get_class_hierarchy(class_name)\n        return hierarchy\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get class hierarchy: {str(e)}\")\n\n\n@router.get(\"/file-structure\")\nasync def analyze_file_structure(\n    file_id: str = Query(..., description=\"File ID to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze the structure of a specific file.\n    \"\"\"\n    try:\n        structure = query_service.get_file_structure(file_id)\n        return structure\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to analyze file structure: {str(e)}\")\n\n\n@router.get(\"/change_impact\")\nasync def analyze_change_impact(\n    symbol_name: str = Query(..., description=\"Symbol to analyze impact for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze the impact of changing a specific symbol.\n    \"\"\"\n    try:\n        # Get all usages of the symbol to understand impact\n        usages = query_service.find_method_usages(symbol_name)\n        callers = query_service.find_callers(symbol_name)\n        \n        return {\n            \"symbol\": symbol_name,\n            \"usages\": usages,\n            \"callers\": callers,\n            \"impact_level\": \"high\" if len(callers) > 5 else \"medium\" if len(callers) > 0 else \"low\"\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to analyze change impact: {str(e)}\")\n\n\n@router.get(\"/relationships\")\nasync def get_code_relationships(\n    symbol_name: str = Query(..., description=\"Symbol to find relationships for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get code relationship analysis for a symbol.\n    \"\"\"\n    try:\n        # Get comprehensive relationship data\n        usages = query_service.find_method_usages(symbol_name)\n        callers = query_service.find_callers(symbol_name)\n        \n        return {\n            \"symbol\": symbol_name,\n            \"relationships\": {\n                \"usages\": usages,\n                \"callers\": callers,\n                \"usage_count\": len(usages.get('usages', [])),\n                \"caller_count\": len(callers)\n            }\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get code relationships: {str(e)}\")\n\n\n@router.get(\"/metrics\")\nasync def get_code_metrics(\n    repo_id: str = Query(None, description=\"Repository ID for repo-specific metrics\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get code metrics and statistics.\n    \"\"\"\n    try:\n        if repo_id:\n            # Get repository-specific stats\n            stats = query_service.get_repository_stats(repo_id)\n            return {\n                \"repository_id\": repo_id,\n                \"metrics\": stats\n            }\n        else:\n            # Get global graph stats\n            stats = query_service.get_graph_stats()\n            return {\n                \"global_metrics\": stats\n            }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get code metrics: {str(e)}\")\n\n\n@router.get(\"/stats\")\nasync def get_graph_stats(\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get overall graph statistics.\n    \"\"\"\n    try:\n        stats = query_service.get_graph_stats()\n        return stats\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get graph stats: {str(e)}\")\n\n\n@router.get(\"/symbol/{qualified_name}\")\nasync def get_symbol_by_qualified_name(\n    qualified_name: str,\n    repo_id: str = Query(..., description=\"Repository ID\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get symbol information by its qualified name.\n    \"\"\"\n    try:\n        symbol = query_service.find_symbol_by_qualified_name(qualified_name, repo_id)\n        if not symbol:\n            raise HTTPException(status_code=404, detail=\"Symbol not found\")\n        return symbol\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find symbol: {str(e)}\")\n\n\n# =========================================================================\n# CodeFinder Tool Integration Endpoints\n# =========================================================================\n\n@router.get(\"/code-finder/function\")\nasync def find_function_by_name(\n    name: str = Query(..., description=\"Function name to search for\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_function_name(name, fuzzy)\n        return {\n            \"function_name\": name,\n            \"fuzzy_search\": fuzzy,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/class\")\nasync def find_class_by_name(\n    name: str = Query(..., description=\"Class name to search for\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find classes by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_class_name(name, fuzzy)\n        return {\n            \"class_name\": name,\n            \"fuzzy_search\": fuzzy,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Class search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/variable\")\nasync def find_variable_by_name(\n    name: str = Query(..., description=\"Variable name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find variables by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_variable_name(name)\n        return {\n            \"variable_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Variable search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/content\")\nasync def find_by_content(\n    query: str = Query(..., description=\"Content search term\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find code by content matching using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_content(query)\n        return {\n            \"search_query\": query,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Content search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/module\")\nasync def find_module_by_name(\n    name: str = Query(..., description=\"Module name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find modules by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_module_name(name)\n        return {\n            \"module_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Module search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/imports\")\nasync def find_imports(\n    name: str = Query(..., description=\"Import name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find import statements using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_imports(name)\n        return {\n            \"import_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Import search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/related\")\nasync def find_related_code(\n    query: str = Query(..., description=\"Search query for related code\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    edit_distance: int = Query(2, description=\"Edit distance for fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find code related to a query using multiple search strategies.\n    \"\"\"\n    try:\n        results = code_finder.find_related_code(query, fuzzy, edit_distance)\n        return {\n            \"search_query\": query,\n            \"fuzzy_search\": fuzzy,\n            \"edit_distance\": edit_distance,\n            **results\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Related code search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/function/arguments\")\nasync def find_functions_by_argument(\n    argument_name: str = Query(..., description=\"Argument name to search for\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions that take a specific argument.\n    \"\"\"\n    try:\n        results = code_finder.find_functions_by_argument(argument_name, path)\n        return {\n            \"argument_name\": argument_name,\n            \"path_filter\": path,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function argument search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/function/decorator\")\nasync def find_functions_by_decorator(\n    decorator_name: str = Query(..., description=\"Decorator name to search for\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions that have a specific decorator.\n    \"\"\"\n    try:\n        results = code_finder.find_functions_by_decorator(decorator_name, path)\n        return {\n            \"decorator_name\": decorator_name,\n            \"path_filter\": path,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function decorator search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/complexity\")\nasync def get_cyclomatic_complexity(\n    function_name: str = Query(..., description=\"Function name to analyze\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get cyclomatic complexity of a function.\n    \"\"\"\n    try:\n        result = code_finder.get_cyclomatic_complexity(function_name, path)\n        if not result:\n            raise HTTPException(status_code=404, detail=\"Function not found\")\n        return {\n            \"function_name\": function_name,\n            \"path_filter\": path,\n            \"complexity\": result\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complexity analysis failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/complexity/top\")\nasync def find_most_complex_functions(\n    limit: int = Query(10, description=\"Number of results to return\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find the most complex functions by cyclomatic complexity.\n    \"\"\"\n    try:\n        results = code_finder.find_most_complex_functions(limit)\n        return {\n            \"limit\": limit,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complex function search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/line\")\nasync def find_by_line(\n    query: str = Query(..., description=\"Search term to find in file content\"),\n    limit: int = Query(50, description=\"Maximum number of line matches to return\"),\n    query_service: CodeQueryService = Depends(get_query_service),\n) -> Dict[str, Any]:\n    \"\"\"\n    Search raw file content line-by-line.\n    Uses file_content_search fulltext index (falls back to CONTAINS).\n    Returns path + line_number + match_line for each hit — no source dumps.\n    Pair with /code-finder/peek to view context around a hit.\n    \"\"\"\n    try:\n        results = query_service.search_file_content(query, limit)\n        return {\n            \"query\": query,\n            \"results\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Line search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/peek\")\nasync def peek_file_lines(\n    path: str = Query(..., description=\"Absolute file path (as stored in graph)\"),\n    line: int = Query(..., description=\"Anchor line number (1-indexed)\"),\n    above: int = Query(10, description=\"Lines to show above the anchor\"),\n    below: int = Query(10, description=\"Lines to show below the anchor\"),\n    query_service: CodeQueryService = Depends(get_query_service),\n) -> Dict[str, Any]:\n    \"\"\"\n    Return a window of lines around a given line in a file.\n    The anchor line is flagged with is_anchor=true.\n    Use above/below to control the context window size.\n    \"\"\"\n    try:\n        result = query_service.peek_file_lines(path, line, above, below)\n        if \"error\" in result:\n            raise HTTPException(status_code=404, detail=result[\"error\"])\n        return result\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Peek failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/relationships\")\nasync def analyze_code_relationships(\n    query_type: str = Query(..., description=\"Type of relationship query\"),\n    target: str = Query(..., description=\"Target symbol for analysis\"),\n    context: str = Query(None, description=\"Additional context for the query\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze code relationships using the CodeFinder's relationship query system.\n    \n    Supported query types:\n    - find_callers: Find all functions that call the target function\n    - find_callees: Find all functions called by the target function\n    - find_importers: Find all files that import the target module\n    - who_modifies: Find what functions modify a target variable\n    - class_hierarchy: Find inheritance relationships for a class\n    - call_chain: Find call paths between functions (format: 'start->end')\n    - module_deps: Find module dependencies\n    - variable_scope: Find variable usage across scopes\n    \"\"\"\n    try:\n        results = code_finder.execute_relationship_query(query_type, target, context)\n        return results\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Relationship analysis failed: {str(e)}\")\n\n\n@router.get(\"/repositories/indexed\")\nasync def list_indexed_repositories(\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    List all indexed repositories using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.list_indexed_repositories()\n        return {\n            \"repositories\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to list repositories: {str(e)}\")\n\n\n\n@router.get(\"/language/{language}/symbols\")\nasync def get_language_symbols(\n    language: str,\n    symbol_type: str = Query(..., description=\"Symbol type: function, class, variable, etc.\"),\n    limit: int = Query(50, description=\"Maximum number of results\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get all symbols of a specific type for a given language.\n    \n    Supported symbol types:\n    - function: All functions\n    - class: All classes  \n    - variable: All variables\n    - module: All modules\n    - file: All files\n    \"\"\"\n    try:\n        # Use Neo4j to query symbols by type and language\n        if symbol_type.lower() == \"function\":\n            query = f\"\"\"\n                MATCH (n:Function)\n                OPTIONAL MATCH (f:File)-[:CONTAINS]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.docstring as docstring, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"class\":\n            query = f\"\"\"\n                MATCH (n:Class)\n                OPTIONAL MATCH (f:File)-[:CONTAINS]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.docstring as docstring, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"variable\":\n            query = f\"\"\"\n                MATCH (n:Variable)\n                OPTIONAL MATCH (f:File)-[:CONTAINS*]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.value as value, n.context as context, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"file\":\n            query = f\"\"\"\n                MATCH (n:File)\n                WHERE n.language = $language OR n.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.relative_path as relative_path,\n                       n.language as language, n.extension as extension,\n                       n.is_dependency as is_dependency\n                ORDER BY n.is_dependency ASC, n.path\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"module\":\n            query = f\"\"\"\n                MATCH (n:Module)\n                WHERE n.lang = $language\n                RETURN n.name as name, n.lang as language,\n                       n.full_import_name as full_import_name\n                ORDER BY n.name\n                LIMIT $limit\n            \"\"\"\n        else:\n            raise HTTPException(status_code=400, detail=f\"Unsupported symbol type: {symbol_type}\")\n        \n        records, _, _ = query_service.db.run_query(query, {\"language\": language, \"limit\": limit})\n        \n        return {\n            \"language\": language,\n            \"symbol_type\": symbol_type,\n            \"results\": [dict(record) for record in records],\n            \"total\": len(records),\n            \"limit\": limit\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Language symbol query failed: {str(e)}\")\n\n\n@router.get(\"/language/stats\")\nasync def get_language_statistics(\n    language: str = Query(None, description=\"Optional language filter\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get statistics about programming languages in the codebase.\n    \"\"\"\n    try:\n        if language:\n            # Get stats for specific language\n            query = \"\"\"\n                MATCH (f:File)\n                WHERE f.language = $language OR f.extension IN ['.{}'.format($language.lower()), '.{}'.format($language[:2].lower())]\n                OPTIONAL MATCH (f)-[:CONTAINS]->(func:Function)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(cls:Class)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(var:Variable)\n                RETURN \n                    count(DISTINCT f) as file_count,\n                    count(DISTINCT func) as function_count,\n                    count(DISTINCT cls) as class_count,\n                    count(DISTINCT var) as variable_count\n            \"\"\"\n            records, _, _ = query_service.db.run_query(query, {\"language\": language})\n            result = dict(records[0]) if records else {}\n            result[\"language\"] = language\n            return result\n        else:\n            # Get stats for all languages\n            query = \"\"\"\n                MATCH (f:File)\n                WHERE f.language IS NOT NULL\n                OPTIONAL MATCH (f)-[:CONTAINS]->(func:Function)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(cls:Class)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(var:Variable)\n                RETURN \n                    f.language as language,\n                    count(DISTINCT f) as file_count,\n                    count(DISTINCT func) as function_count,\n                    count(DISTINCT cls) as class_count,\n                    count(DISTINCT var) as variable_count\n                ORDER BY file_count DESC\n            \"\"\"\n            records, _, _ = query_service.db.run_query(query)\n            return {\n                \"languages\": [dict(record) for record in records],\n                \"total_languages\": len(records)\n            }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Language statistics query failed: {str(e)}\")\n\n\n# --- Code Review / Diff Context Endpoints ---\n\n\n@router.get(\"/symbols-at-lines\")\nasync def get_symbols_at_lines(\n    file_path: str = Query(..., description=\"Absolute file path\"),\n    start_line: int = Query(..., description=\"Start line number\"),\n    end_line: int = Query(..., description=\"End line number\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all symbols (functions, classes, variables) overlapping a line range.\n    Useful for mapping diff hunks to affected code.\n    \"\"\"\n    try:\n        results = query_service.get_symbols_at_lines(file_path, start_line, end_line)\n        return {\n            \"file_path\": file_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n            \"symbols\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol lookup failed: {str(e)}\")\n\n\n@router.get(\"/symbols-at-lines-relative\")\nasync def get_symbols_at_lines_relative(\n    repo_id: str = Query(..., description=\"Repository ID (e.g. owner/repo)\"),\n    file_path: str = Query(..., description=\"Repo-relative file path (e.g. src/main.py)\"),\n    start_line: int = Query(..., description=\"Start line number\"),\n    end_line: int = Query(..., description=\"End line number\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all symbols overlapping a line range using repo-relative path.\n    \"\"\"\n    try:\n        results = query_service.get_symbols_at_lines_by_relative_path(\n            repo_id, file_path, start_line, end_line\n        )\n        return {\n            \"repo_id\": repo_id,\n            \"file_path\": file_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n            \"symbols\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol lookup failed: {str(e)}\")\n\n\nclass FileChange(BaseModel):\n    file_path: str\n    start_line: int = 1\n    end_line: int = 999999\n\n\nclass DiffContextRequest(BaseModel):\n    repo_id: str\n    changes: List[FileChange]\n\n\n@router.post(\"/diff-context\")\nasync def get_diff_context(\n    request: DiffContextRequest,\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Build full RAG context for a code diff.\n\n    Given a repository and a list of file changes (path + line ranges),\n    returns affected symbols with source code, their callers, class hierarchy,\n    and full file sources. Designed for AI-powered code review.\n\n    Example request:\n    ```json\n    {\n        \"repo_id\": \"owner/repo\",\n        \"changes\": [\n            {\"file_path\": \"src/main.py\", \"start_line\": 10, \"end_line\": 30},\n            {\"file_path\": \"src/utils.py\", \"start_line\": 1, \"end_line\": 50}\n        ]\n    }\n    ```\n    \"\"\"\n    try:\n        changes_dicts = [c.model_dump() for c in request.changes]\n        result = query_service.get_diff_context(request.repo_id, changes_dicts)\n        return result\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Diff context failed: {str(e)}\")\n\n\n@router.get(\"/file-source\")\nasync def get_file_source(\n    repo_id: str = Query(..., description=\"Repository ID\"),\n    file_path: str = Query(..., description=\"Repo-relative file path\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get the full source code of a file from the graph.\n    \"\"\"\n    try:\n        query = \"\"\"\n        MATCH (f:File)\n        WHERE f.relative_path = $relative_path AND f.path CONTAINS $repo_id\n        RETURN f.source_code as source_code, f.relative_path as path,\n               f.language as language, f.lines_count as lines_count\n        LIMIT 1\n        \"\"\"\n        records, _, _ = query_service.db.run_query(query, {\n            \"relative_path\": file_path,\n            \"repo_id\": repo_id,\n        })\n        if not records:\n            raise HTTPException(status_code=404, detail=\"File not found\")\n        record = records[0]\n        return {\n            \"file_path\": record.get(\"path\"),\n            \"language\": record.get(\"language\"),\n            \"lines_count\": record.get(\"lines_count\"),\n            \"source_code\": record.get(\"source_code\"),\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"File source retrieval failed: {str(e)}\")\n","structuredPatch":[{"oldStart":501,"oldLines":6,"newStart":501,"newLines":9,"lines":["     Returns path + line_number + match_line for each hit — no source dumps.","     Pair with /code-finder/peek to view context around a hit.","     \"\"\"","+    if len(query) > 500:","+        raise HTTPException(status_code=400, detail=\"Query too long (max 500 characters)\")","+    limit = min(limit, 100)  # hard cap","     try:","         results = query_service.search_file_content(query, limit)","         return {"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"aae4aa24-fa3e-489d-82e1-252e7a71fbee"}
{"parentUuid":"318035b6-b291-48a4-a63d-18a2ab64c4dd","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01XWyQBQKdAXuFfDpQj3o5ok","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_018AKMf6rsKo7WAPscMJ7K6F","name":"Edit","input":{"replace_all":false,"file_path":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","old_string":"    try:\n        result = query_service.peek_file_lines(path, line, above, below)\n        if \"error\" in result:\n            raise HTTPException(status_code=404, detail=result[\"error\"])\n        return result\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Peek failed: {str(e)}\")","new_string":"    above = min(above, 200)   # hard cap — prevents fetching entire file as \"context\"\n    below = min(below, 200)\n    if line < 1:\n        raise HTTPException(status_code=400, detail=\"line must be >= 1\")\n    try:\n        result = query_service.peek_file_lines(path, line, above, below)\n        if \"error\" in result:\n            raise HTTPException(status_code=404, detail=result[\"error\"])\n        return result\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Peek failed: {str(e)}\")"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":389,"cache_read_input_tokens":144501,"output_tokens":391,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":389,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLvgCUENcyKhZrhAbNH2","type":"assistant","uuid":"a693b280-daf5-4d23-aa0f-b91f3678414b","timestamp":"2026-02-21T08:49:27.536Z"}
{"parentUuid":"a693b280-daf5-4d23-aa0f-b91f3678414b","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_018AKMf6rsKo7WAPscMJ7K6F","toolUseID":"toolu_018AKMf6rsKo7WAPscMJ7K6F","timestamp":"2026-02-21T08:49:27.712Z","uuid":"aeeef728-86d9-44e3-9e26-998ae191e2e8"}
{"parentUuid":"a693b280-daf5-4d23-aa0f-b91f3678414b","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018AKMf6rsKo7WAPscMJ7K6F","type":"tool_result","content":"The file /Users/skmabudalam/Documents/BugViper/api/routers/query.py has been updated successfully."}]},"uuid":"1dc8c787-2d09-486b-8579-87a94aa14a4c","timestamp":"2026-02-21T08:49:27.712Z","toolUseResult":{"filePath":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","oldString":"    try:\n        result = query_service.peek_file_lines(path, line, above, below)\n        if \"error\" in result:\n            raise HTTPException(status_code=404, detail=result[\"error\"])\n        return result\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Peek failed: {str(e)}\")","newString":"    above = min(above, 200)   # hard cap — prevents fetching entire file as \"context\"\n    below = min(below, 200)\n    if line < 1:\n        raise HTTPException(status_code=400, detail=\"line must be >= 1\")\n    try:\n        result = query_service.peek_file_lines(path, line, above, below)\n        if \"error\" in result:\n            raise HTTPException(status_code=404, detail=result[\"error\"])\n        return result\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Peek failed: {str(e)}\")","originalFile":"\"\"\"\nCode query endpoints - Advanced implementation with Neo4j integration.\n\"\"\"\n\nfrom fastapi import APIRouter, HTTPException, Query, Depends\nfrom pydantic import BaseModel\nfrom typing import Dict, Any, List\n\nfrom db.client import Neo4jClient\nfrom db.queries import CodeQueryService\nfrom api.dependencies import get_neo4j_client\nfrom api.services.code_search import CodeFinder\n\nrouter = APIRouter()\n\n\ndef get_query_service(db: Neo4jClient = Depends(get_neo4j_client)) -> CodeQueryService:\n    \"\"\"Dependency to get query service.\"\"\"\n    return CodeQueryService(db)\n\n\ndef get_code_finder(db: Neo4jClient = Depends(get_neo4j_client)) -> CodeFinder:\n    \"\"\"Dependency to get code finder.\"\"\"\n    return CodeFinder(db)\n\n\n@router.get(\"/search\")\nasync def search_code(\n    query: str = Query(..., description=\"Search term — any identifier, snippet, or keyword\"),\n    limit: int = Query(30, description=\"Maximum results to return\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Unified code search.\n\n    Three-tier strategy:\n    1. Fulltext index on symbols (name, docstring, source_code)\n    2. Name CONTAINS fallback (uses primary extracted identifier)\n    3. File content line search (file_content_search / source_code CONTAINS)\n\n    Results include type ('function' | 'class' | 'variable' | 'line'),\n    name, path, line_number, and score. Symbol results come first\n    (higher score), file-content line matches follow.\n    \"\"\"\n    if len(query) > 500:\n        raise HTTPException(status_code=400, detail=\"Query too long (max 500 characters)\")\n    try:\n        results = query_service.search_code(query)\n        if limit:\n            results = results[:limit]\n        return {\n            \"results\": results,\n            \"total\": len(results),\n            \"query\": query,\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")\n\n\n@router.get(\"/method-usages\")\nasync def find_method_usages(\n    method_name: str = Query(..., description=\"Name of the method to find usages for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all usages of a specific method.\n    \"\"\"\n    try:\n        usages = query_service.find_method_usages(method_name)\n        return usages\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find method usages: {str(e)}\")\n\n\n@router.get(\"/find_usages\")\nasync def find_usages(\n    symbol_name: str = Query(..., description=\"Symbol name to find usages for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all usages of a specific symbol (alias for method-usages).\n    \"\"\"\n    try:\n        usages = query_service.find_method_usages(symbol_name)\n        return usages\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find usages: {str(e)}\")\n\n\n@router.get(\"/find_callers\")\nasync def find_callers(\n    symbol_name: str = Query(..., description=\"Symbol name to find callers for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all methods/functions that call a specific symbol.\n    \"\"\"\n    try:\n        callers = query_service.find_callers(symbol_name)\n        return {\n            \"callers\": callers,\n            \"symbol\": symbol_name,\n            \"total\": len(callers)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find callers: {str(e)}\")\n\n\n@router.get(\"/class_hierarchy\")\nasync def get_class_hierarchy(\n    class_name: str = Query(..., description=\"Name of the class to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get class hierarchy (inheritance tree).\n    \"\"\"\n    try:\n        hierarchy = query_service.get_class_hierarchy(class_name)\n        return hierarchy\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get class hierarchy: {str(e)}\")\n\n\n@router.get(\"/class-hierarchy\")\nasync def get_class_hierarchy_alt(\n    class_name: str = Query(..., description=\"Name of the class to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get class hierarchy (inheritance tree) - alternative endpoint.\n    \"\"\"\n    try:\n        hierarchy = query_service.get_class_hierarchy(class_name)\n        return hierarchy\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get class hierarchy: {str(e)}\")\n\n\n@router.get(\"/file-structure\")\nasync def analyze_file_structure(\n    file_id: str = Query(..., description=\"File ID to analyze\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze the structure of a specific file.\n    \"\"\"\n    try:\n        structure = query_service.get_file_structure(file_id)\n        return structure\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to analyze file structure: {str(e)}\")\n\n\n@router.get(\"/change_impact\")\nasync def analyze_change_impact(\n    symbol_name: str = Query(..., description=\"Symbol to analyze impact for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze the impact of changing a specific symbol.\n    \"\"\"\n    try:\n        # Get all usages of the symbol to understand impact\n        usages = query_service.find_method_usages(symbol_name)\n        callers = query_service.find_callers(symbol_name)\n        \n        return {\n            \"symbol\": symbol_name,\n            \"usages\": usages,\n            \"callers\": callers,\n            \"impact_level\": \"high\" if len(callers) > 5 else \"medium\" if len(callers) > 0 else \"low\"\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to analyze change impact: {str(e)}\")\n\n\n@router.get(\"/relationships\")\nasync def get_code_relationships(\n    symbol_name: str = Query(..., description=\"Symbol to find relationships for\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get code relationship analysis for a symbol.\n    \"\"\"\n    try:\n        # Get comprehensive relationship data\n        usages = query_service.find_method_usages(symbol_name)\n        callers = query_service.find_callers(symbol_name)\n        \n        return {\n            \"symbol\": symbol_name,\n            \"relationships\": {\n                \"usages\": usages,\n                \"callers\": callers,\n                \"usage_count\": len(usages.get('usages', [])),\n                \"caller_count\": len(callers)\n            }\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get code relationships: {str(e)}\")\n\n\n@router.get(\"/metrics\")\nasync def get_code_metrics(\n    repo_id: str = Query(None, description=\"Repository ID for repo-specific metrics\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get code metrics and statistics.\n    \"\"\"\n    try:\n        if repo_id:\n            # Get repository-specific stats\n            stats = query_service.get_repository_stats(repo_id)\n            return {\n                \"repository_id\": repo_id,\n                \"metrics\": stats\n            }\n        else:\n            # Get global graph stats\n            stats = query_service.get_graph_stats()\n            return {\n                \"global_metrics\": stats\n            }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get code metrics: {str(e)}\")\n\n\n@router.get(\"/stats\")\nasync def get_graph_stats(\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get overall graph statistics.\n    \"\"\"\n    try:\n        stats = query_service.get_graph_stats()\n        return stats\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to get graph stats: {str(e)}\")\n\n\n@router.get(\"/symbol/{qualified_name}\")\nasync def get_symbol_by_qualified_name(\n    qualified_name: str,\n    repo_id: str = Query(..., description=\"Repository ID\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get symbol information by its qualified name.\n    \"\"\"\n    try:\n        symbol = query_service.find_symbol_by_qualified_name(qualified_name, repo_id)\n        if not symbol:\n            raise HTTPException(status_code=404, detail=\"Symbol not found\")\n        return symbol\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to find symbol: {str(e)}\")\n\n\n# =========================================================================\n# CodeFinder Tool Integration Endpoints\n# =========================================================================\n\n@router.get(\"/code-finder/function\")\nasync def find_function_by_name(\n    name: str = Query(..., description=\"Function name to search for\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_function_name(name, fuzzy)\n        return {\n            \"function_name\": name,\n            \"fuzzy_search\": fuzzy,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/class\")\nasync def find_class_by_name(\n    name: str = Query(..., description=\"Class name to search for\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find classes by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_class_name(name, fuzzy)\n        return {\n            \"class_name\": name,\n            \"fuzzy_search\": fuzzy,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Class search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/variable\")\nasync def find_variable_by_name(\n    name: str = Query(..., description=\"Variable name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find variables by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_variable_name(name)\n        return {\n            \"variable_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Variable search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/content\")\nasync def find_by_content(\n    query: str = Query(..., description=\"Content search term\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find code by content matching using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_content(query)\n        return {\n            \"search_query\": query,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Content search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/module\")\nasync def find_module_by_name(\n    name: str = Query(..., description=\"Module name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find modules by name using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_by_module_name(name)\n        return {\n            \"module_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Module search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/imports\")\nasync def find_imports(\n    name: str = Query(..., description=\"Import name to search for\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find import statements using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.find_imports(name)\n        return {\n            \"import_name\": name,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Import search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/related\")\nasync def find_related_code(\n    query: str = Query(..., description=\"Search query for related code\"),\n    fuzzy: bool = Query(False, description=\"Enable fuzzy search\"),\n    edit_distance: int = Query(2, description=\"Edit distance for fuzzy search\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find code related to a query using multiple search strategies.\n    \"\"\"\n    try:\n        results = code_finder.find_related_code(query, fuzzy, edit_distance)\n        return {\n            \"search_query\": query,\n            \"fuzzy_search\": fuzzy,\n            \"edit_distance\": edit_distance,\n            **results\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Related code search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/function/arguments\")\nasync def find_functions_by_argument(\n    argument_name: str = Query(..., description=\"Argument name to search for\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions that take a specific argument.\n    \"\"\"\n    try:\n        results = code_finder.find_functions_by_argument(argument_name, path)\n        return {\n            \"argument_name\": argument_name,\n            \"path_filter\": path,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function argument search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/function/decorator\")\nasync def find_functions_by_decorator(\n    decorator_name: str = Query(..., description=\"Decorator name to search for\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find functions that have a specific decorator.\n    \"\"\"\n    try:\n        results = code_finder.find_functions_by_decorator(decorator_name, path)\n        return {\n            \"decorator_name\": decorator_name,\n            \"path_filter\": path,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Function decorator search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/complexity\")\nasync def get_cyclomatic_complexity(\n    function_name: str = Query(..., description=\"Function name to analyze\"),\n    path: str = Query(None, description=\"Optional file path to filter by\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get cyclomatic complexity of a function.\n    \"\"\"\n    try:\n        result = code_finder.get_cyclomatic_complexity(function_name, path)\n        if not result:\n            raise HTTPException(status_code=404, detail=\"Function not found\")\n        return {\n            \"function_name\": function_name,\n            \"path_filter\": path,\n            \"complexity\": result\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complexity analysis failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/complexity/top\")\nasync def find_most_complex_functions(\n    limit: int = Query(10, description=\"Number of results to return\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find the most complex functions by cyclomatic complexity.\n    \"\"\"\n    try:\n        results = code_finder.find_most_complex_functions(limit)\n        return {\n            \"limit\": limit,\n            \"results\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Complex function search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/line\")\nasync def find_by_line(\n    query: str = Query(..., description=\"Search term to find in file content\"),\n    limit: int = Query(50, description=\"Maximum number of line matches to return\"),\n    query_service: CodeQueryService = Depends(get_query_service),\n) -> Dict[str, Any]:\n    \"\"\"\n    Search raw file content line-by-line.\n    Uses file_content_search fulltext index (falls back to CONTAINS).\n    Returns path + line_number + match_line for each hit — no source dumps.\n    Pair with /code-finder/peek to view context around a hit.\n    \"\"\"\n    if len(query) > 500:\n        raise HTTPException(status_code=400, detail=\"Query too long (max 500 characters)\")\n    limit = min(limit, 100)  # hard cap\n    try:\n        results = query_service.search_file_content(query, limit)\n        return {\n            \"query\": query,\n            \"results\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Line search failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/peek\")\nasync def peek_file_lines(\n    path: str = Query(..., description=\"Absolute file path (as stored in graph)\"),\n    line: int = Query(..., description=\"Anchor line number (1-indexed)\"),\n    above: int = Query(10, description=\"Lines to show above the anchor\"),\n    below: int = Query(10, description=\"Lines to show below the anchor\"),\n    query_service: CodeQueryService = Depends(get_query_service),\n) -> Dict[str, Any]:\n    \"\"\"\n    Return a window of lines around a given line in a file.\n    The anchor line is flagged with is_anchor=true.\n    Use above/below to control the context window size.\n    \"\"\"\n    try:\n        result = query_service.peek_file_lines(path, line, above, below)\n        if \"error\" in result:\n            raise HTTPException(status_code=404, detail=result[\"error\"])\n        return result\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Peek failed: {str(e)}\")\n\n\n@router.get(\"/code-finder/relationships\")\nasync def analyze_code_relationships(\n    query_type: str = Query(..., description=\"Type of relationship query\"),\n    target: str = Query(..., description=\"Target symbol for analysis\"),\n    context: str = Query(None, description=\"Additional context for the query\"),\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    Analyze code relationships using the CodeFinder's relationship query system.\n    \n    Supported query types:\n    - find_callers: Find all functions that call the target function\n    - find_callees: Find all functions called by the target function\n    - find_importers: Find all files that import the target module\n    - who_modifies: Find what functions modify a target variable\n    - class_hierarchy: Find inheritance relationships for a class\n    - call_chain: Find call paths between functions (format: 'start->end')\n    - module_deps: Find module dependencies\n    - variable_scope: Find variable usage across scopes\n    \"\"\"\n    try:\n        results = code_finder.execute_relationship_query(query_type, target, context)\n        return results\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Relationship analysis failed: {str(e)}\")\n\n\n@router.get(\"/repositories/indexed\")\nasync def list_indexed_repositories(\n    code_finder: CodeFinder = Depends(get_code_finder)\n) -> Dict[str, Any]:\n    \"\"\"\n    List all indexed repositories using the CodeFinder tool.\n    \"\"\"\n    try:\n        results = code_finder.list_indexed_repositories()\n        return {\n            \"repositories\": results,\n            \"total\": len(results)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Failed to list repositories: {str(e)}\")\n\n\n\n@router.get(\"/language/{language}/symbols\")\nasync def get_language_symbols(\n    language: str,\n    symbol_type: str = Query(..., description=\"Symbol type: function, class, variable, etc.\"),\n    limit: int = Query(50, description=\"Maximum number of results\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get all symbols of a specific type for a given language.\n    \n    Supported symbol types:\n    - function: All functions\n    - class: All classes  \n    - variable: All variables\n    - module: All modules\n    - file: All files\n    \"\"\"\n    try:\n        # Use Neo4j to query symbols by type and language\n        if symbol_type.lower() == \"function\":\n            query = f\"\"\"\n                MATCH (n:Function)\n                OPTIONAL MATCH (f:File)-[:CONTAINS]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.docstring as docstring, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"class\":\n            query = f\"\"\"\n                MATCH (n:Class)\n                OPTIONAL MATCH (f:File)-[:CONTAINS]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.docstring as docstring, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"variable\":\n            query = f\"\"\"\n                MATCH (n:Variable)\n                OPTIONAL MATCH (f:File)-[:CONTAINS*]->(n)\n                WHERE f.language = $language OR f.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.line_number as line_number,\n                       n.value as value, n.context as context, n.is_dependency as is_dependency,\n                       f.language as file_language\n                ORDER BY n.is_dependency ASC, n.name\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"file\":\n            query = f\"\"\"\n                MATCH (n:File)\n                WHERE n.language = $language OR n.extension IN ['.{language.lower()}', '.{language[:2].lower()}']\n                RETURN n.name as name, n.path as path, n.relative_path as relative_path,\n                       n.language as language, n.extension as extension,\n                       n.is_dependency as is_dependency\n                ORDER BY n.is_dependency ASC, n.path\n                LIMIT $limit\n            \"\"\"\n        elif symbol_type.lower() == \"module\":\n            query = f\"\"\"\n                MATCH (n:Module)\n                WHERE n.lang = $language\n                RETURN n.name as name, n.lang as language,\n                       n.full_import_name as full_import_name\n                ORDER BY n.name\n                LIMIT $limit\n            \"\"\"\n        else:\n            raise HTTPException(status_code=400, detail=f\"Unsupported symbol type: {symbol_type}\")\n        \n        records, _, _ = query_service.db.run_query(query, {\"language\": language, \"limit\": limit})\n        \n        return {\n            \"language\": language,\n            \"symbol_type\": symbol_type,\n            \"results\": [dict(record) for record in records],\n            \"total\": len(records),\n            \"limit\": limit\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Language symbol query failed: {str(e)}\")\n\n\n@router.get(\"/language/stats\")\nasync def get_language_statistics(\n    language: str = Query(None, description=\"Optional language filter\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get statistics about programming languages in the codebase.\n    \"\"\"\n    try:\n        if language:\n            # Get stats for specific language\n            query = \"\"\"\n                MATCH (f:File)\n                WHERE f.language = $language OR f.extension IN ['.{}'.format($language.lower()), '.{}'.format($language[:2].lower())]\n                OPTIONAL MATCH (f)-[:CONTAINS]->(func:Function)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(cls:Class)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(var:Variable)\n                RETURN \n                    count(DISTINCT f) as file_count,\n                    count(DISTINCT func) as function_count,\n                    count(DISTINCT cls) as class_count,\n                    count(DISTINCT var) as variable_count\n            \"\"\"\n            records, _, _ = query_service.db.run_query(query, {\"language\": language})\n            result = dict(records[0]) if records else {}\n            result[\"language\"] = language\n            return result\n        else:\n            # Get stats for all languages\n            query = \"\"\"\n                MATCH (f:File)\n                WHERE f.language IS NOT NULL\n                OPTIONAL MATCH (f)-[:CONTAINS]->(func:Function)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(cls:Class)\n                OPTIONAL MATCH (f)-[:CONTAINS]->(var:Variable)\n                RETURN \n                    f.language as language,\n                    count(DISTINCT f) as file_count,\n                    count(DISTINCT func) as function_count,\n                    count(DISTINCT cls) as class_count,\n                    count(DISTINCT var) as variable_count\n                ORDER BY file_count DESC\n            \"\"\"\n            records, _, _ = query_service.db.run_query(query)\n            return {\n                \"languages\": [dict(record) for record in records],\n                \"total_languages\": len(records)\n            }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Language statistics query failed: {str(e)}\")\n\n\n# --- Code Review / Diff Context Endpoints ---\n\n\n@router.get(\"/symbols-at-lines\")\nasync def get_symbols_at_lines(\n    file_path: str = Query(..., description=\"Absolute file path\"),\n    start_line: int = Query(..., description=\"Start line number\"),\n    end_line: int = Query(..., description=\"End line number\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all symbols (functions, classes, variables) overlapping a line range.\n    Useful for mapping diff hunks to affected code.\n    \"\"\"\n    try:\n        results = query_service.get_symbols_at_lines(file_path, start_line, end_line)\n        return {\n            \"file_path\": file_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n            \"symbols\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol lookup failed: {str(e)}\")\n\n\n@router.get(\"/symbols-at-lines-relative\")\nasync def get_symbols_at_lines_relative(\n    repo_id: str = Query(..., description=\"Repository ID (e.g. owner/repo)\"),\n    file_path: str = Query(..., description=\"Repo-relative file path (e.g. src/main.py)\"),\n    start_line: int = Query(..., description=\"Start line number\"),\n    end_line: int = Query(..., description=\"End line number\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Find all symbols overlapping a line range using repo-relative path.\n    \"\"\"\n    try:\n        results = query_service.get_symbols_at_lines_by_relative_path(\n            repo_id, file_path, start_line, end_line\n        )\n        return {\n            \"repo_id\": repo_id,\n            \"file_path\": file_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n            \"symbols\": results,\n            \"total\": len(results),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Symbol lookup failed: {str(e)}\")\n\n\nclass FileChange(BaseModel):\n    file_path: str\n    start_line: int = 1\n    end_line: int = 999999\n\n\nclass DiffContextRequest(BaseModel):\n    repo_id: str\n    changes: List[FileChange]\n\n\n@router.post(\"/diff-context\")\nasync def get_diff_context(\n    request: DiffContextRequest,\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Build full RAG context for a code diff.\n\n    Given a repository and a list of file changes (path + line ranges),\n    returns affected symbols with source code, their callers, class hierarchy,\n    and full file sources. Designed for AI-powered code review.\n\n    Example request:\n    ```json\n    {\n        \"repo_id\": \"owner/repo\",\n        \"changes\": [\n            {\"file_path\": \"src/main.py\", \"start_line\": 10, \"end_line\": 30},\n            {\"file_path\": \"src/utils.py\", \"start_line\": 1, \"end_line\": 50}\n        ]\n    }\n    ```\n    \"\"\"\n    try:\n        changes_dicts = [c.model_dump() for c in request.changes]\n        result = query_service.get_diff_context(request.repo_id, changes_dicts)\n        return result\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Diff context failed: {str(e)}\")\n\n\n@router.get(\"/file-source\")\nasync def get_file_source(\n    repo_id: str = Query(..., description=\"Repository ID\"),\n    file_path: str = Query(..., description=\"Repo-relative file path\"),\n    query_service: CodeQueryService = Depends(get_query_service)\n) -> Dict[str, Any]:\n    \"\"\"\n    Get the full source code of a file from the graph.\n    \"\"\"\n    try:\n        query = \"\"\"\n        MATCH (f:File)\n        WHERE f.relative_path = $relative_path AND f.path CONTAINS $repo_id\n        RETURN f.source_code as source_code, f.relative_path as path,\n               f.language as language, f.lines_count as lines_count\n        LIMIT 1\n        \"\"\"\n        records, _, _ = query_service.db.run_query(query, {\n            \"relative_path\": file_path,\n            \"repo_id\": repo_id,\n        })\n        if not records:\n            raise HTTPException(status_code=404, detail=\"File not found\")\n        record = records[0]\n        return {\n            \"file_path\": record.get(\"path\"),\n            \"language\": record.get(\"language\"),\n            \"lines_count\": record.get(\"lines_count\"),\n            \"source_code\": record.get(\"source_code\"),\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"File source retrieval failed: {str(e)}\")\n","structuredPatch":[{"oldStart":528,"oldLines":6,"newStart":528,"newLines":10,"lines":["     The anchor line is flagged with is_anchor=true.","     Use above/below to control the context window size.","     \"\"\"","+    above = min(above, 200)   # hard cap — prevents fetching entire file as \"context\"","+    below = min(below, 200)","+    if line < 1:","+        raise HTTPException(status_code=400, detail=\"line must be >= 1\")","     try:","         result = query_service.peek_file_lines(path, line, above, below)","         if \"error\" in result:"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"a693b280-daf5-4d23-aa0f-b91f3678414b"}
{"parentUuid":"1dc8c787-2d09-486b-8579-87a94aa14a4c","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01T5guprCuPDAPhZfiMbk2Gq","type":"message","role":"assistant","content":[{"type":"text","text":"Now fix the biggest performance problem — rewrite `search_file_content` to do the line scan server-side in Cypher (no more fetching full `source_code` blobs to Python), and add the size guard to `peek_file_lines`:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":432,"cache_read_input_tokens":144890,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":432},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvgdKxX9fpTWWxuHaUb","type":"assistant","uuid":"bd7bfc5f-5b96-455c-bb10-e5b25fe0ec5e","timestamp":"2026-02-21T08:49:32.401Z"}
{"parentUuid":"bd7bfc5f-5b96-455c-bb10-e5b25fe0ec5e","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01T5guprCuPDAPhZfiMbk2Gq","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01L4VkFh91XNwjK49ju7xDxP","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/db/queries.py","offset":463,"limit":75},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":432,"cache_read_input_tokens":144890,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":432},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvgdKxX9fpTWWxuHaUb","type":"assistant","uuid":"ea04d5df-cf5c-4060-a767-896e1472ef33","timestamp":"2026-02-21T08:49:32.937Z"}
{"parentUuid":"ea04d5df-cf5c-4060-a767-896e1472ef33","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01L4VkFh91XNwjK49ju7xDxP","toolUseID":"toolu_01L4VkFh91XNwjK49ju7xDxP","timestamp":"2026-02-21T08:49:33.110Z","uuid":"c7b23be3-545d-4a5f-8cb6-6a69e5b7fee4"}
{"parentUuid":"ea04d5df-cf5c-4060-a767-896e1472ef33","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01L4VkFh91XNwjK49ju7xDxP","type":"tool_result","content":"   463→    def search_file_content(self, search_term: str, limit: int = 50) -> List[Dict[str, Any]]:\n   464→        \"\"\"\n   465→        Search file source code line by line.\n   466→        Uses file_content_search fulltext index to find candidate files,\n   467→        then scans lines in Python to find the exact matching lines.\n   468→        \"\"\"\n   469→        escaped_term = self._escape_lucene_query(search_term)\n   470→        file_records: List[Dict[str, Any]] = []\n   471→\n   472→        try:\n   473→            ft_query = \"\"\"\n   474→            CALL db.index.fulltext.queryNodes('file_content_search', $search_term) YIELD node, score\n   475→            WHERE node.source_code IS NOT NULL\n   476→            RETURN node.path as path, node.source_code as source_code, score\n   477→            ORDER BY score DESC\n   478→            LIMIT 20\n   479→            \"\"\"\n   480→            records, _, _ = self.db.run_query(ft_query, {\"search_term\": escaped_term})\n   481→            file_records = [dict(r) for r in records]\n   482→        except Exception as e:\n   483→            logger.warning(\"file_content_search index failed, falling back to CONTAINS: %s\", e)\n   484→\n   485→        if not file_records:\n   486→            fallback = \"\"\"\n   487→            MATCH (f:File)\n   488→            WHERE f.source_code CONTAINS $search_term\n   489→            RETURN f.path as path, f.source_code as source_code, 1.0 as score\n   490→            LIMIT 20\n   491→            \"\"\"\n   492→            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})\n   493→            file_records = [dict(r) for r in records]\n   494→\n   495→        results: List[Dict[str, Any]] = []\n   496→        term_lower = search_term.lower()\n   497→        for rec in file_records:\n   498→            path = rec.get(\"path\")\n   499→            source = rec.get(\"source_code\")\n   500→            if not path or not source:\n   501→                continue\n   502→            for i, line in enumerate(source.split(\"\\n\")):\n   503→                if search_term in line or term_lower in line.lower():\n   504→                    results.append({\n   505→                        \"path\": path,\n   506→                        \"line_number\": i + 1,\n   507→                        \"match_line\": line.rstrip(),\n   508→                    })\n   509→                    if len(results) >= limit:\n   510→                        return results\n   511→        return results\n   512→\n   513→    def peek_file_lines(\n   514→        self,\n   515→        path: str,\n   516→        line: int,\n   517→        above: int = 10,\n   518→        below: int = 10,\n   519→    ) -> Dict[str, Any]:\n   520→        \"\"\"\n   521→        Return a window of lines around `line` in the given file.\n   522→        Lines are 1-indexed. The anchor line is flagged with is_anchor=True.\n   523→        \"\"\"\n   524→        query = \"\"\"\n   525→        MATCH (f:File {path: $path})\n   526→        RETURN f.source_code as source_code\n   527→        LIMIT 1\n   528→        \"\"\"\n   529→        records, _, _ = self.db.run_query(query, {\"path\": path})\n   530→        if not records or not records[0].get(\"source_code\"):\n   531→            return {\"error\": \"File not found\", \"path\": path}\n   532→\n   533→        lines = records[0][\"source_code\"].split(\"\\n\")\n   534→        total = len(lines)\n   535→        start = max(0, line - above - 1)   # 0-indexed inclusive\n   536→        end = min(total, line + below)       # 0-indexed exclusive\n   537→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"636046c2-522b-4d26-a112-20bfd390df59","timestamp":"2026-02-21T08:49:33.109Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/db/queries.py","content":"    def search_file_content(self, search_term: str, limit: int = 50) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search file source code line by line.\n        Uses file_content_search fulltext index to find candidate files,\n        then scans lines in Python to find the exact matching lines.\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n        file_records: List[Dict[str, Any]] = []\n\n        try:\n            ft_query = \"\"\"\n            CALL db.index.fulltext.queryNodes('file_content_search', $search_term) YIELD node, score\n            WHERE node.source_code IS NOT NULL\n            RETURN node.path as path, node.source_code as source_code, score\n            ORDER BY score DESC\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(ft_query, {\"search_term\": escaped_term})\n            file_records = [dict(r) for r in records]\n        except Exception as e:\n            logger.warning(\"file_content_search index failed, falling back to CONTAINS: %s\", e)\n\n        if not file_records:\n            fallback = \"\"\"\n            MATCH (f:File)\n            WHERE f.source_code CONTAINS $search_term\n            RETURN f.path as path, f.source_code as source_code, 1.0 as score\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})\n            file_records = [dict(r) for r in records]\n\n        results: List[Dict[str, Any]] = []\n        term_lower = search_term.lower()\n        for rec in file_records:\n            path = rec.get(\"path\")\n            source = rec.get(\"source_code\")\n            if not path or not source:\n                continue\n            for i, line in enumerate(source.split(\"\\n\")):\n                if search_term in line or term_lower in line.lower():\n                    results.append({\n                        \"path\": path,\n                        \"line_number\": i + 1,\n                        \"match_line\": line.rstrip(),\n                    })\n                    if len(results) >= limit:\n                        return results\n        return results\n\n    def peek_file_lines(\n        self,\n        path: str,\n        line: int,\n        above: int = 10,\n        below: int = 10,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Return a window of lines around `line` in the given file.\n        Lines are 1-indexed. The anchor line is flagged with is_anchor=True.\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {path: $path})\n        RETURN f.source_code as source_code\n        LIMIT 1\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"path\": path})\n        if not records or not records[0].get(\"source_code\"):\n            return {\"error\": \"File not found\", \"path\": path}\n\n        lines = records[0][\"source_code\"].split(\"\\n\")\n        total = len(lines)\n        start = max(0, line - above - 1)   # 0-indexed inclusive\n        end = min(total, line + below)       # 0-indexed exclusive\n","numLines":75,"startLine":463,"totalLines":1834}},"sourceToolAssistantUUID":"ea04d5df-cf5c-4060-a767-896e1472ef33"}
{"parentUuid":"636046c2-522b-4d26-a112-20bfd390df59","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_015KeySp33eXXKP45FbnXeQi","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012Vfgrr8725ddEjPcy8XdtC","name":"Edit","input":{"replace_all":false,"file_path":"/Users/skmabudalam/Documents/BugViper/db/queries.py","old_string":"    def search_file_content(self, search_term: str, limit: int = 50) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search file source code line by line.\n        Uses file_content_search fulltext index to find candidate files,\n        then scans lines in Python to find the exact matching lines.\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n        file_records: List[Dict[str, Any]] = []\n\n        try:\n            ft_query = \"\"\"\n            CALL db.index.fulltext.queryNodes('file_content_search', $search_term) YIELD node, score\n            WHERE node.source_code IS NOT NULL\n            RETURN node.path as path, node.source_code as source_code, score\n            ORDER BY score DESC\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(ft_query, {\"search_term\": escaped_term})\n            file_records = [dict(r) for r in records]\n        except Exception as e:\n            logger.warning(\"file_content_search index failed, falling back to CONTAINS: %s\", e)\n\n        if not file_records:\n            fallback = \"\"\"\n            MATCH (f:File)\n            WHERE f.source_code CONTAINS $search_term\n            RETURN f.path as path, f.source_code as source_code, 1.0 as score\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})\n            file_records = [dict(r) for r in records]\n\n        results: List[Dict[str, Any]] = []\n        term_lower = search_term.lower()\n        for rec in file_records:\n            path = rec.get(\"path\")\n            source = rec.get(\"source_code\")\n            if not path or not source:\n                continue\n            for i, line in enumerate(source.split(\"\\n\")):\n                if search_term in line or term_lower in line.lower():\n                    results.append({\n                        \"path\": path,\n                        \"line_number\": i + 1,\n                        \"match_line\": line.rstrip(),\n                    })\n                    if len(results) >= limit:\n                        return results\n        return results\n\n    def peek_file_lines(\n        self,\n        path: str,\n        line: int,\n        above: int = 10,\n        below: int = 10,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Return a window of lines around `line` in the given file.\n        Lines are 1-indexed. The anchor line is flagged with is_anchor=True.\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {path: $path})\n        RETURN f.source_code as source_code\n        LIMIT 1\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"path\": path})\n        if not records or not records[0].get(\"source_code\"):\n            return {\"error\": \"File not found\", \"path\": path}","new_string":"    # Skip files larger than this (bytes) in content search — avoids scanning minified/generated files\n    _MAX_FILE_BYTES = 500_000\n\n    def search_file_content(self, search_term: str, limit: int = 50) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search file source code line by line — all scanning runs server-side in Cypher.\n\n        Tier A: file_content_search fulltext index → split + unwind + CONTAINS in Neo4j.\n        Tier B: source_code CONTAINS fallback (also server-side split/unwind).\n\n        Files larger than 500 KB are skipped to avoid exploding intermediate row counts.\n        Only matching lines are returned over the wire (not full source blobs).\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n        limit = min(limit, 200)\n\n        # Tier A — fulltext to locate candidate files, then server-side line scan\n        try:\n            ft_query = \"\"\"\n            CALL db.index.fulltext.queryNodes('file_content_search', $search_term) YIELD node, score\n            WHERE node.source_code IS NOT NULL\n              AND size(node.source_code) < $max_bytes\n            WITH node, score, split(node.source_code, '\\n') as lines\n            LIMIT 10\n            UNWIND range(0, size(lines) - 1) AS idx\n            WITH node.path AS path, lines[idx] AS line_content, idx + 1 AS line_number, score\n            WHERE toLower(line_content) CONTAINS toLower($raw_term)\n            RETURN path, line_number, line_content AS match_line\n            ORDER BY score DESC, path, line_number\n            LIMIT $limit\n            \"\"\"\n            records, _, _ = self.db.run_query(ft_query, {\n                \"search_term\": escaped_term,\n                \"raw_term\": search_term,\n                \"max_bytes\": self._MAX_FILE_BYTES,\n                \"limit\": limit,\n            })\n            results = [\n                {\n                    \"path\": r[\"path\"],\n                    \"line_number\": r[\"line_number\"],\n                    \"match_line\": r[\"match_line\"].rstrip() if r[\"match_line\"] else \"\",\n                }\n                for r in records\n            ]\n            if results:\n                return results\n        except Exception as e:\n            logger.warning(\"file_content_search fulltext failed: %s\", e)\n\n        # Tier B — CONTAINS on source_code, server-side split/unwind (no Python scanning)\n        fallback_query = \"\"\"\n        MATCH (f:File)\n        WHERE f.source_code IS NOT NULL\n          AND f.source_code CONTAINS $raw_term\n          AND size(f.source_code) < $max_bytes\n        WITH f, split(f.source_code, '\\n') AS lines\n        LIMIT 5\n        UNWIND range(0, size(lines) - 1) AS idx\n        WITH f.path AS path, lines[idx] AS line_content, idx + 1 AS line_number\n        WHERE line_content CONTAINS $raw_term\n        RETURN path, line_number, line_content AS match_line\n        ORDER BY path, line_number\n        LIMIT $limit\n        \"\"\"\n        records, _, _ = self.db.run_query(fallback_query, {\n            \"raw_term\": search_term,\n            \"max_bytes\": self._MAX_FILE_BYTES,\n            \"limit\": limit,\n        })\n        return [\n            {\n                \"path\": r[\"path\"],\n                \"line_number\": r[\"line_number\"],\n                \"match_line\": r[\"match_line\"].rstrip() if r[\"match_line\"] else \"\",\n            }\n            for r in records\n        ]\n\n    def peek_file_lines(\n        self,\n        path: str,\n        line: int,\n        above: int = 10,\n        below: int = 10,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Return a window of lines around `line` in the given file.\n        Lines are 1-indexed. The anchor line is flagged with is_anchor=True.\n        Files > 2 MB are rejected to prevent memory spikes.\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {path: $path})\n        WHERE f.source_code IS NOT NULL AND size(f.source_code) < 2000000\n        RETURN f.source_code as source_code\n        LIMIT 1\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"path\": path})\n        if not records or not records[0].get(\"source_code\"):\n            return {\"error\": \"File not found or too large\", \"path\": path}"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1307,"cache_read_input_tokens":145322,"output_tokens":2049,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":1307,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLvh1jLgEjUH1SdyBf88","type":"assistant","uuid":"86beceea-f802-4e20-b45a-d02350470630","timestamp":"2026-02-21T08:49:56.901Z"}
{"parentUuid":"86beceea-f802-4e20-b45a-d02350470630","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Edit","command":"callback"},"parentToolUseID":"toolu_012Vfgrr8725ddEjPcy8XdtC","toolUseID":"toolu_012Vfgrr8725ddEjPcy8XdtC","timestamp":"2026-02-21T08:49:57.075Z","uuid":"a56251f7-397a-48da-955b-020dffdcc924"}
{"parentUuid":"86beceea-f802-4e20-b45a-d02350470630","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012Vfgrr8725ddEjPcy8XdtC","type":"tool_result","content":"The file /Users/skmabudalam/Documents/BugViper/db/queries.py has been updated successfully."}]},"uuid":"81d57366-b981-4842-9d74-e8d0131eb805","timestamp":"2026-02-21T08:49:57.075Z","toolUseResult":{"filePath":"/Users/skmabudalam/Documents/BugViper/db/queries.py","oldString":"    def search_file_content(self, search_term: str, limit: int = 50) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search file source code line by line.\n        Uses file_content_search fulltext index to find candidate files,\n        then scans lines in Python to find the exact matching lines.\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n        file_records: List[Dict[str, Any]] = []\n\n        try:\n            ft_query = \"\"\"\n            CALL db.index.fulltext.queryNodes('file_content_search', $search_term) YIELD node, score\n            WHERE node.source_code IS NOT NULL\n            RETURN node.path as path, node.source_code as source_code, score\n            ORDER BY score DESC\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(ft_query, {\"search_term\": escaped_term})\n            file_records = [dict(r) for r in records]\n        except Exception as e:\n            logger.warning(\"file_content_search index failed, falling back to CONTAINS: %s\", e)\n\n        if not file_records:\n            fallback = \"\"\"\n            MATCH (f:File)\n            WHERE f.source_code CONTAINS $search_term\n            RETURN f.path as path, f.source_code as source_code, 1.0 as score\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})\n            file_records = [dict(r) for r in records]\n\n        results: List[Dict[str, Any]] = []\n        term_lower = search_term.lower()\n        for rec in file_records:\n            path = rec.get(\"path\")\n            source = rec.get(\"source_code\")\n            if not path or not source:\n                continue\n            for i, line in enumerate(source.split(\"\\n\")):\n                if search_term in line or term_lower in line.lower():\n                    results.append({\n                        \"path\": path,\n                        \"line_number\": i + 1,\n                        \"match_line\": line.rstrip(),\n                    })\n                    if len(results) >= limit:\n                        return results\n        return results\n\n    def peek_file_lines(\n        self,\n        path: str,\n        line: int,\n        above: int = 10,\n        below: int = 10,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Return a window of lines around `line` in the given file.\n        Lines are 1-indexed. The anchor line is flagged with is_anchor=True.\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {path: $path})\n        RETURN f.source_code as source_code\n        LIMIT 1\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"path\": path})\n        if not records or not records[0].get(\"source_code\"):\n            return {\"error\": \"File not found\", \"path\": path}","newString":"    # Skip files larger than this (bytes) in content search — avoids scanning minified/generated files\n    _MAX_FILE_BYTES = 500_000\n\n    def search_file_content(self, search_term: str, limit: int = 50) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search file source code line by line — all scanning runs server-side in Cypher.\n\n        Tier A: file_content_search fulltext index → split + unwind + CONTAINS in Neo4j.\n        Tier B: source_code CONTAINS fallback (also server-side split/unwind).\n\n        Files larger than 500 KB are skipped to avoid exploding intermediate row counts.\n        Only matching lines are returned over the wire (not full source blobs).\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n        limit = min(limit, 200)\n\n        # Tier A — fulltext to locate candidate files, then server-side line scan\n        try:\n            ft_query = \"\"\"\n            CALL db.index.fulltext.queryNodes('file_content_search', $search_term) YIELD node, score\n            WHERE node.source_code IS NOT NULL\n              AND size(node.source_code) < $max_bytes\n            WITH node, score, split(node.source_code, '\\n') as lines\n            LIMIT 10\n            UNWIND range(0, size(lines) - 1) AS idx\n            WITH node.path AS path, lines[idx] AS line_content, idx + 1 AS line_number, score\n            WHERE toLower(line_content) CONTAINS toLower($raw_term)\n            RETURN path, line_number, line_content AS match_line\n            ORDER BY score DESC, path, line_number\n            LIMIT $limit\n            \"\"\"\n            records, _, _ = self.db.run_query(ft_query, {\n                \"search_term\": escaped_term,\n                \"raw_term\": search_term,\n                \"max_bytes\": self._MAX_FILE_BYTES,\n                \"limit\": limit,\n            })\n            results = [\n                {\n                    \"path\": r[\"path\"],\n                    \"line_number\": r[\"line_number\"],\n                    \"match_line\": r[\"match_line\"].rstrip() if r[\"match_line\"] else \"\",\n                }\n                for r in records\n            ]\n            if results:\n                return results\n        except Exception as e:\n            logger.warning(\"file_content_search fulltext failed: %s\", e)\n\n        # Tier B — CONTAINS on source_code, server-side split/unwind (no Python scanning)\n        fallback_query = \"\"\"\n        MATCH (f:File)\n        WHERE f.source_code IS NOT NULL\n          AND f.source_code CONTAINS $raw_term\n          AND size(f.source_code) < $max_bytes\n        WITH f, split(f.source_code, '\\n') AS lines\n        LIMIT 5\n        UNWIND range(0, size(lines) - 1) AS idx\n        WITH f.path AS path, lines[idx] AS line_content, idx + 1 AS line_number\n        WHERE line_content CONTAINS $raw_term\n        RETURN path, line_number, line_content AS match_line\n        ORDER BY path, line_number\n        LIMIT $limit\n        \"\"\"\n        records, _, _ = self.db.run_query(fallback_query, {\n            \"raw_term\": search_term,\n            \"max_bytes\": self._MAX_FILE_BYTES,\n            \"limit\": limit,\n        })\n        return [\n            {\n                \"path\": r[\"path\"],\n                \"line_number\": r[\"line_number\"],\n                \"match_line\": r[\"match_line\"].rstrip() if r[\"match_line\"] else \"\",\n            }\n            for r in records\n        ]\n\n    def peek_file_lines(\n        self,\n        path: str,\n        line: int,\n        above: int = 10,\n        below: int = 10,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Return a window of lines around `line` in the given file.\n        Lines are 1-indexed. The anchor line is flagged with is_anchor=True.\n        Files > 2 MB are rejected to prevent memory spikes.\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {path: $path})\n        WHERE f.source_code IS NOT NULL AND size(f.source_code) < 2000000\n        RETURN f.source_code as source_code\n        LIMIT 1\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"path\": path})\n        if not records or not records[0].get(\"source_code\"):\n            return {\"error\": \"File not found or too large\", \"path\": path}","originalFile":"\n\nfrom typing import Dict, List, Any, Optional\nimport re\nimport logging\n\nfrom .client import Neo4jClient\nfrom .schema import CYPHER_QUERIES\n\nlogger = logging.getLogger(__name__)\n\nclass CodeQueryService:\n    \"\"\"\n    Service for querying code elements from the Neo4j graph.\n    \n    Provides methods for:\n    - Finding method/function usages and callers\n    - Analyzing class hierarchies\n    - Searching code by name or content\n    - Reconstructing files from the graph\n    \"\"\"\n    \n    def __init__(self, client: Neo4jClient):\n        self.db = client\n    \n    # =========================================================================\n    # Graph Statistics\n    # =========================================================================\n    \n    def get_graph_stats(self) -> Dict[str, int]:\n        \"\"\"Get statistics about the code graph.\"\"\"\n        query = CYPHER_QUERIES[\"get_graph_stats\"]\n        records, _, _ = self.db.run_query(query)\n        \n        if records:\n            return dict(records[0])\n        return {}\n\n    def list_repositories(self) -> List[Dict[str, Any]]:\n        \"\"\"List all repositories in the database.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        OPTIONAL MATCH (r)-[:CONTAINS*]->(f:File)\n        RETURN r.id as id, r.name as name, r.owner as owner,\n               r.url as url, r.path as local_path,\n               r.last_commit_hash as last_commit,\n               r.created_at as created_at,\n               r.updated_at as updated_at,\n               count(DISTINCT f) as file_count\n        ORDER BY r.updated_at DESC, r.name\n        \"\"\"\n        records, _, _ = self.db.run_query(query)\n        \n        def convert_datetime(value):\n            \"\"\"Convert Neo4j DateTime to ISO string format.\"\"\"\n            if value is None:\n                return None\n            # Check if it's a Neo4j DateTime object\n            if hasattr(value, 'iso_format'):\n                return value.iso_format()\n            # If it's already a string or other type, return as is\n            return str(value) if value is not None else None\n        \n        return [\n            {\n                \"id\": record.get(\"id\"),\n                \"name\": record.get(\"name\"),\n                \"owner\": record.get(\"owner\"),\n                \"url\": record.get(\"url\"),\n                \"local_path\": record.get(\"local_path\"),\n                \"last_commit\": record.get(\"last_commit\"),\n                \"created_at\": convert_datetime(record.get(\"created_at\")),\n                \"updated_at\": convert_datetime(record.get(\"updated_at\")),\n                \"file_count\": record.get(\"file_count\") or 0\n            }\n            for record in records\n        ]\n\n    def delete_repository(self, repo_id: str) -> bool:\n        \"\"\"Delete a repository and all its associated data.\"\"\"\n        try:\n            query = \"\"\"\n            MATCH (r:Repository)\n            WHERE r.id = $repo_id OR r.repo = $repo_id\n            OPTIONAL MATCH (r)-[:CONTAINS*]->(n)\n            DETACH DELETE r, n\n            RETURN count(r) as deleted_count\n            \"\"\"\n            records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n            return records and records[0][\"deleted_count\"] > 0\n        except Exception as e:\n            logger.error(\"Error deleting repository %s: %s\", repo_id, e)\n            return False\n    \n    def get_repository_stats(self, repo_id: str) -> Dict[str, Any]:\n        \"\"\"Get statistics for a specific repository.\"\"\"\n        if not self.db.connected:\n            # Return mock stats\n            return {\n                \"files\": 25,\n                \"classes\": 12,\n                \"functions\": 89,\n                \"methods\": 156,\n                \"lines\": 3420,\n                \"imports\": 67,\n                \"languages\": [\"Python\", \"TypeScript\", \"JavaScript\"]\n            }\n            \n        query = CYPHER_QUERIES[\"get_repo_stats\"]\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        \n        if records:\n            record = records[0]\n            return {\n                \"files\": record[\"file_count\"],\n                \"classes\": record[\"class_count\"],\n                \"functions\": record[\"function_count\"],\n                \"methods\": record[\"method_count\"],\n                \"lines\": record[\"line_count\"],\n                \"imports\": record[\"import_count\"],\n                \"languages\": record[\"languages\"]\n            }\n        return {}\n    \n    # =========================================================================\n    # Method and Function Queries\n    # =========================================================================\n    \n    def find_method_usages(self, method_name: str) -> Dict[str, Any]:\n        \"\"\"Find all usages of a method by name.\"\"\"\n        query = CYPHER_QUERIES[\"find_method_usages\"]\n        records, _, _ = self.db.run_query(query, {\"method_name\": method_name})\n\n        results = []\n        for record in records:\n            # Convert Neo4j Node objects to dictionaries for JSON serialization\n            callers = []\n            for caller_dict in record[\"callers\"]:\n                if caller_dict and caller_dict.get(\"caller\"):\n                    callers.append({\n                        \"caller\": dict(caller_dict[\"caller\"]) if hasattr(caller_dict[\"caller\"], \"__iter__\") and not isinstance(caller_dict[\"caller\"], str) else {\"name\": str(caller_dict[\"caller\"])},\n                        \"line\": caller_dict.get(\"line\")\n                    })\n\n            references = []\n            for ref_dict in record[\"references\"]:\n                if ref_dict and ref_dict.get(\"line\"):\n                    references.append({\n                        \"line\": dict(ref_dict[\"line\"]) if hasattr(ref_dict[\"line\"], \"__iter__\") and not isinstance(ref_dict[\"line\"], str) else {\"line\": str(ref_dict[\"line\"])},\n                        \"col_start\": ref_dict.get(\"col_start\")\n                    })\n\n            results.append({\n                \"method\": dict(record[\"m\"]) if record[\"m\"] else None,\n                \"callers\": callers,\n                \"references\": references\n            })\n        return {\"usages\": results}\n    \n    def find_method_context(self, method_id: str) -> Dict[str, Any]:\n        \"\"\"Find the full context of a method (class, file, repo, user).\"\"\"\n        query = CYPHER_QUERIES[\"find_method_context\"]\n        records, _, _ = self.db.run_query(query, {\"method_id\": method_id})\n        \n        if records:\n            record = records[0]\n            return {\n                \"user\": record[\"user\"],\n                \"repo\": record[\"repo\"],\n                \"file\": record[\"file\"],\n                \"class\": record[\"class_name\"],\n                \"method\": record[\"method\"],\n                \"lines\": f\"{record['start_line']}-{record['end_line']}\"\n            }\n        return {}\n    \n    def find_callers(self, symbol_name: str) -> List[Dict[str, Any]]:\n        \"\"\"Find all methods/functions that call a specific symbol.\"\"\"\n        query = CYPHER_QUERIES[\"find_callers\"]\n        records, _, _ = self.db.run_query(query, {\"name\": symbol_name})\n        \n        return [\n            {\n                \"caller\": record[\"caller_name\"],\n                \"type\": record[\"caller_type\"],\n                \"file\": record[\"file_path\"],\n                \"line\": record[\"call_line\"]\n            }\n            for record in records\n        ]\n    \n    # =========================================================================\n    # Class Queries\n    # =========================================================================\n    \n    def get_class_hierarchy(self, class_name: str) -> Dict[str, Any]:\n        \"\"\"Get the inheritance hierarchy of a class.\"\"\"\n        query = CYPHER_QUERIES[\"get_class_hierarchy\"]\n        records, _, _ = self.db.run_query(query, {\"class_name\": class_name})\n        \n        if records:\n            record = records[0]\n            return {\n                \"class\": dict(record[\"c\"]) if record[\"c\"] else None,\n                \"ancestors\": [dict(n) for n in record[\"ancestors\"]] if record[\"ancestors\"] else [],\n                \"descendants\": [dict(n) for n in record[\"descendants\"]] if record[\"descendants\"] else []\n            }\n        return {}\n    \n    # =========================================================================\n    # File Queries\n    # =========================================================================\n    \n    def get_file_structure(self, file_id: str) -> Dict[str, Any]:\n        \"\"\"Get the structure of a file (classes, functions, imports).\"\"\"\n        query = CYPHER_QUERIES[\"get_file_structure\"]\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n        \n        if records:\n            record = records[0]\n            return {\n                \"file\": dict(record[\"f\"]) if record[\"f\"] else None,\n                \"classes\": record[\"classes\"],\n                \"functions\": [dict(f) for f in record[\"functions\"]] if record[\"functions\"] else [],\n                \"imports\": [dict(i) for i in record[\"imports\"]] if record[\"imports\"] else []\n            }\n        return {}\n    \n    def get_repo_overview(self, repo_id: str) -> Dict[str, Any]:\n        \"\"\"Get an overview of a repository.\"\"\"\n        if not self.db.connected:\n            # Return mock overview\n            return {\n                \"repo\": {\n                    \"id\": repo_id,\n                    \"name\": repo_id.split(\"/\")[-1] if \"/\" in repo_id else repo_id,\n                    \"owner\": repo_id.split(\"/\")[0] if \"/\" in repo_id else \"unknown\"\n                },\n                \"files\": 25,\n                \"classes\": 12,\n                \"functions\": 89,\n                \"languages\": [\"Python\", \"TypeScript\", \"JavaScript\"]\n            }\n            \n        query = CYPHER_QUERIES[\"get_repo_overview\"]\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        \n        if records:\n            record = records[0]\n            return {\n                \"repo\": record[\"repo\"],\n                \"files\": record[\"file_count\"],\n                \"classes\": record[\"class_count\"],\n                \"functions\": record[\"function_count\"],\n                \"languages\": record[\"languages\"]\n            }\n        return {}\n    \n    def get_repo_files(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all files in a repository.\"\"\"\n        query = CYPHER_QUERIES[\"get_repo_files\"]\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        \n        return [\n            {\n                \"file\": dict(record[\"f\"]) if record[\"f\"] else None,\n                \"language\": record[\"language\"],\n                \"lines_count\": record[\"lines_count\"]\n                \n            }\n            for record in records\n        ]\n    \n    # =========================================================================\n    # Search Operations\n    # =========================================================================\n    \n    # Python/JS keywords that should not be used as search identifiers\n    _CODE_KEYWORDS = frozenset({\n        'class', 'def', 'import', 'from', 'return', 'self', 'cls', 'None',\n        'True', 'False', 'and', 'or', 'not', 'in', 'is', 'if', 'else',\n        'elif', 'for', 'while', 'try', 'except', 'with', 'as', 'pass',\n        'break', 'continue', 'raise', 'yield', 'async', 'await', 'lambda',\n        'function', 'const', 'let', 'var', 'new', 'this', 'super',\n    })\n\n    def _extract_identifiers(self, query: str) -> List[str]:\n        \"\"\"Extract meaningful code identifiers from a raw query string.\"\"\"\n        tokens = re.findall(r'\\b[A-Za-z_][A-Za-z0-9_]{2,}\\b', query)\n        seen: set = set()\n        result = []\n        for t in tokens:\n            if t not in self._CODE_KEYWORDS and t not in seen:\n                seen.add(t)\n                result.append(t)\n        return result\n\n    def _escape_lucene_query(self, query: str) -> str:\n        \"\"\"\n        Build a safe Lucene query string.\n\n        Strategy:\n        - Simple identifier (word chars only) → phrase search  e.g. \"LoginRequest\"\n        - Complex query with special chars     → AND-keyword strategy\n          e.g. \"class GitHubRepo(BaseModel)\" → \"GitHubRepo\" AND \"BaseModel\"\n          This avoids Lucene parse errors while still matching meaningful tokens.\n        \"\"\"\n        query = query.strip()\n        if not query:\n            return '*'\n\n        # Simple identifier — use phrase search directly\n        if re.match(r'^[A-Za-z0-9_]+$', query):\n            return f'\"{query}\"'\n\n        # Complex query — extract identifiers and build AND search\n        identifiers = self._extract_identifiers(query)\n        if identifiers:\n            # Cap at 3 identifiers to keep the query lean\n            return ' AND '.join(f'\"{t}\"' for t in identifiers[:3])\n\n        # Pure symbols / numbers with no useful identifiers — wrap and hope for best\n        escaped = query.replace('\"', '\\\\\"')\n        return f'\"{escaped}\"'\n\n    def _name_contains_fallback(\n        self,\n        search_term: str,\n        limit: int = 20,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        CONTAINS fallback against node names.\n        Uses the primary identifier extracted from the search term so that\n        queries like 'class GitHubRepo(BaseModel)' still find 'GitHubRepo'.\n        \"\"\"\n        identifiers = self._extract_identifiers(search_term)\n        # Use the first (longest) identifier, falling back to raw term\n        name_term = max(identifiers, key=len) if identifiers else search_term\n\n        fallback = \"\"\"\n        MATCH (node)\n        WHERE (node:Function OR node:Class OR node:Variable)\n          AND node.name CONTAINS $name_term\n        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n        RETURN\n            CASE WHEN node:Function THEN 'function'\n                 WHEN node:Class THEN 'class'\n                 ELSE 'variable' END as type,\n            node.name as name,\n            coalesce(f.path, node.path) as path,\n            coalesce(node.line_number, 0) as line_number,\n            1.0 as score\n        ORDER BY node.name\n        LIMIT $limit\n        \"\"\"\n        records, _, _ = self.db.run_query(fallback, {\"name_term\": name_term, \"limit\": limit})\n        return [\n            {\n                \"type\": record[\"type\"],\n                \"name\": record[\"name\"],\n                \"path\": record[\"path\"],\n                \"line_number\": record[\"line_number\"],\n                \"score\": record[\"score\"],\n            }\n            for record in records\n        ]\n\n    def search_code(self, search_term: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search for code using a three-tier strategy:\n        1. code_search fulltext index (symbols: name, docstring, source_code)\n        2. Name CONTAINS fallback (uses primary extracted identifier)\n        3. File content line search (file_content_search / source_code CONTAINS)\n        Returns lean results: type, name, path, line_number, score.\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        # Tier 1 — fulltext symbol search\n        results: List[Dict[str, Any]] = []\n        try:\n            records, _, _ = self.db.run_query(\n                CYPHER_QUERIES[\"search_code\"], {\"search_term\": escaped_term}\n            )\n            results = [\n                {\n                    \"type\": record[\"type\"],\n                    \"name\": record[\"name\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"code_search fulltext failed: %s\", e)\n\n        # Tier 2 — name CONTAINS (works even when fulltext index misses)\n        if not results:\n            results = self._name_contains_fallback(search_term, limit=20)\n\n        # Tier 3 — file content line search (raw code snippets, declarations, etc.)\n        if not results:\n            file_hits = self.search_file_content(search_term, limit=20)\n            results = [\n                {\n                    \"type\": \"line\",\n                    \"name\": h[\"match_line\"].strip(),\n                    \"path\": h[\"path\"],\n                    \"line_number\": h[\"line_number\"],\n                    \"score\": 0.5,\n                }\n                for h in file_hits\n            ]\n\n        return results\n\n    def search_symbols(\n        self,\n        search_term: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search symbols (Function/Class/Variable) using fulltext index.\n        Falls back to name CONTAINS using the primary extracted identifier.\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n\n        results: List[Dict[str, Any]] = []\n        try:\n            records, _, _ = self.db.run_query(\n                CYPHER_QUERIES[\"search_symbols\"],\n                {\"search_term\": escaped_term, \"limit\": limit},\n            )\n            results = [\n                {\n                    \"name\": record[\"name\"],\n                    \"type\": record[\"type\"],\n                    \"path\": record[\"path\"],\n                    \"line_number\": record[\"line_number\"],\n                    \"score\": record[\"score\"],\n                }\n                for record in records\n            ]\n        except Exception as e:\n            logger.warning(\"symbol fulltext search failed: %s\", e)\n\n        if not results:\n            raw = self._name_contains_fallback(search_term, limit=limit)\n            # _name_contains_fallback returns same shape, just reorder keys\n            results = [\n                {\n                    \"name\": r[\"name\"],\n                    \"type\": r[\"type\"],\n                    \"path\": r[\"path\"],\n                    \"line_number\": r[\"line_number\"],\n                    \"score\": r[\"score\"],\n                }\n                for r in raw\n            ]\n\n        return results\n\n    def search_file_content(self, search_term: str, limit: int = 50) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search file source code line by line.\n        Uses file_content_search fulltext index to find candidate files,\n        then scans lines in Python to find the exact matching lines.\n        \"\"\"\n        escaped_term = self._escape_lucene_query(search_term)\n        file_records: List[Dict[str, Any]] = []\n\n        try:\n            ft_query = \"\"\"\n            CALL db.index.fulltext.queryNodes('file_content_search', $search_term) YIELD node, score\n            WHERE node.source_code IS NOT NULL\n            RETURN node.path as path, node.source_code as source_code, score\n            ORDER BY score DESC\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(ft_query, {\"search_term\": escaped_term})\n            file_records = [dict(r) for r in records]\n        except Exception as e:\n            logger.warning(\"file_content_search index failed, falling back to CONTAINS: %s\", e)\n\n        if not file_records:\n            fallback = \"\"\"\n            MATCH (f:File)\n            WHERE f.source_code CONTAINS $search_term\n            RETURN f.path as path, f.source_code as source_code, 1.0 as score\n            LIMIT 20\n            \"\"\"\n            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})\n            file_records = [dict(r) for r in records]\n\n        results: List[Dict[str, Any]] = []\n        term_lower = search_term.lower()\n        for rec in file_records:\n            path = rec.get(\"path\")\n            source = rec.get(\"source_code\")\n            if not path or not source:\n                continue\n            for i, line in enumerate(source.split(\"\\n\")):\n                if search_term in line or term_lower in line.lower():\n                    results.append({\n                        \"path\": path,\n                        \"line_number\": i + 1,\n                        \"match_line\": line.rstrip(),\n                    })\n                    if len(results) >= limit:\n                        return results\n        return results\n\n    def peek_file_lines(\n        self,\n        path: str,\n        line: int,\n        above: int = 10,\n        below: int = 10,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Return a window of lines around `line` in the given file.\n        Lines are 1-indexed. The anchor line is flagged with is_anchor=True.\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {path: $path})\n        RETURN f.source_code as source_code\n        LIMIT 1\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"path\": path})\n        if not records or not records[0].get(\"source_code\"):\n            return {\"error\": \"File not found\", \"path\": path}\n\n        lines = records[0][\"source_code\"].split(\"\\n\")\n        total = len(lines)\n        start = max(0, line - above - 1)   # 0-indexed inclusive\n        end = min(total, line + below)       # 0-indexed exclusive\n\n        window = [\n            {\n                \"line_number\": i + 1,\n                \"content\": lines[i],\n                \"is_anchor\": (i + 1) == line,\n            }\n            for i in range(start, end)\n        ]\n\n        return {\n            \"path\": path,\n            \"anchor_line\": line,\n            \"window\": window,\n            \"total_lines\": total,\n        }\n\n    def find_symbol_by_qualified_name(\n        self,\n        qualified_name: str,\n        repo_id: str\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Find a symbol by its exact qualified name.\n\n        Args:\n            qualified_name: Full qualified name (e.g., module.Class.method)\n            repo_id: Repository ID to search in\n\n        Returns:\n            Symbol information if found\n        \"\"\"\n        query = CYPHER_QUERIES[\"search_symbols_by_qualified_name\"]\n        records, _, _ = self.db.run_query(query, {\n            \"qualified_name\": qualified_name,\n            \"repo_id\": repo_id\n        })\n\n        if records:\n            record = records[0]\n            return {\n                \"id\": record[\"id\"],\n                \"name\": record[\"name\"],\n                \"qualified_name\": record[\"qualified_name\"],\n                \"type\": record[\"type\"],\n                \"file_id\": record[\"file_id\"],\n                \"line_start\": record[\"line_start\"],\n                \"line_end\": record[\"line_end\"],\n                \"scope\": record[\"scope\"],\n                \"visibility\": record[\"visibility\"],\n                \"docstring\": record[\"docstring\"]\n            }\n        return None\n\n    def autocomplete_symbols(\n        self,\n        prefix: str,\n        repo_id: str,\n        limit: int = 20\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get symbol autocomplete suggestions.\n\n        Args:\n            prefix: Prefix to match (e.g., \"module.Clas\")\n            repo_id: Repository ID\n            limit: Maximum results\n\n        Returns:\n            List of matching symbol qualified names\n        \"\"\"\n        query = CYPHER_QUERIES[\"autocomplete_symbols\"]\n        records, _, _ = self.db.run_query(query, {\n            \"prefix\": prefix,\n            \"repo_id\": repo_id,\n            \"limit\": limit\n        })\n\n        return [\n            {\n                \"qualified_name\": record[\"qualified_name\"],\n                \"type\": record[\"type\"],\n                \"visibility\": record[\"visibility\"],\n                \"file_id\": record[\"file_id\"]\n            }\n            for record in records\n        ]\n\n    def find_symbols_in_scope(\n        self,\n        file_id: str,\n        scope: str = \"module\"\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Find all symbols in a specific scope.\n\n        Args:\n            file_id: File ID to search in\n            scope: Scope type (module, class, function)\n\n        Returns:\n            List of symbols in the scope\n        \"\"\"\n        query = CYPHER_QUERIES[\"find_symbols_in_scope\"]\n        records, _, _ = self.db.run_query(query, {\n            \"file_id\": file_id,\n            \"scope\": scope\n        })\n\n        return [\n            {\n                \"name\": record[\"name\"],\n                \"qualified_name\": record[\"qualified_name\"],\n                \"type\": record[\"type\"],\n                \"line_start\": record[\"line_start\"],\n                \"visibility\": record[\"visibility\"]\n            }\n            for record in records\n        ]\n    \n    def find_symbol_definition(self, symbol_name: str, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Find where a symbol (class, function, method, variable) is defined.\"\"\"\n        query = \"\"\"\n        MATCH (symbol)\n        WHERE symbol.name = $symbol_name\n          AND (symbol.file_id STARTS WITH $repo_id OR symbol.class_id STARTS WITH $repo_id)\n        MATCH (f:File)-[:DEFINES*1..2]->(symbol)\n        RETURN symbol.name as name, labels(symbol)[0] as type,\n               f.path as file, symbol.line_start as line,\n               symbol.docstring as docstring, symbol.source_code as source_code\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\n            \"symbol_name\": symbol_name,\n            \"repo_id\": repo_id\n        })\n\n        return [\n            {\n                \"name\": record[\"name\"],\n                \"type\": record[\"type\"],\n                \"file\": record[\"file\"],\n                \"line\": record[\"line\"],\n                \"docstring\": record[\"docstring\"],\n                \"source_code\": record.get(\"source_code\")\n            }\n            for record in records\n        ]\n    \n    # =========================================================================\n    # Impact Analysis\n    # =========================================================================\n    \n    def analyze_change_impact(self, target_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Analyze the impact of changing a specific code element.\"\"\"\n        query = CYPHER_QUERIES[\"analyze_change_impact\"]\n        records, _, _ = self.db.run_query(query, {\"target_id\": target_id})\n\n        return [\n            {\n                \"affected\": record[\"affected\"],\n                \"type\": record[\"type\"],\n                \"file\": record[\"file\"],\n                \"distance\": record[\"distance\"]\n            }\n            for record in records\n        ]\n\n    def analyze_change_impact_enhanced(\n        self,\n        qualified_name: str,\n        repo_id: str\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Enhanced impact analysis with multi-dimensional impact tracking.\n\n        Analyzes:\n        - Direct callers\n        - Transitive callers (up to 3 levels)\n        - Inheritance impact (for classes/methods)\n        - Import impact (files that import changed file)\n\n        Args:\n            qualified_name: Fully qualified name of the symbol\n            repo_id: Repository ID\n\n        Returns:\n            Dict with categorized impact analysis\n        \"\"\"\n        query = CYPHER_QUERIES[\"analyze_change_impact_enhanced\"]\n        records, _, _ = self.db.run_query(query, {\n            \"qualified_name\": qualified_name,\n            \"repo_id\": repo_id\n        })\n\n        if records:\n            record = records[0]\n            return {\n                \"target\": record[\"target\"],\n                \"direct_calls\": [call for call in record[\"direct_calls\"] if call.get(\"name\")],\n                \"transitive_calls\": [call for call in record[\"transitive_calls\"] if call.get(\"name\")],\n                \"inheritance_impact\": [imp for imp in record[\"inheritance_impact\"] if imp.get(\"name\")],\n                \"import_impact\": [imp for imp in record[\"import_impact\"] if imp.get(\"name\")],\n                \"total_impact\": record[\"total_impact\"]\n            }\n        return {\n            \"target\": qualified_name,\n            \"direct_calls\": [],\n            \"transitive_calls\": [],\n            \"inheritance_impact\": [],\n            \"import_impact\": [],\n            \"total_impact\": 0\n        }\n\n    def get_call_graph(\n        self,\n        qualified_name: str,\n        repo_id: str,\n        max_depth: int = 3\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get the call graph starting from a symbol.\n\n        Args:\n            qualified_name: Starting symbol\n            repo_id: Repository ID\n            max_depth: Maximum depth to traverse\n\n        Returns:\n            List of caller-callee relationships\n        \"\"\"\n        query = CYPHER_QUERIES[\"get_call_graph\"]\n        records, _, _ = self.db.run_query(query, {\n            \"qualified_name\": qualified_name,\n            \"repo_id\": repo_id,\n            \"max_depth\": max_depth\n        })\n\n        return [\n            {\n                \"caller\": record[\"caller\"],\n                \"callee\": record[\"callee\"],\n                \"caller_type\": record[\"caller_type\"],\n                \"callee_type\": record[\"callee_type\"],\n                \"line\": record[\"line\"],\n                \"depth\": record[\"depth\"]\n            }\n            for record in records\n        ]\n    \n    # =========================================================================\n    # Code Retrieval Operations\n    # =========================================================================\n\n    def get_code_at_line(self, file_id: str, line_number: int) -> Optional[str]:\n        \"\"\"\n        Get the code content at a specific line.\n\n        Note: Uses file source_code and extracts the specific line.\n        \"\"\"\n        source_code = self.reconstruct_file(file_id)\n        if not source_code:\n            return None\n\n        lines = source_code.split('\\n')\n        if 0 < line_number <= len(lines):\n            return lines[line_number - 1]\n        return None\n\n    def get_code_range(\n        self,\n        file_id: str,\n        start_line: int,\n        end_line: int\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get code content for a range of lines.\n\n        Note: Uses file source_code and extracts the range.\n        \"\"\"\n        source_code = self.reconstruct_file(file_id)\n        if not source_code:\n            return []\n\n        lines = source_code.split('\\n')\n        result = []\n\n        for i in range(start_line - 1, min(end_line, len(lines))):\n            if i >= 0:\n                line_content = lines[i]\n                result.append({\n                    \"line\": i + 1,\n                    \"content\": line_content,\n                    \"is_comment\": line_content.strip().startswith(('#', '//', '/*')),\n                    \"is_blank\": len(line_content.strip()) == 0\n                })\n\n        return result\n    \n    # =========================================================================\n    # File Reconstruction\n    # =========================================================================\n    \n    def get_repository_files(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all files in a repository.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:CONTAINS*]->(f:File)\n        RETURN f.id as id, f.path as path, f.language as language,\n               f.lines_count as lines_count\n        ORDER BY f.path\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        return [\n            {\n                \"id\": record[\"id\"],\n                \"path\": record[\"path\"],\n                \"language\": record[\"language\"],\n                \"lines_count\": record[\"lines_count\"]\n            }\n            for record in records\n        ]\n    \n    def reconstruct_file(self, file_id: str) -> Optional[str]:\n        \"\"\"\n        Reconstruct a file's complete content from source_code property.\n\n        Returns:\n            Complete file source code or None if not found\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {id: $file_id})\n        RETURN f.source_code as source_code, f.path as path\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n\n        if not records:\n            return None\n\n        source_code = records[0].get(\"source_code\")\n        if not source_code:\n            # Fallback: try to reconstruct from individual code elements\n            # This shouldn't be needed but provides a safety net\n            print(f\"⚠️  Warning: File {records[0].get('path')} has no source_code stored\")\n            return None\n\n        return source_code\n\n    def verify_reconstruction(self, file_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Verify that file reconstruction is possible and show stats.\n\n        Args:\n            file_id: File ID to verify\n\n        Returns:\n            Dict with verification results\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {id: $file_id})\n        OPTIONAL MATCH (f)-[:DEFINES]->(c:Class)\n        OPTIONAL MATCH (f)-[:DEFINES]->(fn:Function)\n        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)\n        RETURN f.path as path,\n               f.language as language,\n               f.lines_count as lines_count,\n               f.source_code IS NOT NULL as has_source_code,\n               size(f.source_code) as source_code_size,\n               count(DISTINCT c) as class_count,\n               count(DISTINCT fn) as function_count,\n               count(DISTINCT m) as method_count\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n\n        if not records:\n            return {\"error\": \"File not found\", \"file_id\": file_id}\n\n        record = records[0]\n        can_reconstruct = record[\"has_source_code\"]\n\n        return {\n            \"file_id\": file_id,\n            \"path\": record[\"path\"],\n            \"language\": record[\"language\"],\n            \"lines_count\": record[\"lines_count\"],\n            \"can_reconstruct\": can_reconstruct,\n            \"source_code_size\": record[\"source_code_size\"] or 0,\n            \"classes\": record[\"class_count\"],\n            \"functions\": record[\"function_count\"],\n            \"methods\": record[\"method_count\"],\n            \"status\": \"✅ Ready\" if can_reconstruct else \"❌ No source_code\"\n        }\n    \n    def get_symbol_source(self, qualified_name: str, repo_id: str) -> Optional[str]:\n        \"\"\"\n        Get source code for a specific symbol.\n\n        Args:\n            qualified_name: Fully qualified name of the symbol\n            repo_id: Repository ID\n\n        Returns:\n            Source code of the symbol or None\n        \"\"\"\n        query = \"\"\"\n        MATCH (s:Symbol {qualified_name: $qualified_name})\n        WHERE s.file_id STARTS WITH $repo_id\n        RETURN s.source_code as source_code\n        LIMIT 1\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\n            \"qualified_name\": qualified_name,\n            \"repo_id\": repo_id\n        })\n\n        if records and records[0][\"source_code\"]:\n            return records[0][\"source_code\"]\n\n        # Fallback: try to get from definition node\n        symbol = self.find_symbol_by_qualified_name(qualified_name, repo_id)\n        if symbol and symbol.get(\"type\"):\n            if symbol[\"type\"] == \"class\":\n                return self.get_class_source(f\"{symbol['file_id']}:class:{symbol['name']}:{symbol['line_start']}\")\n            elif symbol[\"type\"] == \"function\":\n                return self.get_function_source(f\"{symbol['file_id']}:func:{symbol['name']}:{symbol['line_start']}\")\n            elif symbol[\"type\"] == \"method\":\n                # More complex - need to find class first\n                pass\n\n        return None\n\n    def verify_repository_reconstruction(self, repo_id: str) -> Dict[str, Any]:\n        \"\"\"\n        Verify that all files in a repository can be reconstructed.\n\n        Args:\n            repo_id: Repository ID\n\n        Returns:\n            Dict with verification stats\n        \"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:CONTAINS*]->(f:File)\n        RETURN count(f) as total_files,\n               sum(CASE WHEN f.source_code IS NOT NULL THEN 1 ELSE 0 END) as files_with_source,\n               sum(f.lines_count) as total_lines,\n               sum(size(f.source_code)) as total_source_size\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n\n        if not records:\n            return {\"error\": \"Repository not found\", \"repo_id\": repo_id}\n\n        record = records[0]\n        total_files = record[\"total_files\"] or 0\n        files_with_source = record[\"files_with_source\"] or 0\n        success_rate = (files_with_source / total_files * 100) if total_files > 0 else 0\n\n        # Get list of files without source code\n        problem_files_query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:CONTAINS*]->(f:File)\n        WHERE f.source_code IS NULL\n        RETURN f.path as path, f.id as file_id\n        LIMIT 10\n        \"\"\"\n        problem_records, _, _ = self.db.run_query(problem_files_query, {\"repo_id\": repo_id})\n\n        return {\n            \"repo_id\": repo_id,\n            \"total_files\": total_files,\n            \"files_with_source\": files_with_source,\n            \"files_without_source\": total_files - files_with_source,\n            \"success_rate\": f\"{success_rate:.1f}%\",\n            \"total_lines\": record[\"total_lines\"] or 0,\n            \"total_source_size_mb\": (record[\"total_source_size\"] or 0) / 1024 / 1024,\n            \"status\": \"✅ All files ready\" if success_rate == 100 else f\"⚠️  {total_files - files_with_source} files missing source\",\n            \"problem_files\": [r[\"path\"] for r in problem_records] if problem_records else []\n        }\n\n    def reconstruct_repository(self, repo_id: str) -> Dict[str, str]:\n        \"\"\"\n        Reconstruct all files in a repository.\n        \n        Returns:\n            Dict mapping file paths to their reconstructed content\n        \"\"\"\n        files = self.get_repository_files(repo_id)\n        reconstructed = {}\n        \n        for file_info in files:\n            content = self.reconstruct_file(file_info[\"id\"])\n            if content is not None:\n                reconstructed[file_info[\"path\"]] = content\n        \n        return reconstructed\n    \n    def get_file_metadata(self, file_id: str) -> Dict[str, Any]:\n        \"\"\"Get complete metadata for a file including all code elements.\"\"\"\n        query = \"\"\"\n        MATCH (f:File {id: $file_id})\n        OPTIONAL MATCH (f)-[:DEFINES]->(c:Class)\n        OPTIONAL MATCH (f)-[:DEFINES]->(fn:Function)\n        OPTIONAL MATCH (f)-[:HAS_IMPORT]->(i:Import)\n        RETURN f.path as path,\n               f.language as language,\n               f.lines_count as lines_count,\n               collect(DISTINCT {name: c.name, line: c.line_start, bases: c.base_classes}) as classes,\n               collect(DISTINCT {name: fn.name, line: fn.line_start, params: fn.params}) as functions,\n               collect(DISTINCT {module: i.module, names: i.imported_names}) as imports\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n\n        if records:\n            record = records[0]\n            return {\n                \"path\": record[\"path\"],\n                \"language\": record[\"language\"],\n                \"lines_count\": record[\"lines_count\"],\n                \"classes\": [c for c in record[\"classes\"] if c[\"name\"]],\n                \"functions\": [f for f in record[\"functions\"] if f[\"name\"]],\n                \"imports\": [i for i in record[\"imports\"] if i[\"module\"]]\n            }\n        return {}\n\n    def get_method_source(self, method_id: str) -> Optional[str]:\n        \"\"\"Get the source code of a specific method.\"\"\"\n        query = \"\"\"\n        MATCH (m:Method {id: $method_id})\n        RETURN m.source_code as source_code\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"method_id\": method_id})\n        return records[0][\"source_code\"] if records and records[0][\"source_code\"] else None\n\n    def get_function_source(self, function_id: str) -> Optional[str]:\n        \"\"\"Get the source code of a specific function.\"\"\"\n        query = \"\"\"\n        MATCH (f:Function {id: $function_id})\n        RETURN f.source_code as source_code\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"function_id\": function_id})\n        return records[0][\"source_code\"] if records and records[0][\"source_code\"] else None\n\n    def get_class_source(self, class_id: str) -> Optional[str]:\n        \"\"\"Get the source code of a specific class.\"\"\"\n        query = \"\"\"\n        MATCH (c:Class {id: $class_id})\n        RETURN c.source_code as source_code\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"class_id\": class_id})\n        return records[0][\"source_code\"] if records and records[0][\"source_code\"] else None\n    \n    # =========================================================================\n    # Config File Queries\n    # =========================================================================\n    \n    def get_repo_config_files(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all config files in a repository.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:HAS_CONFIG]->(cf:ConfigFile)\n        RETURN cf.id as id, cf.path as path, cf.file_type as file_type,\n               cf.project_name as project_name, cf.version as version,\n               cf.lines_count as lines_count\n        ORDER BY cf.path\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        return [\n            {\n                \"id\": record[\"id\"],\n                \"path\": record[\"path\"],\n                \"file_type\": record[\"file_type\"],\n                \"project_name\": record[\"project_name\"],\n                \"version\": record[\"version\"],\n                \"lines_count\": record[\"lines_count\"]\n            }\n            for record in records\n        ]\n    \n    def get_repo_dependencies(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all dependencies in a repository.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        MATCH (r)-[:HAS_CONFIG]->(cf:ConfigFile)-[:HAS_DEPENDENCY]->(d:Dependency)\n        RETURN d.name as name, d.version_spec as version, d.is_dev as is_dev,\n               d.source as source, cf.path as config_file\n        ORDER BY d.is_dev, d.name\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n        return [\n            {\n                \"name\": record[\"name\"],\n                \"version\": record[\"version\"],\n                \"is_dev\": record[\"is_dev\"],\n                \"source\": record[\"source\"],\n                \"config_file\": record[\"config_file\"]\n            }\n            for record in records\n        ]\n    \n    def delete_repository(self, repo_id: str) -> bool:\n        \"\"\"Delete a repository and all its data.\"\"\"\n        if not self.db.connected:\n            # Mock success for testing\n            return True\n\n        query = \"\"\"\n        MATCH (r:Repository)\n        WHERE r.id = $repo_id OR r.repo = $repo_id\n        DETACH DELETE r\n        RETURN count(r) as deleted_count\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n\n        return len(records) > 0 and records[0].get(\"deleted_count\", 0) > 0\n    \n    def get_repo_overview_extended(self, repo_id: str) -> Dict[str, Any]:\n        \"\"\"Get extended repository overview including config files and dependencies.\"\"\"\n        # Get basic stats\n        basic = self.get_repo_overview(repo_id)\n        \n        # Get config file count\n        config_query = \"\"\"\n        MATCH (r:Repository {id: $repo_id})-[:HAS_CONFIG]->(cf:ConfigFile)\n        OPTIONAL MATCH (cf)-[:HAS_DEPENDENCY]->(d:Dependency)\n        RETURN count(DISTINCT cf) as config_count, count(DISTINCT d) as dep_count\n        \"\"\"\n        records, _, _ = self.db.run_query(config_query, {\"repo_id\": repo_id})\n        \n        if records:\n            basic[\"config_files\"] = records[0][\"config_count\"]\n            basic[\"dependencies\"] = records[0][\"dep_count\"]\n        else:\n            basic[\"config_files\"] = 0\n            basic[\"dependencies\"] = 0\n        \n        return basic\n\n    def get_all_ingested_repositories(self, owner: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all ingested repositories.\"\"\"\n        query = \"\"\"\n        MATCH (r:Repository {owner: $owner})\n        RETURN r.id as repo_id, r.owner as owner, r.name as name, r.url as url\n        ORDER BY r.owner, r.name\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"owner\": owner})\n        return [\n            {\n                \"repo_id\": record[\"repo_id\"],\n                \"owner\": record[\"owner\"],\n                \"name\": record[\"name\"],\n                \"url\": record[\"url\"]\n            }\n            for record in records\n        ]\n\n    # =========================================================================\n    # Hierarchy Navigation\n    # =========================================================================\n\n    def get_module_tree(self, repo_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get the complete module/directory tree for a repository.\n\n        Args:\n            repo_id: Repository ID\n\n        Returns:\n            List of modules with hierarchy information\n        \"\"\"\n        query = CYPHER_QUERIES[\"get_module_tree\"]\n        records, _, _ = self.db.run_query(query, {\"repo_id\": repo_id})\n\n        return [\n            {\n                \"path\": record[\"path\"],\n                \"name\": record[\"name\"],\n                \"parent_path\": record[\"parent_path\"],\n                \"is_package\": record[\"is_package\"],\n                \"depth\": record[\"depth\"]\n            }\n            for record in records\n        ]\n\n    def get_file_hierarchy(self, file_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get the breadcrumb hierarchy for a file.\n\n        Args:\n            file_id: File ID\n\n        Returns:\n            Ordered list from repository to file\n        \"\"\"\n        query = CYPHER_QUERIES[\"get_file_hierarchy\"]\n        records, _, _ = self.db.run_query(query, {\"file_id\": file_id})\n\n        return [\n            {\n                \"type\": record[\"type\"],\n                \"name\": record[\"name\"],\n                \"path\": record[\"path\"],\n                \"depth\": record[\"depth\"]\n            }\n            for record in records\n        ]\n\n    def get_directory_contents(\n        self,\n        repo_id: str,\n        dir_path: str\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get contents of a specific directory.\n\n        Args:\n            repo_id: Repository ID\n            dir_path: Directory path\n\n        Returns:\n            List of files and subdirectories\n        \"\"\"\n        query = CYPHER_QUERIES[\"get_directory_contents\"]\n        records, _, _ = self.db.run_query(query, {\n            \"repo_id\": repo_id,\n            \"dir_path\": dir_path\n        })\n\n        return [\n            {\n                \"type\": record[\"type\"],\n                \"name\": record[\"name\"],\n                \"path\": record[\"path\"],\n                \"is_package\": record[\"is_package\"]\n            }\n            for record in records\n        ]\n\n    def get_symbols_at_lines(self, file_path: str, start_line: int, end_line: int) -> List[Dict[str, Any]]:\n        \"\"\"\n        Find all symbols (functions, classes, variables) that overlap a line range in a file.\n        Used to map diff hunks to affected code symbols.\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File {path: $file_path})-[:CONTAINS]->(n)\n        WHERE (n:Function OR n:Class OR n:Variable)\n          AND n.line_number IS NOT NULL\n          AND n.line_number <= $end_line\n          AND coalesce(n.end_line, n.line_number) >= $start_line\n        RETURN\n            CASE\n                WHEN n:Function THEN 'function'\n                WHEN n:Class THEN 'class'\n                ELSE 'variable'\n            END as type,\n            n.name as name,\n            n.line_number as start_line,\n            coalesce(n.end_line, n.line_number) as end_line,\n            n.source as source,\n            n.docstring as docstring,\n            n.path as path\n        ORDER BY n.line_number\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\n            \"file_path\": file_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n        })\n        return [dict(r) for r in records]\n\n    def get_symbols_at_lines_by_relative_path(self, repo_id: str, relative_path: str, start_line: int, end_line: int) -> List[Dict[str, Any]]:\n        \"\"\"\n        Find all symbols overlapping a line range using repo-relative file path.\n        \"\"\"\n        query = \"\"\"\n        MATCH (f:File)\n        WHERE f.relative_path = $relative_path\n          AND f.path CONTAINS $repo_id\n        WITH f\n        MATCH (f)-[:CONTAINS]->(n)\n        WHERE (n:Function OR n:Class OR n:Variable)\n          AND n.line_number IS NOT NULL\n          AND n.line_number <= $end_line\n          AND coalesce(n.end_line, n.line_number) >= $start_line\n        RETURN\n            CASE\n                WHEN n:Function THEN 'function'\n                WHEN n:Class THEN 'class'\n                ELSE 'variable'\n            END as type,\n            n.name as name,\n            n.line_number as start_line,\n            coalesce(n.end_line, n.line_number) as end_line,\n            n.source as source,\n            n.docstring as docstring,\n            f.relative_path as file_path\n        ORDER BY n.line_number\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\n            \"repo_id\": repo_id,\n            \"relative_path\": relative_path,\n            \"start_line\": start_line,\n            \"end_line\": end_line,\n        })\n        return [dict(r) for r in records]\n\n    def get_diff_context(self, repo_id: str, changes: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Build full RAG context for a set of file changes (diff).\n\n        Args:\n            repo_id: Repository ID (e.g. \"owner/repo\")\n            changes: List of {\"file_path\": \"relative/path.py\", \"start_line\": 10, \"end_line\": 30}\n\n        Returns:\n            Dict with affected_symbols, callers, hierarchy, and file_sources.\n        \"\"\"\n        all_affected = []\n        all_callers = []\n        all_hierarchy = []\n        file_sources = {}\n\n        for change in changes:\n            file_path = change[\"file_path\"]\n            start_line = change.get(\"start_line\", 1)\n            end_line = change.get(\"end_line\", 999999)\n\n            # 1. Find affected symbols\n            symbols = self.get_symbols_at_lines_by_relative_path(\n                repo_id, file_path, start_line, end_line\n            )\n            for s in symbols:\n                s[\"change_file\"] = file_path\n            all_affected.extend(symbols)\n\n            # 2. For each affected symbol, find callers\n            for sym in symbols:\n                caller_query = \"\"\"\n                MATCH (caller)-[:CALLS]->(target)\n                WHERE target.name = $name AND target.path CONTAINS $repo_id\n                RETURN\n                    CASE\n                        WHEN caller:Function THEN 'function'\n                        WHEN caller:Class THEN 'class'\n                        ELSE 'other'\n                    END as type,\n                    caller.name as name,\n                    caller.path as path,\n                    caller.line_number as line_number,\n                    caller.source as source\n                LIMIT 20\n                \"\"\"\n                records, _, _ = self.db.run_query(caller_query, {\n                    \"name\": sym[\"name\"],\n                    \"repo_id\": repo_id,\n                })\n                callers = [dict(r) for r in records]\n                if callers:\n                    all_callers.append({\n                        \"symbol\": sym[\"name\"],\n                        \"symbol_type\": sym[\"type\"],\n                        \"callers\": callers,\n                    })\n\n            # 3. For affected classes, get hierarchy\n            class_symbols = [s for s in symbols if s[\"type\"] == \"class\"]\n            for cls in class_symbols:\n                hier_query = \"\"\"\n                MATCH (c:Class {name: $name})-[:INHERITS*0..5]->(parent:Class)\n                WHERE c.path CONTAINS $repo_id\n                RETURN parent.name as name, parent.path as path,\n                       parent.source as source, parent.docstring as docstring\n                \"\"\"\n                records, _, _ = self.db.run_query(hier_query, {\n                    \"name\": cls[\"name\"],\n                    \"repo_id\": repo_id,\n                })\n                if records:\n                    all_hierarchy.append({\n                        \"class\": cls[\"name\"],\n                        \"hierarchy\": [dict(r) for r in records],\n                    })\n\n            # 4. Get file source\n            file_src_query = \"\"\"\n            MATCH (f:File)\n            WHERE f.relative_path = $relative_path AND f.path CONTAINS $repo_id\n            RETURN f.source_code as source_code, f.relative_path as path\n            LIMIT 1\n            \"\"\"\n            records, _, _ = self.db.run_query(file_src_query, {\n                \"relative_path\": file_path,\n                \"repo_id\": repo_id,\n            })\n            if records and records[0].get(\"source_code\"):\n                file_sources[file_path] = records[0][\"source_code\"]\n\n        return {\n            \"affected_symbols\": all_affected,\n            \"callers\": all_callers,\n            \"class_hierarchy\": all_hierarchy,\n            \"file_sources\": file_sources,\n            \"total_affected\": len(all_affected),\n            \"total_files\": len(changes),\n        }\n\n    def get_diff_context_condensed(\n        self, repo_id: str, changes: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Build lean context for a set of file changes — optimized for LLM prompts.\n\n        Compared to get_diff_context:\n        - Only returns functions/classes/methods (skips variables)\n        - Returns symbol source snippets (the changed code chunk, not the whole file)\n        - Returns caller names + file paths only (no caller source code)\n        - Returns hierarchy as name chains only (no parent source)\n        - No full file sources at all\n\n        Args:\n            repo_id: Repository ID (e.g. \"owner/repo\")\n            changes: List of {\"file_path\": \"relative/path.py\", \"start_line\": 10, \"end_line\": 30}\n\n        Returns:\n            Dict with affected_symbols, callers, hierarchy.\n        \"\"\"\n        all_affected: List[Dict[str, Any]] = []\n        all_callers: List[Dict[str, Any]] = []\n        all_hierarchy: List[Dict[str, Any]] = []\n        seen_symbols: set = set()\n\n        for change in changes:\n            file_path = change[\"file_path\"]\n            start_line = change.get(\"start_line\", 1)\n            end_line = change.get(\"end_line\", 999999)\n\n            # 1. Find affected symbols — functions and classes only\n            query = \"\"\"\n            MATCH (f:File)\n            WHERE f.relative_path = $relative_path\n              AND f.path CONTAINS $repo_id\n            WITH f\n            MATCH (f)-[:CONTAINS]->(n)\n            WHERE (n:Function OR n:Class OR n:Method)\n              AND n.line_number IS NOT NULL\n              AND n.line_number <= $end_line\n              AND coalesce(n.end_line, n.line_number) >= $start_line\n            RETURN\n                CASE\n                    WHEN n:Function THEN 'function'\n                    WHEN n:Method THEN 'method'\n                    WHEN n:Class THEN 'class'\n                END as type,\n                n.name as name,\n                n.line_number as start_line,\n                coalesce(n.end_line, n.line_number) as end_line,\n                n.source as source,\n                n.docstring as docstring,\n                f.relative_path as file_path\n            ORDER BY n.line_number\n            \"\"\"\n            records, _, _ = self.db.run_query(query, {\n                \"repo_id\": repo_id,\n                \"relative_path\": file_path,\n                \"start_line\": start_line,\n                \"end_line\": end_line,\n            })\n\n            symbols = [dict(r) for r in records]\n            for s in symbols:\n                s[\"change_file\"] = file_path\n                # Truncate source to keep prompts lean\n                if s.get(\"source\") and len(s[\"source\"]) > 500:\n                    s[\"source\"] = s[\"source\"][:500] + \"\\n... (truncated)\"\n            all_affected.extend(symbols)\n\n            # 2. For each symbol, find caller names only (no source)\n            for sym in symbols:\n                sym_key = f\"{file_path}:{sym['name']}\"\n                if sym_key in seen_symbols:\n                    continue\n                seen_symbols.add(sym_key)\n\n                caller_query = \"\"\"\n                MATCH (caller)-[:CALLS]->(target)\n                WHERE target.name = $name AND target.path CONTAINS $repo_id\n                RETURN DISTINCT\n                    caller.name as name,\n                    CASE\n                        WHEN caller:Function THEN 'function'\n                        WHEN caller:Method THEN 'method'\n                        WHEN caller:Class THEN 'class'\n                        ELSE 'other'\n                    END as type,\n                    caller.path as path\n                LIMIT 10\n                \"\"\"\n                records, _, _ = self.db.run_query(caller_query, {\n                    \"name\": sym[\"name\"],\n                    \"repo_id\": repo_id,\n                })\n                callers = [dict(r) for r in records]\n                if callers:\n                    all_callers.append({\n                        \"symbol\": sym[\"name\"],\n                        \"symbol_type\": sym[\"type\"],\n                        \"callers\": callers,\n                    })\n\n            # 3. For affected classes, get hierarchy names only\n            class_symbols = [s for s in symbols if s[\"type\"] == \"class\"]\n            for cls in class_symbols:\n                hier_query = \"\"\"\n                MATCH (c:Class {name: $name})-[:INHERITS*0..3]->(parent:Class)\n                WHERE c.path CONTAINS $repo_id\n                RETURN parent.name as name, parent.path as path\n                \"\"\"\n                records, _, _ = self.db.run_query(hier_query, {\n                    \"name\": cls[\"name\"],\n                    \"repo_id\": repo_id,\n                })\n                if records:\n                    all_hierarchy.append({\n                        \"class\": cls[\"name\"],\n                        \"hierarchy\": [{\"name\": r[\"name\"], \"path\": r[\"path\"]} for r in records],\n                    })\n\n        return {\n            \"affected_symbols\": all_affected,\n            \"callers\": all_callers,\n            \"class_hierarchy\": all_hierarchy,\n            \"total_affected\": len(all_affected),\n            \"total_files\": len(set(c[\"file_path\"] for c in changes)),\n        }\n\n    def get_diff_context_enhanced(\n        self, repo_id: str, changes: List[Dict[str, Any]]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Build full relationship context for every changed Function, Method, and Class.\n\n        For each symbol in the diff line ranges:\n          - Full source code of the symbol itself\n          - Methods belonging to each changed Class (with source)\n          - Callers: every Function/Method that calls this symbol via CALLS edges\n          - Dependencies: every Function/Method this symbol calls via CALLS edges\n          - Imports: other in-repo symbols imported by the changed file\n          - Class hierarchy: parent/child classes for any changed Class\n\n        Both Function and Method node types are handled throughout — the graph\n        stores class methods as Function nodes under the class via CONTAINS.\n        \"\"\"\n        from api.services.code_search import CodeFinder\n\n        code_finder = CodeFinder(self.db)\n\n        all_affected: List[Dict[str, Any]] = []\n        all_callers: List[Dict[str, Any]] = []\n        all_imports: List[Dict[str, Any]] = []\n        all_dependencies: List[Dict[str, Any]] = []\n        all_hierarchy: List[Dict[str, Any]] = []\n        seen_affected: set = set()\n        seen_callers: set = set()\n        seen_imports: set = set()\n\n        for change in changes:\n            file_path = change[\"file_path\"]\n            start_line = change.get(\"start_line\", 1)\n            end_line = change.get(\"end_line\", 999999)\n\n            # ── 1. Affected symbols (Function, Class, and Method) ─────────────\n            # Method nodes are stored under Class via CONTAINS — we surface them\n            # here so the agent sees both the class body and individual methods.\n            affected_query = \"\"\"\n            MATCH (f:File {repo: $repo_id, path: $file_path})\n            MATCH (f)-[:CONTAINS]->(n)\n            WHERE (n:Function OR n:Class OR n:Method)\n              AND n.line_number IS NOT NULL\n              AND n.line_number <= $end_line\n              AND coalesce(n.end_line, n.line_number) >= $start_line\n            RETURN\n                CASE\n                    WHEN n:Class    THEN 'class'\n                    WHEN n:Method   THEN 'method'\n                    ELSE                 'function'\n                END AS type,\n                n.name          AS name,\n                n.line_number   AS start_line,\n                coalesce(n.end_line, n.line_number) AS end_line,\n                n.source        AS source,\n                n.docstring     AS docstring,\n                n.args          AS args,\n                f.path          AS file_path\n            ORDER BY n.line_number\n            \"\"\"\n            records, _, _ = self.db.run_query(affected_query, {\n                \"repo_id\": repo_id,\n                \"file_path\": file_path,\n                \"start_line\": start_line,\n                \"end_line\": end_line,\n            })\n            symbols = [dict(r) for r in records]\n\n            for s in symbols:\n                s[\"change_file\"] = file_path\n                sym_key = f\"{s['file_path']}:{s['name']}:{s['start_line']}\"\n                if sym_key not in seen_affected:\n                    seen_affected.add(sym_key)\n                    all_affected.append(s)\n\n            for sym in symbols:\n                caller_key = f\"{sym['file_path']}:{sym['name']}\"\n                if caller_key in seen_callers:\n                    continue\n                seen_callers.add(caller_key)\n\n                # ── 2. Callers: who calls this symbol? ────────────────────────\n                # Match both Function and Method callers so class methods that\n                # call the changed code are not missed.\n                try:\n                    caller_query = \"\"\"\n                    MATCH (target)\n                    WHERE (target:Function OR target:Method OR target:Class)\n                      AND target.name = $name\n                      AND coalesce(target.path, '') CONTAINS $repo_id\n                    WITH target\n                    MATCH (caller)-[call:CALLS]->(target)\n                    WHERE (caller:Function OR caller:Method)\n                      AND NOT coalesce(caller.is_dependency, false)\n                    OPTIONAL MATCH (caller_file:File)-[:CONTAINS]->(caller)\n                    RETURN DISTINCT\n                        caller.name             AS caller_name,\n                        CASE WHEN caller:Method THEN 'method' ELSE 'function' END AS caller_type,\n                        coalesce(caller.path, caller_file.path) AS caller_path,\n                        caller.line_number      AS caller_line,\n                        call.line_number        AS call_line,\n                        call.args               AS call_args\n                    ORDER BY caller_path, caller.line_number\n                    LIMIT 10\n                    \"\"\"\n                    caller_records, _, _ = self.db.run_query(\n                        caller_query, {\"name\": sym[\"name\"], \"repo_id\": repo_id}\n                    )\n                    callers_list = [dict(r) for r in caller_records]\n                    if callers_list:\n                        all_callers.append({\n                            \"symbol\": sym[\"name\"],\n                            \"symbol_type\": sym[\"type\"],\n                            \"callers\": callers_list,\n                        })\n                except Exception as e:\n                    logger.warning(f\"Error finding callers for {sym['name']}: {e}\")\n\n                # ── 3. Dependencies: what does this symbol call? ──────────────\n                # Match both Function and Method targets to catch calls to methods.\n                try:\n                    dep_query = \"\"\"\n                    MATCH (caller)\n                    WHERE (caller:Function OR caller:Method)\n                      AND caller.name = $name\n                      AND caller.path = $path\n                    MATCH (caller)-[call:CALLS]->(called)\n                    WHERE (called:Function OR called:Method)\n                      AND NOT coalesce(called.is_dependency, false)\n                    RETURN DISTINCT\n                        called.name  AS called_name,\n                        CASE WHEN called:Method THEN 'method' ELSE 'function' END AS called_type,\n                        called.path  AS called_path,\n                        call.line_number AS call_line,\n                        call.args    AS call_args\n                    ORDER BY call.line_number\n                    LIMIT 15\n                    \"\"\"\n                    dep_records, _, _ = self.db.run_query(dep_query, {\n                        \"name\": sym[\"name\"],\n                        \"path\": sym[\"file_path\"],\n                    })\n                    deps_list = [dict(r) for r in dep_records]\n                    if deps_list:\n                        all_dependencies.append({\n                            \"symbol\": sym[\"name\"],\n                            \"dependencies\": deps_list,\n                        })\n                except Exception as e:\n                    logger.warning(f\"Error finding dependencies for {sym['name']}: {e}\")\n\n                # ── 4. Class methods: when a Class is affected, fetch all ──────\n                # its methods with full source so the agent sees what each\n                # method does — not just the class skeleton.\n                if sym[\"type\"] == \"class\":\n                    try:\n                        methods_query = \"\"\"\n                        MATCH (cls:Class {name: $class_name, path: $path})\n                        MATCH (cls)-[:CONTAINS]->(m:Function)\n                        RETURN\n                            m.name          AS name,\n                            m.line_number   AS line_number,\n                            coalesce(m.end_line, m.line_number) AS end_line,\n                            m.source        AS source,\n                            m.docstring     AS docstring,\n                            m.args          AS args\n                        ORDER BY m.line_number\n                        \"\"\"\n                        method_records, _, _ = self.db.run_query(methods_query, {\n                            \"class_name\": sym[\"name\"],\n                            \"path\": sym[\"file_path\"],\n                        })\n                        methods_list = [dict(r) for r in method_records]\n                        if methods_list:\n                            sym[\"methods\"] = methods_list\n                    except Exception as e:\n                        logger.warning(f\"Error fetching methods for class {sym['name']}: {e}\")\n\n            # ── 5. Imports: resolve imported names to in-repo source ──────────\n            import_query = \"\"\"\n            MATCH (f:File {repo: $repo_id, path: $file_path})\n            MATCH (f)-[r:IMPORTS]->(m)\n            RETURN\n                r.alias          AS alias,\n                r.imported_name  AS imported_name,\n                m.name           AS module_name,\n                r.line_number    AS line_number\n            ORDER BY r.line_number\n            LIMIT 20\n            \"\"\"\n            import_records, _, _ = self.db.run_query(import_query, {\n                \"repo_id\": repo_id,\n                \"file_path\": file_path,\n            })\n\n            for imp in import_records:\n                imported_name = imp.get(\"imported_name\") or imp.get(\"alias\")\n                if not imported_name or imported_name in seen_imports:\n                    continue\n                seen_imports.add(imported_name)\n\n                try:\n                    func_results = code_finder.find_by_function_name(imported_name, fuzzy_search=False)\n                    if func_results:\n                        for func in func_results[:1]:\n                            if func.get(\"path\") and repo_id in func.get(\"path\", \"\"):\n                                all_imports.append({\n                                    \"name\": imported_name,\n                                    \"type\": \"function\",\n                                    \"source\": func.get(\"source\", \"\"),\n                                    \"path\": func.get(\"path\"),\n                                    \"line\": func.get(\"line_number\"),\n                                    \"docstring\": func.get(\"docstring\"),\n                                    \"from_file\": file_path,\n                                })\n                    else:\n                        class_results = code_finder.find_by_class_name(imported_name, fuzzy_search=False)\n                        if class_results:\n                            for cls in class_results[:1]:\n                                if cls.get(\"path\") and repo_id in cls.get(\"path\", \"\"):\n                                    all_imports.append({\n                                        \"name\": imported_name,\n                                        \"type\": \"class\",\n                                        \"source\": cls.get(\"source\", \"\"),\n                                        \"path\": cls.get(\"path\"),\n                                        \"line\": cls.get(\"line_number\"),\n                                        \"docstring\": cls.get(\"docstring\"),\n                                        \"from_file\": file_path,\n                                    })\n                except Exception as e:\n                    logger.warning(f\"Error resolving import {imported_name}: {e}\")\n\n            # ── 6. Class hierarchy for affected classes ───────────────────────\n            for cls in [s for s in symbols if s[\"type\"] == \"class\"]:\n                try:\n                    hierarchy_info = code_finder.find_class_hierarchy(\n                        cls[\"name\"], cls.get(\"file_path\")\n                    )\n                    if hierarchy_info:\n                        all_hierarchy.append({\n                            \"class\": cls[\"name\"],\n                            \"parents\": hierarchy_info.get(\"parent_classes\", []),\n                            \"children\": hierarchy_info.get(\"child_classes\", []),\n                            \"methods\": hierarchy_info.get(\"methods\", []),\n                        })\n                except Exception as e:\n                    logger.warning(f\"Error finding hierarchy for {cls['name']}: {e}\")\n\n        return {\n            \"affected_symbols\": all_affected,\n            \"callers\": all_callers,\n            \"imports\": all_imports,\n            \"dependencies\": all_dependencies,\n            \"class_hierarchy\": all_hierarchy,\n            \"total_affected\": len(all_affected),\n            \"total_imports\": len(all_imports),\n            \"total_files\": len(set(c[\"file_path\"] for c in changes)),\n        }","structuredPatch":[{"oldStart":460,"oldLines":56,"newStart":460,"newLines":85,"lines":[" ","         return results"," ","+    # Skip files larger than this (bytes) in content search — avoids scanning minified/generated files","+    _MAX_FILE_BYTES = 500_000","+","     def search_file_content(self, search_term: str, limit: int = 50) -> List[Dict[str, Any]]:","         \"\"\"","-        Search file source code line by line.","-        Uses file_content_search fulltext index to find candidate files,","-        then scans lines in Python to find the exact matching lines.","+        Search file source code line by line — all scanning runs server-side in Cypher.","+","+        Tier A: file_content_search fulltext index → split + unwind + CONTAINS in Neo4j.","+        Tier B: source_code CONTAINS fallback (also server-side split/unwind).","+","+        Files larger than 500 KB are skipped to avoid exploding intermediate row counts.","+        Only matching lines are returned over the wire (not full source blobs).","         \"\"\"","         escaped_term = self._escape_lucene_query(search_term)","-        file_records: List[Dict[str, Any]] = []","+        limit = min(limit, 200)"," ","+        # Tier A — fulltext to locate candidate files, then server-side line scan","         try:","             ft_query = \"\"\"","             CALL db.index.fulltext.queryNodes('file_content_search', $search_term) YIELD node, score","             WHERE node.source_code IS NOT NULL","-            RETURN node.path as path, node.source_code as source_code, score","-            ORDER BY score DESC","-            LIMIT 20","+              AND size(node.source_code) < $max_bytes","+            WITH node, score, split(node.source_code, '\\n') as lines","+            LIMIT 10","+            UNWIND range(0, size(lines) - 1) AS idx","+            WITH node.path AS path, lines[idx] AS line_content, idx + 1 AS line_number, score","+            WHERE toLower(line_content) CONTAINS toLower($raw_term)","+            RETURN path, line_number, line_content AS match_line","+            ORDER BY score DESC, path, line_number","+            LIMIT $limit","             \"\"\"","-            records, _, _ = self.db.run_query(ft_query, {\"search_term\": escaped_term})","-            file_records = [dict(r) for r in records]","+            records, _, _ = self.db.run_query(ft_query, {","+                \"search_term\": escaped_term,","+                \"raw_term\": search_term,","+                \"max_bytes\": self._MAX_FILE_BYTES,","+                \"limit\": limit,","+            })","+            results = [","+                {","+                    \"path\": r[\"path\"],","+                    \"line_number\": r[\"line_number\"],","+                    \"match_line\": r[\"match_line\"].rstrip() if r[\"match_line\"] else \"\",","+                }","+                for r in records","+            ]","+            if results:","+                return results","         except Exception as e:","-            logger.warning(\"file_content_search index failed, falling back to CONTAINS: %s\", e)","+            logger.warning(\"file_content_search fulltext failed: %s\", e)"," ","-        if not file_records:","-            fallback = \"\"\"","-            MATCH (f:File)","-            WHERE f.source_code CONTAINS $search_term","-            RETURN f.path as path, f.source_code as source_code, 1.0 as score","-            LIMIT 20","-            \"\"\"","-            records, _, _ = self.db.run_query(fallback, {\"search_term\": search_term})","-            file_records = [dict(r) for r in records]","+        # Tier B — CONTAINS on source_code, server-side split/unwind (no Python scanning)","+        fallback_query = \"\"\"","+        MATCH (f:File)","+        WHERE f.source_code IS NOT NULL","+          AND f.source_code CONTAINS $raw_term","+          AND size(f.source_code) < $max_bytes","+        WITH f, split(f.source_code, '\\n') AS lines","+        LIMIT 5","+        UNWIND range(0, size(lines) - 1) AS idx","+        WITH f.path AS path, lines[idx] AS line_content, idx + 1 AS line_number","+        WHERE line_content CONTAINS $raw_term","+        RETURN path, line_number, line_content AS match_line","+        ORDER BY path, line_number","+        LIMIT $limit","+        \"\"\"","+        records, _, _ = self.db.run_query(fallback_query, {","+            \"raw_term\": search_term,","+            \"max_bytes\": self._MAX_FILE_BYTES,","+            \"limit\": limit,","+        })","+        return [","+            {","+                \"path\": r[\"path\"],","+                \"line_number\": r[\"line_number\"],","+                \"match_line\": r[\"match_line\"].rstrip() if r[\"match_line\"] else \"\",","+            }","+            for r in records","+        ]"," ","-        results: List[Dict[str, Any]] = []","-        term_lower = search_term.lower()","-        for rec in file_records:","-            path = rec.get(\"path\")","-            source = rec.get(\"source_code\")","-            if not path or not source:","-                continue","-            for i, line in enumerate(source.split(\"\\n\")):","-                if search_term in line or term_lower in line.lower():","-                    results.append({","-                        \"path\": path,","-                        \"line_number\": i + 1,","-                        \"match_line\": line.rstrip(),","-                    })","-                    if len(results) >= limit:","-                        return results","-        return results","-","     def peek_file_lines(","         self,","         path: str,"]},{"oldStart":520,"oldLines":15,"newStart":549,"newLines":17,"lines":["         \"\"\"","         Return a window of lines around `line` in the given file.","         Lines are 1-indexed. The anchor line is flagged with is_anchor=True.","+        Files > 2 MB are rejected to prevent memory spikes.","         \"\"\"","         query = \"\"\"","         MATCH (f:File {path: $path})","+        WHERE f.source_code IS NOT NULL AND size(f.source_code) < 2000000","         RETURN f.source_code as source_code","         LIMIT 1","         \"\"\"","         records, _, _ = self.db.run_query(query, {\"path\": path})","         if not records or not records[0].get(\"source_code\"):","-            return {\"error\": \"File not found\", \"path\": path}","+            return {\"error\": \"File not found or too large\", \"path\": path}"," ","         lines = records[0][\"source_code\"].split(\"\\n\")","         total = len(lines)"]}],"userModified":false,"replaceAll":false},"sourceToolAssistantUUID":"86beceea-f802-4e20-b45a-d02350470630"}
{"parentUuid":"81d57366-b981-4842-9d74-e8d0131eb805","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01V3Q67nm3kqfWbsEAPLCKHE","type":"message","role":"assistant","content":[{"type":"text","text":"Verify the rest of `peek_file_lines` still reads cleanly:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2087,"cache_read_input_tokens":146629,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2087},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvinomizcm3gVBCbvdt","type":"assistant","uuid":"9a78a73c-b0b7-4e24-acfa-7f4710144f39","timestamp":"2026-02-21T08:49:59.337Z"}
{"parentUuid":"9a78a73c-b0b7-4e24-acfa-7f4710144f39","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01V3Q67nm3kqfWbsEAPLCKHE","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017wY1jn2TaYR2TVmk2xg4GR","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/db/queries.py","offset":555,"limit":25},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2087,"cache_read_input_tokens":146629,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":2087},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvinomizcm3gVBCbvdt","type":"assistant","uuid":"f100fa2d-2416-4a75-874c-009b724cabec","timestamp":"2026-02-21T08:50:00.084Z"}
{"parentUuid":"f100fa2d-2416-4a75-874c-009b724cabec","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_017wY1jn2TaYR2TVmk2xg4GR","toolUseID":"toolu_017wY1jn2TaYR2TVmk2xg4GR","timestamp":"2026-02-21T08:50:00.096Z","uuid":"acbf57b8-ebcb-40a1-851b-17655f760d2a"}
{"parentUuid":"f100fa2d-2416-4a75-874c-009b724cabec","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017wY1jn2TaYR2TVmk2xg4GR","type":"tool_result","content":"   555→        MATCH (f:File {path: $path})\n   556→        WHERE f.source_code IS NOT NULL AND size(f.source_code) < 2000000\n   557→        RETURN f.source_code as source_code\n   558→        LIMIT 1\n   559→        \"\"\"\n   560→        records, _, _ = self.db.run_query(query, {\"path\": path})\n   561→        if not records or not records[0].get(\"source_code\"):\n   562→            return {\"error\": \"File not found or too large\", \"path\": path}\n   563→\n   564→        lines = records[0][\"source_code\"].split(\"\\n\")\n   565→        total = len(lines)\n   566→        start = max(0, line - above - 1)   # 0-indexed inclusive\n   567→        end = min(total, line + below)       # 0-indexed exclusive\n   568→\n   569→        window = [\n   570→            {\n   571→                \"line_number\": i + 1,\n   572→                \"content\": lines[i],\n   573→                \"is_anchor\": (i + 1) == line,\n   574→            }\n   575→            for i in range(start, end)\n   576→        ]\n   577→\n   578→        return {\n   579→            \"path\": path,\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"6bf87d83-f44c-40be-bac7-d4facc07d21e","timestamp":"2026-02-21T08:50:00.095Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/db/queries.py","content":"        MATCH (f:File {path: $path})\n        WHERE f.source_code IS NOT NULL AND size(f.source_code) < 2000000\n        RETURN f.source_code as source_code\n        LIMIT 1\n        \"\"\"\n        records, _, _ = self.db.run_query(query, {\"path\": path})\n        if not records or not records[0].get(\"source_code\"):\n            return {\"error\": \"File not found or too large\", \"path\": path}\n\n        lines = records[0][\"source_code\"].split(\"\\n\")\n        total = len(lines)\n        start = max(0, line - above - 1)   # 0-indexed inclusive\n        end = min(total, line + below)       # 0-indexed exclusive\n\n        window = [\n            {\n                \"line_number\": i + 1,\n                \"content\": lines[i],\n                \"is_anchor\": (i + 1) == line,\n            }\n            for i in range(start, end)\n        ]\n\n        return {\n            \"path\": path,","numLines":25,"startLine":555,"totalLines":1865}},"sourceToolAssistantUUID":"f100fa2d-2416-4a75-874c-009b724cabec"}
{"parentUuid":"6bf87d83-f44c-40be-bac7-d4facc07d21e","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_017tLvJ3upUf7tueiT7C4doK","type":"message","role":"assistant","content":[{"type":"text","text":"Good — the rest of `peek_file_lines` is intact and correct. Let me do a final audit pass:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":658,"cache_read_input_tokens":148716,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":658},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvj24VSQj68WWZduGKV","type":"assistant","uuid":"64892c83-d0d3-47e2-bcb7-ee2404c92832","timestamp":"2026-02-21T08:50:02.610Z"}
{"parentUuid":"64892c83-d0d3-47e2-bcb7-ee2404c92832","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_017tLvJ3upUf7tueiT7C4doK","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01TGoeQKSWQAZdH46nh6fp1A","name":"Grep","input":{"pattern":"Body|import os|Optional","path":"/Users/skmabudalam/Documents/BugViper/api/routers/query.py","output_mode":"content"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":658,"cache_read_input_tokens":148716,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":658},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvj24VSQj68WWZduGKV","type":"assistant","uuid":"51875341-c168-43ee-a125-9937a46a6b28","timestamp":"2026-02-21T08:50:03.766Z"}
{"parentUuid":"51875341-c168-43ee-a125-9937a46a6b28","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_017tLvJ3upUf7tueiT7C4doK","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01TGxEqtr7WmNaWztqZdKNGP","name":"Grep","input":{"pattern":"source_code as source_code","path":"/Users/skmabudalam/Documents/BugViper/db/queries.py","output_mode":"content"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":658,"cache_read_input_tokens":148716,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":658},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvj24VSQj68WWZduGKV","type":"assistant","uuid":"bd01b211-3b50-44cf-a62b-5e5b54ce6d3c","timestamp":"2026-02-21T08:50:04.432Z"}
{"parentUuid":"bd01b211-3b50-44cf-a62b-5e5b54ce6d3c","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01TGoeQKSWQAZdH46nh6fp1A","toolUseID":"toolu_01TGoeQKSWQAZdH46nh6fp1A","timestamp":"2026-02-21T08:50:04.626Z","uuid":"698f8d2d-6ffe-4a96-b267-fda98d25ad0d"}
{"parentUuid":"51875341-c168-43ee-a125-9937a46a6b28","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01TGoeQKSWQAZdH46nh6fp1A","type":"tool_result","content":"410:    path: str = Query(None, description=\"Optional file path to filter by\"),\n431:    path: str = Query(None, description=\"Optional file path to filter by\"),\n452:    path: str = Query(None, description=\"Optional file path to filter by\"),\n682:    language: str = Query(None, description=\"Optional language filter\"),"}]},"uuid":"21e1277d-6a2e-4a27-92d3-7fedb2031a5c","timestamp":"2026-02-21T08:50:04.625Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"410:    path: str = Query(None, description=\"Optional file path to filter by\"),\n431:    path: str = Query(None, description=\"Optional file path to filter by\"),\n452:    path: str = Query(None, description=\"Optional file path to filter by\"),\n682:    language: str = Query(None, description=\"Optional language filter\"),","numLines":4},"sourceToolAssistantUUID":"51875341-c168-43ee-a125-9937a46a6b28"}
{"parentUuid":"21e1277d-6a2e-4a27-92d3-7fedb2031a5c","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Grep","command":"callback"},"parentToolUseID":"toolu_01TGxEqtr7WmNaWztqZdKNGP","toolUseID":"toolu_01TGxEqtr7WmNaWztqZdKNGP","timestamp":"2026-02-21T08:50:04.806Z","uuid":"0e98f799-6e08-4e83-b3ad-58ade361923e"}
{"parentUuid":"bd01b211-3b50-44cf-a62b-5e5b54ce6d3c","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01TGxEqtr7WmNaWztqZdKNGP","type":"tool_result","content":"557:        RETURN f.source_code as source_code\n697:               symbol.docstring as docstring, symbol.source_code as source_code\n900:        RETURN f.source_code as source_code, f.path as path\n975:        RETURN s.source_code as source_code\n1100:        RETURN m.source_code as source_code\n1109:        RETURN f.source_code as source_code\n1118:        RETURN c.source_code as source_code\n1460:            RETURN f.source_code as source_code, f.relative_path as path"}]},"uuid":"f0bb8cab-0f38-4041-aee4-393ef12fb980","timestamp":"2026-02-21T08:50:04.805Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"557:        RETURN f.source_code as source_code\n697:               symbol.docstring as docstring, symbol.source_code as source_code\n900:        RETURN f.source_code as source_code, f.path as path\n975:        RETURN s.source_code as source_code\n1100:        RETURN m.source_code as source_code\n1109:        RETURN f.source_code as source_code\n1118:        RETURN c.source_code as source_code\n1460:            RETURN f.source_code as source_code, f.relative_path as path","numLines":8},"sourceToolAssistantUUID":"bd01b211-3b50-44cf-a62b-5e5b54ce6d3c"}
{"parentUuid":"f0bb8cab-0f38-4041-aee4-393ef12fb980","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01TrpnbQ9YkjpT52JDQ2VA57","type":"message","role":"assistant","content":[{"type":"text","text":"Unused imports are gone. The only `source_code` fetch remaining in the search path is the single-file peek — all the rest is either individual symbol reads (small) or already cleaned up. \n\nHere's the complete audit summary:\n\n---\n\n## Audit results\n\n### What was fixed\n\n| Issue | Severity | Fix |\n|---|---|---|\n| `Body`, `Optional`, `os` unused imports | Low | Removed — also silenced the Pylance warnings |\n| No query length limit | Medium | 500-char max on `/search` and `/code-finder/line`; `above`/`below` capped at 200 on peek |\n| `search_file_content` fetching full `source_code` blobs | **High** | Rewrote to do `split + UNWIND + CONTAINS` entirely in Cypher — only matching lines returned over the wire |\n| `search_file_content` CONTAINS fallback full table scan | **High** | Added `size(source_code) < 500 000` guard; Cypher now does the split server-side (5 files max in fallback) |\n| `peek_file_lines` no size guard | Medium | Added `size(source_code) < 2 000 000` in the Cypher query — rejects minified/generated files before they're transferred |\n| `line < 1` not validated on peek | Low | Added `line < 1` → 400 check in the endpoint |\n\n### What was already good (no change needed)\n\n- **Cypher injection** — all queries use parameterised parameters via the Neo4j driver. Injection is not possible.\n- **Lucene injection** — `_escape_lucene_query` extracts only word-char identifiers (`\\b[A-Za-z_][A-Za-z0-9_]{2,}\\b`) before building the Lucene query. No raw user text reaches the index parser.\n- **Path traversal on peek** — the `path` param queries Neo4j (not the filesystem), so you can only read files already indexed in the graph. No risk.\n- **Tier 1 and Tier 2 speed** — fulltext index is O(log n), name CONTAINS is acceptable for typical graph sizes (~100 K nodes ≈ <100 ms).\n\n### What needs infra-level work (can't fix here)\n- **Rate limiting** — needs middleware (e.g. `slowapi`) or an API gateway. Not something to add in the query handler."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":521,"cache_read_input_tokens":149374,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":521},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvjNN8FSP1Sue8TNUx5","type":"assistant","uuid":"47731e6e-343b-4d94-8a37-4debd6111913","timestamp":"2026-02-21T08:50:24.107Z"}
{"parentUuid":"47731e6e-343b-4d94-8a37-4debd6111913","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"ecac71c5-6dc1-45f3-b962-9eee813d4b40","toolUseID":"ecac71c5-6dc1-45f3-b962-9eee813d4b40","timestamp":"2026-02-21T08:50:24.315Z","uuid":"dd39ec51-6915-43fc-ba4f-e85e47b10bae"}
{"parentUuid":"dd39ec51-6915-43fc-ba4f-e85e47b10bae","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":2052}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-21T08:50:26.369Z","uuid":"68a705e8-a42f-498f-8f3f-42f8349a4c7b","toolUseID":"ecac71c5-6dc1-45f3-b962-9eee813d4b40"}
{"parentUuid":"68a705e8-a42f-498f-8f3f-42f8349a4c7b","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"system","subtype":"turn_duration","durationMs":203377,"timestamp":"2026-02-21T08:50:26.371Z","uuid":"b7ebd012-cb5a-4340-b2ce-851ed9b01e2b","isMeta":false}
{"type":"file-history-snapshot","messageId":"a724e6d0-fc97-4a37-b12b-d349dba5f3c9","snapshot":{"messageId":"a724e6d0-fc97-4a37-b12b-d349dba5f3c9","trackedFileBackups":{"db/schema.py":{"backupFileName":"283975a9ba984ffc@v2","version":2,"backupTime":"2026-02-21T08:34:53.260Z"},"db/queries.py":{"backupFileName":"3dbb7f971a633538@v4","version":4,"backupTime":"2026-02-21T08:51:52.096Z"},"api/routers/query.py":{"backupFileName":"e6ad69c83e8fb9b0@v4","version":4,"backupTime":"2026-02-21T08:51:52.097Z"},"frontend/app/(protected)/query/page.tsx":{"backupFileName":"30dea031ecc29fcb@v3","version":3,"backupTime":"2026-02-21T08:47:02.991Z"},"frontend/lib/api.ts":{"backupFileName":"a3322355f2d59118@v2","version":2,"backupTime":"2026-02-21T08:47:02.991Z"},"Claude.md":{"backupFileName":"8ee2a4b8e81d0daa@v2","version":2,"backupTime":"2026-02-21T08:47:02.992Z"}},"timestamp":"2026-02-21T08:51:52.095Z"},"isSnapshotUpdate":false}
{"parentUuid":"b7ebd012-cb5a-4340-b2ce-851ed9b01e2b","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":"Can you explain the cyper query and how this full text search and it;s components work , I have no knowledge f the cyper , i don;t mind details"},"uuid":"a724e6d0-fc97-4a37-b12b-d349dba5f3c9","timestamp":"2026-02-21T08:51:49.294Z","todos":[],"permissionMode":"acceptEdits"}
{"parentUuid":"a724e6d0-fc97-4a37-b12b-d349dba5f3c9","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01PUK7T6hg8w8uvLJz7qQCMD","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The user wants a detailed explanation of Cypher query language and how the full-text search works in the context of BugViper. Let me give a thorough explanation covering:\n\n1. What Cypher is\n2. Graph database concepts (nodes, relationships, properties)\n3. The specific queries used in BugViper\n4. How Neo4j full-text indexes work (Lucene under the hood)\n5. The three-tier search strategy\n6. The escaping logic\n\nI'll use the actual code from the project to illustrate each concept. Let me read the relevant sections to make sure I'm accurate.","signature":"EsAFCkYICxgCKkBp1UxPNKFj/nu0ZJ2fDRy893OnNi4kgpjmTTYv1G4fBAXApMqVJsEr14Fxbv/2jE49JW/wSzZri6s2zb9xvbzKEgxs8fb0GbbQIym18qYaDIwskX/7S6ugX02V2SIwpAwz8U0ZYDUeDp2LRA14Btx4F4FsJVUk+9VHALJ0cFEtoSdjhvLQkMxQ/fdYZQDUKqcEOZx7Y58YPFhmFtkt9yDQbh8o8szVJ9E1fXXeKIWAweS5S3o8pgBbtqblqfgpZHPdIhCjaZmymCA6qxdtjDn89ALrhYU+YepHDE+Fk+71VduifW6qTeZm8dwNiBa/GURtM5Wv/eLGGg881zSIgU4cGlzroJKMEYAyeJcj9VFw3wLS1wRujVDBnN/agbVqJJDWKACbJcOlp4jbXbmGtsOz4Z/W5Y2RXXIU26VM3q9zD2j/N5eKZY35kaAc/9tHQd1GP9j4IKvcSga6QeBQCUwQjl9ELTO96bms+/303En4bZHFnhxylewtW3zw2CRnySzryL2IJQ/MsIqRC8SoFuhsfg2weLzRTH1e6V6gYKplJbPpVxBTkHJYEJ7P1uODgUGxt8FsZw1Rh8Gf96ra90rC00medLWCZNEnAg3pA4NS2YYwEnxDYdQMX2sRjAsd4evSD02EKW7ISRvrRnMj0WasK0WtQOwo9Gd4tgY7xBRzYluGpUt+ommmLkaLMho4Q2m2OqT1aUzrSDzetxI67UwN1KzJzVs9Pbm6tB7EMwtjInNQDly+eWeVap8g6RmVESA1leQrdxRhBUD2t/g0ojxPvvDJW5m3GMbPteaCJYTn571sJXlg+//A8snVGyEIN4Hwj/SNpKaxFyWBVGFDpqy7U00jbZTuGA9QqvCrrA124+bBOue6BfbnwkeeGlmOB5r+h8wRASfp/PTJGJc0tQbrZC6v8JGhoBYYAQ=="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":94,"cache_read_input_tokens":150480,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":94},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvsGQvCFmJhmN7M4Ywn","type":"assistant","uuid":"85a3bb82-cb27-4bf5-b449-b113a8873b2e","timestamp":"2026-02-21T08:51:56.274Z"}
{"parentUuid":"85a3bb82-cb27-4bf5-b449-b113a8873b2e","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01PUK7T6hg8w8uvLJz7qQCMD","type":"message","role":"assistant","content":[{"type":"text","text":"Let me pull up the actual queries so I can explain each part precisely."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":94,"cache_read_input_tokens":150480,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":94},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvsGQvCFmJhmN7M4Ywn","type":"assistant","uuid":"bc83c2cf-853e-4bbb-adbb-8ead79610403","timestamp":"2026-02-21T08:51:57.030Z"}
{"parentUuid":"bc83c2cf-853e-4bbb-adbb-8ead79610403","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01PUK7T6hg8w8uvLJz7qQCMD","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Gec9ugXQGQG8vsEfLRXtbb","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/db/schema.py","offset":68,"limit":20},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":94,"cache_read_input_tokens":150480,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":94},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvsGQvCFmJhmN7M4Ywn","type":"assistant","uuid":"79920a6e-05a3-4c3b-9ead-65f5c8a47aa5","timestamp":"2026-02-21T08:51:57.934Z"}
{"parentUuid":"79920a6e-05a3-4c3b-9ead-65f5c8a47aa5","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01Gec9ugXQGQG8vsEfLRXtbb","toolUseID":"toolu_01Gec9ugXQGQG8vsEfLRXtbb","timestamp":"2026-02-21T08:51:58.136Z","uuid":"cc0d4f0b-5930-42de-8c6b-3d4501fdba57"}
{"parentUuid":"79920a6e-05a3-4c3b-9ead-65f5c8a47aa5","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Gec9ugXQGQG8vsEfLRXtbb","type":"tool_result","content":"    68→            # Config file indexes\n    69→            \"CREATE INDEX config_file_type IF NOT EXISTS FOR (cf:ConfigFile) ON (cf.file_type)\",\n    70→            \"CREATE INDEX dependency_name IF NOT EXISTS FOR (d:Dependency) ON (d.name)\",\n    71→            \"CREATE INDEX dependency_source IF NOT EXISTS FOR (d:Dependency) ON (d.source)\",\n    72→\n    73→            # Full-text search indexes for code search (including source_code)\n    74→            \"CREATE FULLTEXT INDEX code_search IF NOT EXISTS FOR (n:Class|Function|Method|Variable|Symbol) ON EACH [n.name, n.docstring, n.source_code]\",\n    75→            \"CREATE FULLTEXT INDEX symbol_search IF NOT EXISTS FOR (s:Symbol) ON EACH [s.name, s.qualified_name, s.docstring]\",\n    76→            \"CREATE FULLTEXT INDEX file_content_search IF NOT EXISTS FOR (f:File) ON EACH [f.source_code]\",\n    77→        ]\n    78→        \n    79→        for constraint in constraints:\n    80→            try:\n    81→                self.db.run_query(constraint)\n    82→                print(\"✓ Created constraint\")\n    83→            except Exception as e:\n    84→                if \"already exists\" not in str(e).lower():\n    85→                    print(f\"⚠ Constraint warning: {e}\")\n    86→        \n    87→        for index in indexes:\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"c1677667-5eda-41c7-a552-d406cf14f820","timestamp":"2026-02-21T08:51:58.135Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/db/schema.py","content":"            # Config file indexes\n            \"CREATE INDEX config_file_type IF NOT EXISTS FOR (cf:ConfigFile) ON (cf.file_type)\",\n            \"CREATE INDEX dependency_name IF NOT EXISTS FOR (d:Dependency) ON (d.name)\",\n            \"CREATE INDEX dependency_source IF NOT EXISTS FOR (d:Dependency) ON (d.source)\",\n\n            # Full-text search indexes for code search (including source_code)\n            \"CREATE FULLTEXT INDEX code_search IF NOT EXISTS FOR (n:Class|Function|Method|Variable|Symbol) ON EACH [n.name, n.docstring, n.source_code]\",\n            \"CREATE FULLTEXT INDEX symbol_search IF NOT EXISTS FOR (s:Symbol) ON EACH [s.name, s.qualified_name, s.docstring]\",\n            \"CREATE FULLTEXT INDEX file_content_search IF NOT EXISTS FOR (f:File) ON EACH [f.source_code]\",\n        ]\n        \n        for constraint in constraints:\n            try:\n                self.db.run_query(constraint)\n                print(\"✓ Created constraint\")\n            except Exception as e:\n                if \"already exists\" not in str(e).lower():\n                    print(f\"⚠ Constraint warning: {e}\")\n        \n        for index in indexes:","numLines":20,"startLine":68,"totalLines":1264}},"sourceToolAssistantUUID":"79920a6e-05a3-4c3b-9ead-65f5c8a47aa5"}
{"parentUuid":"c1677667-5eda-41c7-a552-d406cf14f820","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01PUK7T6hg8w8uvLJz7qQCMD","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01QPcxLwC7hfmjfk2tAfNMHz","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/db/schema.py","offset":811,"limit":45},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":94,"cache_read_input_tokens":150480,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":94},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLvsGQvCFmJhmN7M4Ywn","type":"assistant","uuid":"009bc5d7-8338-45bf-8427-bef818380b2e","timestamp":"2026-02-21T08:51:58.725Z"}
{"parentUuid":"009bc5d7-8338-45bf-8427-bef818380b2e","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_01QPcxLwC7hfmjfk2tAfNMHz","toolUseID":"toolu_01QPcxLwC7hfmjfk2tAfNMHz","timestamp":"2026-02-21T08:51:58.911Z","uuid":"c64cd3f4-06c9-4274-9066-da23c0607ad5"}
{"parentUuid":"009bc5d7-8338-45bf-8427-bef818380b2e","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01QPcxLwC7hfmjfk2tAfNMHz","type":"tool_result","content":"   811→    \"search_code\": \"\"\"\n   812→        CALL db.index.fulltext.queryNodes('code_search', $search_term)\n   813→        YIELD node, score\n   814→        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n   815→        RETURN\n   816→            CASE WHEN node:Function THEN 'function'\n   817→                 WHEN node:Class THEN 'class'\n   818→                 ELSE 'variable' END as type,\n   819→            node.name as name,\n   820→            coalesce(f.path, node.path) as path,\n   821→            coalesce(node.line_number, 0) as line_number,\n   822→            score\n   823→        ORDER BY score DESC\n   824→        LIMIT 20\n   825→    \"\"\",\n   826→\n   827→    \"search_symbols\": \"\"\"\n   828→        CALL db.index.fulltext.queryNodes('code_search', $search_term)\n   829→        YIELD node, score\n   830→        WHERE node:Function OR node:Class OR node:Variable\n   831→        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n   832→        RETURN\n   833→            node.name as name,\n   834→            CASE WHEN node:Function THEN 'function'\n   835→                 WHEN node:Class THEN 'class'\n   836→                 ELSE 'variable' END as type,\n   837→            coalesce(f.path, node.path) as path,\n   838→            coalesce(node.line_number, 0) as line_number,\n   839→            score\n   840→        ORDER BY score DESC\n   841→        LIMIT $limit\n   842→    \"\"\",\n   843→\n   844→    \"search_symbols_by_qualified_name\": \"\"\"\n   845→        MATCH (s:Symbol)\n   846→        WHERE s.qualified_name = $qualified_name\n   847→          AND s.file_id STARTS WITH $repo_id\n   848→        RETURN s.id as id,\n   849→               s.name as name,\n   850→               s.qualified_name as qualified_name,\n   851→               s.type as type,\n   852→               s.file_id as file_id,\n   853→               s.line_start as line_start,\n   854→               s.line_end as line_end,\n   855→               s.scope as scope,\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"ebfa16e8-4d53-4215-a5f2-afd7caeec04b","timestamp":"2026-02-21T08:51:58.910Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/db/schema.py","content":"    \"search_code\": \"\"\"\n        CALL db.index.fulltext.queryNodes('code_search', $search_term)\n        YIELD node, score\n        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n        RETURN\n            CASE WHEN node:Function THEN 'function'\n                 WHEN node:Class THEN 'class'\n                 ELSE 'variable' END as type,\n            node.name as name,\n            coalesce(f.path, node.path) as path,\n            coalesce(node.line_number, 0) as line_number,\n            score\n        ORDER BY score DESC\n        LIMIT 20\n    \"\"\",\n\n    \"search_symbols\": \"\"\"\n        CALL db.index.fulltext.queryNodes('code_search', $search_term)\n        YIELD node, score\n        WHERE node:Function OR node:Class OR node:Variable\n        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n        RETURN\n            node.name as name,\n            CASE WHEN node:Function THEN 'function'\n                 WHEN node:Class THEN 'class'\n                 ELSE 'variable' END as type,\n            coalesce(f.path, node.path) as path,\n            coalesce(node.line_number, 0) as line_number,\n            score\n        ORDER BY score DESC\n        LIMIT $limit\n    \"\"\",\n\n    \"search_symbols_by_qualified_name\": \"\"\"\n        MATCH (s:Symbol)\n        WHERE s.qualified_name = $qualified_name\n          AND s.file_id STARTS WITH $repo_id\n        RETURN s.id as id,\n               s.name as name,\n               s.qualified_name as qualified_name,\n               s.type as type,\n               s.file_id as file_id,\n               s.line_start as line_start,\n               s.line_end as line_end,\n               s.scope as scope,","numLines":45,"startLine":811,"totalLines":1264}},"sourceToolAssistantUUID":"009bc5d7-8338-45bf-8427-bef818380b2e"}
{"parentUuid":"ebfa16e8-4d53-4215-a5f2-afd7caeec04b","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01PUK7T6hg8w8uvLJz7qQCMD","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0172RcC2VxpSU5pdLWdp2os5","name":"Read","input":{"file_path":"/Users/skmabudalam/Documents/BugViper/db/queries.py","offset":278,"limit":90},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":94,"cache_read_input_tokens":150480,"output_tokens":451,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":94,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLvsGQvCFmJhmN7M4Ywn","type":"assistant","uuid":"7db566f4-6d9f-4d64-8c5d-31cbd8b41f3d","timestamp":"2026-02-21T08:51:59.301Z"}
{"parentUuid":"7db566f4-6d9f-4d64-8c5d-31cbd8b41f3d","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Read","command":"callback"},"parentToolUseID":"toolu_0172RcC2VxpSU5pdLWdp2os5","toolUseID":"toolu_0172RcC2VxpSU5pdLWdp2os5","timestamp":"2026-02-21T08:51:59.506Z","uuid":"427d0d28-a9b1-46db-ba97-e3bb7a8b5e2e"}
{"parentUuid":"7db566f4-6d9f-4d64-8c5d-31cbd8b41f3d","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0172RcC2VxpSU5pdLWdp2os5","type":"tool_result","content":"   278→    # Python/JS keywords that should not be used as search identifiers\n   279→    _CODE_KEYWORDS = frozenset({\n   280→        'class', 'def', 'import', 'from', 'return', 'self', 'cls', 'None',\n   281→        'True', 'False', 'and', 'or', 'not', 'in', 'is', 'if', 'else',\n   282→        'elif', 'for', 'while', 'try', 'except', 'with', 'as', 'pass',\n   283→        'break', 'continue', 'raise', 'yield', 'async', 'await', 'lambda',\n   284→        'function', 'const', 'let', 'var', 'new', 'this', 'super',\n   285→    })\n   286→\n   287→    def _extract_identifiers(self, query: str) -> List[str]:\n   288→        \"\"\"Extract meaningful code identifiers from a raw query string.\"\"\"\n   289→        tokens = re.findall(r'\\b[A-Za-z_][A-Za-z0-9_]{2,}\\b', query)\n   290→        seen: set = set()\n   291→        result = []\n   292→        for t in tokens:\n   293→            if t not in self._CODE_KEYWORDS and t not in seen:\n   294→                seen.add(t)\n   295→                result.append(t)\n   296→        return result\n   297→\n   298→    def _escape_lucene_query(self, query: str) -> str:\n   299→        \"\"\"\n   300→        Build a safe Lucene query string.\n   301→\n   302→        Strategy:\n   303→        - Simple identifier (word chars only) → phrase search  e.g. \"LoginRequest\"\n   304→        - Complex query with special chars     → AND-keyword strategy\n   305→          e.g. \"class GitHubRepo(BaseModel)\" → \"GitHubRepo\" AND \"BaseModel\"\n   306→          This avoids Lucene parse errors while still matching meaningful tokens.\n   307→        \"\"\"\n   308→        query = query.strip()\n   309→        if not query:\n   310→            return '*'\n   311→\n   312→        # Simple identifier — use phrase search directly\n   313→        if re.match(r'^[A-Za-z0-9_]+$', query):\n   314→            return f'\"{query}\"'\n   315→\n   316→        # Complex query — extract identifiers and build AND search\n   317→        identifiers = self._extract_identifiers(query)\n   318→        if identifiers:\n   319→            # Cap at 3 identifiers to keep the query lean\n   320→            return ' AND '.join(f'\"{t}\"' for t in identifiers[:3])\n   321→\n   322→        # Pure symbols / numbers with no useful identifiers — wrap and hope for best\n   323→        escaped = query.replace('\"', '\\\\\"')\n   324→        return f'\"{escaped}\"'\n   325→\n   326→    def _name_contains_fallback(\n   327→        self,\n   328→        search_term: str,\n   329→        limit: int = 20,\n   330→    ) -> List[Dict[str, Any]]:\n   331→        \"\"\"\n   332→        CONTAINS fallback against node names.\n   333→        Uses the primary identifier extracted from the search term so that\n   334→        queries like 'class GitHubRepo(BaseModel)' still find 'GitHubRepo'.\n   335→        \"\"\"\n   336→        identifiers = self._extract_identifiers(search_term)\n   337→        # Use the first (longest) identifier, falling back to raw term\n   338→        name_term = max(identifiers, key=len) if identifiers else search_term\n   339→\n   340→        fallback = \"\"\"\n   341→        MATCH (node)\n   342→        WHERE (node:Function OR node:Class OR node:Variable)\n   343→          AND node.name CONTAINS $name_term\n   344→        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n   345→        RETURN\n   346→            CASE WHEN node:Function THEN 'function'\n   347→                 WHEN node:Class THEN 'class'\n   348→                 ELSE 'variable' END as type,\n   349→            node.name as name,\n   350→            coalesce(f.path, node.path) as path,\n   351→            coalesce(node.line_number, 0) as line_number,\n   352→            1.0 as score\n   353→        ORDER BY node.name\n   354→        LIMIT $limit\n   355→        \"\"\"\n   356→        records, _, _ = self.db.run_query(fallback, {\"name_term\": name_term, \"limit\": limit})\n   357→        return [\n   358→            {\n   359→                \"type\": record[\"type\"],\n   360→                \"name\": record[\"name\"],\n   361→                \"path\": record[\"path\"],\n   362→                \"line_number\": record[\"line_number\"],\n   363→                \"score\": record[\"score\"],\n   364→            }\n   365→            for record in records\n   366→        ]\n   367→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"34253407-8df5-4224-bffa-e533bb11e395","timestamp":"2026-02-21T08:51:59.505Z","toolUseResult":{"type":"text","file":{"filePath":"/Users/skmabudalam/Documents/BugViper/db/queries.py","content":"    # Python/JS keywords that should not be used as search identifiers\n    _CODE_KEYWORDS = frozenset({\n        'class', 'def', 'import', 'from', 'return', 'self', 'cls', 'None',\n        'True', 'False', 'and', 'or', 'not', 'in', 'is', 'if', 'else',\n        'elif', 'for', 'while', 'try', 'except', 'with', 'as', 'pass',\n        'break', 'continue', 'raise', 'yield', 'async', 'await', 'lambda',\n        'function', 'const', 'let', 'var', 'new', 'this', 'super',\n    })\n\n    def _extract_identifiers(self, query: str) -> List[str]:\n        \"\"\"Extract meaningful code identifiers from a raw query string.\"\"\"\n        tokens = re.findall(r'\\b[A-Za-z_][A-Za-z0-9_]{2,}\\b', query)\n        seen: set = set()\n        result = []\n        for t in tokens:\n            if t not in self._CODE_KEYWORDS and t not in seen:\n                seen.add(t)\n                result.append(t)\n        return result\n\n    def _escape_lucene_query(self, query: str) -> str:\n        \"\"\"\n        Build a safe Lucene query string.\n\n        Strategy:\n        - Simple identifier (word chars only) → phrase search  e.g. \"LoginRequest\"\n        - Complex query with special chars     → AND-keyword strategy\n          e.g. \"class GitHubRepo(BaseModel)\" → \"GitHubRepo\" AND \"BaseModel\"\n          This avoids Lucene parse errors while still matching meaningful tokens.\n        \"\"\"\n        query = query.strip()\n        if not query:\n            return '*'\n\n        # Simple identifier — use phrase search directly\n        if re.match(r'^[A-Za-z0-9_]+$', query):\n            return f'\"{query}\"'\n\n        # Complex query — extract identifiers and build AND search\n        identifiers = self._extract_identifiers(query)\n        if identifiers:\n            # Cap at 3 identifiers to keep the query lean\n            return ' AND '.join(f'\"{t}\"' for t in identifiers[:3])\n\n        # Pure symbols / numbers with no useful identifiers — wrap and hope for best\n        escaped = query.replace('\"', '\\\\\"')\n        return f'\"{escaped}\"'\n\n    def _name_contains_fallback(\n        self,\n        search_term: str,\n        limit: int = 20,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        CONTAINS fallback against node names.\n        Uses the primary identifier extracted from the search term so that\n        queries like 'class GitHubRepo(BaseModel)' still find 'GitHubRepo'.\n        \"\"\"\n        identifiers = self._extract_identifiers(search_term)\n        # Use the first (longest) identifier, falling back to raw term\n        name_term = max(identifiers, key=len) if identifiers else search_term\n\n        fallback = \"\"\"\n        MATCH (node)\n        WHERE (node:Function OR node:Class OR node:Variable)\n          AND node.name CONTAINS $name_term\n        OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n        RETURN\n            CASE WHEN node:Function THEN 'function'\n                 WHEN node:Class THEN 'class'\n                 ELSE 'variable' END as type,\n            node.name as name,\n            coalesce(f.path, node.path) as path,\n            coalesce(node.line_number, 0) as line_number,\n            1.0 as score\n        ORDER BY node.name\n        LIMIT $limit\n        \"\"\"\n        records, _, _ = self.db.run_query(fallback, {\"name_term\": name_term, \"limit\": limit})\n        return [\n            {\n                \"type\": record[\"type\"],\n                \"name\": record[\"name\"],\n                \"path\": record[\"path\"],\n                \"line_number\": record[\"line_number\"],\n                \"score\": record[\"score\"],\n            }\n            for record in records\n        ]\n","numLines":90,"startLine":278,"totalLines":1865}},"sourceToolAssistantUUID":"7db566f4-6d9f-4d64-8c5d-31cbd8b41f3d"}
{"parentUuid":"34253407-8df5-4224-bffa-e533bb11e395","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01NNveL46HWPopH1PiHurx3F","type":"message","role":"assistant","content":[{"type":"text","text":"Good — I have everything I need. Here's the full breakdown.\n\n---\n\n## Part 1 — What is Cypher?\n\nCypher is Neo4j's query language. Think of it like SQL but for graphs instead of tables.\n\nIn SQL you say: \"find rows in a table where column = value\"  \nIn Cypher you say: \"find **nodes** with certain **labels** connected by certain **relationships**\"\n\nThe data model has three things:\n\n```\nNODE        — like a row. Has a label (type) and properties (key/value).\n              Example: a Function node with {name: \"login\", line_number: 42}\n\nRELATIONSHIP — a directed edge between two nodes. Has a type.\n              Example: (File)-[:CONTAINS]->(Function)\n              Means \"this file contains this function\"\n\nPROPERTY    — a key/value on a node or relationship.\n              Example: node.name, relationship.line_number\n```\n\nIn BugViper your graph looks like this:\n\n```\n(Repository)-[:CONTAINS]->(File)-[:CONTAINS]->(Function)\n                                              ->(Class)-[:CONTAINS]->(Function)  ← methods\n                                              ->(Variable)\n(File)-[:IMPORTS]->(Module)\n(Function)-[:CALLS]->(Function)\n(Class)-[:INHERITS]->(Class)\n```\n\n---\n\n## Part 2 — Reading a basic Cypher query\n\nLet's take the name CONTAINS fallback from `db/queries.py:340`:\n\n```cypher\nMATCH (node)\nWHERE (node:Function OR node:Class OR node:Variable)\n  AND node.name CONTAINS $name_term\nOPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\nRETURN\n    CASE WHEN node:Function THEN 'function'\n         WHEN node:Class THEN 'class'\n         ELSE 'variable' END as type,\n    node.name as name,\n    coalesce(f.path, node.path) as path,\n    coalesce(node.line_number, 0) as line_number,\n    1.0 as score\nORDER BY node.name\nLIMIT $limit\n```\n\nLine by line:\n\n```cypher\nMATCH (node)\n```\nFind **any** node in the graph. `node` is just a variable name (could be anything).\n\n```cypher\nWHERE (node:Function OR node:Class OR node:Variable)\n  AND node.name CONTAINS $name_term\n```\nFilter it: only keep nodes whose **label** is Function, Class, or Variable **and** whose `name` property contains the search term as a substring.  \n`$name_term` is a parameter — the Python driver substitutes the actual value safely (prevents injection).\n\n```cypher\nOPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n```\nTry to find a File that is connected to our node via a `[:CONTAINS]` relationship. `OPTIONAL` means \"if no File is found, keep the row anyway with `f = null`\" — like a LEFT JOIN in SQL.\n\n```cypher\nRETURN\n    CASE WHEN node:Function THEN 'function'\n         WHEN node:Class THEN 'class'\n         ELSE 'variable' END as type,\n```\nBuild a string from the node's label. Cypher's `CASE` is exactly like SQL's `CASE WHEN`.\n\n```cypher\n    coalesce(f.path, node.path) as path,\n```\n`coalesce()` returns the first non-null value. Some nodes store `path` directly on themselves; others only have it via the File. This handles both cases.\n\n```cypher\nORDER BY node.name\nLIMIT $limit\n```\nSort results alphabetically by name, cap at `limit` rows.\n\n---\n\n## Part 3 — The three fulltext indexes\n\nDefined in `db/schema.py:74–76`:\n\n```cypher\nCREATE FULLTEXT INDEX code_search\n  FOR (n:Class|Function|Method|Variable|Symbol)\n  ON EACH [n.name, n.docstring, n.source_code]\n\nCREATE FULLTEXT INDEX file_content_search\n  FOR (f:File)\n  ON EACH [f.source_code]\n```\n\n**What a fulltext index actually is:**  \nNeo4j uses **Apache Lucene** under the hood — the same engine that powers Elasticsearch. When you ingest a repository, Neo4j feeds every node's `name`, `docstring`, and `source_code` into Lucene. Lucene breaks the text into **tokens** (individual words, split by whitespace and punctuation), builds an **inverted index** (a map of `token → list of nodes that contain it`), and stores it on disk.\n\nAt query time, instead of scanning every node, Neo4j looks up tokens in the inverted index — O(log n), like a book index. That's why fulltext search is so much faster than `CONTAINS`.\n\n**`code_search`** covers `Function`, `Class`, `Variable`, `Method`, `Symbol` nodes — on their `name`, `docstring`, and `source_code` fields. So searching for `\"LoginRequest\"` will find:\n- A Class node whose **name** is `LoginRequest`\n- A Function node whose **docstring** mentions `LoginRequest`\n- A Variable node whose **source_code** contains it\n\n**`file_content_search`** covers only `File` nodes on `source_code`. This is for raw line searches — you're searching the file as a blob of text.\n\n---\n\n## Part 4 — The fulltext CALL query\n\n```cypher\nCALL db.index.fulltext.queryNodes('code_search', $search_term)\nYIELD node, score\nOPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\nRETURN\n    CASE WHEN node:Function THEN 'function'\n         WHEN node:Class THEN 'class'\n         ELSE 'variable' END as type,\n    node.name as name,\n    coalesce(f.path, node.path) as path,\n    coalesce(node.line_number, 0) as line_number,\n    score\nORDER BY score DESC\nLIMIT 20\n```\n\n`CALL db.index.fulltext.queryNodes(...)` — this is a **stored procedure** built into Neo4j. You pass it the index name and a Lucene query string.\n\n`YIELD node, score` — \"give me back each matching node and its relevance score (0.0–1.0, higher = better match)\". `YIELD` is Cypher's way of unpacking the output of a procedure call.\n\nEverything after `YIELD` is normal Cypher — you can `WHERE`, `MATCH`, `RETURN` as usual.\n\n---\n\n## Part 5 — The Lucene query language (what gets sent to `$search_term`)\n\nLucene has its own mini query language. This is what `_escape_lucene_query()` builds.\n\n**Phrase search** — `\"LoginRequest\"` (double quotes)  \nFinds nodes where any indexed field contains the exact word `LoginRequest`. Faster and more precise than a raw term.\n\n**AND search** — `\"GitHubRepo\" AND \"BaseModel\"`  \nBoth tokens must appear somewhere in the indexed fields. Order doesn't matter. This is what we build when the raw query is `class GitHubRepo(BaseModel)`.\n\n**Why we can't just pass `class GitHubRepo(BaseModel):` raw:**  \nLucene treats `(`, `)`, `:` as special syntax characters — grouping, field selectors, boosting. Passing them unescaped crashes the parser with the error you saw earlier.\n\n**The escaping logic in `_escape_lucene_query`** (`db/queries.py:298`):\n\n```\nInput: \"LoginRequest\"             → simple identifier → \"LoginRequest\"\nInput: \"class GitHubRepo(BaseModel):\" → has special chars →\n   1. Extract word-character tokens: ['class', 'GitHubRepo', 'BaseModel']\n   2. Strip code keywords: ['GitHubRepo', 'BaseModel']\n   3. Cap at 3, wrap in quotes: \"GitHubRepo\" AND \"BaseModel\"\n```\n\n---\n\n## Part 6 — The server-side line scan (file_content_search)\n\nThe most interesting query — all happens inside Neo4j, no data sent to Python (`db/queries.py:480`):\n\n```cypher\nCALL db.index.fulltext.queryNodes('file_content_search', $search_term)\nYIELD node, score\nWHERE node.source_code IS NOT NULL\n  AND size(node.source_code) < $max_bytes   -- skip files > 500KB\nWITH node, score, split(node.source_code, '\\n') as lines\nLIMIT 10                                    -- process at most 10 files\nUNWIND range(0, size(lines) - 1) AS idx    -- expand into one row per line\nWITH node.path AS path, lines[idx] AS line_content, idx + 1 AS line_number, score\nWHERE toLower(line_content) CONTAINS toLower($raw_term)\nRETURN path, line_number, line_content AS match_line\nORDER BY score DESC, path, line_number\nLIMIT $limit\n```\n\nStep by step:\n\n1. **Fulltext index** finds `File` nodes whose `source_code` contains the tokens — fast, Lucene lookup\n2. **`size() < $max_bytes`** — skip any minified/generated files over 500 KB\n3. **`split(node.source_code, '\\n') as lines`** — split the file into an array of lines, server-side in Neo4j\n4. **`LIMIT 10`** — only process the 10 best-matching files (applied before UNWIND to control row explosion)\n5. **`UNWIND range(0, size(lines) - 1) AS idx`** — this is like a `for` loop. Takes the array `[0, 1, 2, ... N]` and turns it into one row per index. Each row now represents one line\n6. **`WHERE line_content CONTAINS $raw_term`** — filter to only lines that actually match (case-insensitive)\n7. **`RETURN path, line_number, match_line`** — only the lean result comes back over the network. The full source_code blob never leaves Neo4j\n\nBefore this change, all `source_code` blobs were sent to Python and scanned there — potentially megabytes of transfer for large repos. Now only the matching lines cross the wire.\n\n---\n\n## Part 7 — The full three-tier strategy in plain English\n\n```\nUser types: \"class GitHubRepo(BaseModel)\"\n                        │\n                        ▼\n         ┌──────────────────────────────┐\n         │ TIER 1: Lucene fulltext      │\n         │ Lucene query:                │\n         │ \"GitHubRepo\" AND \"BaseModel\" │\n         │ Searches: Function, Class,   │\n         │ Variable nodes on name/      │\n         │ docstring/source_code        │\n         └──────────────┬───────────────┘\n                        │ results? → return them\n                        │ empty?  ↓\n         ┌──────────────────────────────┐\n         │ TIER 2: name CONTAINS        │\n         │ Picks longest identifier:    │\n         │ \"GitHubRepo\"                 │\n         │ node.name CONTAINS \"GitHubRepo\" │\n         │ (substring scan on all nodes)│\n         └──────────────┬───────────────┘\n                        │ results? → return them\n                        │ empty?  ↓\n         ┌──────────────────────────────┐\n         │ TIER 3: File content lines   │\n         │ Lucene on file_content_search│\n         │ then server-side line scan   │\n         │ Returns: path + line number  │\n         │ + the actual matching line   │\n         └──────────────────────────────┘\n```\n\nTier 1 is for \"I know the symbol name\". Tier 2 is for \"fulltext index missed it but name matches\". Tier 3 is for \"I'm searching for a raw code snippet or declaration that might not be a symbol\"."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3073,"cache_read_input_tokens":150574,"output_tokens":2968,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":3073,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLvsoxE6t5kSkMwbspj4","type":"assistant","uuid":"483ef089-0fba-48c5-9372-4ee87b5127f2","timestamp":"2026-02-21T08:52:55.423Z"}
{"parentUuid":"483ef089-0fba-48c5-9372-4ee87b5127f2","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"767551c4-7f54-45a5-8f6c-8ba6f1778390","toolUseID":"767551c4-7f54-45a5-8f6c-8ba6f1778390","timestamp":"2026-02-21T08:52:55.428Z","uuid":"29356e29-0638-46d7-a39a-a40b2969a023"}
{"parentUuid":"29356e29-0638-46d7-a39a-a40b2969a023","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":1516}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-21T08:52:56.945Z","uuid":"3b9653fa-7f16-4097-a6d6-5368d3dc0603","toolUseID":"767551c4-7f54-45a5-8f6c-8ba6f1778390"}
{"parentUuid":"3b9653fa-7f16-4097-a6d6-5368d3dc0603","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"system","subtype":"turn_duration","durationMs":64848,"timestamp":"2026-02-21T08:52:56.947Z","uuid":"43414d4e-71b4-4d2a-b666-dde6050a37ef","isMeta":false}
{"type":"file-history-snapshot","messageId":"c7720134-7b4f-4513-9ac8-3a31601ecc93","snapshot":{"messageId":"c7720134-7b4f-4513-9ac8-3a31601ecc93","trackedFileBackups":{"db/schema.py":{"backupFileName":"283975a9ba984ffc@v2","version":2,"backupTime":"2026-02-21T08:34:53.260Z"},"db/queries.py":{"backupFileName":"3dbb7f971a633538@v4","version":4,"backupTime":"2026-02-21T08:51:52.096Z"},"api/routers/query.py":{"backupFileName":"e6ad69c83e8fb9b0@v4","version":4,"backupTime":"2026-02-21T08:51:52.097Z"},"frontend/app/(protected)/query/page.tsx":{"backupFileName":"30dea031ecc29fcb@v3","version":3,"backupTime":"2026-02-21T08:47:02.991Z"},"frontend/lib/api.ts":{"backupFileName":"a3322355f2d59118@v2","version":2,"backupTime":"2026-02-21T08:47:02.991Z"},"Claude.md":{"backupFileName":"8ee2a4b8e81d0daa@v2","version":2,"backupTime":"2026-02-21T08:47:02.992Z"}},"timestamp":"2026-02-21T09:12:24.960Z"},"isSnapshotUpdate":false}
{"parentUuid":"43414d4e-71b4-4d2a-b666-dde6050a37ef","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":"Can you create a easy guide for someone who doesnot know about sql and explain all the qqueres like coasclale , and other query language of the cyper , I know no sql (firestore ) . Put the guide in a .md file "},"uuid":"c7720134-7b4f-4513-9ac8-3a31601ecc93","timestamp":"2026-02-21T09:12:21.636Z","todos":[],"permissionMode":"acceptEdits"}
{"parentUuid":"c7720134-7b4f-4513-9ac8-3a31601ecc93","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01PLgdSzqwwnvsFCHcPxEvw8","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The user wants a comprehensive guide to Cypher query language written for someone with no SQL knowledge (they know Firestore). They want it in a .md file. Let me create a detailed, beginner-friendly guide that:\n\n1. Explains graph databases vs Firestore (what they know)\n2. Covers all core Cypher concepts\n3. Explains every function/keyword used in BugViper's actual queries\n4. Uses clear analogies and examples\n\nLet me think about what to cover:\n- What is a graph database vs Firestore\n- Nodes, relationships, properties\n- MATCH\n- WHERE\n\n\n- RETURN, aliasing, OPTIONAL MATCH, CASE WHEN, and functions like coalesce(), ORDER BY, LIMIT, WITH, CALL/YIELD, UNWIND, range(), split(), size(), toLower(), CONTAINS, STARTS WITH, count(), sum(), collect(), DISTINCT\n- CREATE, MERGE, DETACH DELETE\n- Parameters, labels, relationship types\n- Fulltext and property indexes\n\nI'll organize this as a proper guide with sections, examples, and relate everything back to Firestore concepts they already understand.\n\nWriting the Cypher guide...","signature":"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"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":58,"cache_read_input_tokens":156613,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":58},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLxSA7SKE1JigdP4z3hu","type":"assistant","uuid":"985e974c-ceef-4134-ab46-0d3fe4e27ec4","timestamp":"2026-02-21T09:12:37.506Z"}
{"parentUuid":"985e974c-ceef-4134-ab46-0d3fe4e27ec4","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01PLgdSzqwwnvsFCHcPxEvw8","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014nFU3fSmfCuEPPeJxXxS7m","name":"Bash","input":{"command":"ls /Users/skmabudalam/Documents/BugViper/*.md 2>/dev/null","description":"Check existing markdown files at project root"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":58,"cache_read_input_tokens":156613,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":58},"output_tokens":0,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLxSA7SKE1JigdP4z3hu","type":"assistant","uuid":"86df8a16-3d4a-4de6-ba88-ca143c9d3330","timestamp":"2026-02-21T09:12:39.306Z"}
{"parentUuid":"86df8a16-3d4a-4de6-ba88-ca143c9d3330","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014nFU3fSmfCuEPPeJxXxS7m","type":"tool_result","content":"/Users/skmabudalam/Documents/BugViper/Claude.md\n/Users/skmabudalam/Documents/BugViper/README.md","is_error":false}]},"uuid":"996f93ca-891e-4dd6-8835-086e3ae26934","timestamp":"2026-02-21T09:12:41.185Z","toolUseResult":{"stdout":"/Users/skmabudalam/Documents/BugViper/Claude.md\n/Users/skmabudalam/Documents/BugViper/README.md","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"86df8a16-3d4a-4de6-ba88-ca143c9d3330"}
{"parentUuid":"996f93ca-891e-4dd6-8835-086e3ae26934","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01EDWUjezm4LGsF9fp8YWqf5","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01RcVduRoAUotnb9oxNdr6Me","name":"Write","input":{"file_path":"REDACTED.md","content":"# Cypher Query Language — A Complete Beginner's Guide\n\n> Written for BugViper developers who know Firestore but have never touched SQL or Cypher.\n> Every concept is explained from scratch. Every function used in BugViper's codebase is covered.\n\n---\n\n## Table of Contents\n\n1. [Why a different database at all?](#1-why-a-different-database-at-all)\n2. [The three building blocks: Nodes, Relationships, Properties](#2-the-three-building-blocks)\n3. [How BugViper's data looks as a graph](#3-how-bugvipers-data-looks-as-a-graph)\n4. [Your first Cypher query — MATCH and RETURN](#4-your-first-cypher-query)\n5. [Filtering results — WHERE](#5-filtering-results--where)\n6. [String operators — CONTAINS, STARTS WITH, ENDS WITH](#6-string-operators)\n7. [Following relationships — pattern matching](#7-following-relationships)\n8. [Optional relationships — OPTIONAL MATCH](#8-optional-match)\n9. [Shaping output — AS, CASE WHEN, coalesce()](#9-shaping-output)\n10. [Sorting and limiting — ORDER BY, LIMIT, SKIP](#10-sorting-and-limiting)\n11. [Chaining steps — WITH](#11-chaining-steps--with)\n12. [Aggregation — count(), sum(), collect(), DISTINCT](#12-aggregation)\n13. [List operations — range(), UNWIND, split(), size()](#13-list-operations)\n14. [String functions — toLower(), toUpper(), trim(), left()](#14-string-functions)\n15. [Full-text search — CALL and YIELD](#15-full-text-search)\n16. [Parameters — the $variable syntax](#16-parameters)\n17. [Writing data — CREATE, MERGE, SET, DELETE](#17-writing-data)\n18. [Indexes — why queries are fast](#18-indexes)\n19. [Every query in BugViper explained line by line](#19-every-bugviper-query-explained)\n\n---\n\n## 1. Why a different database at all?\n\nYou know **Firestore**. In Firestore you have collections and documents:\n\n```\nusers/\n  uid_123/\n    name: \"Mabud\"\n    email: \"mabud@example.com\"\n\nrepositories/\n  repo_abc/\n    owner: \"uid_123\"    ← you store the user's ID manually\n    name:  \"BugViper\"\n```\n\nTo answer \"who owns this repo?\" you do two reads — first get the repo, then get the user by that stored ID. That manual link is called a **foreign key** in traditional databases.\n\nNow imagine you want to answer: *\"Show me all functions in all files in all repos owned by this user, and show me which other functions call those functions.\"*\n\nIn Firestore that's 4–5 separate reads, then you join the data yourself in JavaScript/Python. It gets messy fast.\n\n**Neo4j is a graph database.** Instead of storing IDs that point to other documents, you draw a direct line between two pieces of data. That line **is** the relationship. Traversing it is the database's core operation — it's optimised for exactly that.\n\n```\n(User) ──OWNS──► (Repository) ──CONTAINS──► (File) ──CONTAINS──► (Function)\n                                                                       │\n                                                                    CALLS\n                                                                       ▼\n                                                                  (Function)\n```\n\nOne query can walk this entire chain. No manual ID lookups.\n\n**Cypher** is how you talk to Neo4j. It's designed to look like the diagrams you'd draw on a whiteboard.\n\n---\n\n## 2. The Three Building Blocks\n\n### Nodes\n\nA **node** is a single entity — like a Firestore document. It has:\n- A **label** (the type) — written with `:` prefix\n- **Properties** (key/value pairs) — written with `{}`\n\n```\n(:Function {name: \"login\", line_number: 42, is_dependency: false})\n(:Class    {name: \"LoginRequest\"})\n(:File     {path: \"/api/auth.py\", language: \"Python\"})\n```\n\nIn Cypher you write a node in **parentheses**: `(variable:Label {key: value})`\n\n```cypher\n(f:Function)          -- f is a variable, Function is the label\n(n)                   -- no label filter — matches any node\n(c:Class {name: \"X\"}) -- only Class nodes where name = \"X\"\n```\n\n### Relationships\n\nA **relationship** connects two nodes. It always has:\n- A **direction** (arrow `->` or `<-`)\n- A **type** — written with `:`\n- Optional properties\n\n```\n(File)-[:CONTAINS]->(Function)   -- a file contains a function\n(Function)-[:CALLS]->(Function)  -- one function calls another\n(Class)-[:INHERITS]->(Class)     -- inheritance\n```\n\nIn Cypher you write relationships in **square brackets**: `-[:TYPE]->`\n\n```cypher\n-[:CONTAINS]->     -- going outward (from left to right)\n<-[:CONTAINS]-     -- going inward  (from right to left)\n-[:CONTAINS]-      -- either direction (no arrow)\n```\n\n### Properties\n\nProperties are just key/value data on a node or relationship:\n\n```cypher\nnode.name          -- the name property of a node\nnode.line_number   -- the line_number property\nrel.line_number    -- a property on a relationship\n```\n\n---\n\n## 3. How BugViper's Data Looks as a Graph\n\n```\n(Repository {id: \"Pavel401/BugViper\"})\n    │\n    └──[:CONTAINS]──► (File {path: \"api/auth.py\", language: \"Python\"})\n                           │\n                           ├──[:CONTAINS]──► (Class {name: \"LoginRequest\"})\n                           │                      │\n                           │                      └──[:CONTAINS]──► (Function {name: \"__init__\"})\n                           │\n                           ├──[:CONTAINS]──► (Function {name: \"login_user\", line_number: 55})\n                           │                      │\n                           │                      └──[:CALLS]──► (Function {name: \"verify_token\"})\n                           │\n                           └──[:IMPORTS]──► (Module {name: \"fastapi\"})\n```\n\nEvery function, class, variable, and file in every ingested repo lives as a node. The connections between them are relationships. Searching the codebase = traversing this graph.\n\n---\n\n## 4. Your First Cypher Query\n\n### MATCH\n\n`MATCH` is how you describe the pattern you're looking for. Think of it as \"find me things that look like this drawing.\"\n\n```cypher\nMATCH (f:Function)\nRETURN f\n```\n\n\"Find all Function nodes, return them.\"\n\nFirestore equivalent:\n```javascript\ndb.collection('functions').get()\n```\n\n---\n\n### RETURN\n\n`RETURN` picks what to send back — like `SELECT` in SQL, or just choosing which fields to include in your Firestore response.\n\n```cypher\nMATCH (f:Function)\nRETURN f.name, f.line_number, f.path\n```\n\nReturns just those three fields from every Function node.\n\nYou can also return the whole node:\n```cypher\nRETURN f       -- returns all properties as an object\nRETURN f.name  -- returns just the name string\n```\n\n---\n\n## 5. Filtering Results — WHERE\n\n`WHERE` narrows down results. Runs after `MATCH` finds candidates.\n\n```cypher\nMATCH (f:Function)\nWHERE f.name = \"login_user\"\nRETURN f.path, f.line_number\n```\n\n\"Find all Function nodes where the name is exactly `login_user`.\"\n\n### Comparison operators\n\n```cypher\nWHERE f.line_number = 42          -- equal\nWHERE f.line_number > 10          -- greater than\nWHERE f.line_number >= 10         -- greater than or equal\nWHERE f.line_number < 100         -- less than\nWHERE f.name <> \"test\"            -- not equal\nWHERE f.is_dependency = false     -- boolean\nWHERE f.docstring IS NOT NULL     -- property exists and is not null\nWHERE f.docstring IS NULL         -- property is null or missing\n```\n\n### Combining conditions\n\n```cypher\nWHERE f.name = \"login\" AND f.is_dependency = false\nWHERE f.name = \"login\" OR f.name = \"logout\"\nWHERE NOT f.is_dependency\n```\n\n### Filtering by label inside WHERE\n\n```cypher\nWHERE node:Function              -- node must have the Function label\nWHERE node:Function OR node:Class -- either label\nWHERE NOT node:Variable           -- must NOT have this label\n```\n\n---\n\n## 6. String Operators\n\nThese work inside `WHERE` clauses on text properties.\n\n### CONTAINS\n\nIs this string anywhere inside the property?\n\n```cypher\nWHERE node.name CONTAINS \"Request\"\n-- matches: \"LoginRequest\", \"MyRequest\", \"RequestHandler\"\n-- does NOT match: \"request\" (case-sensitive by default)\n```\n\n### STARTS WITH\n\n```cypher\nWHERE f.path STARTS WITH \"/api/\"\n-- matches: \"/api/auth.py\", \"/api/routes/query.py\"\n-- does NOT match: \"/lib/api.py\"\n```\n\n### ENDS WITH\n\n```cypher\nWHERE f.path ENDS WITH \".py\"\n-- matches any Python file path\n```\n\n### =~ (regular expression)\n\n```cypher\nWHERE f.name =~ \".*[Rr]equest.*\"\n-- regex match — .* means \"anything\"\n```\n\n> **Note:** `CONTAINS` does a full scan (slow on large data). That's why BugViper uses fulltext indexes (covered in section 15) as the first approach, falling back to `CONTAINS` only when needed.\n\n---\n\n## 7. Following Relationships — Pattern Matching\n\nThis is where Cypher shines. You describe the **shape** of the graph you want to find.\n\n### Direct relationship\n\n```cypher\nMATCH (file:File)-[:CONTAINS]->(func:Function)\nRETURN file.path, func.name\n```\n\n\"Find all File→Function pairs connected by a CONTAINS relationship.\"\n\nThink of it as drawing: `[File] ---CONTAINS---> [Function]`\n\n### Chaining multiple hops\n\n```cypher\nMATCH (repo:Repository)-[:CONTAINS]->(file:File)-[:CONTAINS]->(func:Function)\nRETURN repo.id, file.path, func.name\n```\n\nTwo hops: Repo → File → Function.\n\n### Variable-length paths — `*`\n\n```cypher\nMATCH (repo:Repository)-[:CONTAINS*]->(func:Function)\n```\n\nThe `*` means \"one or more hops\". This matches:\n- `(Repo)-[:CONTAINS]->(Function)` — one hop\n- `(Repo)-[:CONTAINS]->(File)-[:CONTAINS]->(Function)` — two hops\n- etc.\n\n```cypher\n-[:CONTAINS*1..3]->   -- between 1 and 3 hops\n-[:CONTAINS*2..]-     -- at least 2 hops\n-[:INHERITS*0..5]->   -- 0 to 5 hops (0 means the node itself)\n```\n\nBugViper uses this in `list_repositories`:\n```cypher\nOPTIONAL MATCH (r)-[:CONTAINS*]->(f:File)\n```\n\"Find any File reachable from the Repository via any number of CONTAINS hops.\"\n\n### Ignoring direction\n\n```cypher\nMATCH (a)-[:CALLS]-(b)   -- no arrow = either direction\n```\n\n---\n\n## 8. OPTIONAL MATCH\n\nLike `MATCH` but won't throw away the row if no match is found. Instead it fills with `null`.\n\n**Regular MATCH** — if no File is found, the entire row is dropped:\n```cypher\nMATCH (func:Function)\nMATCH (f:File)-[:CONTAINS]->(func)   -- if File missing, func row is lost\nRETURN func.name, f.path\n```\n\n**OPTIONAL MATCH** — if no File is found, `f` is `null` but the row survives:\n```cypher\nMATCH (func:Function)\nOPTIONAL MATCH (f:File)-[:CONTAINS]->(func)\nRETURN func.name, f.path   -- f.path will be null if no file found\n```\n\nThis is exactly like a **LEFT JOIN** in SQL.\n\nBugViper uses this everywhere in search queries:\n```cypher\nOPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n```\nBecause some nodes store `path` directly on themselves — they don't all have a File parent in the graph.\n\n---\n\n## 9. Shaping Output\n\n### AS — renaming output columns\n\n```cypher\nRETURN f.name AS function_name, f.line_number AS line\n```\n\nThe response object will have keys `function_name` and `line`, not `f.name` and `f.line_number`.\n\n### CASE WHEN — conditional values\n\nExactly like an `if/else` inside your return statement.\n\n```cypher\nRETURN\n    CASE WHEN node:Function THEN 'function'\n         WHEN node:Class    THEN 'class'\n         ELSE                    'variable'\n    END AS type\n```\n\n\"If the node has the Function label, return the string `'function'`. If it has Class, return `'class'`. Otherwise return `'variable'`.\"\n\nBugViper uses this because a single search can return multiple node types (Function, Class, Variable). The frontend needs to know which type it got.\n\nYou can also use CASE with an expression:\n```cypher\nCASE node.visibility\n    WHEN 'public'  THEN 'Public API'\n    WHEN 'private' THEN 'Internal'\n    ELSE 'Unknown'\nEND\n```\n\n### coalesce() — first non-null value\n\n`coalesce(a, b, c)` returns the first argument that is **not null**.\n\n```cypher\ncoalesce(f.path, node.path)\n```\n\n\"Use `f.path` if it exists. If `f` is null (OPTIONAL MATCH found nothing), fall back to `node.path`.\"\n\n```cypher\ncoalesce(node.line_number, 0)\n```\n\n\"Use `node.line_number` if it exists. If null, use `0` as default.\"\n\nThis prevents `null` values leaking into your API response.\n\nReal example from BugViper's `search_code` query:\n```cypher\ncoalesce(f.path, node.path) as path,\ncoalesce(node.line_number, 0) as line_number,\n```\n\nSome nodes have a File parent (so `f.path` works), some store path directly (so `node.path` is the fallback).\n\n---\n\n## 10. Sorting and Limiting\n\n### ORDER BY\n\n```cypher\nMATCH (f:Function)\nRETURN f.name, f.line_number\nORDER BY f.line_number         -- ascending (default)\nORDER BY f.line_number DESC    -- descending (highest first)\nORDER BY f.name, f.line_number -- sort by name first, then by line\n```\n\n### LIMIT\n\n```cypher\nLIMIT 20    -- return at most 20 rows\n```\n\nAlways put `LIMIT` at the end. BugViper uses it on every search query to prevent returning thousands of results.\n\n### SKIP\n\nSkip the first N results (useful for pagination):\n```cypher\nSKIP 20 LIMIT 20   -- page 2 of 20-per-page results\n```\n\n---\n\n## 11. Chaining Steps — WITH\n\n`WITH` is like a pipe `|` in a Unix shell — it takes the output of one step and feeds it as input to the next step.\n\nWithout `WITH`, you'd have to write one enormous query. With it, you can build queries in stages.\n\n```cypher\nMATCH (f:File)\nWITH f, split(f.source_code, '\\n') AS lines    -- compute lines\nWHERE size(lines) > 100                         -- filter by line count\nRETURN f.path, size(lines) AS line_count\nORDER BY line_count DESC\nLIMIT 10\n```\n\nStep 1: Find all Files\nStep 2: Split source_code into an array of lines, carry both `f` and `lines` forward\nStep 3: Filter to only files with more than 100 lines\nStep 4: Return path and line count\n\n**Important rule:** anything you don't name in `WITH` is dropped. If you write `WITH f`, you lose all other variables.\n\n```cypher\nMATCH (f:File)-[:CONTAINS]->(func:Function)\nWITH f, collect(func.name) AS function_names   -- f survives, func is gone\nRETURN f.path, function_names\n```\n\nBugViper uses `WITH` heavily in the file content line scan:\n```cypher\nWITH node, score, split(node.source_code, '\\n') AS lines\nLIMIT 10\nUNWIND range(0, size(lines) - 1) AS idx\nWITH node.path AS path, lines[idx] AS line_content, idx + 1 AS line_number, score\nWHERE toLower(line_content) CONTAINS toLower($raw_term)\n```\n\nEach `WITH` passes only what's needed to the next step.\n\n---\n\n## 12. Aggregation\n\nThese functions collapse multiple rows into one summary.\n\n### count()\n\n```cypher\nMATCH (f:Function)\nRETURN count(f) AS total_functions\n```\n\n```cypher\nMATCH (repo:Repository)-[:CONTAINS*]->(f:File)\nRETURN repo.name, count(f) AS file_count\n```\n\n`count(DISTINCT f.path)` — count unique values only.\n\n### sum()\n\n```cypher\nMATCH (f:Function)\nRETURN sum(f.cyclomatic_complexity) AS total_complexity\n```\n\n### collect()\n\nTurns multiple rows into a **list** (array):\n\n```cypher\nMATCH (file:File)-[:CONTAINS]->(func:Function)\nRETURN file.path, collect(func.name) AS functions\n-- returns: {path: \"auth.py\", functions: [\"login\", \"logout\", \"verify\"]}\n```\n\n### DISTINCT\n\nDeduplicate values:\n\n```cypher\nMATCH (f:File)\nRETURN DISTINCT f.language     -- each language name once\n```\n\n```cypher\ncount(DISTINCT f.language)     -- how many unique languages\n```\n\n### Aggregation in BugViper (graph stats query)\n\n```cypher\nMATCH (f:File)\nWHERE f.language IS NOT NULL\nOPTIONAL MATCH (f)-[:CONTAINS]->(func:Function)\nOPTIONAL MATCH (f)-[:CONTAINS]->(cls:Class)\nRETURN\n    f.language AS language,\n    count(DISTINCT f)    AS file_count,\n    count(DISTINCT func) AS function_count,\n    count(DISTINCT cls)  AS class_count\nORDER BY file_count DESC\n```\n\n---\n\n## 13. List Operations\n\n### range(start, end)\n\nCreates a list of integers from `start` to `end` (inclusive):\n\n```cypher\nrange(0, 4)    -- [0, 1, 2, 3, 4]\nrange(1, 3)    -- [1, 2, 3]\n```\n\nUsed to generate line indexes when scanning file content.\n\n### UNWIND\n\nTakes a list and turns it into individual rows — the opposite of `collect()`.\n\n```cypher\nUNWIND [1, 2, 3] AS number\nRETURN number\n-- returns three rows: 1, 2, 3\n```\n\nThe killer use case — iterating file lines:\n\n```cypher\nWITH split(file.source_code, '\\n') AS lines\nUNWIND range(0, size(lines) - 1) AS idx\nWITH lines[idx] AS line_content, idx + 1 AS line_number\nWHERE line_content CONTAINS \"def login\"\nRETURN line_number, line_content\n```\n\nStep by step:\n1. Split source code into array: `[\"import fastapi\", \"class Auth:\", \"def login():\"]`\n2. `range(0, 2)` → `[0, 1, 2]`\n3. `UNWIND` → three rows with `idx = 0`, `idx = 1`, `idx = 2`\n4. `lines[idx]` picks the line at that index\n5. `idx + 1` converts 0-based index to 1-based line numbers\n6. `WHERE` filters to only matching lines\n7. Return just the matching ones\n\nThis is the entire BugViper line-search engine — all server-side in Neo4j.\n\n### split(string, delimiter)\n\nSplits a string into an array:\n\n```cypher\nsplit(\"a,b,c\", \",\")          -- [\"a\", \"b\", \"c\"]\nsplit(file.source_code, '\\n') -- array of lines\n```\n\n### size()\n\nReturns the length of a string or list:\n\n```cypher\nsize(\"hello\")                    -- 5 (character count)\nsize([1, 2, 3])                  -- 3 (list length)\nsize(split(code, '\\n'))          -- number of lines in a file\nsize(node.source_code) < 500000  -- file smaller than 500KB?\n```\n\nBugViper uses `size()` as a size guard to skip minified/generated files before scanning them:\n```cypher\nWHERE size(node.source_code) < 500000\n```\n\n### List indexing\n\n```cypher\nlines[0]     -- first element\nlines[idx]   -- element at variable index\nlines[-1]    -- last element\n```\n\n---\n\n## 14. String Functions\n\n### toLower() / toUpper()\n\n```cypher\nWHERE toLower(line_content) CONTAINS toLower($raw_term)\n```\n\nMakes the comparison case-insensitive. `toLower(\"LoginRequest\")` → `\"loginrequest\"`.\n\n### trim()\n\nRemoves whitespace from both ends:\n```cypher\ntrim(\"  hello  \")   -- \"hello\"\n```\n\n### left() / right() / substring()\n\n```cypher\nleft(\"Hello World\", 5)        -- \"Hello\"\nright(\"Hello World\", 5)       -- \"World\"\nsubstring(\"Hello World\", 6)   -- \"World\"     (start at index 6)\nsubstring(\"Hello World\", 0, 5)-- \"Hello\"     (start, length)\n```\n\n### replace()\n\n```cypher\nreplace(\"hello world\", \"world\", \"neo4j\")  -- \"hello neo4j\"\n```\n\n---\n\n## 15. Full-Text Search — CALL and YIELD\n\nNormal `CONTAINS` scans every node one by one — slow on large graphs. Full-text indexes use **Lucene** (same engine as Elasticsearch) to find results in milliseconds.\n\n### Creating a fulltext index\n\nDone once when the database is set up (`db/schema.py`):\n\n```cypher\nCREATE FULLTEXT INDEX code_search\n  FOR (n:Class|Function|Method|Variable|Symbol)\n  ON EACH [n.name, n.docstring, n.source_code]\n```\n\nThis tells Neo4j: \"Keep a Lucene index over these node types, indexing these three properties.\"\n\nWhen a node is created or updated, Neo4j automatically updates the index. You never rebuild it manually.\n\n```cypher\nCREATE FULLTEXT INDEX file_content_search\n  FOR (f:File)\n  ON EACH [f.source_code]\n```\n\nA separate index just for File content — used for the line-search feature.\n\n### Querying a fulltext index\n\n```cypher\nCALL db.index.fulltext.queryNodes('code_search', $search_term)\nYIELD node, score\n```\n\n`CALL` — invoke a built-in Neo4j procedure (like calling a function).\n`db.index.fulltext.queryNodes` — the procedure name. Pass it the index name and the Lucene query.\n`YIELD node, score` — \"give me back each matching node and its relevance score.\"\n\n`score` is a float between 0 and 1. Higher = more relevant. Nodes that match multiple fields or match more frequently score higher.\n\nAfter `YIELD`, the result flows into normal Cypher:\n\n```cypher\nCALL db.index.fulltext.queryNodes('code_search', $search_term)\nYIELD node, score\nOPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\nRETURN node.name, f.path, score\nORDER BY score DESC\nLIMIT 20\n```\n\n### The Lucene query language\n\nWhat you pass as `$search_term` is a Lucene query string:\n\n```\n\"LoginRequest\"                  -- phrase: exact word match\n\"GitHubRepo\" AND \"BaseModel\"    -- both words must appear (in any field)\n\"login\" OR \"auth\"               -- either word\nname:\"LoginRequest\"             -- search only the name field\n```\n\n**Why special characters break it:**\nLucene treats `(`, `)`, `:`, `[`, `]`, `{`, `}`, `!`, `~`, `*`, `?`, `^`, `+`, `-` as syntax.\nIf you pass `class GitHubRepo(BaseModel):` raw, Lucene sees `(BaseModel)` as a grouping expression and `:` as a field selector — crash.\n\n**BugViper's `_escape_lucene_query` function:**\n\n```python\ninput:  \"LoginRequest\"               # simple word → \"LoginRequest\"\ninput:  \"class GitHubRepo(BaseModel):\"\n  step 1: extract word identifiers  → [\"class\", \"GitHubRepo\", \"BaseModel\"]\n  step 2: remove code keywords      → [\"GitHubRepo\", \"BaseModel\"]\n  step 3: cap at 3, wrap in quotes  → '\"GitHubRepo\" AND \"BaseModel\"'\n```\n\nThe AND query finds nodes where both `GitHubRepo` AND `BaseModel` appear anywhere in the indexed fields.\n\n---\n\n## 16. Parameters — The $variable Syntax\n\nNever build queries by concatenating strings. Always use parameters.\n\n**Wrong (vulnerable to injection):**\n```python\nquery = f\"MATCH (n:Function) WHERE n.name = '{user_input}' RETURN n\"\n```\nIf `user_input` is `\"x' OR 1=1 RETURN n //\"`, you have a security hole.\n\n**Correct (parameterised):**\n```python\nquery = \"MATCH (n:Function) WHERE n.name = $name RETURN n\"\ndb.run_query(query, {\"name\": user_input})\n```\n\nThe Neo4j driver handles the value safely. `$name` is a placeholder, never interpreted as Cypher syntax.\n\nBugViper uses parameters everywhere:\n```cypher\nWHERE node.name CONTAINS $name_term   -- $name_term from Python dict\nLIMIT $limit                          -- $limit from Python dict\nAND size(node.source_code) < $max_bytes\n```\n\nPassed as:\n```python\ndb.run_query(query, {\n    \"name_term\": \"LoginRequest\",\n    \"limit\": 20,\n    \"max_bytes\": 500_000,\n})\n```\n\n---\n\n## 17. Writing Data — CREATE, MERGE, SET, DELETE\n\nYou don't need these for search, but they're used by the ingestion engine.\n\n### CREATE — create a new node\n\n```cypher\nCREATE (f:Function {\n    name: \"login_user\",\n    path: \"/api/auth.py\",\n    line_number: 42\n})\n```\n\nCreates a new Function node. If you run it twice, you get two identical nodes.\n\n### MERGE — create if not exists, match if exists\n\n```cypher\nMERGE (f:Function {name: \"login_user\", path: \"/api/auth.py\"})\n```\n\n\"Find a Function with this name and path. If found, use it. If not, create it.\"\n\nThis is how BugViper avoids duplicate nodes when re-ingesting a repo.\n\n### CREATE with a relationship\n\n```cypher\nMATCH (file:File {path: \"/api/auth.py\"})\nMATCH (func:Function {name: \"login_user\"})\nCREATE (file)-[:CONTAINS]->(func)\n```\n\n### SET — update properties\n\n```cypher\nMATCH (f:Function {name: \"login_user\"})\nSET f.cyclomatic_complexity = 7\nSET f.docstring = \"Handles user login\"\n```\n\n### SET with +=\n\nMerge properties (don't replace the whole node, just update specific fields):\n```cypher\nSET f += {cyclomatic_complexity: 7, updated_at: datetime()}\n```\n\n### DELETE and DETACH DELETE\n\n```cypher\nMATCH (f:Function {name: \"old_function\"})\nDELETE f\n```\n\nFails if `f` has any relationships. Use `DETACH DELETE` to also delete all its relationships:\n\n```cypher\nMATCH (r:Repository {id: \"owner/repo\"})\nOPTIONAL MATCH (r)-[:CONTAINS*]->(n)\nDETACH DELETE r, n\n```\n\n\"Delete the Repository node, all nodes it reaches via any CONTAINS chain, and all their relationships.\"\n\n---\n\n## 18. Indexes — Why Queries Are Fast\n\nWithout indexes, every query scans every node — like reading an entire book to find one word.\n\n### Property indexes (for exact/range lookups)\n\n```cypher\nCREATE INDEX function_name IF NOT EXISTS FOR (f:Function) ON (f.name)\n```\n\nNow `WHERE f.name = \"login\"` is O(log n) instead of O(n). The index is a sorted structure; Neo4j binary-searches it.\n\n```cypher\nCREATE CONSTRAINT repo_id_unique IF NOT EXISTS\n  FOR (r:Repository) REQUIRES r.id IS UNIQUE\n```\n\nA uniqueness constraint also creates an index. BugViper creates one per node type for the `id` property.\n\n### Fulltext indexes (for text search)\n\n```cypher\nCREATE FULLTEXT INDEX code_search\n  FOR (n:Class|Function|Method|Variable|Symbol)\n  ON EACH [n.name, n.docstring, n.source_code]\n```\n\nUses Lucene internally. Splits text into tokens, builds an inverted index. Looking up `\"login\"` returns all nodes containing that word in under a millisecond, regardless of graph size.\n\n### Why CONTAINS is slow without a fulltext index\n\n`node.name CONTAINS \"login\"` cannot use a property index — property indexes only support exact and prefix matches. Neo4j must load every Function node and check its name string one by one.\n\nThat's why BugViper uses fulltext search as Tier 1 (fast) and falls back to CONTAINS as Tier 2 (slower, but a safety net).\n\n---\n\n## 19. Every BugViper Query Explained\n\n### Search query — `search_code` (db/schema.py)\n\n```cypher\nCALL db.index.fulltext.queryNodes('code_search', $search_term)\nYIELD node, score\nOPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\nRETURN\n    CASE WHEN node:Function THEN 'function'\n         WHEN node:Class THEN 'class'\n         ELSE 'variable' END as type,\n    node.name as name,\n    coalesce(f.path, node.path) as path,\n    coalesce(node.line_number, 0) as line_number,\n    score\nORDER BY score DESC\nLIMIT 20\n```\n\n| Part | What it does |\n|------|-------------|\n| `CALL db.index.fulltext.queryNodes(...)` | Hit the Lucene index — returns matching nodes in milliseconds |\n| `YIELD node, score` | Unpack: give me the node and how relevant it is (0–1) |\n| `OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)` | Try to find the file this node lives in. If the node stores its path directly, `f` will be null |\n| `CASE WHEN node:Function THEN 'function' ...` | Convert the Neo4j label into a human-readable string |\n| `coalesce(f.path, node.path)` | Use the file's path if we found a file; otherwise use the path stored on the node itself |\n| `coalesce(node.line_number, 0)` | Default to 0 if line_number is missing |\n| `ORDER BY score DESC` | Best matches first |\n| `LIMIT 20` | Never return more than 20 |\n\n---\n\n### Name CONTAINS fallback — `_name_contains_fallback` (db/queries.py)\n\n```cypher\nMATCH (node)\nWHERE (node:Function OR node:Class OR node:Variable)\n  AND node.name CONTAINS $name_term\nOPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\nRETURN\n    CASE WHEN node:Function THEN 'function'\n         WHEN node:Class THEN 'class'\n         ELSE 'variable' END as type,\n    node.name as name,\n    coalesce(f.path, node.path) as path,\n    coalesce(node.line_number, 0) as line_number,\n    1.0 as score\nORDER BY node.name\nLIMIT $limit\n```\n\n| Part | What it does |\n|------|-------------|\n| `MATCH (node)` | Find any node (no label filter yet) |\n| `WHERE (node:Function OR node:Class OR node:Variable)` | Now filter to only these three types |\n| `AND node.name CONTAINS $name_term` | The name must contain the search term as a substring |\n| `1.0 as score` | Hardcoded score — CONTAINS doesn't have relevance ranking, so all results are equally \"relevant\" |\n\nThis runs when Tier 1 returns nothing. It catches things the fulltext index missed (e.g. a newly ingested node not yet indexed).\n\n---\n\n### File content line scan — `search_file_content` (db/queries.py)\n\n```cypher\nCALL db.index.fulltext.queryNodes('file_content_search', $search_term)\nYIELD node, score\nWHERE node.source_code IS NOT NULL\n  AND size(node.source_code) < $max_bytes\nWITH node, score, split(node.source_code, '\\n') AS lines\nLIMIT 10\nUNWIND range(0, size(lines) - 1) AS idx\nWITH node.path AS path, lines[idx] AS line_content, idx + 1 AS line_number, score\nWHERE toLower(line_content) CONTAINS toLower($raw_term)\nRETURN path, line_number, line_content AS match_line\nORDER BY score DESC, path, line_number\nLIMIT $limit\n```\n\n| Part | What it does |\n|------|-------------|\n| `CALL db.index.fulltext.queryNodes('file_content_search', ...)` | Find files whose source_code matches the Lucene query |\n| `WHERE size(node.source_code) < $max_bytes` | Skip files over 500 KB (minified, generated) |\n| `WITH ..., split(node.source_code, '\\n') AS lines` | Split source code into an array of lines, server-side |\n| `LIMIT 10` | Only process the 10 best-matching files **before** UNWIND to prevent a row explosion |\n| `UNWIND range(0, size(lines) - 1) AS idx` | Turn the array `[0, 1, 2, ...]` into individual rows — one row per line |\n| `lines[idx] AS line_content` | Pick the line at this index |\n| `idx + 1 AS line_number` | Convert 0-based index to 1-based line number |\n| `WHERE toLower(line_content) CONTAINS toLower($raw_term)` | Case-insensitive match against the raw search term |\n| `RETURN path, line_number, match_line` | Only the matching lines come back over the network — not the full source blobs |\n\n---\n\n### Peek — `peek_file_lines` (db/queries.py)\n\n```cypher\nMATCH (f:File {path: $path})\nWHERE f.source_code IS NOT NULL AND size(f.source_code) < 2000000\nRETURN f.source_code as source_code\nLIMIT 1\n```\n\n| Part | What it does |\n|------|-------------|\n| `{path: $path}` | Shorthand for `WHERE f.path = $path` — matches by exact property value |\n| `size(f.source_code) < 2000000` | Reject files over 2 MB to prevent memory spikes |\n| `LIMIT 1` | Safety net — path should be unique, but just in case |\n\nAfter this, Python slices the source_code array to extract just the window of lines around the anchor.\n\n---\n\n### Repository listing — `list_repositories` (db/queries.py)\n\n```cypher\nMATCH (r:Repository)\nOPTIONAL MATCH (r)-[:CONTAINS*]->(f:File)\nRETURN r.id as id, r.name as name, r.owner as owner,\n       r.url as url, r.path as local_path,\n       r.last_commit_hash as last_commit,\n       r.created_at as created_at,\n       r.updated_at as updated_at,\n       count(DISTINCT f) as file_count\nORDER BY r.updated_at DESC, r.name\n```\n\n| Part | What it does |\n|------|-------------|\n| `MATCH (r:Repository)` | Get all repositories |\n| `OPTIONAL MATCH (r)-[:CONTAINS*]->(f:File)` | Try to count all Files reachable from each repo. `*` = any number of hops |\n| `count(DISTINCT f) as file_count` | Count unique File nodes per repository (DISTINCT prevents double-counting if a file is reachable via multiple paths) |\n| `ORDER BY r.updated_at DESC, r.name` | Most recently updated repos first; alphabetical as tiebreaker |\n\n---\n\n### Delete repository — `delete_repository` (db/queries.py)\n\n```cypher\nMATCH (r:Repository)\nWHERE r.id = $repo_id OR r.repo = $repo_id\nOPTIONAL MATCH (r)-[:CONTAINS*]->(n)\nDETACH DELETE r, n\nRETURN count(r) as deleted_count\n```\n\n| Part | What it does |\n|------|-------------|\n| `WHERE r.id = $repo_id OR r.repo = $repo_id` | Match either property name (handles legacy data format) |\n| `OPTIONAL MATCH (r)-[:CONTAINS*]->(n)` | Find every node reachable from this repo — all files, functions, classes, variables |\n| `DETACH DELETE r, n` | Delete the repo node, all its children, and all relationships. `DETACH` removes relationships first (required before deleting nodes) |\n| `RETURN count(r)` | Return how many repos were deleted (0 = not found, 1 = success) |\n\n---\n\n### Callers query — `find_callers` (db/queries.py)\n\n```cypher\nMATCH (caller)-[:CALLS]->(target)\nWHERE target.name = $name AND target.path CONTAINS $repo_id\nRETURN DISTINCT\n    caller.name as caller_name,\n    CASE WHEN caller:Function THEN 'function'\n         WHEN caller:Method THEN 'method'\n         ELSE 'other' END as caller_type,\n    caller.path as path\nLIMIT 10\n```\n\n| Part | What it does |\n|------|-------------|\n| `(caller)-[:CALLS]->(target)` | Find any pair of nodes connected by CALLS. `caller` is anything that calls `target` |\n| `target.name = $name` | The thing being called must have this exact name |\n| `target.path CONTAINS $repo_id` | Scope to nodes in this repository (paths contain the repo identifier) |\n| `RETURN DISTINCT` | Deduplicate — the same caller might call the same function multiple times at different lines; we only want the caller once |\n\n---\n\n## Quick Reference Card\n\n```\nMATCH (n:Label)              find nodes\nMATCH (a)-[:REL]->(b)        follow a relationship\nOPTIONAL MATCH               like MATCH but keep nulls (LEFT JOIN)\nWHERE n.prop = $val          filter\nWHERE n.prop CONTAINS $val   substring match\nWHERE n:Label                filter by label\nRETURN n.name AS name        output (with optional rename)\nORDER BY n.name DESC         sort\nLIMIT 20                     cap results\nSKIP 20                      pagination offset\nWITH n, value AS alias        pipe output to next step\nCASE WHEN x THEN y END       conditional value\ncoalesce(a, b, c)            first non-null\ncount(DISTINCT n)            count unique\ncollect(n.name)              aggregate into list\nUNWIND list AS item          expand list into rows\nsplit(str, '\\n')             string → array\nrange(0, 5)                  [0,1,2,3,4,5]\nsize(list)                   length\ntoLower(str)                 lowercase\n$param                       safe parameter (never string-concat)\nCALL procedure() YIELD x     call built-in procedure\nCREATE (n:Label {k: v})      create a node\nMERGE (n:Label {k: v})       create if not exists\nSET n.prop = value           update a property\nDETACH DELETE n              delete node + its relationships\n```\n\n---\n\n*This guide covers every Cypher construct used in BugViper's codebase as of 2026-02-21.*\n"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":650,"cache_read_input_tokens":156671,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":650},"output_tokens":24,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLxTLzomAoXKwCVBfiZj","type":"assistant","uuid":"0248327e-8c15-47a8-9c0b-c4807af2724a","timestamp":"2026-02-21T09:15:37.165Z"}
{"type":"file-history-snapshot","messageId":"0248327e-8c15-47a8-9c0b-c4807af2724a","snapshot":{"messageId":"c7720134-7b4f-4513-9ac8-3a31601ecc93","trackedFileBackups":{"db/schema.py":{"backupFileName":"283975a9ba984ffc@v2","version":2,"backupTime":"2026-02-21T08:34:53.260Z"},"db/queries.py":{"backupFileName":"3dbb7f971a633538@v4","version":4,"backupTime":"2026-02-21T08:51:52.096Z"},"api/routers/query.py":{"backupFileName":"e6ad69c83e8fb9b0@v4","version":4,"backupTime":"2026-02-21T08:51:52.097Z"},"frontend/app/(protected)/query/page.tsx":{"backupFileName":"30dea031ecc29fcb@v3","version":3,"backupTime":"2026-02-21T08:47:02.991Z"},"frontend/lib/api.ts":{"backupFileName":"a3322355f2d59118@v2","version":2,"backupTime":"2026-02-21T08:47:02.991Z"},"Claude.md":{"backupFileName":"8ee2a4b8e81d0daa@v2","version":2,"backupTime":"2026-02-21T08:47:02.992Z"},"CYPHER_GUIDE.md":{"backupFileName":null,"version":1,"backupTime":"2026-02-21T09:15:37.367Z"}},"timestamp":"2026-02-21T09:12:24.960Z"},"isSnapshotUpdate":true}
{"parentUuid":"0248327e-8c15-47a8-9c0b-c4807af2724a","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"PostToolUse","hookName":"PostToolUse:Write","command":"callback"},"parentToolUseID":"toolu_01RcVduRoAUotnb9oxNdr6Me","toolUseID":"toolu_01RcVduRoAUotnb9oxNdr6Me","timestamp":"2026-02-21T09:15:38.021Z","uuid":"a1fdcfd5-611b-4733-9fa2-495cf7f3a0d9"}
{"parentUuid":"0248327e-8c15-47a8-9c0b-c4807af2724a","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01RcVduRoAUotnb9oxNdr6Me","type":"tool_result","content":"File created successfully at: REDACTED.md"}]},"uuid":"93a1921c-36dd-4e22-8cc0-7edcc8032fe8","timestamp":"2026-02-21T09:15:38.020Z","toolUseResult":{"type":"create","filePath":"REDACTED.md","content":"# Cypher Query Language — A Complete Beginner's Guide\n\n> Written for BugViper developers who know Firestore but have never touched SQL or Cypher.\n> Every concept is explained from scratch. Every function used in BugViper's codebase is covered.\n\n---\n\n## Table of Contents\n\n1. [Why a different database at all?](#1-why-a-different-database-at-all)\n2. [The three building blocks: Nodes, Relationships, Properties](#2-the-three-building-blocks)\n3. [How BugViper's data looks as a graph](#3-how-bugvipers-data-looks-as-a-graph)\n4. [Your first Cypher query — MATCH and RETURN](#4-your-first-cypher-query)\n5. [Filtering results — WHERE](#5-filtering-results--where)\n6. [String operators — CONTAINS, STARTS WITH, ENDS WITH](#6-string-operators)\n7. [Following relationships — pattern matching](#7-following-relationships)\n8. [Optional relationships — OPTIONAL MATCH](#8-optional-match)\n9. [Shaping output — AS, CASE WHEN, coalesce()](#9-shaping-output)\n10. [Sorting and limiting — ORDER BY, LIMIT, SKIP](#10-sorting-and-limiting)\n11. [Chaining steps — WITH](#11-chaining-steps--with)\n12. [Aggregation — count(), sum(), collect(), DISTINCT](#12-aggregation)\n13. [List operations — range(), UNWIND, split(), size()](#13-list-operations)\n14. [String functions — toLower(), toUpper(), trim(), left()](#14-string-functions)\n15. [Full-text search — CALL and YIELD](#15-full-text-search)\n16. [Parameters — the $variable syntax](#16-parameters)\n17. [Writing data — CREATE, MERGE, SET, DELETE](#17-writing-data)\n18. [Indexes — why queries are fast](#18-indexes)\n19. [Every query in BugViper explained line by line](#19-every-bugviper-query-explained)\n\n---\n\n## 1. Why a different database at all?\n\nYou know **Firestore**. In Firestore you have collections and documents:\n\n```\nusers/\n  uid_123/\n    name: \"Mabud\"\n    email: \"mabud@example.com\"\n\nrepositories/\n  repo_abc/\n    owner: \"uid_123\"    ← you store the user's ID manually\n    name:  \"BugViper\"\n```\n\nTo answer \"who owns this repo?\" you do two reads — first get the repo, then get the user by that stored ID. That manual link is called a **foreign key** in traditional databases.\n\nNow imagine you want to answer: *\"Show me all functions in all files in all repos owned by this user, and show me which other functions call those functions.\"*\n\nIn Firestore that's 4–5 separate reads, then you join the data yourself in JavaScript/Python. It gets messy fast.\n\n**Neo4j is a graph database.** Instead of storing IDs that point to other documents, you draw a direct line between two pieces of data. That line **is** the relationship. Traversing it is the database's core operation — it's optimised for exactly that.\n\n```\n(User) ──OWNS──► (Repository) ──CONTAINS──► (File) ──CONTAINS──► (Function)\n                                                                       │\n                                                                    CALLS\n                                                                       ▼\n                                                                  (Function)\n```\n\nOne query can walk this entire chain. No manual ID lookups.\n\n**Cypher** is how you talk to Neo4j. It's designed to look like the diagrams you'd draw on a whiteboard.\n\n---\n\n## 2. The Three Building Blocks\n\n### Nodes\n\nA **node** is a single entity — like a Firestore document. It has:\n- A **label** (the type) — written with `:` prefix\n- **Properties** (key/value pairs) — written with `{}`\n\n```\n(:Function {name: \"login\", line_number: 42, is_dependency: false})\n(:Class    {name: \"LoginRequest\"})\n(:File     {path: \"/api/auth.py\", language: \"Python\"})\n```\n\nIn Cypher you write a node in **parentheses**: `(variable:Label {key: value})`\n\n```cypher\n(f:Function)          -- f is a variable, Function is the label\n(n)                   -- no label filter — matches any node\n(c:Class {name: \"X\"}) -- only Class nodes where name = \"X\"\n```\n\n### Relationships\n\nA **relationship** connects two nodes. It always has:\n- A **direction** (arrow `->` or `<-`)\n- A **type** — written with `:`\n- Optional properties\n\n```\n(File)-[:CONTAINS]->(Function)   -- a file contains a function\n(Function)-[:CALLS]->(Function)  -- one function calls another\n(Class)-[:INHERITS]->(Class)     -- inheritance\n```\n\nIn Cypher you write relationships in **square brackets**: `-[:TYPE]->`\n\n```cypher\n-[:CONTAINS]->     -- going outward (from left to right)\n<-[:CONTAINS]-     -- going inward  (from right to left)\n-[:CONTAINS]-      -- either direction (no arrow)\n```\n\n### Properties\n\nProperties are just key/value data on a node or relationship:\n\n```cypher\nnode.name          -- the name property of a node\nnode.line_number   -- the line_number property\nrel.line_number    -- a property on a relationship\n```\n\n---\n\n## 3. How BugViper's Data Looks as a Graph\n\n```\n(Repository {id: \"Pavel401/BugViper\"})\n    │\n    └──[:CONTAINS]──► (File {path: \"api/auth.py\", language: \"Python\"})\n                           │\n                           ├──[:CONTAINS]──► (Class {name: \"LoginRequest\"})\n                           │                      │\n                           │                      └──[:CONTAINS]──► (Function {name: \"__init__\"})\n                           │\n                           ├──[:CONTAINS]──► (Function {name: \"login_user\", line_number: 55})\n                           │                      │\n                           │                      └──[:CALLS]──► (Function {name: \"verify_token\"})\n                           │\n                           └──[:IMPORTS]──► (Module {name: \"fastapi\"})\n```\n\nEvery function, class, variable, and file in every ingested repo lives as a node. The connections between them are relationships. Searching the codebase = traversing this graph.\n\n---\n\n## 4. Your First Cypher Query\n\n### MATCH\n\n`MATCH` is how you describe the pattern you're looking for. Think of it as \"find me things that look like this drawing.\"\n\n```cypher\nMATCH (f:Function)\nRETURN f\n```\n\n\"Find all Function nodes, return them.\"\n\nFirestore equivalent:\n```javascript\ndb.collection('functions').get()\n```\n\n---\n\n### RETURN\n\n`RETURN` picks what to send back — like `SELECT` in SQL, or just choosing which fields to include in your Firestore response.\n\n```cypher\nMATCH (f:Function)\nRETURN f.name, f.line_number, f.path\n```\n\nReturns just those three fields from every Function node.\n\nYou can also return the whole node:\n```cypher\nRETURN f       -- returns all properties as an object\nRETURN f.name  -- returns just the name string\n```\n\n---\n\n## 5. Filtering Results — WHERE\n\n`WHERE` narrows down results. Runs after `MATCH` finds candidates.\n\n```cypher\nMATCH (f:Function)\nWHERE f.name = \"login_user\"\nRETURN f.path, f.line_number\n```\n\n\"Find all Function nodes where the name is exactly `login_user`.\"\n\n### Comparison operators\n\n```cypher\nWHERE f.line_number = 42          -- equal\nWHERE f.line_number > 10          -- greater than\nWHERE f.line_number >= 10         -- greater than or equal\nWHERE f.line_number < 100         -- less than\nWHERE f.name <> \"test\"            -- not equal\nWHERE f.is_dependency = false     -- boolean\nWHERE f.docstring IS NOT NULL     -- property exists and is not null\nWHERE f.docstring IS NULL         -- property is null or missing\n```\n\n### Combining conditions\n\n```cypher\nWHERE f.name = \"login\" AND f.is_dependency = false\nWHERE f.name = \"login\" OR f.name = \"logout\"\nWHERE NOT f.is_dependency\n```\n\n### Filtering by label inside WHERE\n\n```cypher\nWHERE node:Function              -- node must have the Function label\nWHERE node:Function OR node:Class -- either label\nWHERE NOT node:Variable           -- must NOT have this label\n```\n\n---\n\n## 6. String Operators\n\nThese work inside `WHERE` clauses on text properties.\n\n### CONTAINS\n\nIs this string anywhere inside the property?\n\n```cypher\nWHERE node.name CONTAINS \"Request\"\n-- matches: \"LoginRequest\", \"MyRequest\", \"RequestHandler\"\n-- does NOT match: \"request\" (case-sensitive by default)\n```\n\n### STARTS WITH\n\n```cypher\nWHERE f.path STARTS WITH \"/api/\"\n-- matches: \"/api/auth.py\", \"/api/routes/query.py\"\n-- does NOT match: \"/lib/api.py\"\n```\n\n### ENDS WITH\n\n```cypher\nWHERE f.path ENDS WITH \".py\"\n-- matches any Python file path\n```\n\n### =~ (regular expression)\n\n```cypher\nWHERE f.name =~ \".*[Rr]equest.*\"\n-- regex match — .* means \"anything\"\n```\n\n> **Note:** `CONTAINS` does a full scan (slow on large data). That's why BugViper uses fulltext indexes (covered in section 15) as the first approach, falling back to `CONTAINS` only when needed.\n\n---\n\n## 7. Following Relationships — Pattern Matching\n\nThis is where Cypher shines. You describe the **shape** of the graph you want to find.\n\n### Direct relationship\n\n```cypher\nMATCH (file:File)-[:CONTAINS]->(func:Function)\nRETURN file.path, func.name\n```\n\n\"Find all File→Function pairs connected by a CONTAINS relationship.\"\n\nThink of it as drawing: `[File] ---CONTAINS---> [Function]`\n\n### Chaining multiple hops\n\n```cypher\nMATCH (repo:Repository)-[:CONTAINS]->(file:File)-[:CONTAINS]->(func:Function)\nRETURN repo.id, file.path, func.name\n```\n\nTwo hops: Repo → File → Function.\n\n### Variable-length paths — `*`\n\n```cypher\nMATCH (repo:Repository)-[:CONTAINS*]->(func:Function)\n```\n\nThe `*` means \"one or more hops\". This matches:\n- `(Repo)-[:CONTAINS]->(Function)` — one hop\n- `(Repo)-[:CONTAINS]->(File)-[:CONTAINS]->(Function)` — two hops\n- etc.\n\n```cypher\n-[:CONTAINS*1..3]->   -- between 1 and 3 hops\n-[:CONTAINS*2..]-     -- at least 2 hops\n-[:INHERITS*0..5]->   -- 0 to 5 hops (0 means the node itself)\n```\n\nBugViper uses this in `list_repositories`:\n```cypher\nOPTIONAL MATCH (r)-[:CONTAINS*]->(f:File)\n```\n\"Find any File reachable from the Repository via any number of CONTAINS hops.\"\n\n### Ignoring direction\n\n```cypher\nMATCH (a)-[:CALLS]-(b)   -- no arrow = either direction\n```\n\n---\n\n## 8. OPTIONAL MATCH\n\nLike `MATCH` but won't throw away the row if no match is found. Instead it fills with `null`.\n\n**Regular MATCH** — if no File is found, the entire row is dropped:\n```cypher\nMATCH (func:Function)\nMATCH (f:File)-[:CONTAINS]->(func)   -- if File missing, func row is lost\nRETURN func.name, f.path\n```\n\n**OPTIONAL MATCH** — if no File is found, `f` is `null` but the row survives:\n```cypher\nMATCH (func:Function)\nOPTIONAL MATCH (f:File)-[:CONTAINS]->(func)\nRETURN func.name, f.path   -- f.path will be null if no file found\n```\n\nThis is exactly like a **LEFT JOIN** in SQL.\n\nBugViper uses this everywhere in search queries:\n```cypher\nOPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n```\nBecause some nodes store `path` directly on themselves — they don't all have a File parent in the graph.\n\n---\n\n## 9. Shaping Output\n\n### AS — renaming output columns\n\n```cypher\nRETURN f.name AS function_name, f.line_number AS line\n```\n\nThe response object will have keys `function_name` and `line`, not `f.name` and `f.line_number`.\n\n### CASE WHEN — conditional values\n\nExactly like an `if/else` inside your return statement.\n\n```cypher\nRETURN\n    CASE WHEN node:Function THEN 'function'\n         WHEN node:Class    THEN 'class'\n         ELSE                    'variable'\n    END AS type\n```\n\n\"If the node has the Function label, return the string `'function'`. If it has Class, return `'class'`. Otherwise return `'variable'`.\"\n\nBugViper uses this because a single search can return multiple node types (Function, Class, Variable). The frontend needs to know which type it got.\n\nYou can also use CASE with an expression:\n```cypher\nCASE node.visibility\n    WHEN 'public'  THEN 'Public API'\n    WHEN 'private' THEN 'Internal'\n    ELSE 'Unknown'\nEND\n```\n\n### coalesce() — first non-null value\n\n`coalesce(a, b, c)` returns the first argument that is **not null**.\n\n```cypher\ncoalesce(f.path, node.path)\n```\n\n\"Use `f.path` if it exists. If `f` is null (OPTIONAL MATCH found nothing), fall back to `node.path`.\"\n\n```cypher\ncoalesce(node.line_number, 0)\n```\n\n\"Use `node.line_number` if it exists. If null, use `0` as default.\"\n\nThis prevents `null` values leaking into your API response.\n\nReal example from BugViper's `search_code` query:\n```cypher\ncoalesce(f.path, node.path) as path,\ncoalesce(node.line_number, 0) as line_number,\n```\n\nSome nodes have a File parent (so `f.path` works), some store path directly (so `node.path` is the fallback).\n\n---\n\n## 10. Sorting and Limiting\n\n### ORDER BY\n\n```cypher\nMATCH (f:Function)\nRETURN f.name, f.line_number\nORDER BY f.line_number         -- ascending (default)\nORDER BY f.line_number DESC    -- descending (highest first)\nORDER BY f.name, f.line_number -- sort by name first, then by line\n```\n\n### LIMIT\n\n```cypher\nLIMIT 20    -- return at most 20 rows\n```\n\nAlways put `LIMIT` at the end. BugViper uses it on every search query to prevent returning thousands of results.\n\n### SKIP\n\nSkip the first N results (useful for pagination):\n```cypher\nSKIP 20 LIMIT 20   -- page 2 of 20-per-page results\n```\n\n---\n\n## 11. Chaining Steps — WITH\n\n`WITH` is like a pipe `|` in a Unix shell — it takes the output of one step and feeds it as input to the next step.\n\nWithout `WITH`, you'd have to write one enormous query. With it, you can build queries in stages.\n\n```cypher\nMATCH (f:File)\nWITH f, split(f.source_code, '\\n') AS lines    -- compute lines\nWHERE size(lines) > 100                         -- filter by line count\nRETURN f.path, size(lines) AS line_count\nORDER BY line_count DESC\nLIMIT 10\n```\n\nStep 1: Find all Files\nStep 2: Split source_code into an array of lines, carry both `f` and `lines` forward\nStep 3: Filter to only files with more than 100 lines\nStep 4: Return path and line count\n\n**Important rule:** anything you don't name in `WITH` is dropped. If you write `WITH f`, you lose all other variables.\n\n```cypher\nMATCH (f:File)-[:CONTAINS]->(func:Function)\nWITH f, collect(func.name) AS function_names   -- f survives, func is gone\nRETURN f.path, function_names\n```\n\nBugViper uses `WITH` heavily in the file content line scan:\n```cypher\nWITH node, score, split(node.source_code, '\\n') AS lines\nLIMIT 10\nUNWIND range(0, size(lines) - 1) AS idx\nWITH node.path AS path, lines[idx] AS line_content, idx + 1 AS line_number, score\nWHERE toLower(line_content) CONTAINS toLower($raw_term)\n```\n\nEach `WITH` passes only what's needed to the next step.\n\n---\n\n## 12. Aggregation\n\nThese functions collapse multiple rows into one summary.\n\n### count()\n\n```cypher\nMATCH (f:Function)\nRETURN count(f) AS total_functions\n```\n\n```cypher\nMATCH (repo:Repository)-[:CONTAINS*]->(f:File)\nRETURN repo.name, count(f) AS file_count\n```\n\n`count(DISTINCT f.path)` — count unique values only.\n\n### sum()\n\n```cypher\nMATCH (f:Function)\nRETURN sum(f.cyclomatic_complexity) AS total_complexity\n```\n\n### collect()\n\nTurns multiple rows into a **list** (array):\n\n```cypher\nMATCH (file:File)-[:CONTAINS]->(func:Function)\nRETURN file.path, collect(func.name) AS functions\n-- returns: {path: \"auth.py\", functions: [\"login\", \"logout\", \"verify\"]}\n```\n\n### DISTINCT\n\nDeduplicate values:\n\n```cypher\nMATCH (f:File)\nRETURN DISTINCT f.language     -- each language name once\n```\n\n```cypher\ncount(DISTINCT f.language)     -- how many unique languages\n```\n\n### Aggregation in BugViper (graph stats query)\n\n```cypher\nMATCH (f:File)\nWHERE f.language IS NOT NULL\nOPTIONAL MATCH (f)-[:CONTAINS]->(func:Function)\nOPTIONAL MATCH (f)-[:CONTAINS]->(cls:Class)\nRETURN\n    f.language AS language,\n    count(DISTINCT f)    AS file_count,\n    count(DISTINCT func) AS function_count,\n    count(DISTINCT cls)  AS class_count\nORDER BY file_count DESC\n```\n\n---\n\n## 13. List Operations\n\n### range(start, end)\n\nCreates a list of integers from `start` to `end` (inclusive):\n\n```cypher\nrange(0, 4)    -- [0, 1, 2, 3, 4]\nrange(1, 3)    -- [1, 2, 3]\n```\n\nUsed to generate line indexes when scanning file content.\n\n### UNWIND\n\nTakes a list and turns it into individual rows — the opposite of `collect()`.\n\n```cypher\nUNWIND [1, 2, 3] AS number\nRETURN number\n-- returns three rows: 1, 2, 3\n```\n\nThe killer use case — iterating file lines:\n\n```cypher\nWITH split(file.source_code, '\\n') AS lines\nUNWIND range(0, size(lines) - 1) AS idx\nWITH lines[idx] AS line_content, idx + 1 AS line_number\nWHERE line_content CONTAINS \"def login\"\nRETURN line_number, line_content\n```\n\nStep by step:\n1. Split source code into array: `[\"import fastapi\", \"class Auth:\", \"def login():\"]`\n2. `range(0, 2)` → `[0, 1, 2]`\n3. `UNWIND` → three rows with `idx = 0`, `idx = 1`, `idx = 2`\n4. `lines[idx]` picks the line at that index\n5. `idx + 1` converts 0-based index to 1-based line numbers\n6. `WHERE` filters to only matching lines\n7. Return just the matching ones\n\nThis is the entire BugViper line-search engine — all server-side in Neo4j.\n\n### split(string, delimiter)\n\nSplits a string into an array:\n\n```cypher\nsplit(\"a,b,c\", \",\")          -- [\"a\", \"b\", \"c\"]\nsplit(file.source_code, '\\n') -- array of lines\n```\n\n### size()\n\nReturns the length of a string or list:\n\n```cypher\nsize(\"hello\")                    -- 5 (character count)\nsize([1, 2, 3])                  -- 3 (list length)\nsize(split(code, '\\n'))          -- number of lines in a file\nsize(node.source_code) < 500000  -- file smaller than 500KB?\n```\n\nBugViper uses `size()` as a size guard to skip minified/generated files before scanning them:\n```cypher\nWHERE size(node.source_code) < 500000\n```\n\n### List indexing\n\n```cypher\nlines[0]     -- first element\nlines[idx]   -- element at variable index\nlines[-1]    -- last element\n```\n\n---\n\n## 14. String Functions\n\n### toLower() / toUpper()\n\n```cypher\nWHERE toLower(line_content) CONTAINS toLower($raw_term)\n```\n\nMakes the comparison case-insensitive. `toLower(\"LoginRequest\")` → `\"loginrequest\"`.\n\n### trim()\n\nRemoves whitespace from both ends:\n```cypher\ntrim(\"  hello  \")   -- \"hello\"\n```\n\n### left() / right() / substring()\n\n```cypher\nleft(\"Hello World\", 5)        -- \"Hello\"\nright(\"Hello World\", 5)       -- \"World\"\nsubstring(\"Hello World\", 6)   -- \"World\"     (start at index 6)\nsubstring(\"Hello World\", 0, 5)-- \"Hello\"     (start, length)\n```\n\n### replace()\n\n```cypher\nreplace(\"hello world\", \"world\", \"neo4j\")  -- \"hello neo4j\"\n```\n\n---\n\n## 15. Full-Text Search — CALL and YIELD\n\nNormal `CONTAINS` scans every node one by one — slow on large graphs. Full-text indexes use **Lucene** (same engine as Elasticsearch) to find results in milliseconds.\n\n### Creating a fulltext index\n\nDone once when the database is set up (`db/schema.py`):\n\n```cypher\nCREATE FULLTEXT INDEX code_search\n  FOR (n:Class|Function|Method|Variable|Symbol)\n  ON EACH [n.name, n.docstring, n.source_code]\n```\n\nThis tells Neo4j: \"Keep a Lucene index over these node types, indexing these three properties.\"\n\nWhen a node is created or updated, Neo4j automatically updates the index. You never rebuild it manually.\n\n```cypher\nCREATE FULLTEXT INDEX file_content_search\n  FOR (f:File)\n  ON EACH [f.source_code]\n```\n\nA separate index just for File content — used for the line-search feature.\n\n### Querying a fulltext index\n\n```cypher\nCALL db.index.fulltext.queryNodes('code_search', $search_term)\nYIELD node, score\n```\n\n`CALL` — invoke a built-in Neo4j procedure (like calling a function).\n`db.index.fulltext.queryNodes` — the procedure name. Pass it the index name and the Lucene query.\n`YIELD node, score` — \"give me back each matching node and its relevance score.\"\n\n`score` is a float between 0 and 1. Higher = more relevant. Nodes that match multiple fields or match more frequently score higher.\n\nAfter `YIELD`, the result flows into normal Cypher:\n\n```cypher\nCALL db.index.fulltext.queryNodes('code_search', $search_term)\nYIELD node, score\nOPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\nRETURN node.name, f.path, score\nORDER BY score DESC\nLIMIT 20\n```\n\n### The Lucene query language\n\nWhat you pass as `$search_term` is a Lucene query string:\n\n```\n\"LoginRequest\"                  -- phrase: exact word match\n\"GitHubRepo\" AND \"BaseModel\"    -- both words must appear (in any field)\n\"login\" OR \"auth\"               -- either word\nname:\"LoginRequest\"             -- search only the name field\n```\n\n**Why special characters break it:**\nLucene treats `(`, `)`, `:`, `[`, `]`, `{`, `}`, `!`, `~`, `*`, `?`, `^`, `+`, `-` as syntax.\nIf you pass `class GitHubRepo(BaseModel):` raw, Lucene sees `(BaseModel)` as a grouping expression and `:` as a field selector — crash.\n\n**BugViper's `_escape_lucene_query` function:**\n\n```python\ninput:  \"LoginRequest\"               # simple word → \"LoginRequest\"\ninput:  \"class GitHubRepo(BaseModel):\"\n  step 1: extract word identifiers  → [\"class\", \"GitHubRepo\", \"BaseModel\"]\n  step 2: remove code keywords      → [\"GitHubRepo\", \"BaseModel\"]\n  step 3: cap at 3, wrap in quotes  → '\"GitHubRepo\" AND \"BaseModel\"'\n```\n\nThe AND query finds nodes where both `GitHubRepo` AND `BaseModel` appear anywhere in the indexed fields.\n\n---\n\n## 16. Parameters — The $variable Syntax\n\nNever build queries by concatenating strings. Always use parameters.\n\n**Wrong (vulnerable to injection):**\n```python\nquery = f\"MATCH (n:Function) WHERE n.name = '{user_input}' RETURN n\"\n```\nIf `user_input` is `\"x' OR 1=1 RETURN n //\"`, you have a security hole.\n\n**Correct (parameterised):**\n```python\nquery = \"MATCH (n:Function) WHERE n.name = $name RETURN n\"\ndb.run_query(query, {\"name\": user_input})\n```\n\nThe Neo4j driver handles the value safely. `$name` is a placeholder, never interpreted as Cypher syntax.\n\nBugViper uses parameters everywhere:\n```cypher\nWHERE node.name CONTAINS $name_term   -- $name_term from Python dict\nLIMIT $limit                          -- $limit from Python dict\nAND size(node.source_code) < $max_bytes\n```\n\nPassed as:\n```python\ndb.run_query(query, {\n    \"name_term\": \"LoginRequest\",\n    \"limit\": 20,\n    \"max_bytes\": 500_000,\n})\n```\n\n---\n\n## 17. Writing Data — CREATE, MERGE, SET, DELETE\n\nYou don't need these for search, but they're used by the ingestion engine.\n\n### CREATE — create a new node\n\n```cypher\nCREATE (f:Function {\n    name: \"login_user\",\n    path: \"/api/auth.py\",\n    line_number: 42\n})\n```\n\nCreates a new Function node. If you run it twice, you get two identical nodes.\n\n### MERGE — create if not exists, match if exists\n\n```cypher\nMERGE (f:Function {name: \"login_user\", path: \"/api/auth.py\"})\n```\n\n\"Find a Function with this name and path. If found, use it. If not, create it.\"\n\nThis is how BugViper avoids duplicate nodes when re-ingesting a repo.\n\n### CREATE with a relationship\n\n```cypher\nMATCH (file:File {path: \"/api/auth.py\"})\nMATCH (func:Function {name: \"login_user\"})\nCREATE (file)-[:CONTAINS]->(func)\n```\n\n### SET — update properties\n\n```cypher\nMATCH (f:Function {name: \"login_user\"})\nSET f.cyclomatic_complexity = 7\nSET f.docstring = \"Handles user login\"\n```\n\n### SET with +=\n\nMerge properties (don't replace the whole node, just update specific fields):\n```cypher\nSET f += {cyclomatic_complexity: 7, updated_at: datetime()}\n```\n\n### DELETE and DETACH DELETE\n\n```cypher\nMATCH (f:Function {name: \"old_function\"})\nDELETE f\n```\n\nFails if `f` has any relationships. Use `DETACH DELETE` to also delete all its relationships:\n\n```cypher\nMATCH (r:Repository {id: \"owner/repo\"})\nOPTIONAL MATCH (r)-[:CONTAINS*]->(n)\nDETACH DELETE r, n\n```\n\n\"Delete the Repository node, all nodes it reaches via any CONTAINS chain, and all their relationships.\"\n\n---\n\n## 18. Indexes — Why Queries Are Fast\n\nWithout indexes, every query scans every node — like reading an entire book to find one word.\n\n### Property indexes (for exact/range lookups)\n\n```cypher\nCREATE INDEX function_name IF NOT EXISTS FOR (f:Function) ON (f.name)\n```\n\nNow `WHERE f.name = \"login\"` is O(log n) instead of O(n). The index is a sorted structure; Neo4j binary-searches it.\n\n```cypher\nCREATE CONSTRAINT repo_id_unique IF NOT EXISTS\n  FOR (r:Repository) REQUIRES r.id IS UNIQUE\n```\n\nA uniqueness constraint also creates an index. BugViper creates one per node type for the `id` property.\n\n### Fulltext indexes (for text search)\n\n```cypher\nCREATE FULLTEXT INDEX code_search\n  FOR (n:Class|Function|Method|Variable|Symbol)\n  ON EACH [n.name, n.docstring, n.source_code]\n```\n\nUses Lucene internally. Splits text into tokens, builds an inverted index. Looking up `\"login\"` returns all nodes containing that word in under a millisecond, regardless of graph size.\n\n### Why CONTAINS is slow without a fulltext index\n\n`node.name CONTAINS \"login\"` cannot use a property index — property indexes only support exact and prefix matches. Neo4j must load every Function node and check its name string one by one.\n\nThat's why BugViper uses fulltext search as Tier 1 (fast) and falls back to CONTAINS as Tier 2 (slower, but a safety net).\n\n---\n\n## 19. Every BugViper Query Explained\n\n### Search query — `search_code` (db/schema.py)\n\n```cypher\nCALL db.index.fulltext.queryNodes('code_search', $search_term)\nYIELD node, score\nOPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\nRETURN\n    CASE WHEN node:Function THEN 'function'\n         WHEN node:Class THEN 'class'\n         ELSE 'variable' END as type,\n    node.name as name,\n    coalesce(f.path, node.path) as path,\n    coalesce(node.line_number, 0) as line_number,\n    score\nORDER BY score DESC\nLIMIT 20\n```\n\n| Part | What it does |\n|------|-------------|\n| `CALL db.index.fulltext.queryNodes(...)` | Hit the Lucene index — returns matching nodes in milliseconds |\n| `YIELD node, score` | Unpack: give me the node and how relevant it is (0–1) |\n| `OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)` | Try to find the file this node lives in. If the node stores its path directly, `f` will be null |\n| `CASE WHEN node:Function THEN 'function' ...` | Convert the Neo4j label into a human-readable string |\n| `coalesce(f.path, node.path)` | Use the file's path if we found a file; otherwise use the path stored on the node itself |\n| `coalesce(node.line_number, 0)` | Default to 0 if line_number is missing |\n| `ORDER BY score DESC` | Best matches first |\n| `LIMIT 20` | Never return more than 20 |\n\n---\n\n### Name CONTAINS fallback — `_name_contains_fallback` (db/queries.py)\n\n```cypher\nMATCH (node)\nWHERE (node:Function OR node:Class OR node:Variable)\n  AND node.name CONTAINS $name_term\nOPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\nRETURN\n    CASE WHEN node:Function THEN 'function'\n         WHEN node:Class THEN 'class'\n         ELSE 'variable' END as type,\n    node.name as name,\n    coalesce(f.path, node.path) as path,\n    coalesce(node.line_number, 0) as line_number,\n    1.0 as score\nORDER BY node.name\nLIMIT $limit\n```\n\n| Part | What it does |\n|------|-------------|\n| `MATCH (node)` | Find any node (no label filter yet) |\n| `WHERE (node:Function OR node:Class OR node:Variable)` | Now filter to only these three types |\n| `AND node.name CONTAINS $name_term` | The name must contain the search term as a substring |\n| `1.0 as score` | Hardcoded score — CONTAINS doesn't have relevance ranking, so all results are equally \"relevant\" |\n\nThis runs when Tier 1 returns nothing. It catches things the fulltext index missed (e.g. a newly ingested node not yet indexed).\n\n---\n\n### File content line scan — `search_file_content` (db/queries.py)\n\n```cypher\nCALL db.index.fulltext.queryNodes('file_content_search', $search_term)\nYIELD node, score\nWHERE node.source_code IS NOT NULL\n  AND size(node.source_code) < $max_bytes\nWITH node, score, split(node.source_code, '\\n') AS lines\nLIMIT 10\nUNWIND range(0, size(lines) - 1) AS idx\nWITH node.path AS path, lines[idx] AS line_content, idx + 1 AS line_number, score\nWHERE toLower(line_content) CONTAINS toLower($raw_term)\nRETURN path, line_number, line_content AS match_line\nORDER BY score DESC, path, line_number\nLIMIT $limit\n```\n\n| Part | What it does |\n|------|-------------|\n| `CALL db.index.fulltext.queryNodes('file_content_search', ...)` | Find files whose source_code matches the Lucene query |\n| `WHERE size(node.source_code) < $max_bytes` | Skip files over 500 KB (minified, generated) |\n| `WITH ..., split(node.source_code, '\\n') AS lines` | Split source code into an array of lines, server-side |\n| `LIMIT 10` | Only process the 10 best-matching files **before** UNWIND to prevent a row explosion |\n| `UNWIND range(0, size(lines) - 1) AS idx` | Turn the array `[0, 1, 2, ...]` into individual rows — one row per line |\n| `lines[idx] AS line_content` | Pick the line at this index |\n| `idx + 1 AS line_number` | Convert 0-based index to 1-based line number |\n| `WHERE toLower(line_content) CONTAINS toLower($raw_term)` | Case-insensitive match against the raw search term |\n| `RETURN path, line_number, match_line` | Only the matching lines come back over the network — not the full source blobs |\n\n---\n\n### Peek — `peek_file_lines` (db/queries.py)\n\n```cypher\nMATCH (f:File {path: $path})\nWHERE f.source_code IS NOT NULL AND size(f.source_code) < 2000000\nRETURN f.source_code as source_code\nLIMIT 1\n```\n\n| Part | What it does |\n|------|-------------|\n| `{path: $path}` | Shorthand for `WHERE f.path = $path` — matches by exact property value |\n| `size(f.source_code) < 2000000` | Reject files over 2 MB to prevent memory spikes |\n| `LIMIT 1` | Safety net — path should be unique, but just in case |\n\nAfter this, Python slices the source_code array to extract just the window of lines around the anchor.\n\n---\n\n### Repository listing — `list_repositories` (db/queries.py)\n\n```cypher\nMATCH (r:Repository)\nOPTIONAL MATCH (r)-[:CONTAINS*]->(f:File)\nRETURN r.id as id, r.name as name, r.owner as owner,\n       r.url as url, r.path as local_path,\n       r.last_commit_hash as last_commit,\n       r.created_at as created_at,\n       r.updated_at as updated_at,\n       count(DISTINCT f) as file_count\nORDER BY r.updated_at DESC, r.name\n```\n\n| Part | What it does |\n|------|-------------|\n| `MATCH (r:Repository)` | Get all repositories |\n| `OPTIONAL MATCH (r)-[:CONTAINS*]->(f:File)` | Try to count all Files reachable from each repo. `*` = any number of hops |\n| `count(DISTINCT f) as file_count` | Count unique File nodes per repository (DISTINCT prevents double-counting if a file is reachable via multiple paths) |\n| `ORDER BY r.updated_at DESC, r.name` | Most recently updated repos first; alphabetical as tiebreaker |\n\n---\n\n### Delete repository — `delete_repository` (db/queries.py)\n\n```cypher\nMATCH (r:Repository)\nWHERE r.id = $repo_id OR r.repo = $repo_id\nOPTIONAL MATCH (r)-[:CONTAINS*]->(n)\nDETACH DELETE r, n\nRETURN count(r) as deleted_count\n```\n\n| Part | What it does |\n|------|-------------|\n| `WHERE r.id = $repo_id OR r.repo = $repo_id` | Match either property name (handles legacy data format) |\n| `OPTIONAL MATCH (r)-[:CONTAINS*]->(n)` | Find every node reachable from this repo — all files, functions, classes, variables |\n| `DETACH DELETE r, n` | Delete the repo node, all its children, and all relationships. `DETACH` removes relationships first (required before deleting nodes) |\n| `RETURN count(r)` | Return how many repos were deleted (0 = not found, 1 = success) |\n\n---\n\n### Callers query — `find_callers` (db/queries.py)\n\n```cypher\nMATCH (caller)-[:CALLS]->(target)\nWHERE target.name = $name AND target.path CONTAINS $repo_id\nRETURN DISTINCT\n    caller.name as caller_name,\n    CASE WHEN caller:Function THEN 'function'\n         WHEN caller:Method THEN 'method'\n         ELSE 'other' END as caller_type,\n    caller.path as path\nLIMIT 10\n```\n\n| Part | What it does |\n|------|-------------|\n| `(caller)-[:CALLS]->(target)` | Find any pair of nodes connected by CALLS. `caller` is anything that calls `target` |\n| `target.name = $name` | The thing being called must have this exact name |\n| `target.path CONTAINS $repo_id` | Scope to nodes in this repository (paths contain the repo identifier) |\n| `RETURN DISTINCT` | Deduplicate — the same caller might call the same function multiple times at different lines; we only want the caller once |\n\n---\n\n## Quick Reference Card\n\n```\nMATCH (n:Label)              find nodes\nMATCH (a)-[:REL]->(b)        follow a relationship\nOPTIONAL MATCH               like MATCH but keep nulls (LEFT JOIN)\nWHERE n.prop = $val          filter\nWHERE n.prop CONTAINS $val   substring match\nWHERE n:Label                filter by label\nRETURN n.name AS name        output (with optional rename)\nORDER BY n.name DESC         sort\nLIMIT 20                     cap results\nSKIP 20                      pagination offset\nWITH n, value AS alias        pipe output to next step\nCASE WHEN x THEN y END       conditional value\ncoalesce(a, b, c)            first non-null\ncount(DISTINCT n)            count unique\ncollect(n.name)              aggregate into list\nUNWIND list AS item          expand list into rows\nsplit(str, '\\n')             string → array\nrange(0, 5)                  [0,1,2,3,4,5]\nsize(list)                   length\ntoLower(str)                 lowercase\n$param                       safe parameter (never string-concat)\nCALL procedure() YIELD x     call built-in procedure\nCREATE (n:Label {k: v})      create a node\nMERGE (n:Label {k: v})       create if not exists\nSET n.prop = value           update a property\nDETACH DELETE n              delete node + its relationships\n```\n\n---\n\n*This guide covers every Cypher construct used in BugViper's codebase as of 2026-02-21.*\n","structuredPatch":[],"originalFile":null},"sourceToolAssistantUUID":"0248327e-8c15-47a8-9c0b-c4807af2724a"}
{"parentUuid":null,"logicalParentUuid":"93a1921c-36dd-4e22-8cc0-7edcc8032fe8","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"system","subtype":"compact_boundary","content":"Conversation compacted","isMeta":false,"timestamp":"2026-02-21T09:17:33.664Z","uuid":"196b7a85-c6cf-4760-8404-9c32bffd7d86","level":"info","compactMetadata":{"trigger":"auto","preTokens":167599}}
{"parentUuid":"196b7a85-c6cf-4760-8404-9c32bffd7d86","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":"This session is being continued from a previous conversation that ran out of context. The summary below covers the earlier portion of the conversation.\n\nAnalysis:\nLet me chronologically analyze the conversation to capture all technical details, decisions, and patterns.\n\n**Conversation Flow:**\n\n1. User asked if CLAUDE.md was read — confirmed yes\n2. User reported two curl failures:\n   - `/search` returning nothing useful\n   - `/search-symbols` failing with Lucene parse error on `class LoginRequest(BaseModel):`\n3. User reported `/search` still returning nothing for `class GitHubRepo(BaseModel)`\n4. User asked to merge symbol and full-text search into a single endpoint, delete the two separate APIs, and improve the UI with a single text field\n5. User asked if the implementation is fast, optimized, and secure\n6. User asked for a beginner Cypher guide written to a Markdown file\n\n**Key Technical Work:**\n\n**Session 1 - Initial search fixes:**\n- Found `search_code` query used `[:DEFINES*1..2]` (wrong relationship — should be `[:CONTAINS]`)\n- `search_symbols` had no Lucene escaping, causing crash on special chars\n- Both endpoints returned wrong data shapes (raw Node objects)\n- No `/code-finder/line` or `/code-finder/peek` endpoints existed (referenced in api.ts but not implemented)\n- Fixed db/schema.py `search_code` Cypher\n- Fixed db/queries.py `search_code`, `search_symbols` methods\n- Added `search_file_content` and `peek_file_lines` methods\n- Added `/code-finder/line` and `/code-finder/peek` endpoints to query.py\n- Updated frontend query page with `SearchResultsView` and `PeekViewer`\n\n**Session 2 - Still returning nothing:**\n- Root cause: `_escape_lucene_query` always wrapped in quotes (phrase search) — `\"class GitHubRepo(BaseModel)\"` won't match node names which only store `GitHubRepo`\n- CONTAINS fallback searched `node.name CONTAINS \"class GitHubRepo(BaseModel)\"` — impossible to match\n- No fallback to file content search\n- Added `_extract_identifiers()` method to extract meaningful code tokens\n- Rewrote `_escape_lucene_query` to use AND-keyword strategy for complex queries\n- Added `_name_contains_fallback()` using longest extracted identifier\n- Made `search_code` three-tier: fulltext → name CONTAINS → file content line search\n\n**Session 3 - Unify search, improve UI:**\n- Removed `/search-symbols` endpoint from router\n- Updated `/search` with limit param, removed broken repo_id filter\n- Updated `api.ts` — removed `searchSymbols`, updated `searchCode` and `findDefinition`\n- Completely rewrote `query/page.tsx` with:\n  - Standalone `SearchTab` component (single input + Search button)\n  - `GenericQueryTab` for Analysis/CodeFinder/Metrics\n  - `SearchResultsView` grouping symbols vs file matches\n  - `PeekViewer` with load-more above/below buttons\n\n**Session 4 - Optimization and security audit:**\n- Removed unused imports: `Body`, `Optional`, `os` from `query.py`\n- Added 500-char query length limit on `/search` and `/code-finder/line`\n- Added `above/below` caps (200) and `line >= 1` validation on peek\n- Rewrote `search_file_content` to do line scanning entirely server-side in Cypher (UNWIND+split) instead of fetching full source_code blobs to Python\n- Added `_MAX_FILE_BYTES = 500_000` class constant to skip large files\n- Added 2MB size guard to `peek_file_lines`\n\n**Session 5 - Cypher guide:**\n- Created `CYPHER_GUIDE.md` at project root\n- Comprehensive guide covering: nodes/relationships/properties, MATCH, WHERE, string operators, OPTIONAL MATCH, CASE WHEN, coalesce(), ORDER BY/LIMIT, WITH, aggregation, list operations (UNWIND, range, split, size), string functions, fulltext CALL/YIELD, parameters, writing data, indexes\n- Every BugViper query explained line by line with tables\n\n**Files Modified:**\n1. `db/schema.py` — fixed `search_code` and `search_symbols` Cypher queries\n2. `db/queries.py` — major rewrites: `_escape_lucene_query`, new `_extract_identifiers`, `_name_contains_fallback`, `search_code`, `search_symbols`, `search_file_content`, `peek_file_lines`\n3. `api/routers/query.py` — removed `/search-symbols`, updated `/search`, added `/code-finder/line` and `/code-finder/peek`, removed unused imports, added input validation\n4. `frontend/lib/api.ts` — removed `searchSymbols`, updated `searchCode`, updated `findDefinition`\n5. `frontend/app/(protected)/query/page.tsx` — complete rewrite with unified search UI\n6. `CLAUDE.md` — updated Key Endpoints table (removed `/search-symbols`)\n7. `CYPHER_GUIDE.md` — new file created\n\n**Errors encountered:**\n- Lucene ParseException on special chars `(`, `)`, `:` — fixed with AND-keyword escaping\n- `[:DEFINES*1..2]` relationship doesn't exist in schema — fixed to `[:CONTAINS]`\n- `symbol_search` index targets non-existent `Symbol` nodes — switched to `code_search`\n- Search returning nothing — missing three-tier fallback strategy\n- Pylance warnings on unused imports — cleaned up\n\nSummary:\n1. Primary Request and Intent:\n   The user had a series of progressive requests throughout the session:\n   1. **Fix broken full-text search**: `/search` was returning nothing and `/search-symbols` was crashing with a Lucene parse error when searching for `class LoginRequest(BaseModel):`. The user wanted results showing file paths and line numbers.\n   2. **Add peek context**: Results should allow querying 10+ lines above and below the match, in both the API and the UI.\n   3. **Fix search still returning nothing**: After initial fixes, searching for `class GitHubRepo(BaseModel)` still returned nothing. The search needed to find any matching words or lines.\n   4. **Unify search into a single endpoint**: Merge `Full-text Search` and `Symbol Search` into one API (`/search`) and one UI text field. Delete the separate `/search-symbols` endpoint and the two-button pattern.\n   5. **Improve the UI**: Single text field for search, better result cards, grouped results.\n   6. **Audit for performance, optimization, and security**: Confirm the implementation is production-quality.\n   7. **Create a Cypher beginner's guide**: A detailed `.md` file explaining all Cypher concepts, written for someone who only knows Firestore with no SQL knowledge.\n\n2. Key Technical Concepts:\n   - **Neo4j Graph Database**: Nodes, relationships, properties, labels\n   - **Cypher Query Language**: MATCH, WHERE, OPTIONAL MATCH, WITH, UNWIND, CASE WHEN, coalesce(), ORDER BY, LIMIT, CONTAINS, STARTS WITH, split(), range(), size(), toLower(), count(), collect(), DISTINCT, CALL, YIELD, CREATE, MERGE, DETACH DELETE\n   - **Apache Lucene fulltext indexes**: `code_search` (Function/Class/Variable on name/docstring/source_code) and `file_content_search` (File on source_code)\n   - **Lucene query language**: Phrase search `\"term\"`, AND-keyword strategy `\"A\" AND \"B\"`, special character escaping\n   - **Three-tier search strategy**: Fulltext index → name CONTAINS fallback → file content line search\n   - **Server-side line scanning**: Using Cypher `split + UNWIND + CONTAINS` to avoid transferring full source_code blobs to Python\n   - **Parameterised Cypher queries**: Security via `$param` substitution (prevents injection)\n   - **FastAPI**: Router endpoints, Query params, HTTPException, Depends injection\n   - **Next.js 16 / React 19**: Client components, hooks (useState, useRef, useCallback), TypeScript strict mode\n   - **TailwindCSS 4 + shadcn/ui**: Component library used throughout the frontend\n\n3. Files and Code Sections:\n\n   - **`db/schema.py`** (modified)\n     - Fixed `search_code` Cypher: replaced `[:DEFINES*1..2]` (non-existent relationship) with `OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)` and changed return shape to lean fields\n     - Fixed `search_symbols` Cypher: switched from `symbol_search` index (targets non-existent `Symbol` nodes) to `code_search` index\n     ```cypher\n     \"search_code\": \"\"\"\n         CALL db.index.fulltext.queryNodes('code_search', $search_term)\n         YIELD node, score\n         OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)\n         RETURN\n             CASE WHEN node:Function THEN 'function'\n                  WHEN node:Class THEN 'class'\n                  ELSE 'variable' END as type,\n             node.name as name,\n             coalesce(f.path, node.path) as path,\n             coalesce(node.line_number, 0) as line_number,\n             score\n         ORDER BY score DESC\n         LIMIT 20\n     \"\"\",\n     ```\n\n   - **`db/queries.py`** (heavily modified — most important file)\n     - Added `_CODE_KEYWORDS` frozenset of Python/JS keywords to exclude from identifier extraction\n     - Added `_extract_identifiers(query)` method — uses regex `\\b[A-Za-z_][A-Za-z0-9_]{2,}\\b` to extract word tokens, filters out code keywords\n     - Rewrote `_escape_lucene_query()` with two-strategy approach:\n       - Simple identifier → phrase search: `\"LoginRequest\"`\n       - Complex query with special chars → AND-keyword: `\"GitHubRepo\" AND \"BaseModel\"`\n     - Added `_name_contains_fallback()` — extracts the longest identifier from the query and does `node.name CONTAINS $name_term`\n     - Rewrote `search_code()` as three-tier strategy:\n       1. Fulltext `code_search` index\n       2. `_name_contains_fallback()` using primary extracted identifier\n       3. `search_file_content()` for raw line matches\n     - Rewrote `search_symbols()` — uses escaped Lucene query, falls back to `_name_contains_fallback()`\n     - Added `_MAX_FILE_BYTES = 500_000` class constant\n     - Rewrote `search_file_content()` — completely server-side Cypher using `split + UNWIND + CONTAINS`, no Python-side scanning of source_code blobs:\n     ```cypher\n     CALL db.index.fulltext.queryNodes('file_content_search', $search_term) YIELD node, score\n     WHERE node.source_code IS NOT NULL\n       AND size(node.source_code) < $max_bytes\n     WITH node, score, split(node.source_code, '\\n') AS lines\n     LIMIT 10\n     UNWIND range(0, size(lines) - 1) AS idx\n     WITH node.path AS path, lines[idx] AS line_content, idx + 1 AS line_number, score\n     WHERE toLower(line_content) CONTAINS toLower($raw_term)\n     RETURN path, line_number, line_content AS match_line\n     ORDER BY score DESC, path, line_number\n     LIMIT $limit\n     ```\n     - Updated `peek_file_lines()` — added `size(f.source_code) < 2000000` guard in Cypher query to reject files over 2MB\n\n   - **`api/routers/query.py`** (modified)\n     - Removed unused imports: `Body`, `Optional`, `os` (fixed Pylance warnings)\n     - Removed `GET /search-symbols` endpoint entirely\n     - Updated `GET /search` — added `limit` param, removed broken `repo_id` filter (was checking wrong key), added 500-char length validation\n     - Added `GET /code-finder/line` endpoint — calls `search_file_content()`, hard cap at 100 results\n     - Added `GET /code-finder/peek` endpoint — caps `above`/`below` at 200, validates `line >= 1`\n     ```python\n     @router.get(\"/code-finder/line\")\n     async def find_by_line(\n         query: str = Query(...),\n         limit: int = Query(50),\n         query_service: CodeQueryService = Depends(get_query_service),\n     ) -> Dict[str, Any]:\n     \n     @router.get(\"/code-finder/peek\")\n     async def peek_file_lines(\n         path: str = Query(...),\n         line: int = Query(...),\n         above: int = Query(10),\n         below: int = Query(10),\n         query_service: CodeQueryService = Depends(get_query_service),\n     ) -> Dict[str, Any]:\n     ```\n\n   - **`frontend/lib/api.ts`** (modified)\n     - Removed `searchSymbols` export\n     - Updated `searchCode` to accept `limit` parameter: `(query: string, limit = 30)`\n     - Updated `findDefinition` to call `/search` instead of removed `/search-symbols`\n     - `findByLine` and `peekFileLines` already existed and are correct\n\n   - **`frontend/app/(protected)/query/page.tsx`** (completely rewritten twice)\n     - **First rewrite**: Added `SearchResultsView` (renders type badge + name + file:line + score), `PeekViewer` (inline context with load-more above/below), `SearchHit` and `PeekResult` TypeScript interfaces, `isSearch` flag on `QueryDef` type to route to search-specific view\n     - **Second rewrite (unify)**: Standalone `SearchTab` component with single input + Search button; `GenericQueryTab` shared component for Analysis/CodeFinder/Metrics; `TypeBadge` with colour-coded styles per type; `SearchHitCard` with pretty path display (directory dimmed, filename bold, line pill); grouped results (Symbols section vs File matches section); removed two-button pattern entirely\n     - Key components:\n     ```tsx\n     function SearchTab() — standalone search UI, own state, autofocused input\n     function PeekViewer({ path, anchorLine }) — inline context viewer with STEP=20 expand\n     function SearchHitCard({ hit }) — single result card with TypeBadge, path, peek\n     function SearchResultsView({ data }) — groups hits into symbols + lines sections\n     function GenericQueryTab({ queries }) — shared tab for Analysis/CodeFinder/Metrics\n     ```\n\n   - **`CLAUDE.md`** (modified)\n     - Updated Key Endpoints table: removed `/search-symbols` row, updated `/search` description to \"Unified search: symbols → name CONTAINS → file content line search\"\n\n   - **`CYPHER_GUIDE.md`** (created — new file at project root)\n     - 19-section comprehensive Cypher beginner's guide\n     - Written for Firestore developers with no SQL knowledge\n     - Covers: graph database concepts vs Firestore, nodes/relationships/properties, MATCH, RETURN, WHERE, string operators, relationship pattern matching, OPTIONAL MATCH, AS/CASE WHEN/coalesce(), ORDER BY/LIMIT/SKIP, WITH, aggregation (count/sum/collect/DISTINCT), list operations (range/UNWIND/split/size), string functions (toLower/trim/left/substring), fulltext CALL/YIELD, parameters ($var), writing data (CREATE/MERGE/SET/DELETE), indexes\n     - Every BugViper query explained line by line with tables\n\n4. Errors and fixes:\n\n   - **Lucene ParseException on special characters**: `/search-symbols` crashed with `ParseException: Encountered \":\"` when searching `class LoginRequest(BaseModel):`. Root cause: raw user string passed directly to Lucene without escaping. Fix: added `_escape_lucene_query()` call in `search_symbols()`, then later rewrote `_escape_lucene_query()` to use AND-keyword strategy for complex inputs.\n\n   - **Wrong relationship type in `search_code` Cypher**: `(f:File)-[:DEFINES*1..2]->(node)` — `[:DEFINES]` does not exist in the schema. Fix: changed to `OPTIONAL MATCH (f:File)-[:CONTAINS]->(node)`.\n\n   - **`symbol_search` index on non-existent nodes**: `search_symbols` used the `symbol_search` index which targets `Symbol` nodes — but `Symbol` nodes don't exist in the actual graph. Fix: switched both `search_code` and `search_symbols` queries to use `code_search` index (covers real Function/Class/Variable nodes).\n\n   - **Raw Node objects returned (not serializable)**: `search_code` returned `dict(record[\"node\"])` — Neo4j Node objects. Fix: changed to return individual named fields (`type`, `name`, `path`, `line_number`, `score`).\n\n   - **Search still returning nothing after initial fixes** (user reported for `class GitHubRepo(BaseModel)`): `_escape_lucene_query` wrapped everything in quotes making it a phrase search `\"class GitHubRepo(BaseModel)\"`. The `code_search` index stores node `name` as just `GitHubRepo`, not the full declaration — phrase can't match. CONTAINS fallback also used the full raw string which never matches names. No fallback to file content. Fix: rewrote `_escape_lucene_query` with identifier extraction + AND strategy; added `_name_contains_fallback` using longest identifier; added Tier 3 file content search.\n\n   - **Pylance warnings on unused imports**: `Body`, `Optional`, `os` in `query.py`. Fix: removed all three unused imports.\n\n   - **Performance issue — source_code blobs transferred to Python**: `search_file_content` fetched entire `source_code` fields (up to 100KB+ × 20 files) to Python for line scanning. CONTAINS fallback was a full table scan with no size guard. Fix: rewrote both tiers to use server-side Cypher `split + UNWIND + CONTAINS`; added `_MAX_FILE_BYTES = 500_000` guard; `LIMIT 10` before UNWIND to control row explosion.\n\n   - **No size guard on peek**: Large minified files (10MB+) could be fetched entirely. Fix: added `size(f.source_code) < 2000000` in the Cypher query.\n\n5. Problem Solving:\n   - **Unified search strategy**: Designed a three-tier search (fulltext index → name CONTAINS using extracted identifier → file content line scan) that handles: simple symbol names, code-keyword-prefixed queries, raw code snippets, and partial matches\n   - **Lucene injection prevention**: The `_extract_identifiers` regex only passes `[A-Za-z_][A-Za-z0-9_]{2,}` tokens, then wraps each in quotes before building AND query — no raw user text reaches the Lucene parser\n   - **Server-side line scanning**: Eliminated Python-side source blob processing by using Cypher's `split()`, `range()`, and `UNWIND` to do the iteration inside Neo4j, returning only matching lines over the network\n   - **UI unification**: Replaced two-button Search tab (Full-text Search + Symbol Search) with a single `SearchTab` component having one autofocused input; other tabs refactored into shared `GenericQueryTab`\n\n6. All user messages:\n   - \"did you read the claude.md\"\n   - Large curl command block reporting: full-text search not working (should show lines/files with 10+ line context in UI), symbol search failing with Lucene ParseException\n   - Second curl command block for `class GitHubRepo(BaseModel)`: \"it found nothing, it should find any lines or any word\"\n   - \"what is the difference between the symbol and full text search, can we put it in a single endpoint and delete this 2 separate apis and in the Ui as well a single Textfield for the Full text search. And Improve the UI as well if possible.\"\n   - \"is this fast and most optimized and secure?\"\n   - \"Can you create a easy guide for someone who does not know about sql and explain all the queries like coalesce, and other query language of the cypher, I know no sql (firestore). Put the guide in a .md file\"\n   - Summary request (current message)\n\n7. Pending Tasks:\n   - No explicitly pending tasks remain. All user requests in this session have been completed:\n     - Search fixed (three-tier strategy)\n     - `/code-finder/line` and `/code-finder/peek` endpoints added\n     - `/search-symbols` removed, unified into `/search`\n     - UI redesigned with single search field\n     - Performance and security audit completed\n     - `CYPHER_GUIDE.md` created\n\n8. Current Work:\n   The most recent completed task was creating `CYPHER_GUIDE.md` at `REDACTED.md`. This is a 19-section Markdown document written for a Firestore developer with no SQL/Cypher knowledge. It covers every Cypher concept used in BugViper (MATCH, WHERE, OPTIONAL MATCH, WITH, UNWIND, coalesce, CASE WHEN, fulltext CALL/YIELD, parameters, indexes, etc.) and includes a section explaining every BugViper query line by line with tables.\n\n9. Optional Next Step:\n   No next step is directly implied by the user's most recent request (which was to create the guide and has been completed). The guide is at `REDACTED.md`. The user's last explicit request was: \"Can you create a easy guide for someone who does not know about sql and explain all the queries like coalesce, and other query language of the cypher, I know no sql (firestore). Put the guide in a .md file\" — this is fully done.\n\nIf you need specific details from before compaction (like exact code snippets, error messages, or content you generated), read the full transcript at: /Users/skmabudalam/.REDACTED.jsonl\nPlease continue the conversation from where we left off without asking the user any further questions. Continue with the last task that you were asked to work on."},"isVisibleInTranscriptOnly":true,"isCompactSummary":true,"uuid":"a4bfa941-b950-4a8d-8f54-80d8461c5736","timestamp":"2026-02-21T09:17:33.664Z"}
{"parentUuid":"a4bfa941-b950-4a8d-8f54-80d8461c5736","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"SessionStart","hookName":"SessionStart:compact","command":"entire hooks claude-code session-start"},"parentToolUseID":"b028d3ce-a889-4aa4-a363-659d294ef57b","toolUseID":"b028d3ce-a889-4aa4-a363-659d294ef57b","timestamp":"2026-02-21T09:17:32.981Z","uuid":"10d9feaa-6493-44c7-8ad4-316d72d8fa1e"}
{"parentUuid":"10d9feaa-6493-44c7-8ad4-316d72d8fa1e","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01Q3ezBx1EvL1ESyHd6BJohV","type":"message","role":"assistant","content":[{"type":"thinking","thinking":"The conversation summary indicates that the last task was creating `CYPHER_GUIDE.md`, which was completed. Let me check the current state of the project to see if there's anything that needs to be done or if there's anything I missed.\n\nLet me check the memory file and see what the current state is.","signature":"EtQDCkYICxgCKkDht4U47cbTSqtvjV3ZfEebPVA96gnlMouHUUEHoo0bOIE5cQ9tDbluJQjSDOhFdMHSll24S/QyugkLSprZ9ijpEgwHxsfEhO9AK3C8X0UaDLMeyHv0tHtk+uuyyiIwnF6evKcPYz3ntPAyrvxJkQyMcHh1fiDsvxtXSiGuxPBIYas8eP778g7H4m2T2VkAKrsCVmxIIbp4pdOIhSpzZDyv2Uqez73yWQH96tqRH8xMLx3i75K5zzv1NvY6M7MoKEK9Xcj9TrVTs6xSOkghx/xJZSZzMo7cZ/lXOUonkVGcNuJR1zVXr3o4grdvDw1A+vJRQkmN1RFfmR2Otv2ltKPF1A0Vik8iLdwlj/Qg4pcF9pEUlaEDLwr/VeHyxzkwzNe1xSeGuhfrwjLwjbvSehdzMDgAoyuHQtIa5LoUyvpy+/IZ3nzQEfDc7nF6nZstwItL9H9gEy2WGq/QLF5XWcySdr/LTRCgJkx8FE1s7AHq493EF3x/KDqW4PvJZkOSxYfR6/mpCskCzRP79utgbH52YcFSe/FN5IGd1VswEmi7ba84ylKRlS78FkwzMNFNy9Cz53DMOHOxJ93gqBk/WCpIEydAsuG9VOOsXUzqGAE="}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":15583,"cache_read_input_tokens":19790,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":15583},"output_tokens":7,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLxpshrEKUpMpauadynt","type":"assistant","uuid":"47aa3cfb-97cb-4ecc-84ec-c239c9a66d9f","timestamp":"2026-02-21T09:17:36.920Z"}
{"parentUuid":"47aa3cfb-97cb-4ecc-84ec-c239c9a66d9f","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01Q3ezBx1EvL1ESyHd6BJohV","type":"message","role":"assistant","content":[{"type":"text","text":"The previous session completed all requested tasks. Let me verify the current state of the key files that were modified."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":15583,"cache_read_input_tokens":19790,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":15583},"output_tokens":7,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLxpshrEKUpMpauadynt","type":"assistant","uuid":"5fa8ac3f-ab35-413e-97c9-c1dfbdc67ca3","timestamp":"2026-02-21T09:17:37.730Z"}
{"parentUuid":"5fa8ac3f-ab35-413e-97c9-c1dfbdc67ca3","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01Q3ezBx1EvL1ESyHd6BJohV","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JbbjCnWYGctS36pfDueLHP","name":"Bash","input":{"command":"ls REDACTED.md && wc -l REDACTED.md","description":"Check CYPHER_GUIDE.md exists and size"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":15583,"cache_read_input_tokens":19790,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":15583},"output_tokens":7,"service_tier":"standard","inference_geo":"not_available"}},"requestId":"req_011CYLxpshrEKUpMpauadynt","type":"assistant","uuid":"f6a4acc0-9cb7-45f2-9c47-831c2083cd83","timestamp":"2026-02-21T09:17:38.933Z"}
{"parentUuid":"f6a4acc0-9cb7-45f2-9c47-831c2083cd83","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JbbjCnWYGctS36pfDueLHP","type":"tool_result","content":"REDACTED.md\n    1094 REDACTED.md","is_error":false}]},"uuid":"b88523b8-edf0-436f-be26-5f3e07a22943","timestamp":"2026-02-21T09:17:39.045Z","toolUseResult":{"stdout":"REDACTED.md\n    1094 REDACTED.md","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"f6a4acc0-9cb7-45f2-9c47-831c2083cd83"}
{"parentUuid":"b88523b8-edf0-436f-be26-5f3e07a22943","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01Q3ezBx1EvL1ESyHd6BJohV","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017om4ewPaUNrb8m3Q27MyMQ","name":"Bash","input":{"command":"git status","description":"Show git status of modified files"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":15583,"cache_read_input_tokens":19790,"output_tokens":310,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":15583,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLxpshrEKUpMpauadynt","type":"assistant","uuid":"5d3694f1-4bc7-47a7-b5b5-0a910839da2c","timestamp":"2026-02-21T09:17:39.433Z"}
{"parentUuid":"5d3694f1-4bc7-47a7-b5b5-0a910839da2c","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017om4ewPaUNrb8m3Q27MyMQ","type":"tool_result","content":"On branch main\nYour branch is up to date with 'bugviper/main'.\n\nChanges to be committed:\n  (use \"git restore --staged <file>...\" to unstage)\n\tnew file:   Claude.md\n\tmodified:   api/routers/auth.py\n\tmodified:   api/routers/query.py\n\tmodified:   db/queries.py\n\tmodified:   db/schema.py\n\tmodified:   frontend/app/(protected)/query/page.tsx\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\tCYPHER_GUIDE.md","is_error":false}]},"uuid":"e8a0ab8c-bf2a-41e0-9492-77c1863c9df1","timestamp":"2026-02-21T09:17:39.525Z","toolUseResult":{"stdout":"On branch main\nYour branch is up to date with 'bugviper/main'.\n\nChanges to be committed:\n  (use \"git restore --staged <file>...\" to unstage)\n\tnew file:   Claude.md\n\tmodified:   api/routers/auth.py\n\tmodified:   api/routers/query.py\n\tmodified:   db/queries.py\n\tmodified:   db/schema.py\n\tmodified:   frontend/app/(protected)/query/page.tsx\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\tCYPHER_GUIDE.md","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false},"sourceToolAssistantUUID":"5d3694f1-4bc7-47a7-b5b5-0a910839da2c"}
{"parentUuid":"e8a0ab8c-bf2a-41e0-9492-77c1863c9df1","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","message":{"model":"claude-sonnet-4-6","id":"msg_01YSixUAgqRvB6tf4Kub3rhB","type":"message","role":"assistant","content":[{"type":"text","text":"All previous work is intact. Here's a summary of what was completed in the previous session:\n\n**All tasks done:**\n\n1. **Fixed broken search** (`db/queries.py`, `db/schema.py`) — three-tier strategy: fulltext index → name CONTAINS fallback → file content line scan. Lucene injection-safe via identifier extraction + AND-keyword escaping.\n\n2. **Added missing endpoints** (`api/routers/query.py`) — `/code-finder/line` and `/code-finder/peek` with input validation (500-char cap, 200-line window cap, 2MB file size guard).\n\n3. **Unified search** — removed `/search-symbols`, everything goes through `/search`. Frontend updated with single text field.\n\n4. **UI redesign** (`frontend/app/(protected)/query/page.tsx`) — standalone `SearchTab` with autofocused input, `SearchHitCard` with grouped results (Symbols vs File matches), `PeekViewer` with load-more.\n\n5. **Performance audit** — server-side Cypher line scanning (`split + UNWIND + CONTAINS`) instead of fetching blobs to Python, `_MAX_FILE_BYTES = 500_000` guard.\n\n6. **`CYPHER_GUIDE.md`** created (1094 lines) — comprehensive Cypher guide written for a Firestore developer, covering every concept used in BugViper.\n\nThe changes are staged but not committed. Let me know what you'd like to work on next."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":925,"cache_read_input_tokens":35373,"output_tokens":352,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":925,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"}},"requestId":"req_011CYLxqKBHZoueGuBW8cqji","type":"assistant","uuid":"4eff1a80-b94a-4666-8b4b-a145f535d219","timestamp":"2026-02-21T09:17:51.544Z"}
{"parentUuid":"4eff1a80-b94a-4666-8b4b-a145f535d219","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"progress","data":{"type":"hook_progress","hookEvent":"Stop","hookName":"Stop","command":"entire hooks claude-code stop"},"parentToolUseID":"2f145d7e-76d2-48ed-b4f1-c6e807801c55","toolUseID":"2f145d7e-76d2-48ed-b4f1-c6e807801c55","timestamp":"2026-02-21T09:17:51.548Z","uuid":"7cd4f1cc-e1a6-4a19-b4c9-e0153b6baffc"}
{"parentUuid":"7cd4f1cc-e1a6-4a19-b4c9-e0153b6baffc","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"system","subtype":"stop_hook_summary","hookCount":1,"hookInfos":[{"command":"entire hooks claude-code stop","durationMs":2499}],"hookErrors":[],"preventedContinuation":false,"stopReason":"","hasOutput":true,"level":"suggestion","timestamp":"2026-02-21T09:17:54.048Z","uuid":"0a2c6ce0-72eb-4d43-a808-df6d130c915c","toolUseID":"2f145d7e-76d2-48ed-b4f1-c6e807801c55"}
{"parentUuid":"0a2c6ce0-72eb-4d43-a808-df6d130c915c","isSidechain":false,"userType":"external","cwd":"/Users/skmabudalam/Documents/BugViper","sessionId":"b0273ced-89a6-4b81-89a4-eac94e094db0","version":"2.1.50","gitBranch":"main","slug":"resilient-yawning-lake","type":"system","subtype":"turn_duration","durationMs":329091,"timestamp":"2026-02-21T09:17:54.053Z","uuid":"7d617a75-ad75-4978-a69e-74c3201d5ee2","isMeta":false}
