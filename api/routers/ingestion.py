import logging
import os
import uuid
from datetime import datetime, timezone

from fastapi import APIRouter, Depends, HTTPException

from api.dependencies import get_neo4j_client, get_current_user
from api.models.schemas import (
    GitHubIngestRequest,
    IngestionJobResponse,
    JobStatusResponse,
)
from api.services.firebase_service import firebase_service
from common.github_client import GitHubClient

from ingestion_service.core.repo_ingestion_engine import AdvancedIngestionEngine
from api.services.cloud_tasks_service import CloudTasksService
from common.firebase_models import RepoIngestionError, RepoIngestionUpdate, RepoMetadata
from common.job_models import (
    IngestionJobStats,
    IngestionTaskPayload,
    JobStatus,
)
from common.job_tracker import JobTrackerService
from db import Neo4jClient

logger = logging.getLogger(__name__)

router = APIRouter()
cloud_tasks = CloudTasksService()
job_tracker = JobTrackerService()


@router.post("/github", response_model=IngestionJobResponse)
async def ingest_github_repository(
    request: GitHubIngestRequest,
    neo4j_client: Neo4jClient = Depends(get_neo4j_client),
    user: dict = Depends(get_current_user),
):
    """
    Start an ingestion job for a GitHub repository, record initial repo metadata, and return a job response describing the created or existing ingestion job.
    
    This endpoint:
    - Prevents duplicate active ingestions for the same owner/repo and returns the existing job if found.
    - Attempts to fetch GitHub repository metadata and stores an initial repository document with ingestion_status "pending".
    - In dev mode (env var "dev" == "true"): runs ingestion in-process, updates job status and repo metadata with ingestion stats on success, or records an error and raises on failure.
    - In production mode: creates a job record and dispatches a Cloud Task to perform ingestion; updates job status to DISPATCHED when the task is enqueued.
    
    Returns:
        IngestionJobResponse: object containing `job_id`, `status`, `message`, and `poll_url` describing the job and where to poll for status.
    
    Raises:
        HTTPException: with status 500 if dev-mode ingestion fails or if Cloud Task dispatch fails.
    """
    uid = user["uid"]

    # Prevent duplicate active jobs for the same repo
    existing = job_tracker.find_active_job(request.owner, request.repo_name)
    if existing:
        return IngestionJobResponse(
            job_id=existing.job_id,
            status=existing.status.value,
            message=f"Ingestion already in progress for {request.owner}/{request.repo_name}",
            poll_url=f"/api/v1/ingest/jobs/{existing.job_id}",
        )

    # ── Fetch GitHub repo metadata ─────────────────────────────────────────
    gh_meta: dict = {}
    try:
        gh = GitHubClient()
        gh_meta = await gh.get_repository_info(request.owner, request.repo_name)
    except Exception:
        logger.warning("Could not fetch GitHub metadata for %s/%s", request.owner, request.repo_name)

    # ── Write initial repo doc to Firestore (status: pending) ─────────────
    firebase_service.upsert_repo_metadata(
        uid,
        request.owner,
        request.repo_name,
        RepoMetadata(
            owner=request.owner,
            repo_name=request.repo_name,
            full_name=gh_meta.get("full_name", f"{request.owner}/{request.repo_name}"),
            description=gh_meta.get("description"),
            language=gh_meta.get("language"),
            stars=gh_meta.get("stars", 0),
            forks=gh_meta.get("forks", 0),
            private=gh_meta.get("private", False),
            default_branch=gh_meta.get("default_branch", request.branch or "main"),
            size=gh_meta.get("size", 0),
            topics=gh_meta.get("topics", []),
            github_created_at=gh_meta.get("created_at"),
            github_updated_at=gh_meta.get("updated_at"),
            branch=request.branch,
            ingestion_status="pending",
        ),
    )

    job_id = str(uuid.uuid4())
    payload = IngestionTaskPayload(
        job_id=job_id,
        owner=request.owner,
        repo_name=request.repo_name,
        branch=request.branch,
        clear_existing=request.clear_existing,
        uid=uid,
    )

    if os.getenv("dev") == "true":
        # Dev mode: run ingestion locally in-process
        job_tracker.create_job(payload)
        job_tracker.update_status(job_id, JobStatus.RUNNING)

        try:
            engine = AdvancedIngestionEngine(neo4j_client)
            engine.setup()

            stats = await engine.ingest_github_repository(
                owner=request.owner,
                repo_name=request.repo_name,
                branch=request.branch,
                clear_existing=request.clear_existing,
            )

            engine.close()

            job_stats = IngestionJobStats(
                files_processed=stats.files_processed,
                files_skipped=stats.files_skipped,
                classes_found=stats.classes_found,
                functions_found=stats.functions_found,
                imports_found=stats.imports_found,
                total_lines=stats.total_lines,
                errors=stats.errors or [],
            )
            job_tracker.update_status(job_id, JobStatus.COMPLETED, stats=job_stats)

            # ── Update Firestore with ingestion stats ──────────────────────
            firebase_service.upsert_repo_metadata(
                uid,
                request.owner,
                request.repo_name,
                RepoIngestionUpdate(
                    ingestion_status="ingested",
                    ingested_at=datetime.now(timezone.utc).isoformat(),
                    files_processed=stats.files_processed,
                    files_skipped=stats.files_skipped,
                    classes_found=stats.classes_found,
                    functions_found=stats.functions_found,
                    imports_found=stats.imports_found,
                    total_lines=stats.total_lines,
                ),
            )
            logger.info("Dev-mode ingestion completed for %s/%s", request.owner, request.repo_name)

        except Exception as exc:
            logger.exception("Dev-mode ingestion failed for %s/%s", request.owner, request.repo_name)
            job_tracker.update_status(
                job_id,
                JobStatus.FAILED,
                error_message=f"{type(exc).__name__}: {exc}",
            )
            firebase_service.upsert_repo_metadata(
                uid,
                request.owner,
                request.repo_name,
                RepoIngestionError(ingestion_status="failed", error_message=str(exc)),
            )
            raise HTTPException(status_code=500, detail=str(exc))

        return IngestionJobResponse(
            job_id=job_id,
            status=JobStatus.COMPLETED.value,
            message=f"Ingestion completed for {request.owner}/{request.repo_name} (dev mode)",
            poll_url=f"/api/v1/ingest/jobs/{job_id}",
        )

    else:
        # Create Firestore job record
        job_tracker.create_job(payload)

        # Dispatch to Cloud Tasks → ingestion service (uid is in payload for worker to use)
        task_name = cloud_tasks.dispatch_ingestion(payload)
        if task_name:
            job_tracker.update_status(
                job_id, JobStatus.DISPATCHED, cloud_task_name=task_name
            )
        else:
            job_tracker.update_status(
                job_id,
                JobStatus.FAILED,
                error_message="Failed to dispatch Cloud Task",
            )
            firebase_service.upsert_repo_metadata(
                uid,
                request.owner,
                request.repo_name,
                RepoIngestionError(
                    ingestion_status="failed",
                    error_message="Failed to dispatch Cloud Task",
                ),
            )
            raise HTTPException(status_code=500, detail="Failed to dispatch ingestion task")

        return IngestionJobResponse(
            job_id=job_id,
            status=JobStatus.PENDING.value,
            message=f"Ingestion queued for {request.owner}/{request.repo_name}",
            poll_url=f"/api/v1/ingest/jobs/{job_id}",
        )


@router.get("/jobs/{job_id}", response_model=JobStatusResponse)
async def get_job_status(job_id: str):
    job = job_tracker.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")
    return JobStatusResponse(
        job_id=job.job_id,
        owner=job.owner,
        repo_name=job.repo_name,
        branch=job.branch,
        status=job.status.value,
        created_at=job.created_at,
        updated_at=job.updated_at,
        started_at=job.started_at,
        completed_at=job.completed_at,
        stats=job.stats.model_dump() if job.stats else None,
        error_message=job.error_message,
    )


@router.get("/jobs", response_model=list[JobStatusResponse])
async def list_jobs(limit: int = 20):
    jobs = job_tracker.list_jobs(limit=limit)
    return [
        JobStatusResponse(
            job_id=j.job_id,
            owner=j.owner,
            repo_name=j.repo_name,
            branch=j.branch,
            status=j.status.value,
            created_at=j.created_at,
            updated_at=j.updated_at,
            started_at=j.started_at,
            completed_at=j.completed_at,
            stats=j.stats.model_dump() if j.stats else None,
            error_message=j.error_message,
        )
        for j in jobs
    ]